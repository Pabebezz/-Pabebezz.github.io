<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[常函数的运用]]></title>
    <url>%2Farticle%2Fe17bc1d7%2F</url>
    <content type="text"><![CDATA[统计一段词中出现次数最多的高频词（不区分大小写） 思路：用map存储每个词出现的频率（注意为什么不用unordered_map，因为若想实现“不区分大小写”的功能，就必须添加一个自定义比较器，unordered_map不支持这一选项），然后用priority_queue优先级队列的小顶堆特性找到高频词（TOPK问题转换为TOP1）。 （小顶堆求最大TOPK）堆（size = k）里存放的是当前元素的频率，其中堆顶的元素最小。加入新进来的元素，此时若size&gt;k，弹出堆顶元素，调整堆。【大顶堆求最小TOPK类似】 在写自定义比较器的过程中出现bug 错误 C3848 具有类型“const my_less”的表达式会丢失一些 const-volatile 限定符以调用“bool my_less::operator ()(const std::string &amp;,const std::string &amp;)” 解决方案：仿函数后 + const 变成常函数。 原因：重载()(string)不具备const属性（即使添加const属性），应防止调用过程中改变string的值，所以将函数变成常函数。 参考https://blog.csdn.net/weixin_42157432/article/details/108573062 https://blog.csdn.net/qq_37613319/article/details/104360043（也有说Visual Studio的编译器优化的问题 —- 具有指定 const volatile 类型的变量智能调用相同或更大的const volatile限定的成员函数） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;queue&gt;#include &lt;string&gt;#include &lt;map&gt;#include &lt;algorithm&gt;using namespace std;class cmp &#123;public: // 小顶堆(比较符号是&gt;,greater) 大顶堆(比较符号是&lt;,less) bool operator()(pair&lt;string, int&gt; &amp;a, pair&lt;string, int&gt; &amp;b) &#123; //频率相同 if (a.second == b.second) &#123; //字符序小的优先 return a.first &lt; b.first; &#125; return a.second &gt; b.second; &#125;&#125;;//自定义比较器：不区分字符串中的大小写struct my_less &#123; struct nocase_compare &#123; //仿函数 bool operator ()( const char &amp; c1, const char &amp; c2) const &#123; return tolower(c1) &lt; tolower(c2); &#125; &#125;; bool operator ()(const string &amp;s1, const string &amp;s2) const &#123; return lexicographical_compare(s1.begin(), s1.end(), s2.begin(), s2.end(), nocase_compare()); &#125;&#125;;int main() &#123; string str = "高兴 开心 高兴 ++ -- .. aa aA bbb aec aa Aa AA AA ac aA beds bbb cc sss bbb cc"; //getline(cin, str); map&lt;string, int, my_less&gt; count_map; priority_queue&lt;pair&lt;string, int&gt;, vector&lt;pair&lt;string, int&gt;&gt;, cmp&gt;count_sort; //cout &lt;&lt; str.length() &lt;&lt; endl; int begin = 0; for (int i = 0; i &lt; str.size(); i++) &#123; if (str[i] == ' ' || i == str.length()-1) &#123; if (i == str.length() - 1) i++; //substr(begin, num) 起始坐标与个数 string temp = str.substr(begin, i-begin); //需要添加一个不区分大小写的比较器 if (count_map.find(temp) != count_map.end() ) count_map[temp]++; else &#123; count_map.insert(&#123; temp, 1&#125;); &#125; begin = i+1; &#125; &#125; cout &lt;&lt; str &lt;&lt; endl &lt;&lt; endl; cout &lt;&lt; "频率统计：" &lt;&lt; endl; for (auto it : count_map) &#123; cout &lt;&lt; it.first &lt;&lt; " " &lt;&lt; it.second &lt;&lt; endl; &#125; cout &lt;&lt; endl; int k = 1; // k = 3; for (auto it = count_map.begin(); it != count_map.end(); it++) &#123; count_sort.push(*it); if (count_sort.size() &gt; k) &#123; count_sort.pop(); &#125; &#125; cout &lt;&lt; "第" &lt;&lt; k &lt;&lt; "高频率统计：" &lt;&lt; endl; while (!count_sort.empty()) &#123; cout &lt;&lt; count_sort.top().first &lt;&lt; " " &lt;&lt; count_sort.top().second &lt;&lt; endl; count_sort.pop(); &#125; return 0;&#125; 将k改为任意数，则解决TOPK问题。]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++ Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性表、顺序表、广义表（其表头表尾）]]></title>
    <url>%2Farticle%2F13827808%2F</url>
    <content type="text"><![CDATA[线性表n个具有相同特性的数据元素的有限序列,线性表中数据元素之间的关系是一对一的关系，即除了第一个和最后一个数据元素之外，其它数据元素都是首尾相接的（注意，这句话只适用大部分线性表，而不是全部) 特征:1．集合中必存在唯一的一个“第一元素”。 2．集合中必存在唯一的一个 “最后元素” 。 3．除最后一个元素之外，均有唯一的后继(后件)。 4．除第一个元素之外，均有唯一的前驱(前件)。 存储结构:线性表主要由顺序表示或链式表示。在实际应用中，常以栈、队列、字符串等特殊形式使用。 顺序表定义:采用顺序存储结构的线性表通常称为顺序表，如:数组。 顺序存储结构：一组地址连续的存储单元依次存储线性表中的各个元素使得线性表中在逻辑结构上相邻的数据元素存储在相邻的物理存储单元中 广义表定义:广义表是n(n≥0)个元素a1，a2，…，ai，…，an的有限序列。 长度：n ——– 最大括号中的元素（子广义表看作一个整体） 深度：嵌套的字表最多的嵌套次数 ——– 最里层括号到最外层括号的层数 注意点： （1）表头：当广义表LS非空时，称第一个元素为LS的表头； （2）表尾：称广义表LS中除去表头后其余元素组成的广义表为LS的表尾。 对任意一个非空的广义表，其表头可能是单元素，也可能是广义表。但是表尾一定是广义表！ eg:(a,(b,c),d) 这个广义表的长度为3,深度为2,表头是a, 表尾是(d) . eg:((x，(a，b))，((x，(a，b))，y)) 这个广义表的长度为2, 深度为4 eg：LS“（）”与LS“（ （ ） ）”不一样，前者为空表，后者为长度为 1 的表，可分解得到表头和表尾都是长度为 1 的空表。 123456789101112131415161718192021222324typedef struct CNode *GList;struct GNode&#123; int tag;//标志域：0表示节点是单元素，1表示节点是广义表； union&#123;//子表指针域Sublist与单元素数据域Data复用，即共用储存空间； ElementType Data;//Data是原子节点的值域 GList SubList; &#125;URegion; GList Next;//指向后继结点&#125;;ortypedef int Atomtype;typedef enum &#123; Atom, list &#125;Elenment;typedef struct Glnode &#123; Elenment tag;//公共部分用于区分原子节点与表结点 union &#123; Atomtype atom; struct &#123; struct Glnode *hp;//表结点指针域，tp表尾指针域 struct Glnode *tp; &#125;ptr; &#125;;&#125;; 补充：多重链表多重链表：链表中的节点可能同时隶属于多个链。(但包含两个指针域的链表不一定是多重链表，比如双向链表不是多重链表) eg: 十字链表来储存稀疏矩阵 只储存矩阵非0元素项 结点的数据域：行坐标Row、列坐标Col、数值Value 每个节点通过两个指针域，把同行、同列串起来 行指针（或称为右指针）Right 列指针（或称为向下指针）Down 参考文章https://blog.csdn.net/laizhuoyu/article/details/87905506 数据结构–线性表、广义表 广义表的表头和表尾是什么？]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么拷贝构造函数参数必须为引用？]]></title>
    <url>%2Farticle%2Fc13c7aad%2F</url>
    <content type="text"><![CDATA[今天朋友问我一个特别有意思的点，eg： 1234567891011121314151617181920212223242526class Person&#123;private: int m_age; int *m_height;public: //构造函数 Person(int a, int h) &#123; m_age = p.m_age; //堆区 m_height = new int(h); &#125; //拷贝构造函数 Person(const Person&amp; p) &#123; cout &lt;&lt; "拷贝构造函数!" &lt;&lt; endl; //如果不利用深拷贝在堆区创建新内存，会导致浅拷贝带来的重复释放堆区问题 m_age = p.m_age; //m_height = p.m_heigh (浅拷贝，系统默认拷贝构造函数) //m_height 是指针 m_height = new int(*p.m_height); &#125; &#125;;int main()&#123; Person p1(1,2); Person p2(p1);&#125; 无论是系统默认还是自定义的拷贝构造函数，都是传一个引用，而不是值，这是为什么呢？ naive的我想了想：节省一次值拷贝（赋值给形参）,节省空间? 当然不会那么简单。若拷贝构造函数参数为值传递，当实参赋值给形参时，又发生了一次拷贝函数的调用，无限递归下去，导致爆栈。 123456//拷贝构造函数变成这样 Person(const Person p); Person p2(p1); // 等价于p2(Person temp = p1),此时又调用一次拷贝构造函数(赋值引起)，变成 p2(Person temp(p1)) // p2(Person temp(p1)) 又等价于p2(Person temp(Person temp2 = p1),赋值引起拷贝，变成 p2(Person temp( Person temp2(p1)))... 这个例子还要注意一点：m_height开辟在堆区，利用赋值运算符 operator=进行类对象赋值时，因此不能只是做简单浅拷贝（防止析构时野指针的出现—-一个内存地址有两个指向的指针），因此需要自定义拷贝构造函数。 结论：拷贝构造函数参数为引用，不为值传递是为了防止拷贝构造函数的无限递归，最终导致栈溢出。 各种构造函数也是重载,编译器自动找寻合适的函数。 PS：没事多看看C++ Primer，讲的细又深刻。 名字查找优于类型查找，其本质是作用域]]></content>
      <categories>
        <category>C++</category>
      </categories>
      <tags>
        <tag>C++ Primer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打怪之旅-C++基础]]></title>
    <url>%2Farticle%2F23d2b7d5%2F</url>
    <content type="text"><![CDATA[小tips volatile volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素（操作系统、硬件、其它线程等）更改。所以使用 volatile 告诉编译器不应对这样的对象进行优化。 volatile 关键字声明的变量，每次访问时都必须从内存中取出值（没有被 volatile 修饰的变量，可能由于编译器的优化，从 CPU 寄存器中取值） const 可以是 volatile （如只读的状态寄存器） 指针可以是 volatile 常量:用于记录程序中不可更改的数据 宏常量(声明没有分号) 1# define name value const 修饰变量为常量 1const int a = 1; 标识符:不能是关键字,区分大小写,只由字母\数字\下划线组成,首字符不能为数字. VS越界,便%(范围); 1short a = 2^15 ; 会输出-2^15 ,因为short 的范围是[-2^15 , 2^15-1] sizeof 求数据类型占用内存大小 12默认情况下,只会显示6位小数float a = 3.1415926f //f是避免从double转换为float 转义字符:表示不能显示出来的ASCII字符 1\n \t(8个位置,水平制表符,对齐效果) \\(反斜杠) 取余\除 除数不能为0 , int/int = int, 小数不能做取模运算 C++中除了0, 均为真 (-2也是真哦) 在C++中 三目运算符返回若返回的是变量, 可继续赋值 1(a &gt; b ? a : b) = 100 //a,b中大的那个赋值为100 C++随机种子 1234567891011121314//随机数发生器----产生伪随机数字(是由小M多项式序列生成的，其中产生每个小序列都有一个初始值，即随机种子。（注意： 小M多项式序列的周期是65535，即每次利用一个随机种子生成的随机数的周期是65535，当你取得65535个随机数后它们又重复出现了。）)//线性同余法 是根据一个数（我们可以称它为种子）为基准以某个递推公式推算出来的一系列数，当这系列数很大的时候，就符合正态公布，从而相当于产生了随机数，但这不是真正的随机数，当计算机正常开机后，这个种子的值是定了的，除非你破坏了系统。所在头文件: stdlib.h （被包含于iostream中）int rand(void) //初始化随机数发生器, 设置rand()产生随机数时的随机数种子。参数seed必须是个整数，如果每次seed都设相同值，rand()所产生的随机数值每次就会一样。 缺省值为1void srand(unsigned int seed) //使用当前时钟作为随机数种子 //time函数可以获取当前的系统时间（但是获取的是秒数，是从1970年1月1日零时零分零秒到目前为止所经过的时间），ctime可以将其转化为常规的时间在c中的头文件为&lt;time.h&gt;,在c++中头文件为&lt;ctime&gt;原型为： time_t time（time_t * timer） (其中time_t是long int) char * ctime（const time_t *time） srand((unsigned int)time(NULL)); 线性同余方法线性同余方法（LCG）是一种产生伪随机数的方法。 它是根据递归公式：RandSeed = (A * RandSeed + B) % M 线性同余法最重要的是定义了三个整数，乘数 A、增量 B和模数 M，其中A, B, M是产生器设定的常数。 LCG的周期最大为 M，但大部分情况都会少于M。要令LCG达到最大周期，应符合以下条件： B,M互质； M的所有质因数都能整除A-1； 若M是4的倍数，A-1也是； A,B,N[0]都比M小； A,B是正整数。 goto无条件跳转 123goto flag;flag: ..... 1二维数组初始化: 数组[][列数] = &#123;a,b,c,...&#125; 函数的声明–告诉编译器函数名称及如何调用函数。函数的实际主体可以单独定义。 函数的声明可以多次，但是函数的定义只能有一次, 在.h头文件中写函数的声明,在.cpp源文件中写函数的定义 #include&lt;&gt; 和 #include””的区别 1234567#include&lt; file &gt;编译程序会先到 标准函数库 中找文件, 指示预处理程序到预定义的缺省路径下寻找文件。预定义的缺省路径通常是在INCLUDE环境变量中指定的. 一般用来包含标准头文件(例如stdio.h或stdlib.h)，因为这些头文件极少被修改，并且它们总是存放在编译程序的标准包含文件目录下。#include”file” 编译程序会先从 当前目录 中找文件,再到预定义的缺省路径下寻找文件. 一般用来包含非标准头文件，因为这些头文件一般存放在当前目录下，可以经常修改它们，并且要求编译程序总是使用这些头文件的最新版本。例：INCLUDE=C:\COMPILER\INCLUDE；S:\SOURCE\HEADERS；1, 如果用#include&lt;file &gt;语句包含文件，编译程序将首先到C:\COMPILER\INCLUDE目录下寻找文件；如果未找到，则到S:\SOURCE\HEADERS目录下继续寻找；如果还未找到，则到当前目录下继续寻找。2, 如果用#include“file”语句包含文件，编译程序将首先到当前目录下寻找文件；如果未找到，则到C:\COMPILER\INCLUDE目录下继续寻找；如果还未找到，则到S:\SOURCE\HEADERS目录下继续寻找。 在32位(编译环境)中,指针(无论什么类型int,char,double…)都占4个字节; 64位,则占8个字节. 在32位系统和64位系统(32,64指的是寄存器的位宽)下只有指针类型和长整型字节数有所差别，其余全部相同 空指针与野指针 空指针：指针变量指向内存中编号为0的空间,初始化指针变量 （悬挂指针）野指针：指针变量指向非法的内存空间 内存编号0 ~255为系统占用内存，不允许用户访问,空指针和野指针都不是我们申请的空间，因此不要访问。 const 修饰指针 123456指针和const出现的顺序常量指针const int *p = &amp;a; (*p 不能修改值) 关键是cons离(* / p ) 谁近指针常量 int * const p = &amp;a; (p 不能修改地址) 指针和数组 12345678910111213141516171819核心 优先级：()&gt;[]&gt;*主要看后面的两个字是什么（前面是修饰作用），因此指针数组是数组，而数组指针是指针。 //数组指针(也称行指针）-是指一个指向数组的指针,执行p+1时，p要跨过n个整型数据的长度。定义形式:int (*p)[n];eg:如要将二维数组赋给一指针，应这样赋值：int a[3][4];int (*p)[4]; //该语句是定义一个数组指针，指向含4个元素的一维数组。 p=a; //将该二维数组的首地址赋给p，也就是a[0]或&amp;a[0][0] p++; //该语句执行过后，也就是p=p+1;p跨过行a[0][]指向了行a[1][]//指针数组-是指一个数组里面装着指针，也即指针数组是一个数组；有n个指针类型的数组元素定义形式:int *p[n]； //a 和&amp;a 之间的区别&amp;a 是整个数组的首地址，a是数组首元素(单个字符)的首地址，其值相同但意义不同。报错如下, char (*p2)[5]=a;必须使用强制转换,如:char (*p2)[5]=(char (*)[5])a; 并且大小必须一致. 1234567891011121314151617181920指针变量与一个整数相加减并不是用指针变量里的地址直接加减这个整数。这个整数的单位不是byte 而是元素的个数; eg:struct Test&#123; int Num; char *pcName; short sDate; char cha[2]; short sBa[4];&#125;*p;假设p 的值为0x100000。如下表表达式的值分别为多少？ p + 0x1 = 0x___ ? //0x100000+sizof（Test）*0x1 (unsigned long)p + 0x1 = 0x___? //涉及到强制转换，将指针变量p 保存的值强制转换成无符号的长整型数。任何数值一旦被强制转换，其类型就改变了。所以这个表达式其实就是一个无符号的长整型数加上另一个整数。所以其值为：0x100001。 (unsigned int*)p + 0x1 = 0x___? //p 被强制转换成一个指向无符号整型的指针。所以其值为：0x100000+sizof（unsigned int）*0x1，等于0x100004 123456789&lt;&lt;C语言深度剖析&gt;&gt;陈正冲 著int main()&#123; int a[5]=&#123;1,2,3,4,5&#125;; int *ptr1=(int*)(&amp;a+1); int *ptr2=(int*)((int)a+1); printf("%x,%x",ptr1[-1],*ptr2); return 0;&#125; 这里讲的比较清楚: https://www.cnblogs.com/mq0036/p/3382732.html https://zhidao.baidu.com/question/521307615.html 大端模式与小端模式 1234567891011121314151617大端模式:高 位字节排放在内存的低 地址端，低位字节排放在内存的高地址端。小端模式:低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。 //大端小端没有谁优谁劣，各自优势便是对方劣势：小端模式 ：强制转换数据不需要调整字节内容，1、2、4字节的存储方式一样。大端模式 ：符号位的判定固定为第一个字节，容易判断正负。 int checkSystem()&#123; union check &#123; int i; char ch; &#125; c; c.i = 1; return (c.ch ==1);//如果当前系统为大端模式这个函数返回0；如果为小端模式，函数返回1。&#125; 结构体 struct 12345678910111213struct 结构体名 &#123; 结构体成员列表 &#125;；创建变量方式:1 struct student&#123; //成员列表 string name; int age; &#125;stu3; //结构体变量直接创建2 struct student stu1; //struct 关键字可以省略 .成员在初始化3 struct student stu2 = &#123; "李四",19 &#125;;student *p = &amp;stu1;p-&gt;name 共用体 union 同一时刻，共用体只存放一个被选中的成员，对不同成员的赋值会导致对其他成员重写（原来成员的值就不存在了）—因此可以用于判断大小端模式。 默认访问控制符为 public 可以含有构造函数、析构函数 不能含有引用类型的成员 不能继承自其他类，不能作为基类 不能含有虚函数 匿名 union 在定义所在作用域可直接访问 union 成员 匿名 union 不能包含 protected 成员或 private 成员 全局匿名联合必须是静态（static）的 #pragma once 指定该文件在编译源代码文件时仅由编译器包含（打开）一次。使用预处理宏定义#ifndef HEADER_H_ .....#define HEADER_H_来避免多次包含文件的内容的效果是一样的，但是需要键入的代码少，可减少错误率 对于内置类型而言，new仅仅是分配内存，除非后面显示加(),相当于调用它的构造函数，对于自定义类型而言，只要一调用new，那么编译器不仅仅给它分配内存，还调用它的默认构造函数初始化，即使后面没有加() 函数外定义则为全局变量，系统初始化为0；函数内定义则为局部变量，是随机值，局部变量需要初始化才能使用 宏宏定义可以实现类似于函数的功能，但是它终归不是函数，而宏定义中括弧中的“参数”也不是真的参数，在宏展开的时候对 “参数” 进行的是一对一的替换。 inline 内联函数程序在编译器编译的时候，编译器将程序中出现的内联函数的调用表达式用内联函数的函数体进行替换，而对于其他的函数，都是在运行时候才被替代。 特征 相当于把内联函数里面的内容写在调用内联函数处； 相当于不用执行进入函数的步骤，直接执行函数体； 相当于宏，却比宏多了类型检查，真正具有函数特性； 编译器一般不内联包含循环、递归、switch 等复杂操作的内联函数； 在类声明中定义的函数，除了虚函数的其他函数都会自动隐式地当成内联函数。 优点 内联函数同宏函数一样将在被调用处进行代码展开，省去了参数压栈、栈帧开辟与回收，结果返回等，从而提高程序运行速度。 内联函数相比宏函数来说，在代码展开时，会做安全检查或自动类型转换（同普通函数），而宏定义则不会。 在类中声明同时定义的成员函数，自动转化为内联函数，因此内联函数可以访问类的成员变量，宏定义则不能。 内联函数在运行时可调试，而宏定义不可以。 缺点 代码膨胀。内联是以代码膨胀（复制）为代价，消除函数调用带来的开销。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。 inline 函数无法随着函数库升级而升级。inline函数的改变需要重新编译，不像 non-inline 可以直接链接。是否内联，程序员不可控。内联函数只是对编译器的建议，是否对函数内联，决定权在于编译器。 虚函数（virtual）可以是内联函数（inline）吗？ 虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。内联是在编译器建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时（运行期）不可以内联。inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类（如 Base::who()），这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。 面试常见问题C++中static用法一、不考虑类，static的作用 改变全局变量的作用域（未加static前缀的全局变量都具有全局可见性，其他源文件也能访问。）—–以在不同的文件中定义同名函数和同名变量，而不用担心命名冲突。 static的第二作用是默认初始化为0。包括未初始化的全局静态变量和局部静态变量。另外未初始化的全局变量也具备之一属性，因为为初始化的全局变量与未初始化的静态变量存储在同一区域内（BSS，全局（静态）存储区，BSS的特点是在程序执行之前BSS会自动清0）。 保持局部变量内容的持久。函数内的局部变量，当调用时就存在，退出函数时就销毁，但静态局部变量虽然在函数内定义，但静态局部变量始终存在，也就是说它的生存期为整个源程序，其特点是只进行一次初始化且具有“记忆性”。注意一点就是其作用域仍与局部变量相同。 二、类中static的作用 表示属于一个类而不是属于此类的任何特定对象的变量和函数。 静态成员变量并不是创建类对象时被定义，这意味着不是有类的构造函数初始化。一般来说，static数据成员要在类定义体的外部定义，只能定义一次。一直存在于程序的整个生命周期。 静态成员函数由于不予任何的对象相关联，因此它不具有this指针。因而无法访问类对象的非静态成员函数，也无法访问静态成员函数，只能调用其余的静态成员函数与访问静态数据成员。另外，因为static成员不是任何对象的组成部分，所以static成员函数不能被声明为const， 也不能被声明为虚函数、volatile。 const能否用于重载（1）常成员函数和非常成员函数之间的重载 非常量对象也可以调用常成员函数，但是如果有重载的非常成员函数（与常函数类似）则会调用非常成员函数。 （2）const修饰函数形参时的重载（形参类型本质上不能相同，否则会出现重定义） 重载重写重定义的区别 重载overload：在同一个类中，函数名相同，参数列表不同，编译器会根据这些函数的不同参数列表，将同名的函数名称做修饰，从而生成一些不同名称的预处理函数，未体现多态。 重写override：也叫覆盖，子类重新定义父类中有相同名称相同参数的虚函数，主要是在继承关系中出现的，被重写的函数必须是virtual的，重写函数的访问修饰符可以不同，尽管virtual是private的，子类中重写函数改为public,protected也可以，体现了多态。 重定义redefining：也叫隐藏，子类重新定义父类中有相同名称的非虚函数，参数列表可以相同可以不同，会覆盖其父类的方法，未体现多态。 a. 如果派生类的函数和基类的函数同名，但是参数不同，此时，不管有无virtual，基类的函数被隐藏。 b. 如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有vitual关键字，此时，基类的函数被隐藏。（如果有virtual就成重写了） C++的多态性是通过虚函数来实现的。最常见的用法就是声明基类的指针，利用该指针指向任意一个子类对象，调用相应的虚函数，可以根据指向的子类的不同而实现不同的方法。 虚继承、虚函数 相同之处：都利用了虚指针（均占用类的存储空间）和虚表（均不占用类的存储空间） 不同之处： 虚继承 虚基类依旧存在继承类中，只占用存储空间 虚基类表存储的是虚基类相对直接继承类的偏移 虚函数 虚函数不占用存储空间 虚函数表存储的是虚函数地址 内存分配和管理malloc、calloc、realloc、alloca malloc：申请指定字节数的内存。申请到的内存中的初始值不确定。 calloc：为指定长度的对象，分配能容纳其指定个数的内存。申请到的内存的每一位（bit）都初始化为 0。 realloc：更改以前分配的内存长度（增加或减少）。当增加长度时，可能需将以前分配区的内容移到另一个足够大的区域，而新增区域内的初始值则不确定。 alloca：在栈上申请内存。程序在出栈的时候，会自动释放内存。但是需要注意的是，alloca 不具可移植性, 而且在没有传统堆栈的机器上很难实现。alloca 不宜使用在必须广泛移植的程序中。C99 中支持变长数组 (VLA)，可以用来替代 alloca。 malloc、free用于分配、释放内存 malloc、free 使用 申请内存，确认是否申请成功 12char *str = (char*) malloc(100);assert(str != nullptr); 释放内存后指针置空 12free(p); p = nullptr; new、delete new / new[] (申请时在数组对象的上面还多分配了 4 个字节用来保存数组的大小，但是最终返回的是对象数组的指针，而不是所有分配空间的起始地址。)：完成两件事，先底层调用 malloc 分配了内存，然后调用构造函数（创建对象）。 delete/delete[]：也完成两件事，先调用析构函数（清理资源），然后底层调用 free 释放空间。 new 在申请内存时会自动计算所需字节数，而 malloc 则需我们自己输入申请内存空间的字节数。 new、delete 使用 申请内存，确认是否申请成功 123456int main()&#123; T* t = new T(); // 先内存分配 ，再构造函数 delete t; // 先析构函数，再内存释放 return 0;&#125; 定位 new（placement new）允许我们向 new 传递额外的地址参数，从而在预先指定的内存区域创建对象。 1234new (place_address) typenew (place_address) type (initializers)new (place_address) type [size]new (place_address) type [size] &#123; braced initializer list &#125; place_address 是个指针 initializers 提供一个（可能为空的）以逗号分隔的初始值列表 智能指针头文件：#include &lt;memory&gt; 将基本类型指针封装为类对象指针（这个类肯定是个模板，以适应不同基本类型的需求），并在析构函数里编写delete语句删除指针指向的内存空间。 C++智能指针简单剖析 什么是智能指针？为什么要用智能指针？如何打破循环引用的问题？实现一个智能指针呗！对于资源管理有什么作用？ shared_ptr 创建智能更高的指针，跟踪引用特定对象的智能指针数。这称为引用计数。例如，赋值时，计数将加1，而指针过期时，计数将减1,。当减为0时才调用delete。这是shared_ptr采用的策略。 多个智能指针可以共享同一个对象，对象的最末一个拥有着有责任销毁对象，并清理与该对象相关的所有资源。 支持定制型删除器（custom deleter），可防范 Cross-DLL 问题（对象在动态链接库（DLL）中被 new 创建，却在另一个 DLL 内被 delete 销毁）、自动解除互斥锁 weak_ptrweak_ptr 允许你共享但不拥有某对象，一旦最末一个拥有该对象的智能指针失去了所有权，任何 weak_ptr 都会自动成空（empty）。因此，在 default 和 copy 构造函数之外，weak_ptr 只提供 “接受一个 shared_ptr” 的构造函数。该类型指针通常不单独使用（没有实际用处），只能和 shared_ptr 类型指针搭配使用。 可打破环状引用（cycles of references，两个其实已经没有被使用的对象彼此互指，使之看似还在 “被使用” 的状态）的问题 unique_ptrunique_ptr 是 C++11 才开始提供的类型，是一种在异常时可以帮助避免资源泄漏的智能指针。采用独占式拥有，意味着可以确保一个对象和其相应的资源同一时间只被一个 pointer 拥有。一旦拥有着被销毁或编程 empty，或开始拥有另一个对象，先前拥有的那个对象就会被销毁，其任何相应资源亦会被释放。 unique_ptr 用于取代 auto_ptr auto_ptr被 c++11 弃用，原因是缺乏语言特性如 “针对构造和赋值” 的 std::move 语义，以及其他瑕疵。避免潜在的内存崩溃问题。 auto_ptr 与 unique_ptr 比较 建立所有权（ownership）概念。对于特定的对象，只能有一个智能指针可拥有，这样只有拥有对象的智能指针的构造函数会删除该对象。然后让赋值操作转让所有权。这就是用于auto_ptr和uniqiie_ptr 的策略，但unique_ptr的策略更严格。 当所有权被更改后，再访问原指针（已变为空指针），此时auto_ptr在运行时才会崩溃，而使用unique_ptr，编译器会认为该语句非法，避免了原指针不再指向有效数据的问题。 auto_ptr 可以赋值拷贝，复制拷贝后所有权转移；unqiue_ptr 无拷贝赋值语义，但实现了move 语义； auto_ptr 对象不能管理数组（析构调用 delete），unique_ptr 可以管理数组（析构调用 delete[] ）； 强制类型转换运算符C++四种强制类型转换运算符 举例更容易理解 static_castc++ 的任何的隐式转换都是使用 static_cast 来实现 用于非多态类型的转换 不执行运行时类型检查（转换安全性不如 dynamic_cast） 通常用于转换数值数据类型（如 float -&gt; int） 可以在整个类层次结构中移动指针，子类转化为父类安全（向上转换），父类转化为子类不安全（因为子类可能有不在父类的字段或方法） 向上转换是一种隐式转换。 dynamic_cast 用于多态类型的转换 执行行运行时类型检查 只适用于指针或引用 对不明确的指针的转换将失败（返回 nullptr），但不引发异常 可以在整个类层次结构中移动指针，包括向上转换、向下转换 const_cast 用于删除 const、volatile 和 __unaligned 特性（如将 const int 类型转换为 int 类型 ） reinterpret_cast 用于位的简单重新解释 滥用 reinterpret_cast 运算符可能很容易带来风险。 除非所需转换本身是低级别的，否则应使用其他强制转换运算符之一。 允许将任何指针转换为任何其他指针类型（如 char* 到 int* 或 One_class* 到 Unrelated_class* 之类的转换，但其本身并不安全） 也允许将任何整数类型转换为任何指针类型以及反向转换。 reinterpret_cast 运算符不能丢掉 const、volatile 或 __unaligned 特性。 reinterpret_cast 的一个实际用途是在哈希函数中，即，通过让两个不同的值几乎不以相同的索引结尾的方式将值映射到索引。 bad_cast 由于强制转换为引用类型失败，dynamic_cast 运算符引发 bad_cast 异常。 B树 B+树 B*树以及红黑树关于B树 B+树 B*树以及红黑树的理解 B树、B+树、B*树、红黑树的区别 B树、B-树、B+树、B*树、 红黑树的图例 B树：二叉树，每个结点只存储一个关键字，等于则命中，小于走左结点，大于走右结点；（实际采用了平衡二叉搜索树AVL） ​ B-树：多路搜索树，每个结点存储M/2到M个关键字，非叶子结点存储指向关键字范围的子结点； 所有关键字在整颗树中出现，且只出现一次，非叶子结点可以命中； ​ B+树：在B-树基础上，为叶子结点增加链表指针，所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中； ​ B*树：在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3； B树，B+树：它们特点是一样的，是多路查找树，一般用于数据库系统中，因为它们分支多层数少，都知道磁盘IO是非常耗时的，而像大量数据存储在磁盘中所以我们要有效的减少磁盘IO次数避免磁盘频繁的查找。 B+树是B树的变种树，有n棵子树的节点中含有n个关键字，每个关键字不保存数据，只用来索引，数据都保存在叶子节点。是为文件系统而生的。 字节对齐​ 内存对齐计算方法： ​ (1)看变量所在偏移地址是否为变量大小的整数倍 ​ (2)看对齐后的总大小是否为最长变量的整数倍 （所有成员使用的对齐参数中最大的一个—若结构体S2包含结构体S1，max(S1最长变量，S2最长变量), 还有手动设定字节对齐数min(#pragma pack(n), S最长变量）。 类、结构体都只计算非静态成员变量 C++ 字节对齐的总结(原因和作用) 示例 为什么要进行字节对齐？ 某些平台只能在特定的地址处访问特定类型的数据; 最根本的原因是效率问题，字节对齐能提高存取数据的速度。 比如有的平台每次都是从偶地址处读取数据,对于一个int型的变量,若从偶地址单元处存放,则只需一个读取周期即可读取该变量，但是若从奇地址单元处存放，则需要2个读取周期读取该变量。 字节对齐的原则 数据成员对齐规则：结构体或联合体的数据成员，第一个数据成员放在 offset 为0的地方，以后每个数据成员存储的起始位置要从该成员大小或者成员的子成员大小（只要该成员有子成员，比如说是数组，结构体等）的整数倍开始（比如int在32位机为4字节,则要从4的整数倍地址开始存储）。 结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。(struct a里存有struct b,b里有char,int ,double等元素,那b应该从8的整数倍开始存储。) 收尾工作：结构体的总大小，也就是sizeof的结果，必须是其内部最大成员的整数倍，不足的要补齐。 内存分区模型C++程序在执行时，将内存大方向划分为4个区域 代码区：存放函数体的二进制代码，由操作系统进行管理的 全局区：存放全局变量和静态变量以及常量(const修饰的全局常量, 字符串常量 ) 栈区：由编译器自动分配释放, 存放函数的参数值,局部变量等 堆区：由程序员分配和释放,若程序员不释放,程序结束时由操作系统回收 内存四区意义：不同区域存放的数据，赋予不同的生命周期, 给我们更大的灵活编程 程序运行前​ 在程序编译后，生成了exe可执行程序，未执行该程序前分为两个区域 ​ 代码区： ​ 存放 CPU 执行的机器指令 ​ 代码区是共享的，共享的目的是对于频繁被执行的程序，只需要在内存中有一份代码即可 ​ 代码区是只读的，使其只读的原因是防止程序意外地修改了它的指令 ​ 全局区： ​ 全局变量和静态变量存放在此. ​ 全局区还包含了常量区, 字符串常量和其他常量( const修饰的全局常量)也存放在此. ​ ==该区域的数据在程序结束后由操作系统释放==. 程序运行后​ 栈区： ​ 由编译器自动分配释放, 存放函数的参数值,局部变量等 ​ 注意事项：不要返回局部变量的地址，栈区开辟的数据由编译器自动释放 ​ 堆区： ​ 由程序员分配释放,若程序员不释放,程序结束时由操作系统回收 ​ 在C++中主要利用new在堆区开辟内存(返回的是地址，一般用指针接收),delete释放内存. ​ 引用给变量起别名,指向同一块地址. 引用的本质在c++内部实现是一个指针常量. 引用必须初始化,初始化后，不可以更改地址(赋值不是更改) 引用只能绑定在已存在变量上，不能与字面值或某个表达式的计算结果绑定在一起 指针是解引用(按地址传递),引用参数产生的效果同按地址传递. 不要返回局部变量引用,因为局部变量生命周期结束后由编译器释放了. 函数做左值，那么必须返回引用,多用于链式操作p2.PersonAddPerson(p1).PersonAddPerson(p1).PersonAddPerson(p1); 常量引用(可以绑定常量)(相当于const即修饰指针又修饰常量) -&gt; 修饰形参,防止形参(eg:const int&amp; v)改变实参 函数参数默认参数 如果某个位置参数有默认值，那么从这个位置往后，从左向右，必须都要有默认值 声明与定义之中,只能有一个有默认参数 占位参数 12345678910//函数占位参数 ，占位参数也可以有默认参数void func(int a, int) &#123; cout &lt;&lt; "this is func" &lt;&lt; endl;&#125;int main() &#123; func(10,10); //占位参数必须填补 system("pause"); return 0;&#125; # 函数重载 作用：函数名可以相同，提高复用性 函数重载满足条件： 同一个作用域下 函数名称相同 函数参数类型不同 或者 个数不同或者 顺序不同 注意: 函数的返回值不可以作为函数重载的条件 引用作为重载条件（若传入常量时，需用常量引用const int &amp;a） 函数重载碰到函数默认参数（可能产生歧义，需要避免） 类和对象封装C++面向对象的三大特性为：封装、继承、多态 具有相同性质的对象(有许多属性和行为［术语：成员］)，我们可以抽象称为类 成员被访问的权限： 公共权限 public 类内可以访问 类外可以访问 保护权限 protected 类内可以访问 类外不可以访问 ［子类可以访问］ 私有权限 private 类内可以访问 类外不可以访问 ［子类不可以访问］ 在C++中 struct和class唯一的区别就在于 默认的访问权限不同 区别： struct 默认权限为公共 class 默认权限为私有 对象的初始化和清理构造函数和析构函数 构造函数类名(){}：主要作用在于创建对象时为对象的成员属性赋值，构造函数由编译器自动调用，无须手动调用。 析构函数~类名(){}：主要作用在于对象销毁前系统自动调用，执行一些清理工作。析构函数不可以有参数，因此不可以发生重载 编译器提供的构造函数和析构函数是空实现。 构造函数分类 按照参数分类分为 有参和无参构造 无参又称为默认构造函数 按照类型分类分为 普通构造和拷贝构造Person(const Person&amp; p){} ​ 调用方式：括号法＼显示法＼隐式转换法 注意： 调用无参构造函数不能加括号，如果加了编译器认为这是一个函数声明 不能利用 拷贝构造函数 初始化匿名对象 编译器认为是对象声明 12Person (p3)；//编译器会认为 Person (p3) = Person p3；重定义p3了． C++中拷贝构造函数调用时机通常有三种情况 使用一个已经创建完毕的对象来初始化一个新对象 值传递的方式给函数参数传值 以值方式返回局部对象（也就是新对象） 构造函数调用规则默认情况下，c++编译器至少给一个类添加3个函数，(4) 1．默认构造函数(无参，函数体为空) 2．默认析构函数(无参，函数体为空) 3．默认拷贝构造函数，对属性进行值拷贝 4．赋值运算符 operator=, 对属性进行值拷贝[易发生浅拷贝带来的重复释放堆区问题] 如果类中有属性指向堆区，默认拷贝构造函数＼做赋值操作时 会出现深浅拷贝问题 构造函数调用规则如下： 如果用户定义有参构造函数，c++不在提供默认无参构造，但是会提供默认拷贝构造 如果用户定义拷贝构造函数，c++不会再提供其他构造函数 当类中成员是其他类对象时，我们称该成员为 对象成员．构造的顺序是 ：先调用对象成员的构造，再调用本类构造；析构顺序与构造相反． 深拷贝与浅拷贝浅拷贝：简单的赋值拷贝操作（指向同一地址，易发生堆区内存重复释放） 深拷贝：在堆区重新申请空间，进行拷贝操作 如果属性有在堆区开辟的，一定要自己提供拷贝构造函数，防止浅拷贝带来的问题 123456789101112131415161718//拷贝构造函数 Person(const Person&amp; p) &#123; cout &lt;&lt; "拷贝构造函数!" &lt;&lt; endl; //如果不利用深拷贝在堆区创建新内存，会导致浅拷贝带来的重复释放堆区问题 m_age = p.m_age; //m_height = p.m_heigh (浅拷贝，系统默认拷贝构造函数) //m_height 是指针 m_height = new int(*p.m_height); &#125;//析构函数 ~Person() &#123; cout &lt;&lt; "析构函数!" &lt;&lt; endl; if (m_height != NULL) &#123; //如果用的浅拷贝，p1 p2的m_height指针指向堆区同一块地址 // p2析构后,p1的m_height就变成了悬挂指针（野指针） delete m_height; &#125; &#125; 静态成员静态成员就是在成员变量和成员函数前加上关键字static，称为静态成员 静态成员变量（相当于全局变量） 所有对象共享同一份数据 在编译阶段分配内存 类内声明，类外初始化 静态成员函数 所有对象共享同一个函数 静态成员函数只能访问静态成员变量（因为静态成员在编译阶段就已经分配好内存了，非静态成员变量只有在实例化后才分配内存；还有一种解释是非静态成员变量独属于一个对象，无法确定静态成员函数访问的哪个对象的非静态成员变量） C++对象模型和this指针空对象空对象占用内存空间为：１ 为了区分空对象在内存的位置（占位置），独一无二的内存地址 在C++中，类内的成员变量和成员函数分开存储 只有 非静态成员变量 才属于类的对象上,如果存在虚函数，则要加上虚函数（表）指针，所以空对象占用内存空间变更为４（８是６４位）． 1234567891011121314151617class Person &#123;public: Person() &#123; mA = 0; &#125; //非静态成员变量占对象空间 int mA; //静态成员变量不占对象空间 static int mB; //函数也不占对象空间，所有函数共享一个函数实例 void func() &#123; cout &lt;&lt; "mA:" &lt;&lt; this-&gt;mA &lt;&lt; endl; &#125; //静态成员函数也不占对象空间 static void sfunc() &#123; &#125;&#125;; this指针this指针指向 被调用的成员函数所属的 对象,this指针的本质是一个指针常量 this指针是隐含每一个非静态成员函数内的一种指针 this指针不需要定义，直接使用即可 this指针的用途： 当形参和成员变量同名时，可用this指针来区分 在类的非静态成员函数中返回对象本身，可使用return *this 12345678910111213Person(int age) &#123; //1、当形参和成员变量同名时，可用this指针来区分 this-&gt;age = age; &#125;//注意这里的引用操作（返回对象本体），链式编程 ［不加&amp; 会自动调用拷贝构造函数，此时返回值为p的拷贝体］ Person&amp; PersonAddPerson(Person p) &#123; this-&gt;age += p.age; //返回对象本身 this是指向p的指针， *this就是对象本体（p）． return *this; &#125; 空指针访问成员函数空指针（对象未实例化）可以调用成员函数,但是函数里访问非静态成员就会出错（因为没有分配内存） const修饰成员函数常函数： 成员函数后加const后我们称为这个函数为常函数 常函数内不可以修改成员属性 成员属性声明时加关键字mutable后，在常函数中依然可以修改 常对象： 声明对象前加const称该对象为常对象 常对象只能调用常函数 非常量对象也可以调用常成员函数，但是如果有重载的非常成员函数（与常函数类似）则会调用非常成员函数。 const能否用于重载： （1）常成员函数和非常成员函数之间的重载 （2）const修饰成员函数形参时的重载（形参类型本质上不能相同，否则会出现重定义） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Person &#123;public: Person() &#123; m_A = 0; m_B = 0; &#125; //this指针的本质是一个指针常量，指针的指向不可修改 //如果想让指针指向的值也不可以修改，需要声明常函数 //此时 this 相等于 const Person * const this; void ShowPerson() const &#123; this = NULL; //不能修改指针的指向 this-&gt;mA = 100; //this指针指向的对象的数据不可以修改的 //const修饰成员函数，表示指针指向的内存空间的数据不能修改，除了mutable修饰的变量 this-&gt;m_B = 100; &#125; void MyFunc() const &#123; //mA = 10000; &#125;public: int m_A; mutable int m_B; //可修改 可变的&#125;;//const修饰对象 常对象void test01() &#123; // Person person; const Person person; //常量对象 cout &lt;&lt; person.m_A &lt;&lt; endl; //person.mA = 100; //常对象不能修改成员变量的值,但是可以访问 person.m_B = 100; //但是常对象可以修改mutable修饰成员变量 //常对象访问成员函数 person.MyFunc(); //常对象不能调用const的函数&#125;int main() &#123; test01(); system("pause"); return 0;&#125; 友元让一个函数或者类A （写在类B内）访问另一个类B中私有成员 全局函数做友元 12345class Building&#123; //告诉编译器 goodGay全局函数 是 Building类的好朋友，可以访问类中的私有内容 friend void goodGay(Building * building);&#125; 类做友元 12345class Building&#123; //告诉编译器 goodGay类是Building类的好朋友，可以访问到Building类中私有内容 friend class goodGay;&#125; 成员函数做友元 12345class Building&#123; //告诉编译器 goodGay类中的visit成员函数 是Building好朋友，可以访问私有内容 friend void goodGay::visit();&#125; 运算符重载运算符重载概念：对已有的运算符重新进行定义，赋予其另一种功能，以适应不同的数据类型 对于内置的数据类型的表达式的的运算符是不可能改变的，不要滥用运算符重载（意义相同,+就是+） operator 关键字 加号运算符123456789//成员函数(放到类内)／全局函数（放到外面）实现 + 号运算符重载，可以发生函数重载（参数不同） Person operator+(const Person&amp; p) &#123; Person temp; temp.m_A = this-&gt;m_A + p.m_A; temp.m_B = this-&gt;m_B + p.m_B; return temp; &#125;Person p3 = p2 + p1; //相当于 p2.operaor+(p1) ［成员函数］Person p4 = p3 + 10; //相当于 operator+(p3,10) ［全局函数］ 左移运算符12345678910111213141516171819202122232425262728293031//成员函数 实现不了我们想要的左移效果#include &lt;iostream&gt;#include&lt;string&gt;using namespace std;class test &#123; int a; string b;public: test(int a,string b) &#123; this-&gt;a = a; this-&gt;b = b; &#125; ostream &amp;operator&lt;&lt;(ostream &amp;out) &#123; out &lt;&lt; this-&gt;a &lt;&lt; " " &lt;&lt; this-&gt;b &lt;&lt; endl; ; return out; &#125;&#125;;int main() &#123; test t(1, "mrs .zhang"); t &lt;&lt; cout&lt;&lt;endl;//这样才能正确的输出两个元素，颠覆了我们平时的调用习惯， //希望是cout&lt;&lt;t&lt;&lt;endl; &#125;//只能全局函数实现左移重载//ostream对象只能有一个 ,所以用引用ostream&amp; operator&lt;&lt;(ostream&amp; out, Person&amp; p) &#123; out &lt;&lt; "a:" &lt;&lt; p.m_A &lt;&lt; " b:" &lt;&lt; p.m_B; return out;&#125;//本质上 operate&lt;&lt;(out, p )cout &lt;&lt; p1 &lt;&lt; "hello world" &lt;&lt; endl; //链式编程 递增运算符123456789101112131415//前置++, 注意返回引用，方便链式操作（套娃） MyInteger&amp; operator++() &#123; //先++ m_Num++; //再返回 return *this; &#125; //后置++ ，注意int[占位参数],用于区分前后置++ ; 而且不能返回局部变量temp的引用（地址），栈区开辟的数据由编译器自动释放，非法操作 MyInteger operator++(int) &#123; //先返回 MyInteger temp = *this; //记录当前本身的值，然后让本身的值加1，但是返回的是以前的值，达到先返回后++； m_Num++; return temp; &#125; 赋值运算符123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172//operator=必须是成员函数,因为要返回自身class Person&#123;public: Person(int age) &#123; //将年龄数据开辟到堆区 m_Age = new int(age); &#125; //重载赋值运算符 又是返回本身［引用］ Person&amp; operator=(Person &amp;p) &#123; //判断是否有本身属性在堆区，有就释放干净，再深拷贝（new） if (m_Age != NULL) &#123; delete m_Age; m_Age = NULL; &#125; //编译器提供的代码是浅拷贝 //m_Age = p.m_Age; //提供深拷贝 解决浅拷贝的问题 m_Age = new int(*p.m_Age); //返回自身 return *this; &#125; ~Person() &#123; //释放堆区 if (m_Age != NULL) &#123; delete m_Age; m_Age = NULL; &#125; &#125; //年龄的指针 int *m_Age;&#125;;void test01()&#123; Person p1(18); Person p2(20); Person p3(30); p3 = p2 = p1; //赋值操作 cout &lt;&lt; "p1的年龄为：" &lt;&lt; *p1.m_Age &lt;&lt; endl; cout &lt;&lt; "p2的年龄为：" &lt;&lt; *p2.m_Age &lt;&lt; endl; cout &lt;&lt; "p3的年龄为：" &lt;&lt; *p3.m_Age &lt;&lt; endl;&#125;int main() &#123; test01(); //int a = 10; //int b = 20; //int c = 30; //c = b = a; //cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; //cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl; //cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl; system("pause"); return 0;&#125; 关系运算符重载123456789101112//!= &gt;= &lt;=bool operator==(Person &amp; p) &#123; if (this-&gt;m_Name == p.m_Name &amp;&amp; this-&gt;m_Age == p.m_Age) &#123; return true; &#125; else &#123; return false; &#125; &#125; 函数调用运算符重载 函数调用运算符 () 也可以重载 由于重载后使用的方式非常像函数的调用，因此称为仿函数(用于STL) 仿函数没有固定写法，非常灵活 123456789101112//operator()必须是成员函数，如果是全局函数，便会有二义性void operator()(string text) &#123; cout &lt;&lt; text &lt;&lt; endl; &#125; int operator()(int v1, int v2) &#123; return v1 + v2; &#125;//匿名对象调用 ，该行运行完就被释放cout &lt;&lt; "MyAdd()(100,100) = " &lt;&lt; MyAdd()(100, 100) &lt;&lt; endl; 继承class 子类 : 继承方式 父类 eg:class A : public B; A 类称为子类 或 派生类 [父类的私有成员不能继承，提高访问权限] B 类称为父类 或 基类 父类中私有成员也是被子类继承下去了，只是由编译器给隐藏后访问不到 查看对象模型的工具－－－＇vs2017开发人员命令提示工具＇到.cpp文件的目录， cl /d1 reportSingleClassLayout查看的类名 所属文件名 构造和析构顺序and同名成员处理方式 继承中 先调用父类构造函数，再调用子类构造函数，析构顺序与构造相反 访问子类同名成员(静态＼非静态都一样) 直接访问即可,访问父类同名成员－需要加作用域 多继承语法C++允许一个类继承多个类 语法：class 子类 ：继承方式 父类1 ， 继承方式 父类2... 多继承可能会引发父类中有同名成员出现，需要加作用域区分 C++实际开发中不建议用多继承 菱形继承​ 两个派生类继承同一个基类 ​ 又有某个类同时继承者两个派生类 ​ 这种继承被称为菱形继承，或者钻石继承. 问题 －－ 利用虚继承解决： 羊继承了动物的数据，驼同样继承了动物的数据，当草泥马使用数据时，就会产生二义性。 草泥马继承自动物的数据继承了两份，其实我们应该清楚，这份数据我们只需要一份就可以。 123456789101112class Animal&#123;public: int m_Age;&#125;;//继承前加virtual关键字后，变为虚继承//此时公共的父类Animal称为虚基类class Sheep : virtual public Animal &#123;&#125;;class Tuo : virtual public Animal &#123;&#125;;class SheepTuo : public Sheep, public Tuo &#123;&#125;;//这样 SheepTuo所继承的age成员只有一份，避免二义性 底层实现－虚指针 多态多态的优点： 代码组织结构清晰 可读性强 利于前期和后期的扩展以及维护 类别多态分为两类 静态多态: 函数重载 和 运算符重载属于静态多态，复用函数名 动态多态: 派生类和虚函数实现运行时多态 静态多态和动态多态区别： 静态多态的函数地址早绑定 - 编译阶段确定函数地址 动态多态的函数地址晚绑定 - 运行阶段确定函数地址 动态多态动态多态满足条件： １，有继承关系 ２，派生类重写（函数返回值类型，函数名，参数列表完全相同）基类的虚函数 多态使用：父类指针或引用指向子类对象 原理分析 使用工具查看 cat没有重写speak()函数时，虚函数指针指向基类虚函数 重写后 开闭原则：对扩展进行开放，对修改进行关闭 C++开发提倡利用多态设计程序架构 纯虚函数和抽象类虚函数改写为纯虚函数 virtual 返回值类型 函数名 （参数列表）= 0 ; ＝０是说明符 当类中有了纯虚函数，这个类也称为抽象类 抽象类特点： 无法实例化抽象类对象 子类必须重写抽象类中的纯虚函数，否则也属于抽象类 虚析构和纯虚析构多态使用时，如果子类中有属性开辟到堆区，那么父类指针在释放时无法调用到子类的析构代码,导致内存泄漏． 解决方式：将父类中的析构函数改为虚析构或者纯虚析构 虚析构和纯虚析构共性： 可以解决父类指针释放子类对象 都需要有具体的函数实现［纯虚析构函数需要类内声明，类外实现］ 虚析构和纯虚析构区别： 如果是纯虚析构，该类属于抽象类，无法实例化对象 虚析构语法： virtual ~类名(){} 纯虚析构语法： virtual ~类名() = 0; 类名::~类名(){} 文件文件类型分为两种： 文本文件 - 文件以文本的ASCII码形式存储在计算机中 二进制文件 - 文件以文本的二进制形式存储在计算机中，用户一般不能直接读懂它们 操作文件的三大类: ofstream：写操作 ifstream： 读操作 fstream ： 读写操作 写文件步骤如下： 包含头文件 #include &lt;fstream> 创建流对象 ofstream ofs; 打开文件 ofs.open(“文件路径”,打开方式); 写数据 ofs &lt;&lt; “写入的数据”; 关闭文件 ofs.close(); 文件打开方式： 打开方式 解释 ios::in 为读文件而打开文件 ios::out 为写文件而打开文件 ios::ate 初始位置：文件尾 ios::app 追加方式写文件 ios::trunc 如果文件存在先删除，再创建 ios::binary 二进制方式 注意： 文件打开方式可以配合使用，利用|操作符 例如：用二进制方式写文件 ios::binary | ios:: out 读文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;fstream&gt;#include &lt;string&gt;void test01()&#123; ifstream ifs; ifs.open("test.txt", ios::in); if (!ifs.is_open()) &#123; cout &lt;&lt; "文件打开失败" &lt;&lt; endl; return; &#125; //第一种方式 字符数组 //char buf[1024] = &#123; 0 &#125;; //while (ifs &gt;&gt; buf) //&#123; // cout &lt;&lt; buf &lt;&lt; endl; //&#125; //第二种 //char buf[1024] = &#123; 0 &#125;; //while (ifs.getline(buf,sizeof(buf))) //&#123; // cout &lt;&lt; buf &lt;&lt; endl; //&#125; //第三种 //string buf; //while (getline(ifs, buf)) //&#123; // cout &lt;&lt; buf &lt;&lt; endl; //&#125; //不太推荐 char c; while ((c = ifs.get()) != EOF) &#123; cout &lt;&lt; c; &#125; ifs.close();&#125;int main() &#123; test01(); system("pause"); return 0;&#125; 二进制文件二进制方式写文件主要利用流对象调用成员函数write 函数原型 ：ostream&amp; write(const char * buffer,int len); 参数解释：字符指针buffer指向内存中一段存储空间。len是读写的字节数 1234567891011121314#include &lt;fstream&gt;//2、创建输出流对象ofstream ofs("person.txt", ios::out | ios::binary); //3、打开文件//ofs.open("person.txt", ios::out | ios::binary);Person p = &#123;"张三" , 18&#125;;//4、写文件ofs.write((const char *)&amp;p, sizeof(p));//5、关闭文件ofs.close(); 二进制方式读文件主要利用流对象调用成员函数read 函数原型：istream&amp; read(char *buffer,int len); 参数解释：字符指针buffer指向内存中一段存储空间。len是读写的字节数 12345678910#include &lt;fstream&gt; ifstream ifs("person.txt", ios::in | ios::binary); if (!ifs.is_open()) &#123; cout &lt;&lt; "文件打开失败" &lt;&lt; endl; &#125; Person p; ifs.read((char *)&amp;p, sizeof(p)); ofs.close(); 模板泛型编程 C++提供两种模板机制:函数模板和类模板 函数模板语法： 12template&lt;typename T&gt;函数声明或定义 解释： template — 声明创建模板 typename — 表面其后面的符号是一种数据类型，可以用class代替 T — 通用的数据类型，名称可以替换，通常为大写字母 总结： 函数模板利用关键字 template 使用函数模板有两种方式：自动类型推导、显示指定类型 模板的目的是为了提高复用性，将类型参数化 注意事项： 自动类型推导，必须推导出一致的数据类型T,才可以使用 模板必须要确定出T的数据类型，才可以使用 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//交换整型函数void swapInt(int&amp; a, int&amp; b) &#123; int temp = a; a = b; b = temp;&#125;//交换浮点型函数void swapDouble(double&amp; a, double&amp; b) &#123; double temp = a; a = b; b = temp;&#125;//利用模板提供通用的交换函数template&lt;typename T&gt; //typename 可以替换成classvoid mySwap(T&amp; a, T&amp; b)&#123; T temp = a; a = b; b = temp;&#125;void test01()&#123; int a = 10; int b = 20; //swapInt(a, b); //利用模板实现交换 //1、自动类型推导 mySwap(a, b); //2、显示指定类型 mySwap&lt;int&gt;(a, b); cout &lt;&lt; "a = " &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; "b = " &lt;&lt; b &lt;&lt; endl;&#125;int main() &#123; test01(); system("pause"); return 0;&#125; 普通函数与函数模板区别 普通函数调用时可以发生自动类型转换（隐式类型转换） 函数模板调用时，如果利用自动类型推导，不会发生隐式类型转换 如果利用显示指定类型的方式，可以发生隐式类型转换 调用规则 如果函数模板和普通函数都可以实现，优先调用普通函数 可以通过空模板参数列表来强制调用函数模板myPrint&lt;&gt;(a, b); //调用函数模板 函数模板也可以发生重载 如果函数模板可以产生更好的匹配,优先调用函数模板 既然提供了函数模板，最好就不要提供普通函数，否则容易出现二义性 局限性 模板的通用性并不是万能的 例如： 12345template&lt;class T&gt;void f(T a, T b)&#123; a = b; &#125; 在上述代码中提供的赋值操作，如果传入的a和b是一个数组，就无法实现了 再例如： 12345template&lt;class T&gt;void f(T a, T b)&#123; if(a &gt; b) &#123; ... &#125; &#125; 在上述代码中，如果T的数据类型传入的是像Person这样的自定义数据类型，也无法正常运行 因此C++为了解决这种问题，提供模板的重载，可以为这些特定的类型提供具体化的模板. 利用具体化的模板，可以解决自定义类型的通用化. 1234567891011121314eg：//具体化，显示具体化的原型和定义以template&lt;&gt;开头，并通过名称来指出类型//具体化优先于常规模板template&lt;&gt; bool myCompare(Person &amp;p1, Person &amp;p2)&#123; if ( p1.m_Name == p2.m_Name &amp;&amp; p1.m_Age == p2.m_Age) &#123; return true; &#125; else &#123; return false; &#125;&#125; 类模板语法： 12template&lt;typename T&gt; // template&lt;class T&gt;类 解释： template — 声明创建模板 typename — 表面其后面的符号是一种数据类型，可以用class代替 T — 通用的数据类型，名称可以替换，通常为大写字母 类模板与函数模板区别 类模板没有自动类型推导的使用方式 类模板在模板参数列表中可以有默认参数 类模板中成员函数创建时机类模板中成员函数和普通类中成员函数创建时机是有区别的： 普通类中的成员函数一开始(编译？？)就可以创建 类模板中的成员函数在调用时才创建（因为调用前不知道Ｔ是什么类） 类模板对象做函数参数一共有三种传入方式： 指定传入的类型 — 直接显示对象的数据类型 参数模板化 — 将对象中的参数变为模板进行传递 整个类模板化 — 将这个对象类型 模板化进行传递 123456789101112131415161718192021222324252627282930313233343536373839//1、指定传入的类型（最常用）void printPerson1(Person&lt;string, int&gt; &amp;p) &#123; p.showPerson();&#125;void test01()&#123; Person &lt;string, int &gt;p("孙悟空", 100); printPerson1(p);&#125;//2、参数模板化template &lt;class T1, class T2&gt;void printPerson2(Person&lt;T1, T2&gt;&amp;p)&#123; p.showPerson(); //查看此时模板的类型 cout &lt;&lt; "T1的类型为： " &lt;&lt; typeid(T1).name() &lt;&lt; endl; cout &lt;&lt; "T2的类型为： " &lt;&lt; typeid(T2).name() &lt;&lt; endl;&#125;void test02()&#123; Person &lt;string, int &gt;p("猪八戒", 90); printPerson2(p);&#125;//3、整个类模板化template&lt;class T&gt;void printPerson3(T &amp; p)&#123; cout &lt;&lt; "T的类型为： " &lt;&lt; typeid(T).name() &lt;&lt; endl; p.showPerson();&#125;void test03()&#123; Person &lt;string, int &gt;p("唐僧", 30); printPerson3(p);&#125; 类模板与继承当类模板碰到继承时，需要注意一下几点： 当子类继承的父类是一个类模板时，子类在声明的时候，要指定出父类中T的类型 如果不指定，编译器无法给子类分配内存 如果想灵活指定出父类中T的类型，子类也需变为类模板 类模板成员函数类外实现123456789101112131415161718192021222324252627#include &lt;string&gt;//类模板中成员函数类外实现template&lt;class T1, class T2&gt;class Person &#123;public: //成员函数类内声明 Person(T1 name, T2 age); void showPerson();public: T1 m_Name; T2 m_Age;&#125;;//构造函数 类外实现template&lt;class T1, class T2&gt;Person&lt;T1, T2&gt;::Person(T1 name, T2 age) &#123; this-&gt;m_Name = name; this-&gt;m_Age = age;&#125;//成员函数 类外实现template&lt;class T1, class T2&gt;void Person&lt;T1, T2&gt;::showPerson() &#123; cout &lt;&lt; "姓名: " &lt;&lt; this-&gt;m_Name &lt;&lt; " 年龄:" &lt;&lt; this-&gt;m_Age &lt;&lt; endl;&#125; 类模板分文件编写问题： 类模板中成员函数创建时机是在调用阶段，导致分文件编写时链接不到 解决： 解决方式1：直接包含.cpp源文件 解决方式2：将声明和实现写到同一个文件中，并更改后缀名为.hpp，hpp是约定的名称，并不是强制 类模板与友元全局函数类内实现 - 直接在类内声明友元即可 全局函数类外实现 - 需要提前让编译器知道全局函数的存在 STL函数对象函数对象概念 概念： 重载函数调用操作符的类，其对象常称为函数对象 函数对象使用重载的()时，行为类似函数调用，也叫仿函数 本质： 函数对象(仿函数)是一个类，不是一个函数 特点： 函数对象在使用时，可以像普通函数那样调用, 可以有参数，可以有返回值 函数对象超出普通函数的概念，函数对象可以有自己的状态 函数对象可以作为参数传递 谓词概念： 返回bool类型的仿函数称为谓词 如果operator()接受一个参数，那么叫做一元谓词 如果operator()接受两个参数，那么叫做二元谓词 内建函数对象内建函数对象意义概念： STL内建了一些函数对象 分类: 算术仿函数 关系仿函数 逻辑仿函数 用法： 这些仿函数所产生的对象，用法和一般函数完全相同 使用内建函数对象，需要引入头文件 #include&lt;functional&gt; 算术仿函数功能描述： 实现四则运算 其中negate是一元运算，其他都是二元运算 仿函数原型： template&lt;class T&gt; T plus&lt;T&gt; //加法仿函数 template&lt;class T&gt; T minus&lt;T&gt; //减法仿函数 template&lt;class T&gt; T multiplies&lt;T&gt; //乘法仿函数 template&lt;class T&gt; T divides&lt;T&gt; //除法仿函数 template&lt;class T&gt; T modulus&lt;T&gt; //取模仿函数 template&lt;class T&gt; T negate&lt;T&gt; //取反仿函数 关系仿函数功能描述： 实现关系对比 仿函数原型： template&lt;class T&gt; bool equal_to&lt;T&gt; //等于 template&lt;class T&gt; bool not_equal_to&lt;T&gt; //不等于 template&lt;class T&gt; bool greater&lt;T&gt; //大于 template&lt;class T&gt; bool greater_equal&lt;T&gt; //大于等于 template&lt;class T&gt; bool less&lt;T&gt; //小于 template&lt;class T&gt; bool less_equal&lt;T&gt; //小于等于 逻辑仿函数功能描述： 实现逻辑运算 函数原型： template&lt;class T&gt; bool logical_and&lt;T&gt; //逻辑与 template&lt;class T&gt; bool logical_or&lt;T&gt; //逻辑或 template&lt;class T&gt; bool logical_not&lt;T&gt; //逻辑非 容器STL基本概念C++的面向对象和泛型编程思想，目的就是复用性的提升 STL(Standard Template Library,标准模板库) STL 从广义上分为: 容器(container) 算法(algorithm) 迭代器(iterator) 容器和算法之间通过迭代器进行无缝连接。 STL 几乎所有的代码都采用了模板类或者模板函数 STL六大组件STL大体分为六大组件，分别是:容器、算法、迭代器、仿函数、适配器（配接器）、空间配置器 容器：各种数据结构，如vector、list、deque、set、map等,用来存放数据。 算法：各种常用的算法，如sort、find、copy、for_each等 迭代器：扮演了容器与算法之间的胶合剂。 仿函数：行为类似函数，可作为算法的某种策略。 适配器：一种用来修饰容器或者仿函数或迭代器接口的东西。 空间配置器：负责空间的配置与管理。 STL中容器、算法、迭代器容器：置物之所也 STL容器就是将运用最广泛的一些数据结构实现出来 常用的数据结构：数组, 链表,树, 栈, 队列, 集合, 映射表 等 这些容器分为序列式容器和关联式容器两种: ​ 序列式容器:强调值的排序，序列式容器中的每个元素均有固定的位置。​ 关联式容器:二叉树结构，各元素之间没有严格的物理上的顺序关系 算法：问题之解法也 有限的步骤，解决逻辑或数学上的问题，这一门学科我们叫做算法(Algorithms) 算法分为:质变算法和非质变算法。 质变算法：是指运算过程中会更改区间内的元素的内容。例如拷贝，替换，删除等等 非质变算法：是指运算过程中不会更改区间内的元素内容，例如查找、计数、遍历、寻找极值等等 迭代器：容器和算法之间粘合剂 提供一种方法，使之能够依序寻访某个容器所含的各个元素，而又无需暴露该容器的内部表示方式。 每个容器都有自己专属的迭代器 迭代器使用非常类似于指针，初学阶段我们可以先理解迭代器为指针 迭代器种类： 种类 功能 支持运算 输入迭代器 对数据的只读访问 只读，支持++、==、！= 输出迭代器 对数据的只写访问 只写，支持++ 前向迭代器 读写操作，并能向前推进迭代器 读写，支持++、==、！= 双向迭代器 读写操作，并能向前和向后操作 读写，支持++、–， 随机访问迭代器 读写操作，可以以跳跃的方式访问任意数据，功能最强的迭代器 读写，支持++、–、[n]、-n、&lt;、&lt;=、&gt;、&gt;= 常用的容器中迭代器种类为双向迭代器，和随机访问迭代器 手册cppreference[C++参考手册(已更新到20)]：https://en.cppreference.com/w/ LearnCpp[c++入门]:https://www.learncpp.com/ Cplusplus[论坛]:http://www.cplusplus.com/ TutorialsPoint[教程]:https://www.tutorialspoint.com/cplusplus/index.htm Awesome C++[资源列表]: https://github.com/fffaraz/awesome-cpp]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打怪之旅-计算机网络]]></title>
    <url>%2Farticle%2F6cc0fe42%2F</url>
    <content type="text"><![CDATA[术语ISP (Internet Service Provider) RFC (Request For Comments)因特网标准 ISOC因特网协会 实体：任何可发送或接受信息的硬件或软件进程 对等实体:收发双方相同层次中的实体 协议: 控制两个对等实体进行逻辑通信的规则集合（三要素：语法－定义所交换信息的格式；语义－定义收发双方所要完成的操作；同步－定义收发双方的时许关系） 服务：在协议的控制下，两个对等实体间的逻辑通信使得本层能够向上一层提供服务． 服务访问点：同一系统中相邻两层的实体交换信息的逻辑接口，用于区分不同的服务类型．（eg:数据链路层的点为帧的＂类型＂字段，网络层的点为IP数据报首部中的＂协议字段＂，运输层的点为＂端口号＂） 服务原语：上层使用下层所提供的服务，必须与下层交换的命令． PDU－协议数据单元：对等层次之间传送的数据包 SDU－服务数据单元：同一系统内，层与层之间交换的数据报 三种交换方式电路交换：电话交换机接通电话线的方式称为电路交换 通信之前首先要建立连接；连接建立好之后，就可以使用已建立好的连接进行数据传送；数据传送后，需释放连接，以归还之前建立连接所占用的通信线路资源。 一旦建立连接，中间的各结点交换机就是直通形式的，比特流可以直达终点； 报文交换：表示该消息的整块数据成为一个报文。报文交换中的交换结点也采用存储转发方式，但报文交换对报文的大小没有限制，这就要求交换结点需要较大的缓存空间。 可以随时发送报文，而不需要事先建立连接；整个报文先传送到相邻结点交换机，全部存储下来后进行查表转发，转发到下一个结点交换机。 整个报文需要在各结点交换机上进行存储转发，由于不限制报文大小，因此需要各结点交换机都具有较大的缓存空间。 分组交换：先把较长的报文划分成一个个更小的等长数据段，在每一个数据段前面。加上一些由必要的控制信息组成的首部后，就构成一个分组，也可简称为“包”，相应地，首部也可称为“包头”。 首部包含了分组的目的地址 分组从源主机到目的主机，可走不同的路径。 可以随时发送分组，而不需要事先建立连接。构成原始报文的一个个分组，依次在各结点交换机上存储转发。各结点交换机在发送分组的同时，还缓存接收到的分组。 构成原始报文的一个个分组，在各结点交换机上进行存储转发，相比报文交换，减少了转发时延，还可以避免过长的报文长时间占用链路，同时也有利于进行差错控制。 计算机网络的定义和分类定义 计算机网络的精确定义并未统一 计算机网络的最简单的定义是：一些互相连接的、自治的计算机的集合 互连：是指计算机之间可以通过有线或无线的方式进行数据通信； 自治：是指独立的计算机，他有自己的硬件和软件，可以单独运行使用； 集合：是指至少需要两台计算机； 计算机网络的较好的定义是：计算机网络主要是由一些通用的，可编程的硬件（一定包含有中央处理机CPU）互连而成的，而这些硬件并非专门用来实现某一特定目的（例如，传送数据或视频信号）。这些可编程的硬件能够用来传送多种不同类型的数据，并能支持广泛的和日益增长的应用 计算机网络所连接的硬件，并不限于一般的计算机，而是包括了智能手机等智能硬件。 计算机网络并非专门用来传送数据，而是能够支持很多种的应用（包括今后可能出现的各种应用）。 性能指标 速率(在大部分实际计算中估算) 带宽 吞吐量 表示单位时间内通过某个网络（或信道＼接口）的数据量，受网络带宽或额定速率的限制 时延 发送时延：主机或路由器发送数据帧所需要的时间，也就是从发送数据帧的第一个比特算起，到该帧的最后一个比特发送完毕所需的时间。 传播时延：电磁波在信道中传播一定的距离需要花费的时间。 处理时延：主机或路由器在收到分组时要花费一定时间进行处理 排队时延：分组在进过网络传输时，要经过许多路由器。但分组在进入路由器后要先在输入队列中排队等待处理。 这里将排队时延与处理时延合并成为处理时延． 网络时延应具体问题具体分析（当处理时延忽略不计时，发送时延 和 传播时延谁占主导，要具体情况具体分析） 时延带宽积 时延带宽积 = 传播时延 * 带宽 往返时间 RTT(Round-Trip Time) 双向交互一次所需时间 卫星链路耗时最长 利用率 利用率有信道利用率和网络利用率两种。 丢包率 分组丢失率，在一定时间范围内，传输过程中丢失分组的数量与总分组数量的比率． 计算机网络体系结构OSI(开放系统互连参考模型)失败原因：专家们缺乏实际经验，没有商业驱动力，研发周期过长；实现复杂，运行效率低；层次划分不合理，有些功能在多个层次中出现． 书上的体系结构综合了这两个的优点 TCP/IP体系结构核心是IP协议和TCP协议 分层的必要性：由大化局部，易于研究与处理 举例，通俗易懂 层 解决问题 设备 应用层 解决通过应用进程的交互来实现特定网络应用的问题 运输层 解决进程之间基于网络的通信问题（两台主机中进程之间的通信提供通用的数据传输服务。）－端口；出现误码\丢包 网络层 解决分组在多个网络上传输（路由）的问题－标识各网络以及各主机（共同编址－IP地址）；路由转发；路由选择 数据链路层 解决分组在一个网络（或一段链路）上传输的问题－标识网络中各主机（主机编址－MAC地址；从一串比特流中区分地址与数据；协同主机争用总线） 物理层 解决使用何种信号来传输比特的问题－用什么介质\接口\信号（传输媒体不属于物理层，也不属于任何一层） 物理层 双绞线绞合的作用：（１）抵御部分来自外界的电磁波干扰，（２）减少相邻导线的电磁干扰 传输方式 编码与调制曼彻斯特编码 （判断不会问，简单了解下，涉及到通信原理） 数据链路层链路是从一个结点到相邻结点的一段物理线路，数据链路则是在链路的基础上增加了一些必要的硬件（如网络适配器）和软件（如协议的实现） 网络中的主机、路由器等都必须实现数据链路层 以帧为单元传输和处理数据 CSMA/CD 载波监听多点接入/碰撞检测（以太网的媒体接入控制协议） 局域网属于数据链路层 封装成帧 封装成帧 (framing) 就是在一段数据的前后分别添加首部和尾部，然后就构成了一个帧。 首部和尾部的一个重要作用就是进行帧定界。 透明传输：数据链路层对上层交付的传输数据没有任何限制（这会出现协议数据单元包含标识字段，导致误判帧结束） 面向字符的物理链路 采取转义字符（长度１字节，十进制值27）添加在协议数据单元包含标识字段或转义字符前的操作避免该问题 面向比特的物理链路 使用比特填充的方式：每５个连续的１后面插入一个０ 最大传输单元（帧数据部分上限）MTU(Maximum Transfer Unit) 差错检测在传输过程中可能会产生比特差错：1 可能会变成 0， 而 0 也可能变成 1。 误码率（Bit Error Rate）: 在一段时间内，传输错误比特占所传输比特总数的比率 差错检测码（eg:FCS帧检测序列） 奇偶校验（数据链路层一般不会采用） 在待发送的数据后添加１位奇偶校验位，是整个数据（包括校验位）的＇１＇的个数为奇数（奇校验） 或 偶数（偶校验） 缺陷：奇数个误码，可以检测出；偶数个误码，则漏检 循环冗余校验CRC (Cyclic Redundancy Check) － 易于硬件实现，广泛应用于数据链路层 eg： 异或是不带进位的二进制加法 可靠传输接收方主机收到有误码的帧后，是不会接受该帧的，会将它丢弃 如果数据链路层向其上层提供的是不可靠服务，那么丢弃就丢弃了，不会再有更多措施 如果数据链路层向其上层提供的是可靠服务，那就还需要其他措施，来确保接收方主机还可以重新收到被丢弃的这个帧的正确副本（实现发送端发送什么，接收端就收到什么） 传输差错：比特差错（数据链路层） \ 分组丢失 \ 分组失序 \ 分组重复 实现机制（运用于各层） 停止等待协议 ＳＷ 回退Ｎ帧协议 ＧＢＮ 选择重传协议 ＳＲ 点对点协议 ppp( point-to-point protocol)点对点数据链路层协议特点是：简单；只检测差错，而不是纠正差错；不使用序号，也不进行流量控制；可同时支持多种网络层协议 提供不可靠传输服务 透明传输 面向字节的异步链路 面向比特的异步链路 工作状态 eg:宽带拨号 当用户拨号接入 ISP 时，路由器的调制解调器对拨号做出确认，并建立一条物理连接。 PC 机向路由器发送一系列的 LCP 分组（封装成多个 PPP 帧）。 这些分组及其响应选择一些 PPP 参数，并进行网络层配置，NCP 给新接入的 PC 机 分配一个临时的 IP 地址，使 PC 机成为因特网上的一个主机。 通信完毕时，NCP 释放网络层连接，收回原来分配出去的 IP 地址。接着，LCP 释放数据链路层连接。最后释放的是物理层的连接。 媒体接入控制（介质访问控制）MACMedium Access Control使用一对多的广播通信方式,共享信道：若多个设备在共享信道上同时发送数据，则会造成彼此干扰，导致发送失败。 需协调多个发送接受站点对一个共享传输媒体的占用 静态划分-重点掌握码分复用以及计算 频分多址 FDMA (Frequency Division Multiplex Access) 时分多址 TDMA(Time Division Multiplex Access) 码分多址 CDMA(Code Division Multiplex Access) CSMA/CD 载波监听多点接入/碰撞检测 Carrier Sense Multiple Access / Collision Detection 在总线型局域网中使用 工作原理: 为什么要进行碰撞检测？ 因为信号传播时延对载波监听产生了影响 CSMA/CD 协议的重要特性 使用 CSMA/CD 协议的以太网不能进行全双工通信而只能进行双向交替通信（半双工通信）。 每个站在发送数据之后的一小段时间内，存在着遭遇碰撞的可能性。 这种发送的不确定性使整个以太网的平均通信量远小于以太网的最高数据率。 CSMA/CA 载波监听多点接入/碰撞避免 Carrier Sense Multiple Access / Collision Avoidance 在无线局域网中使用 无线局域网不使用 碰撞检测的原因: 工作原理: 源站为什么在检测到信道空闲后还要再等待一段时间DIFS？ 考虑到可能有其他的站有高优先级的帧要发送。若有，就要让高优先级帧先发送 目的站为什么正确接收数据帧后还要等待一段时间SIFS才能发送ACK帧？ SIFS是最短的帧间间隔，用来分隔开属于一次对话的各帧，在这段时间内，一个站点应当能够从发送方式切换到接收方式 信道由忙转为空闲且经过DIFS时间后，还要退避一段随机时间才能使用信道？防止多个站点同时发送数据而产生碰撞 CSMA/CA协议的信道预约和虚拟载波监听 MAC地址\IP地址\ARP协议MAC地址(物理地址) 使用点对点信道的数据链路层不需要使用地址 使用广播信道的数据链路层必须使用地址来区分各主机 以太网的MAC子层(属于数据链路层)所使用的地址, 是对网络上各接口的唯一标识(eg:路由器的多个网络接口),而不是网络上各设备的唯一标识. MAC地址一般固化在网卡(网络适配器)的电可擦可编程只读存储器EEPROM中, aka 硬件地址\物理地址 随机MAC地址(防止监控电子设备的MAC地址跟踪人物行动) IP地址属于网络层 Internet上主机和路由器所使用的地址,标识网络编号(不同网络)以及主机编号(同一网络中不同主机) ARP协议地址解析协议 只能在一段链路或一个网络上使用,不能跨网络使用,只能逐段链路使用 ARP高速缓存表(IP地址与MAC地址对应关系不是永久性的) 集线器与交换机的区别以太网交换机实质上就是一个多接口的网桥,全双工,使得多对主机同时通信,无碰撞,不需要CSMA/CD协议 交换机:帧交换表,表中每条记录均有有效时间,原因:1交换机的接口改接了其他主机,2主机更换了网卡; 通过自学习算法建立该表. 生成树协议 广播域（broadcast domain）：指这样一部分网络，其中任何一台设备发出的广播通信都能被该部分网络中的所有其他设备所接收。 集线器是也可以看做多口中继器，每个端口都可以成为一个中继器，中继器是对减弱的信号进行放大和发送的设备.集线器的以太网在逻辑上仍是个总线网( 物理架构:双绞线的以太网采用星形拓扑)，需要使用CSMA/CD协议来协调各主机争用总线，只能工作在半双工模式，收发帧不能同时进行. 多台主机同时给另一台主机发送单播帧: 集线器以太网：会产生碰撞，遭遇碰撞的帧会传播到总线上的各主机 交换机以太网：会将它们缓存起来，然后逐个转发给目的主机，不会产生碰撞 广播帧,两者无区别. 虚拟局域网VLAN巨大的广播域的弊端: Virtual Local Area Network 将局域网内的设备划分成与物理位置无关的逻辑组(有共同的需求)的技术,避免巨大的广播域的出现. 在交换机上实现的，需要交换机能够实现以下功能 能够处理带有VLAN标记的帧——IEEE 802.1 Q帧 交换机的各端口可以支持不同的端口类型，不同端口类型的端口对帧的处理方式有所不同 端口类型:Access\Trunk\Hybrid(华为交换机私有) 各端口的缺省VLAN ID : 思科交换机(Native VLAN, 本征VLAN) ; 华为交换机(Port VLAN ID, 端口VLAN ID, 简称 PVID) PVID:端口的虚拟局域网ID VID:数据包的虚拟局域网ID 互连的Trunk端口的PVID值不相等,可能会出现转发错误的情况(到”重新贴标签”那一步) 网络层aka. 网际层 面向连接的虚电路 类似于电路交换，但只是在网络层逻辑上建立连接（虚电路VC-Virtual Circuit），若采用可靠传输的网络协议，则分组（走同一条路线）将无差错、按序到达、不丢失、不重复地到达接收方。 与无连接的数据包服务 不需要在网络层建立连接，分组可走不同路径，所传送的分组可能误码、丢失、重复、失序。将复杂的网络处理功能置于因特网的边缘（用户主机及其内部的运输层），将相对简单、尽最大努力的分组交付功能置于因特网核心。 IPv4地址IPv4地址是Internet 上的每一台主机（路由器）的每个接口分配一个在全世界范围内唯一的32位比特标识符。 点分十进制表示。除2取余，逆序输出（十进制转二进制） 分类编址的IPv4地址左起第一个十进制数值，可以判断网络类别（小于127的为A类（1个字节），128~191的为B类（2个字节），192~223的为C类（3个字节）。 不可以指派给主机或路由器接口： （1）A类网络号0和127 （2）主机号为”全0“， 网络地址 （3）主机号为”全1“ ，广播地址 一般不使用的IP地址 划分子网的IPv4地址子网也要给网络地址与广播地址 默认子网掩码：在未划分子网的情况下使用的子网掩码，网络号所在的位数全‘1’； 无分类编址的IPv4地址无分类域间路由选择CIDR（Classless Inter-Domain Rounting） 消除了ABC类地址、划分子网的概念 不需要区分网络地址、广播地址 变长的子网掩码（子网掩码长度根据子网所需地址[主机接口、路由接口、网络地址、广播地址]的数量而变化） 分配原则是：每个子块的起点位置不能随意选取，只能选取块大小的整数倍地址作为起点。大的子块先分配 IP数据报的发送和转发过程路由器在网络层（VLAN在交换机上实现，数据链路层），隔离冲突域，又隔离广播域 网桥、交换机(多接口网桥) 在数据链路层，隔离冲突域，不隔离广播域 中继器和集线器(多接口中继器) 在物理层，不隔离冲突域，不隔离广播域 路由选择协议”网关“便是”路由“ 路由器是一种具有多个输入端口，和输出端口的专用计算机，其任务是转发分组。结构如下： 路由条目（路由表的表项）有直连网络、静态路由、动态路由（路由选择协议） 静态路由配置（人工配置）因配置错误、接口不存在或故障可能会产生路由环路 特殊的静态路由： 默认路由（目的网络为0.0.0.0， 地址掩码为0.0.0.0） 特定主机路由（目的网络为特定主机的IP地址，地址掩码为255.255.255.255） 黑洞路由（下一跳为null0） 常见的路由选择协议 RIP（内部网关协议）只与相邻的路由器交换信息 OSPF（内部网关协议） BGP（外部网关协议） 直接封装的报文所属协议： IPv4数据报格式 一个 IP 数据报由首部和数据两部分组成。 首部的前一部分是固定长度，共 20 字节，是所有 IP 数据报必须具有的。 注意首部长度、片偏移的单位量 ICMP（网际控制报文协议）架构IP网络时需要特别注意两点： 确认网络是否正常工作 遇到异常时进行问题诊断 ICMP的主要功能包括： 确认IP包是否成功送达目标地址 通知在发送过程当中IP包被废弃的具体原因 改善网络设置等 ICMP 不是高层协议（看起来好像是高层协议，因为 ICMP 报文是装在 IP 数据报中，作为其中的数据部分），而是 IP 层的协议 VPN(虚拟专用网)与 NAT（网络地址转换）VPN aka. IP隧道技术 专用地址（私有地址）只能用于本地地址，不能用于全球地址（私有地址只能用于一个机构的内部通信，而不能用于和因特网上的主机通信） 因特网中所有路由器对目的地址是私有地址的IP数据报一律不进行转发 本地地址与全球地址 本地地址——仅在机构内部使用的 IP 地址，可以由本机构自行分配，而不需要向互联网的管理机构申请。 全球地址——全球唯一的 IP 地址，必须向互联网的管理机构申请。 问题：在内部使用的本地地址就有可能和互联网中某个 IP 地址重合，这样就会出现地址的二义性问题。 使用私有地址的主机，如何才能与因特网上使用全球IP地址的主机进行通信？ 这需要在专用网络连接到因特网的路由器上安装NAT软件,专有NAT软件的路由器叫做NAT路由器.它至少有一个有效的外部全球IP地址,这样，所有使用私有地址的主机在和外界通信时，都要在NAT路由器上将其私有地址转换为全球IP地址 利用端口（运输层）解决一对多映射 总结： 运输层底层（物理层、数据链路层、网络层）共同解决主机之间的通信 端口：用于区分本计算机不同应用进程的标识符（区别于进程标识符PID-不同操作系统使用不同格式的PID） 任务：直接为通信两端主机中应用进程间的逻辑通信提供服务，“端到端”的通信就是进程之间的通信 发送方的复用和接收方的分用多个进程（这里一个端口表示一个进程） 利用一个运输层协议（或者称为运输层接口）发送数据称为 复用 多个进程（这里一个端口表示一个进程） 利用一个运输层协议（或者称为运输层接口）接收时叫做 分用。 应用层常用协议所使用的运输层熟知端口号 访问网页的过程 06:01UDP和TCP的对比UDP 和 TCP 是TCP/IP体系结构运输层中的两个重要协议 当运输层采用面向连接的 TCP 协议时，尽管下面的网络是不可靠的（网际层只提供尽最大努力服务），但这种逻辑通信信道就相当于一条全双工的可靠信道。两个套接字（Socket）之间建立连接。TCP会把应用进程交付下来的数据块看作是一连串无结构的字节流，TCP并不知道这些待传送的字节流的含义并将他们编号，并存储在自己发送缓存中，TCP会根据发送策略，提取一定量的字节构建TCP报文并发送。 接收方从所接受到的TCP报文段中，取出数据载荷部分并存储在接收缓存中；一方面将接收缓存中的一些字节交付给应用进程。【接收方收到的字节流必须和发送方应用进程发出的字节流完全一样】 当运输层采用无连接的 UDP 协议时，这种逻辑通信信道是一条不可靠信道，不需要套接字（Socket）。UDP对应用进程交下来的报文既不合并也不拆分，而是保留这些报文的边界。 TCP 传送的数据单位协议是 TCP 报文段(segment)。 UDP 传送的数据单位协议是 UDP 报文或用户数据报。 TCP的流量控制ACK TCP报文首部中的标志位：1这是一个确认报文段 ack TCP报文首部中的确认号字段， eg：取值201，表示序号201之前的数据已全部正确接收 rwnd TCP报文首部中的窗口字段， eg：取值300，表示接收窗口大小为300 TCP的拥塞控制拥塞：在某段时间内，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏。 网络资源：链路容量（带宽）、交换结点中的缓存和处理机等 网络拥塞往往是由许多因素引起的。例如： 点缓存的容量太小； 链路的容量不足； 处理机处理的速率太慢； 拥塞本身会进一步加剧拥塞； 拥塞控制的一般原理 拥塞控制的前提：网络能够承受现有的网络负荷。 实践证明，拥塞控制是很难设计的，因为它是一个动态问题。 分组的丢失是网络发生拥塞的征兆而不是原因。 在许多情况下，甚至正是拥塞控制本身成为引起网络性能恶化、甚至发生死锁的原因。 开环控制：事先考虑周全，力争避免拥塞 闭环控制：在发生拥塞后，采取措施控制，消除拥塞 监测网络的拥塞 主要指标有： 由于缺少缓存空间而被丢弃的分组的百分数； 平均队列长度； 超时重传的分组数； 平均分组时延； 分组时延的标准差，等等。 上述这些指标的上升都标志着拥塞的增长。 下面4种算法假定以下条件： 数据是单方向传送，而另一个方向只传送确认 接收方总是有足够大的缓存空间，而发送方发送窗口的大小由网络的拥塞程度所决定。 以最大报文段MSS的个数为讨论问题的单位，而不是以字节为单位 真正的发送窗口值 = Min (接收方窗口值，拥塞窗口值) 传输轮次： 发送方给接收方发送数据报文段后，接收方给发送方发发回相应的确认报文段 一个传输轮次所经历的时间其实就是往返时间，往返时间并非是恒定的数值 使用传输轮次是为了强调把拥塞窗口所允许发送的报文段都连续发送出去，并受到了对已发送的最后一个报文段的确认 拥塞窗口（cwnd）：它会随网络拥塞程度，以及所使用的拥塞控制算法动态变化 慢开始门限（ssthresh）：防止拥塞窗口增长过大引起网络拥塞。 慢开始 cwnd = 2^(n-1)(n=1,n++)慢开始是指一开始向网络注入的报文段少，并不是指cwnd的增长速度慢。 cwnd &gt; ssthresh时转为拥塞控制算法 拥塞避免 cwnd ++如果在发送过程中出现部分报文段丢失，这必然会造成发送方对这些丢失报文段的超时重传. 判断网络可能出现拥塞，进行以下工作： （1）慢开始门限更新为发生拥塞时cwnd的一半 （2）cwnd更新为1，并重新开始执行慢开始算法 快重传个别报文段的丢失，实际上并未发生拥塞，而拥塞避免算法误以为出现了拥塞，并进行之后一系列工作。这样降低了传输效率。 让发送方尽快进行重传，而不是等超时重传计时器超时再重传。 发送方一旦收到3个连续的重复确认，就将相应的报文段立即重传。 快恢复 ssthresh=cwnd/2；cwnd= ssthresh；cwnd++快重传后，执行快恢复算法： 方案一（用的比较多） — 慢开始门限、cwnd更新为发生拥塞时cwnd的一半，并开始执行拥塞避免算法。 方案二 — ssthresh为发生拥塞时cwnd的一半， cwnd = ssthresh+3（网络种不是堆积了报文段而是减少了3个报文段） eg: TCP超时重传的选择 TCP报文的首部格式 TCP的可靠传输 TCP的连接“三报文”握手 采用三报文握手，而不是二报文握手：主要是为了防止已失效的连接请求报文段突然又传送到了，因而产生错误。 一端(client)A发出去的第一个连接请求报文并没有丢失，而是因为某些未知的原因在某个网络节点上发生滞留，导致延迟到连接释放以后的某个时间才到达另一端(server)B。本来这是一个&gt; 早已失效的报文段，但是B收到此失效的报文之后，会误认为是A再次发出的一个新的连接请求，于是B端就向A又发出确认报文，表示同&gt; 意建立连接。如果不采用“三次握手”，那么只要B端发出确认报文就会认为新的连接已经建立了，但是A端并没有发出建立连接的请求，因此不会去向B端发送数据，B端没有收到数据就会一直等待，这样B端就会白白浪费掉很多资源。 所以并不多余，这是为了防止已失效的连接请求报文段突然又传送到了TCP服务器，因而导致错误 “四报文”挥手 TCP连接释放报文段首部中 终止位FIN和确认为ACK的值都被设置为1，表明这是一个TCP连接释放报文段，同时也对之前收到的报文段进行确认 序号seq字段的值设置为u，它等于TCP客户进程之前已传送过的数据的最后一个字节的序号加1 确认号ack字段的值设置为v，它等于TCP客户进程之前已收到的、数据的最后一个字节的序号加1 请注意：TCP规定终止位FIN等于1的报文段即使不携带数据，也要消耗掉一个序号 TCP服务器进程收到TCP连接释放报文段后，会发送一个普通的TCP确认报文段并进入关闭等待状态 普通的TCP确认报文段首部中 确认位ACK的值被设置为1，表明这是一个普通的TCP确认报文段 序号seq字段的值设置为v，它等于TCP服务器进程之前已传送过的数据的最后一个字节的序号加1，这也与之前收到的TCP连接释放报文段中的确认号匹配 确认号ack字段的值设置为u+1，这是对TCP连接释放报文段的确认 TCP服务器进程应该通知高层应用进程，TCP客户进程要断开与自己的TCP连接 此时，从TCP客户进程到TCP服务器进程这个方向的连接就释放了 这时的TCP连接属于半关闭状态，也就是TCP客户进程已经没有数据要发送了 但如果TCP服务器进程还有数据要发送，TCP客户进程仍要接收，也就是说从TCP服务器进程到TCP客户进程这个方向的连接并未关闭 TCP客户进程收到TCP确认报文段后就进入终止等待2状态，等待TCP服务器进程发出的TCP连接释放报文段 若使用TCP服务器进程的应用进程已经没有数据要发送了，应用进程就通知其TCP服务器进程释放连接 由于TCP连接释放是由TCP客户进程主动发起的，因此TCP服务器进程对TCP连接的释放称为被动关闭连接 TCP服务器进程发送TCP连接释放报文段并进入最后确认状态 该报文段首部中 终止位FIN和确认位ACK的值都被设置为1，表明这是一个TCP连接释放报文段，同时也对之前收到的报文段进行确认 序号seq字段的值为w，这是因为在半关闭状态下，TCP服务器进程可能又发送 确认号ack字段的值为u+1，这是对之前收到的TCP连接释放报文段的重复确认 TCP客户进程收到TCP连接释放报文段后，必须针对该报文段发送普通的TCP确认报文段，之后进入时间等待状态 该报文段首部中 确认为ACK的值被设置为1，表明这是一个普通的TCP确认报文段 序号seq字段的值设置为u+1，这是因为TCP客户进程之前发送的TCP连接释放报文段虽然不携带数据，但要消耗掉一个序号 确认号ack字段的值设置为w+1，这是对所收到的TCP连接释放报文段的确认 TCP服务器进程收到该报文段后就进入关闭状态，而TCP客户进程还要进过2MSL后才能进入关闭状态 问题一：TCP为什么要四次挥手，能三次吗？ 不能三次。 第二次挥手和第三次挥手不能合并在一起，这是因为第二次挥手后，服务器端可能还在传输数据，需要等待数据传输完毕后再进行第三次挥手。 问题二：TCP客户进程在发送完最后一个确认报文后，为什么不直接进入关闭状态？而是要进入时间等待状态？ 因为时间等待状态以及处于该状态2MSL时长，可以确保TCP服务器进程可以收到最后一个TCP确认报文段而进入关闭状态另外，TCP客户进程在发送完最后一个TCP确认报文段后，在经过2MSL时长，就可以使本次连接持续时间内所产生的所有报文段都从网络中消失，这样就可以使下一个新的TCP连接中，不会出现旧连接中的报文段。 TCP保活计时器的作用 TCP双方已经建立了连接，后来，TCP客户进程所在的主机突然出现了故障。 TCP服务器进程以后就不能再收到TCP客户进程发来的数据。因此，应当有措施使TCP服务器进程不要再白白等待下去。 应用层解决通过应用进程的交互来实现特定网络应用的问题 C/S （客户/服务器方式-服务集中型）与 P2P（对等方式-服务分散型） DHCP（动态主机配置协议）DHCP 使用客户-服务器方式，采用请求/应答方式工作。 DHCP 基于 UDP 工作（DHCP报文在运输层会被封装成为UDP用户数据报），DHCP 服务器运行在 67 号端口， DHCP客户运行在 68 号端口。 互联网广泛使用的动态主机配置协议 DHCP (Dynamic Host Configuration Protocol) 提供了即插即用连网 (plug-and-play networking) 的机制。 这种机制允许一台计算机加入新的网络和获取 IP 地址，而不用手工配置。 DHCP客户端将广播发送DHCP发现报文（DHCP DISCOVER） 事务ID DHCP客户端的MAC地址 封装该报文的IP数据报的源IP地址为0.0.0.0，这是因为主机目前还未分配到IP地址，因此使用该地址代替 目的IP地址为广播地址255.255.255.255，之所以广播发送，是因为主机现在并不知道网络中有哪几个DHCP服务器。它们的IP地址各是什么 DHCP服务器收到DHCP发现报文后，根据其中封装的DHCP客户端的MAC地址来查找自己的数据库，如果查到匹配信息，则使用这些配置信息来构建并发送DHCP提供报文，如果没有则采用默认配置信息来构建报文并发送 DHCP服务端将广播发送DHCP提供报文（DHCP OFFER） 事务ID：DHCP客户端会与之前DHCP发现报文的事务ID做对比，来判断该DHCP提供报文是否是自己的 配置信息： IP地址：DHCP服务器从自己的IP地址池中挑选待租用给主机的IP地址（使用ARP来确保所选IP地址未被网络中其他主机占用） 子网掩码 地址租期 默认网关 DNS服务器 源IP地址：发送DHCP提供报文的DHCP服务器的IP目的地址：因为目的主机还没分配到IP，所以使用广播地址 DHCP客户从中选择一个，一般选择先到的，并向所选择的DHCP服务器发送DHCP请求报文 DHCP客户端将广播发送DHCP请求报文（DHCP REQUEST） 事务ID DHCP客户端的MAC地址 接收的租约中的IP地址 提供此租约的DHCP服务器端的IP地址 源地址：0.0.0.0，因为此时DHCP客户才从多个DHCP服务器中挑选一个作为自己的DHCP服务器。它首先要征得该服务器的同意，之后才能正式使用向该DHCP服务器租用的IP地址 目的地址：广播地址，这样可以一次性向所有DHCP服务器发送DHCP请求报文，来告知它们是否请求它们作为自己的DHCP服务器。 DHCP确认报文 源地址：DHCP服务器1的IP地址 目的地址：广播地址 DHCP客户收到该报文后就可以使用租用的IP地址，在使用前还会进行ARP检测 DNS（域名系统）域名只是一个逻辑概念，不代表计算机所在的物理位置 FTP（文件传输协议）FTP服务器与客户端需要建立：控制连接与数据连接，均需要TCP连接。控制连接在整个会话期间保持打开状态，数据连接传输完毕后就关闭。 电子邮件邮件系统构成：用户代理、邮件服务器、电子邮件所需协议 用户代理：用户与电子邮件系统的接口（电子邮件客户端软件） 邮件发送协议：SMTP 邮件读取协议:POP3, IMAP 简单邮件传送协议SMTP（Simple Mail Transfer Protocol） POP3：邮局协议第三个版本，只能以下载并删除方式或下载并保留方式从邮件服务器下载到用户计算机。（不允许用户在邮件服务器是管理字节的邮件-分类、创建新文件夹等） IMAP：因特网邮件访问协议，是一个联机协议（在自己的计算机上就可以操控邮件服务器中的邮箱） SMTP TCP熟知端口号25；POP3 TCP熟知端口号110；IMAP TCP熟知端口号143； PS:基于万维网的电子邮件 万维网 万维网 WWW (World Wide Web) 并非某种特殊的计算机网络。万维网是一个大规模的、联机式的信息储藏所，运行在因特网上的一个分布式应用 万维网用链接的方法能非常方便地从互联网上的一个站点访问另一个站点，从而主动地按需获取丰富的信息。 这种访问方式称为“链接”。 万维网的工作方式 万维网以客户 - 服务器方式工作。 浏览器就是在用户计算机上的万维网客户程序。万维网文档所驻留的计算机则运行服务器程序，因此这个计算机也称为万维网服务器。 客户程序向服务器程序发出请求，服务器程序向客户程序送回客户所要的万维网文档。 在一个客户程序主窗口上显示出的万维网文档称为页面 (page)。 超文本传输协议HTTP（Hyper Transfer Protocol） 在万维网客户程序与万维网服务器程序之间进行交互所使用的协议 HTTP报文格式HTTP请求报文格式 HTTP响应报文格式 使用Cookie在服务器上记录用户信息 万维网缓存与代理服务器 原始服务器通常会为每个响应的对象设定一个修改时间字段和一个有效日期字段，若过期并且代理服务器的文档和原始服务器的文档一致，原始服务器则给代理服务器发送不包含实体主体的响应，若过期并且代理服务器的文档和原始服务器的文档不一致，原始服务器则给代理服务器发送封装有该文档的响应报文。 参考资源视频课 笔记]]></content>
      <categories>
        <category>Computer Operating</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打怪之旅-操作系统]]></title>
    <url>%2Farticle%2Fe0627a3a%2F</url>
    <content type="text"><![CDATA[所有网络协议也都是采用大端字节序的方式来传输数据的。所以有时我们把大端字节序方式称之为网络字节序。 操作系统（ Operating System，OS）是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织调度计算机的工作和资源的分配，以提供给用户和其他软件方便的接口和环境的程序集合。计算机操作系统是随着计算机研究和应用的发展逐步形成并发展起来的，它是计算机系统中最基本的系统软件。 操作系统提供的接口主要分为两类一类是命令接口，用户利用这些操作命令来组织和控制作业的执行；另一类是程序接口，编程人员可以使用它们来请求操作系统服务。（1）命令接口使用命令接口进行作业控制的主要方式有两种，即联机控制方式和脱机控制方式。按作业控制方式的不同，可以将命令接口分为联机命令接口和脱机命令接口联机命令接口又称交互式命令接口，适用于分时或实时系统的接口。它由一组键盘操作命令组成。用户通过控制台或终端输入操作命令，向系统提出各种服务要求。用户每输入完一条命令，控制权就转入操作系统的命令解释程序，然后由命令解释程序对输入的命令解释并执行，完成指定的功能。之后，控制权又转回到控制台或终端，此时用户又可以输入下一条命令.脱机命令接口又称批处理命令接口，即适用于批处理系统，它由一组作业控制命令（或称作业控制语句）组成。脱机用户不能直接干预作业的运行，应事先用相应的作业控制命令写成一份作业操作说明书，连同作业一起提交给系统。当系统调度到该作业时，由系统中的命令解释程序.对作业说明书上的命令或作业控制语句逐条解释执行，从而间接地控制作业的运行.联机命令接口可以理解为：“雇主”说一句话，“工人”做一件事，并做出反馈，这就强调了交互性。（2）程序接口程序接口由一组系统调用命令（简称系统调用，也称广义指令）组成。用户通过在程序中使用这些系统调用命令来请求操作系统为其提供服务。用户在程序中可以直接使用这组系统调用命令向系统提出各种服务要求，如使用各种外部设备，进行有关磁盘文件的操作，申请分配和回收内存以及其他各种控制要求 操作系统不允许用户直接操作各种硬件资源，因此用户程序只能通过系统调用的方式来请求内核为其服务，间接地使用各种资源(3)GUI图形用户界面（GUI）即图形接口，用户通过鼠标和键盘，在图形界面上单击或使用快捷键就能很方便地使用操作系统。有些系统提供了上述三种接口，但GUI最终是通过调用程序接口实现的，严格地说GUI图形接口不属于操作系统的一部分，但图形接口所调用的系统调用命令，属于操作系统的一部分. 操作系统的基本特征操作系统的基本特征包括并发、共享、虚拟和异步。 PS：并行：（同一时刻—一天内同一时间一起约会）； 并发（同一时间间隔—一天内不同时间段分别约会） 并发和共享是操作系统两个最基本的特征，这两者之间又是互为存在条件的：①资源共享是以程序的并发为条件的，若系统不允许程序并发执行，则自然不存在资源共享问题：②若系统不能对资源共享实施有效的管理，也必将影响到程序的并发执行，甚至根本无法并发执行。 并发并发是指两个或多个事件在同一时间间隔内发生。在多道程序环境下，一段时间内宏观上有多道程序在同时执行，而在每一时刻，单处理机环境下实际仅能有一道程序执行，故微观上这些程序还是在分时地交替执行。操作系统的并发性是通过分时得以实现的。虽然现在CPU很多都是多核的,但是程序有可能很多,所以并发还是很重要. 共享资源共享即共享，是指系统中的资源可供内存中多个并发执行的进程共同使用。共享可分为以下两种资源共享方式：（1）互斥共享方式系统中的某些资源，如打印机、磁带机，虽然它们可以提供给多个进程使用，但为使所打印或记录的结果不致造成混淆，应规定在一段时间内只允许一个进程访问该资源。为此，当进程A访问某资源时，必须先提出请求，如果此时该资源空闲，系统便可将之分配给进程A使用，此后若再有其他进程也要访问该资源时（只要A未用完）则必须等待。仅当进程A访问完并释放该资源后，才允许另一进程对该资源进行访问。我们把这种资源共享方式称为互斥式共享，而把在一段时间内只允许一个进程访问的资源称为临界资源或独占资源。计算机系统中的大多数物理设备，以及某些软件中所用的栈、变量和表格，都属于临界资源，它们都要求被互斥地共享（2）同时共享方式系统中还有另一类资源，允许在一段时间内由多个进程“同时”对它们进行访问。这里所谓的“同时”往往是宏观上的，而在微观上，这些进程可能是交替地对该资源进行访问，即“分时共享”,典型的可供多个进程“同时”访问的资源是磁盘设备，一些用重入码编写的文件也可以被“同时”共享，即若干个用户同时访问该文件. 要注意到，互斥共享，是因为一种资源在一段时间内（哪怕是一段很小的时间）只能满足一个请求，否则就会出现严重的问题（如打印机，第一行打印A文档的内容，第二行打印B文档的内容，你能想象是什么效果吗？）.而同时共享方式，通常要求，一个请求分几个时间片段间隔地完成的效果，与连续完成的效果相同 虚拟虚拟是指把一个物理上的实体变为若干个逻辑上的对应物。物理实体（前者）是实的，即实际存在的；而后者是虚的，是用户感觉上的事物。用于实现虚拟的技术，称为虚拟技术。在操作系统中利用了多种虚拟技术，分别用来实现虚拟处理器、虚拟内存和虚拟外部设备等。在虚拟处理器技术中，是通过多道程序设计技术，让多道程序并发执行的方法，来分时使用一个处理器的。此时，虽然只有一个处理器，但它能同时为多个用户服务，使每个终端用户都感觉有一个中央处理器（CPU）在专门为它服务。利用多道程序设计技术，把一个物理上的CPU虚拟为多个逻辑上的CPU，称为虚拟处理器类似地，可以通过虚拟存储器技术，将一台机器的物理存储器变为虚拟存储器，以便从逻辑上来扩充存储器的容量。当然，这时用户所感觉到的内存容量是虚的。我们把用户所感觉到的存储器（实际是不存在的）称为虚拟存储器。还可以通过虚拟设备技术，将一台物理I/O设备虚拟为多台逻辑上的I/O设备，并允许每个用户占用一台逻辑上的I/O设备，这样便可以使原来仅允许在一段时间内由一个用户访问的设备（即临界资源），变为在一段时间内允许多个用户同时访问的共享设备. 因此，操作系统的虚拟技术可归纳为：时分复用技术，如处理器的分时共享；空分复用技术，如虚拟存储器. 把CPU抽象成进程，把磁盘抽象成文件，把内存抽象成地址空间 异步在多道程序环境下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性（对于有限资源的占用与释放时间问题）. 运行机制与状态PSW（program status word）标识当前处理器处于什么状态：0用户态（目态）、1核心态（管态）]]></content>
      <categories>
        <category>Computer Operating</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打怪之旅-数据结构与算法]]></title>
    <url>%2Farticle%2F737c8fe7%2F</url>
    <content type="text"><![CDATA[刷题顺序： 数组 -&gt;字符串 -&gt;链表-&gt;二分查找-&gt;排序-&gt;哈希表-&gt; 栈-&gt;队列 -&gt;树 、递归、回溯 -&gt; 堆 根据这位作者（代码随想录）的刷题步骤 数据结构相关基础的数据结构：数组、字符串、树、堆、栈、队列、哈希表 数组数组是存放在连续内存空间上的相同类型数据的集合。 一维数组在内存空间的地址是连续的，而二维数组在内存中是存放各个一维数组的首地址的一维数组，再指向各个一维数组的连续内存地址。 题： 35. 搜索插入位置（二分） 27. 移除元素(同26. 删除排序数组中的重复项）双指针 209. 长度最小的子数组滑动窗口(类似于双指针) 59. 螺旋矩阵 II注意循环边界 链表链表节点的定义 1234567891011121314// 单链表struct ListNode &#123; int val; // 节点上存储的元素 ListNode *next; // 指向下一个节点的指针 ListNode(int x) : val(x), next(NULL) &#123;&#125; // 节点的构造函数&#125;;struct ListNode &#123; int val; ListNode *next; ListNode() : val(0), next(nullptr) &#123;&#125; ListNode(int x) : val(x), next(nullptr) &#123;&#125; ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125;&#125;; C++默认生成一个构造函数，但是这个构造函数不会初始化任何成员变化（在初始化的时候就不能直接给变量赋值）。在C++里最好是手动释放内存 题： 203. 移除链表元素(设置虚拟头节点，这样避免头节点的特殊处理~) 707. 设计链表（链表的增删查改） 206. 反转链表（改变指针的指向） 142. 环形链表 II（快慢指针） 有关于慢指针进入环的第一圈就一定会和快指针相遇的解释，也可这么理解:从慢指针进入环（环长为m）那一刻开始算，假设相遇时，慢指针走了x,快指针则为2x。x若大于等于m/2，那快指针一定遇上了慢指针。（也可以理解为物理里面的相对运动~~） 哈希表（牺牲空间换时间） 「一般来说哈希表都是用来快速判断一个元素是否出现集合里」。 对于哈希表，要知道「哈希函数」和「哈希碰撞」在哈希表中的作用. 哈希函数是把传入的key映射到符号表的索引上。 哈希碰撞处理有多个key映射到相同索引上时的情景，处理碰撞的普遍方式是拉链法（链表）和线性探测法（移动到空位）。 哈希法的数据结构 数组 set （集合） map(映射) C++ 红黑树是一种平衡二叉搜索树，所以key值是有序的，但key不可以修改，改动key值会导致整棵树的错乱，所以只能删除和增加。 使用集合来解决哈希问题的时候，优先使用unordered_set，因为它的查询和增删效率是最优的，如果需要集合是有序的，那么就用set，如果要求不仅有序还要有重复数据的话，那么就用multiset。 set 与 map 的异同： 均为关联式容器，有序的key 均以RBTree作为底层容器 。 但set所得元素的只有key没有value，value就是key ，不能通过迭代器来改变set的值；而map所有元素都是键+值存在 , map的键是不能修改的，但是其键对应的值是可以修改的. 题： 242. 有效的字母异位词数组哈希（比map空间消耗要少，因为map要维护红黑树或者符号表，而且还要做哈希函数的运算。） 349. 两个数组的交集set哈希 （set与vector的相互转换） 123vector&lt;int&gt; nums1// 无重复数的num1unordered_set&lt;int&gt; nums_set(nums1.begin(), nums1.end()); 无法使用数组来做哈希表了。 「主要因为如下两点：」 数组的大小是有限的，受到系统栈空间（不是数据结构的栈）的限制。 如果数组空间够大，但哈希值比较少、特别分散、跨度非常大，使用数组就造成空间的极大浪费。 202. 快乐数（所谓“无限循环”，unordered_set来判断一个数是否重复出现过） 1. 两数之和(利用map的key-value特性) 1unordered_map&lt;int, int&gt; map; 15. 三数之和18. 四数之和（15，18都有难度，和二数之和不太一样，双指针更好一些） 454. 四数相加 II（只需要求次数，而且可重复，因此~用map） 字符串字符串与数组的区别字符串是若干字符组成的有限序列，也可以理解为是一个字符数组. 在C语言中，把一个字符串存入一个数组时，也把结束符 ‘\0’存入数组，并以此作为该字符串是否结束的标志。 在C++中，提供一个string类，string类会提供 size接口，可以用来判断string类字符串是否结束，就不用’\0’来判断是否结束 vector&lt; char &gt; 和 string: 在基本操作上没有区别，但是 string提供更多的字符串处理的相关接口，例如string 重载了+，而vector却没有。 题： 344. 反转字符串541. 反转字符串 II剑指 Offer 05. 替换空格151. 翻转字符串里的单词(先整体反转，再局部反转) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950方法一:双指针+栈 时间复杂度 O(n),空间复杂度 O(n) // 思路： 先利用双指针将单词分割出来存入栈中，然后依次弹出 int len = s.size(); if(len &lt; 2) return s; stack&lt;string&gt; word; int slow = 0, fast = 0; // 用slow过空格 while(slow &lt; len)&#123; if( s[slow] != ' ')&#123; fast = slow; while(s[fast] != ' ' &amp;&amp; fast &lt; len) fast++; word.push(s.substr(slow,fast-slow)); slow = fast; &#125; slow++; &#125; // 用fast去过空格 // // 去除开头的空格 // while(s[slow] == ' ') slow++; // fast = slow; // while(slow &lt; len)&#123; // // cout&lt;&lt;slow&lt;&lt;' '&lt;&lt;fast&lt;&lt;endl; // if (s[fast] == ' ' || fast == len)&#123; // // s.substr(a,b)是从a数到后面第b个 // // cout&lt;&lt;s.substr(slow,fast-slow)&lt;&lt;endl; // word.push(s.substr(slow,fast-slow)); // // cout&lt;&lt;slow&lt;&lt;' '&lt;&lt;fast&lt;&lt;endl; // // 去除单词之间的空格 // while(s[fast] == ' ') fast++; // slow = fast; // &#125; // else // fast++; // &#125; string result=""; while(!word.empty())&#123; result += word.top() + ' '; // cout&lt;&lt;word.top()&lt;&lt;endl; word.pop(); &#125; //删去最后一个空格 result.pop_back(); return result; 123456789101112131415161718192021方法二:流+栈 时间复杂度 O(n),空间复杂度 O(n) // istringstream是C++ 里面的一种输入输出控制类，istringstream类用于执行C++ 风格的串流的输入操作，istringstream对象可以绑定一行字符串，然后以空格为分隔符把该行分隔开来。 istringstream s_string(s); stack&lt;string&gt; word; string str; while(s_string &gt;&gt; str)&#123; word.push(str); word.push(" "); &#125; // 去掉最后一个空格. word.pop(); string result = ""; while( ! word.empty())&#123; result += word.top(); word.pop(); &#125; return result; 123456789101112131415161718192021222324252627282930313233343536373839404142434445方法三:// 时间复杂度 O(n),空间复杂度 O(1) // 双指针// 思路： 移除多余空格,再整个字符反转.最后反转每个单词 // 交换 void change(char&amp; a, char&amp; b)&#123; a ^= b; b ^= a; a ^= b; &#125; // 移除多余的空格（快慢指针） void removeExtraSpace(string&amp; s )&#123; int slow = 0, fast = 0; int len = s.size(); // 去除前面的空格 while(s[fast] == ' ' &amp;&amp; fast &lt; len) fast++; for(; fast &lt; len; fast++)&#123; // 去除单词之间多余的空格 if (fast &gt; 1 &amp;&amp; s[fast] == ' ' &amp;&amp; s[fast-1] == ' ') continue; else&#123; s[slow++] = s[fast]; &#125; &#125; removeExtraSpace(s); cout&lt;&lt;s&lt;&lt;endl; int len = s.size(); reverse(s,0,len-1); cout&lt;&lt;s&lt;&lt;endl; int start = 0, end = 0; for(;start &lt; len; start++)&#123; // cout&lt;&lt;start&lt;&lt;' '&lt;&lt;end&lt;&lt;endl; if(s[start] != ' ')&#123; end = start; while(s[end] != ' ' &amp;&amp; end &lt; len) end++; // cout&lt;&lt;start&lt;&lt;' '&lt;&lt;end&lt;&lt;endl; reverse(s,start,end-1); start = end; // end++; &#125; &#125; return s; 剑指 Offer 58 - II. 左旋转字符串（先局部反转再整体反转．） 123456789101112131415161718192021方法一：栈// 栈（时间复杂度Ｏ(n),空间复杂度Ｏ(ｎ)）class Solution &#123;public: string reverseLeftWords(string s, int n) &#123; int len = s.size(); stack&lt;string&gt; word; word.push(s.substr(0,n)); word.push(s.substr(n,len-n)); // cout&lt;&lt;s.substr(n,len-n)&lt;&lt;s.substr(0,n); string str; while(! word.empty())&#123; str += word.top(); word.pop(); &#125; return str; &#125;&#125;; 123456789101112131415161718192021222324252627282930313233343536373839方法二：// 局部反转＋整体反转（时间复杂度Ｏ(n),空间复杂度Ｏ(1)）class Solution &#123;public: // 交换 void change(char&amp; a, char &amp;b)&#123; a ^= b; b ^= a; a ^= b; &#125; // 反转区间在［start, end］ void reverse(string&amp; s, int start, int end)&#123; for (int i = start, j = end; i &lt; j; i++, j--)&#123; change(s[i], s[j]); &#125; &#125; string reverseLeftWords(string s, int n) &#123; int len = s.size(); reverse(s, 0, n-1); reverse(s, n, len-1); reverse(s, 0 ,len-1); return s; &#125;&#125;;或者用自带的库函数class Solution &#123; public: string reverseLeftWords(string s, int n) &#123; reverse(s.begin(), s.begin() + n); reverse(s.begin() + n, s.end()); reverse(s.begin(), s.end()); return s; &#125;&#125;; KMP算法时间O(m+n),空间O(m) 大佬讲解文章 对应视频 主要解决字符串匹配．重复子串问题 KMP的经典思想就是:「当出现字符串不匹配时，可以记录一部分之前已经匹配的文本内容，利用这些信息避免从头再去做匹配。」 核心：前缀表 （前缀包含首字母，不包含尾字母的子串；后缀则是不包含首字母，包含尾字母的子串）定义大体是这样: 设S为非空字符串。若字符串A=BS,则B是A的前缀子串；若A=SB,B是A的后缀子串。比如aabaa: 前缀 后缀 a a aa aa aab baa aaba abaa 「前缀表是用来回溯的，它记录了模式串与主串(文本串)不匹配的时候，模式串应该从哪里开始重新匹配。」 前缀表的任务是当前位置匹配失败，找到之前已经匹配上的位置，在重新匹配，此也意味着在某个字符失配时，前缀表会告诉你下一步匹配中，模式串应该跳到哪个位置。 寻找最长相等前后缀（前缀表存放的值） i 后缀末尾， j前缀末尾； j也代表了ｉ包括ｉ之前子串的最长相等前后缀． 28. 实现 strStr()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Solution &#123;public: // 生成前缀表 void getNext(int *next, const string&amp; s)&#123; // 前缀表的值均减１ int j = -1, len = s.size(); next[0] = -1; // 求下一个i for(int i = 1; i &lt; len; i++)&#123; // 前后缀不相同,回退到之前相同的地方 while (j &gt; -1 &amp;&amp; s[j + 1] != s[i]) j = next[j]; // 前后缀相同,下移 if (s[j + 1] == s[i]) j++; // 将j（前缀的长度）赋给next[i] next[i] = j; &#125; &#125; int strStr(string haystack, string needle) &#123; int len = needle.size(); if (len == 0) return 0; // 得到needle的前缀表 int next[len]; getNext(next,needle); int j = -1; // 字符串匹配 for(int i = 0; i &lt; haystack.size(); i++)&#123; // 不匹配，j向前移 while(j &gt; -1 &amp;&amp; haystack[i] != needle[j + 1]) j = next[j]; // 匹配，j和i同时向后移动 if (haystack[i] == needle[j + 1]) j++; // 如果j到了needle的末尾,则匹配成功 if (j == len-1) // 返回当前在文本串匹配模式串的位置i 减去 模式串的长度，就是文本串字符串中出现模式串的第一个位置 return (i-j); &#125; return -1; &#125;&#125;; 459. 重复的子字符串1234567891011121314151617181920212223242526272829303132333435363738394041// KMPclass Solution &#123;public: // 得到前缀表 void getNext(int* next, string &amp;s)&#123; // 整体减1 int j = -1; next[0] = j; for(int i = 1; i &lt; s.size(); i++)&#123; // 匹配不对,回到上次匹配的地方 while(j &gt; -1 &amp;&amp; s[i] != s[j+1]) j = next[j]; // 匹配则下移 if(s[i] == s[j+1]) j++; // 更新 next[i] = j; &#125; &#125; bool repeatedSubstringPattern(string s) &#123; int len = s.size(); int next[len]; getNext(next, s); int max_equal = next[len-1] + 1; // cout&lt;&lt; max_equal&lt;&lt;' '&lt;&lt;len; //重复子串的判断方式 if( max_equal != 0 &amp;&amp; len % (len - max_equal) == 0) return true; return false; // for(int i = 0; i &lt; len; i++) // cout&lt;&lt;next[i]+1&lt;&lt;' '; &#125;&#125;; 栈和队列（C++） C++中stack 是容器么？ 不是，是container adapter（容器适配器）【同队列】 我们使用的stack是属于那个版本的STL？ SGI STL 由Silicon Graphics Computer Systems公司参照HP STL实现，被Linux的C++编译器GCC所采用，SGI STL是开源软件，源码可读性甚高。 我们使用的STL中stack是如何实现的？ 栈的内部结构，栈的底层实现可以是vector，deque，list 都是可以的， 主要就是数组和链表的底层实现。 「栈是以底层容器完成其所有的工作，对外提供统一的接口，底层容器是可插拔的（也就是说我们可以控制使用哪种容器来实现栈的功能）。」 「我们常用的SGI STL，如果没有指定底层实现的话，默认是以deque为缺省情况下栈的低层结构。」deque是一个双向队列，只要封住一段，只开通另一端就可以实现栈的逻辑了。「SGI STL中 队列底层实现缺省情况下一样使用deque实现的。」 1std::stack&lt;int, std::vector&lt;int&gt; &gt; third; // 使用vector为底层容器的栈 1std::queue&lt;int, std::list&lt;int&gt;&gt; third; // 定义以list为底层容器的队列 stack 提供迭代器来遍历stack空间么？ 不允许有遍历行为，不提供 题: 232. 用栈实现队列225. 用队列实现栈(一个栈: 将队列头部的元素（除了最后一个元素外） 重新添加到队列尾部) 20. 有效的括号由于栈结构的特殊性，非常适合做对称匹配类的题目 1047. 删除字符串中的所有相邻重复项123456789101112131415161718192021222324252627282930// 原地操作class Solution &#123;public: string removeDuplicates(string S) &#123; int len = S.size(); if (len &lt; 2) return S; int slow = 0; // 这种也可以 // for(int i = 1; i &lt; len; i++)&#123; // if (slow &gt; -1 &amp;&amp; S[i] == S[slow]) // slow--; // else // S[++slow] = S[i]; // &#125; // S.resize(slow+1); for(int i = 0; i &lt; len; i++)&#123; // 试探移至下一位 if (slow &gt; 0 &amp;&amp; S[i] == S[slow - 1]) slow--; else S[slow++] = S[i]; &#125; S.resize(slow); return S; &#125;&#125;; 123456789101112131415161718// 字符串作栈class Solution &#123;public: string removeDuplicates(string S) &#123; int len = S.size(); if (len &lt; 2) return S; string result; for(int i = 0; i &lt; len; i++)&#123; if (result.empty() || S[i] != result.back()) result.push_back(S[i]); else result.pop_back(); &#125; return result; &#125;&#125;; 12345678910111213141516171819202122232425// 反向入栈class Solution &#123;public: string removeDuplicates(string S) &#123; int len = S.size(); if (len &lt; 2) return S; stack&lt;char&gt; st; // 从后面往前读 for(int i = len - 1; i &gt; -1; i--)&#123; if (st.empty() || S[i] != st.top()) st.push(S[i]); else st.pop(); &#125; string result; while( ! st.empty())&#123; result += st.top(); st.pop(); &#125; return result; &#125;&#125;; 150. 逆波兰表达式求值—有一点小问题在C++中是不能对字符串std::string使用switch/case语句的,把string 做一下hash处理,变成一个int数. 如何哈希 atoi 与 stoi的区别 相同点：①都是C++的字符处理函数，把数字字符串转换成int输出②头文件都是#include不同点：①atoi()的参数是 const char ,因此对于一个字符串str我们必须调用 c_str()的方法把这个string转换成 const char类型的,而stoi()的参数是const string,不需要转化为 const char； ②stoi()会做范围检查，默认范围是在int的范围内的，如果超出范围的话则会runtime error！而atoi()不会做范围检查，如果超出范围的话，超出上界，则输出上界，超出下界，则输出下界； 12345678910111213141516171819202122232425262728293031323334353637class Solution &#123;public: int evalRPN(vector&lt;string&gt;&amp; tokens) &#123; stack&lt;int&gt; st; unordered_map&lt;string,int&gt; mapStringValues; mapStringValues["+"] = 0; mapStringValues["-"] = 1; mapStringValues["*"] = 2; mapStringValues["/"] = 3; for (int i = 0; i &lt; tokens.size(); i++)&#123; if (tokens[i] == "+" || tokens[i] == "-" || tokens[i] == "*" || tokens[i] == "/") &#123; int a = st.top(); st.pop(); int b = st.top(); st.pop(); // if (tokens[i] == "+") st.push(a+b); // if (tokens[i] == "-") st.push(b-a); // if (tokens[i] == "*") st.push(a*b); // if (tokens[i] == "/") st.push(b/a); // // 把string 做一下hash处理,变成一个int数 switch(mapStringValues[tokens[i].data()])&#123; case 0: st.push(a+b); break; case 1: st.push(b-a); break; case 2: st.push(a*b); break; case 3: st.push(b/a); break; &#125; &#125; else //stoi将string 转换为 int // st.push(tokens[i]); st.push(stoi(tokens[i])); &#125; return st.top(); &#125;&#125;; 239. 滑动窗口最大值12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Solution &#123;private: // 单调队列(用双向队列来实现) class DecreaseQue&#123; // 只需要维护有可能成为窗口里最大值的元素就可以了，同时保证队列里的元素数值是由大到小的。 public: deque&lt;int&gt; que; void pop(int value)&#123; // 每次弹出的时候，比较当前要弹出的数值是否等于队列出口(前)元素的数值，如果相等则弹出。 // 相等就弹出 是 舍弃滑动窗口移动后前一位的值 if( ! que.empty() &amp;&amp; value == que.front()) que.pop_front(); &#125; void push(int value)&#123; // 压入比入口小的值 while( !que.empty() &amp;&amp; value &gt; que.back()) que.pop_back(); que.push_back(value); &#125; // 出口最大值 int front()&#123; return que.front(); &#125; &#125;;public: vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123; int len = nums.size(); if (len &lt; 2) return nums; DecreaseQue de; vector&lt;int&gt; result; for( int i = 0; i &lt; len; i++)&#123; if (i &lt; k) de.push(nums[i]); else&#123; de.pop(nums[i-k]); de.push(nums[i]); result.push_back(de.front()); &#125; // 保存第一个滑动窗口的值 if(i == k-1) result.push_back(de.front()); &#125; return result; &#125;&#125;; 347. 前 K 个高频元素—有一点小问题如何手写堆，优先队列.:https://leetcode-cn.com/problems/top-k-frequent-elements/solution/python-dui-pai-xu-by-xxinjiee/ 小顶堆，因为要统计最大前k个元素; 大顶堆，因为要统计最小前k个元素. 可以这么理解：（小顶堆求最大TOPK）堆（size = k）里存放的是当前元素的频率，其中堆顶的元素最小。加入新进来的元素，此时若size&gt;k，弹出堆顶元素，调整堆。【大顶堆求最小TOPK类似】 123456789101112131415161718192021222324//利用 multimapvector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123; unordered_map&lt;int, int&gt; cout_map; for(int i = 0; i &lt; nums.size(); i++)&#123; cout_map[nums[i]]++; &#125; // 降序排序 multimap&lt;int,int,greater&lt;int&gt;&gt; ordermap; for( auto num : cout_map)&#123; ordermap.insert(pair&lt;int, int&gt;(num.second, num.first)); &#125; // 输出 vector&lt;int&gt; result; for( auto num : ordermap)&#123; result.push_back(num.second); if(--k) break; &#125; return result; &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 优先级队列 「就是一个披着队列外衣的堆」，因为优先级队列对外接口只是从队头取元素，从队尾添加元素，再无其他取元素的方式，看起来就是一个队列。缺省情况下priority_queue利用max-heap（大顶堆）完成对元素的排序，这个大顶堆是以vector为表现形式的complete binary tree（完全二叉树）。//「堆是一颗完全二叉树，树中每个结点的值都不小于（或不大于）其左右孩子的值。」 如果父亲结点是大于等于左右孩子就是大顶堆，小于等于左右孩子就是小顶堆。而且优先级队列内部元素是自动依照元素的权值排列。//「所以我们要用小顶堆，因为要统计最大前k个元素，只有小顶堆每次将最小的元素弹出，最后小顶堆里积累的才是前k个最大元素。」// 小顶堆，因为要统计最大前k个元素; 大顶堆，因为要统计最小前k个元素.class Solution &#123;private: // 小顶堆 class mycomparison&#123; public: bool operator()(const pair&lt;int, int&gt;&amp; lhs, const pair&lt;int, int&gt; &amp;rhs)&#123; return lhs.second&gt; rhs.second; &#125; &#125;;public: vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123; unordered_map&lt;int, int&gt; cout_map; for(int i = 0; i &lt; nums.size(); i++)&#123; cout_map[nums[i]]++; &#125; // 小顶堆-优先队列 priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, mycomparison&gt; pri_que; for(unordered_map&lt;int, int&gt;::iterator it = cout_map.begin(); it != cout_map.end(); it++)&#123; pri_que.push(*it); if (pri_que.size() &gt; k)&#123; pri_que.pop(); &#125; &#125; // 输出,因为小顶堆先弹出的是最小的，所以倒叙来输出到数组 vector&lt;int&gt; result(k); for(int i = k - 1; i &gt; -1; i--)&#123; result[i] = pri_que.top().first; pri_que.pop(); &#125; return result; &#125;&#125;; NC119.最小的K个数大根堆：首先利用前k个数构建“大顶堆”，剩余元素依次与堆顶元素相比较。 如果大于堆顶元素，则不做处理 如果小于堆顶元素，则将堆顶元素与这个元素交换，然后再恢复堆序。 这样的话最后这个堆里面保存的就是最小的k个数（无序），可以通过。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 大顶堆 a[i]&lt; a[2i+1] a[i]&lt;a[2i+2] void swap(vector&lt;int&gt; &amp;a, int i, int j)&#123; a[i] ^= a[j]; a[j] ^= a[i]; a[i] ^= a[j]; &#125; void adjustHeap(vector&lt;int&gt; &amp;a, int i, int k)&#123; int curVal = a[i]; for(int kidIndex = 2*i+1; kidIndex &lt; k; kidIndex = 2*kidIndex+1)&#123; //比较 左右孩子 if(kidIndex+1 &lt; k &amp;&amp; a[kidIndex] &lt; a[kidIndex+1]) kidIndex++; if(a[kidIndex] &gt; curVal)&#123; a[i] = a[kidIndex]; i = kidIndex; &#125; else&#123; break; &#125; &#125; a[i] = curVal; &#125; void heapSort(vector&lt;int&gt; &amp;a, int k)&#123; // 创建k堆,从第一个非叶子节点 从下至上，右至左 for(int i = k/2-1; i &gt; -1; i--)&#123; adjustHeap(a, i, k); &#125; //剩余元素依次与堆顶比较 for(int i = k; i &lt; a.size(); i++)&#123; if(a[i] &lt; a[0])&#123; swap(a, 0, i); adjustHeap(a, 0, k); &#125; &#125; // //这一步若不要求K个排好序的，可以省去// //堆排序(交换堆顶与末尾元素，调整堆,逐渐将最大值沉到最后)// for(int i = k-1; i &gt; 0; i--)&#123;// swap(a, 0, i);// adjustHeap(a, 0, i);// &#125; &#125; vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k) &#123; int len = input.size(); if (len &lt;= 0 || len &lt; k || k &lt;= 0 ) return vector&lt;int&gt;(); heapSort(input, k); return vector&lt;int&gt;(input.begin(), input.begin()+k); &#125; NC88 寻找第K大12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 小顶堆 a[i]&gt; a[2i+1] a[i]&gt;a[2i+2] void swap(vector&lt;int&gt; &amp;a, int i, int j)&#123; a[i] ^= a[j]; a[j] ^= a[i]; a[i] ^= a[j]; &#125; void adjustHeap(vector&lt;int&gt; &amp;a, int i, int k)&#123; int curVal = a[i]; for(int kidIndex = 2*i+1; kidIndex &lt; k; kidIndex = 2*kidIndex+1)&#123; //比较 左右孩子 if(kidIndex+1 &lt; k &amp;&amp; a[kidIndex] &gt; a[kidIndex+1]) kidIndex++; if(a[kidIndex] &lt; curVal)&#123; a[i] = a[kidIndex]; i = kidIndex; &#125; else&#123; break; &#125; &#125; a[i] = curVal; &#125; void heapSort(vector&lt;int&gt; &amp;a, int k)&#123; // 创建k堆,从第一个非叶子节点 从下至上，右至左 for(int i = k/2-1; i &gt; -1; i--)&#123; adjustHeap(a, i, k); &#125; //剩余元素依次与堆顶比较 for(int i = k; i &lt; a.size(); i++)&#123; if(a[i] &gt; a[0])&#123; swap(a, 0, i); adjustHeap(a, 0, k); &#125; &#125; // //这一步若不要求K个排好序的，可以省去// //堆排序(交换堆顶与末尾元素，调整堆,逐渐将最小值沉到最后)// for(int i = k-1; i &gt; 0; i--)&#123;// swap(a, 0, i);// adjustHeap(a, 0, i);// &#125; &#125; int findKth(vector&lt;int&gt; a, int n, int K) &#123; heapSort(a, K); for(auto val : a)&#123; cout&lt;&lt;val&lt;&lt;" "; &#125;// 没有排好序 return a[0];// 排好序// return a[K-1]; &#125; NC97 出现次数的TopK问题12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;unordered_map&gt;class Solution &#123;public: /** * return topK string * @param strings string字符串vector strings * @param k int整型 the k * @return string字符串vector&lt;vector&lt;&gt;&gt; */ class cmp&#123; public: bool operator()(const pair&lt;string, int&gt; &amp;a, const pair&lt;string, int&gt; &amp;b)&#123; //频率相同 if (a.second == b.second) return a.first &lt; b.first; //频率不相同 return a.second &gt; b.second; &#125; &#125;; vector&lt;vector&lt;string&gt; &gt; topKstrings(vector&lt;string&gt;&amp; strings, int k) &#123; // write code here vector&lt;vector&lt;string&gt;&gt; res; unordered_map&lt;string, int&gt; mp; //统计频率 for(string str : strings) mp[str]++; //优先队列（小顶堆） priority_queue&lt;pair&lt;string, int&gt;, vector&lt;pair&lt;string, int&gt;&gt;, cmp&gt; pri_qe; for(unordered_map&lt;string, int&gt;::iterator it = mp.begin(); it != mp.end(); it++)&#123; pri_qe.push(*it); if (pri_qe.size() &gt; k)&#123; pri_qe.pop(); &#125; &#125; //由优先级从小到大依次取出 while(!pri_qe.empty()) &#123; //emplace_back 函数的作用是减少对象拷贝和构造次数，是C++11中的新特性，主要适用于对临时对象的赋值。 res.emplace_back(vector&lt;string&gt; &#123;pri_qe.top().first, to_string(pri_qe.top().second)&#125;); pri_qe.pop(); &#125; // 输出,因为小顶堆先弹出的是最小的，所以倒叙来输出到数组 reverse(res.begin(), res.end()); return res; &#125;&#125;; 二叉树二叉树的种类在我们解题过程中二叉树有两种主要的形式：满二叉树和完全二叉树。 满二叉树【国内定义】：如果一棵二叉树只有度为0的结点（叶子节点）和度为2的结点，并且度为0的结点在同一层上，则这棵二叉树为满二叉树。也可以说深度为k，有2^k-1个节点的二叉树。【国外定义：满二叉树就是没有度为1的节点】 完全二叉树: 在完全二叉树中，除了最底层节点可能没填满外，其余每层节点数都达到最大值，并且最下面一层的节点都集中在该层最左边的若干位置。若最底层为第 h 层，则该层包含 1~ 2h 个节点. 优先级队列其实是一个堆，堆就是一棵完全二叉树，同时保证父子节点的顺序关系。 二叉搜索树:二叉搜索树是有数值的了，「二叉搜索树是一个有序树」。 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树 平衡二叉搜索树:又被称为AVL（Adelson-Velsky and Landis）树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 「C++中map、set、multimap，multiset的底层实现都是平衡二叉搜索树」，所以map、set的增删操作时间时间复杂度是logn，注意我这里没有说unordered_map、unordered_set，unordered_map、unordered_map底层实现是哈希表,时间复杂度是o(1)。 二叉树的存储方式「二叉树可以链式存储(指针)，也可以顺序存储(数组)。」 「如果父节点的数组下表是i，那么它的左孩子就是i * 2 + 1，右孩子就是 i * 2 + 2。」 二叉树的遍历方式 深度优先遍历：先往深走，遇到叶子节点再往回走。 广度优先遍历：一层一层的去遍历。 「这两种遍历是图论中最基本的两种遍历方式」 深度优先遍历(前中后其实指的就是中间节点的遍历顺序) 前序遍历（递归法，迭代法） 中序遍历（递归法，迭代法） 后序遍历（递归法，迭代法） 栈其实就是递归的一种是实现结构，也就说前中后序遍历的逻辑其实都是可以借助栈使用非递归的方式来实现的。 广度优先遍历 层次遍历（迭代法） 一般使用队列来实现，这也是队列先进先出的特点所决定的，因为需要先进先出的结构，才能一层一层的来遍历二叉树。 123456struct TreeNode &#123; int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;&#125;; 二叉树的定义 二叉树节点的深度：指从根节点到该节点的最长简单路径边的条数。 二叉树节点的高度：指从该节点到叶子节点的最长简单路径边的条数。 求深度可以从上到下去查 所以需要前序遍历（中左右），而高度只能从下到上去查，所以只能后序遍历（左右中） 问题 平衡二叉搜索树是不是二叉搜索树和平衡二叉树的结合？ 是的，是二叉搜索树和平衡二叉树的结合。 平衡二叉树与完全二叉树的区别在于底层节点的位置？ 是的，完全二叉树底层必须是从左到右连续的，且次底层是满的。 堆是完全二叉树和排序的结合，而不是平衡二叉搜索树？ 堆是一棵完全二叉树，同时保证父节点一定&gt;=子节点的顺序关系（有序）。「完全二叉树一定是平衡二叉树，搜索树是中大于左小于右，堆不是平衡二叉搜索树」 递归三要素 「确定递归函数的参数和返回值：」确定哪些参数是递归的过程中需要处理的，那么就在递归函数里加上这个参数， 并且还要明确每次递归的返回值是什么进而确定递归函数的返回类型。 「确定终止条件：」写完了递归算法, 运行的时候，经常会遇到栈溢出的错误，就是没写终止条件或者终止条件写的不对，操作系统也是用一个栈的结构来保存每一层递归的信息，如果递归没有终止，操作系统的内存栈必然就会溢出。 「确定单层递归的逻辑：」确定每一层递归需要处理的信息。在这里也就会重复调用自己来实现递归的过程。 题: 144. 二叉树的前序遍历94. 二叉树的中序遍历145. 二叉树的后序遍历–Morris 遍历(面试几乎不会考)1234567891011121314151617181920递归版 //前序class Solution &#123;public: void treeVisit(TreeNode* node, vector&lt;int&gt;&amp; result)&#123; if (node == nullptr) return; result.push_back(node-&gt;val); treeVisit(node-&gt;left, result); treeVisit(node-&gt;right, result); &#125; vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; result; treeVisit(root, result); return result; &#125;&#125;; 只需要将treeVisit中节点顺序替换 //中序 //后序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227迭代版// 前序//前序遍历的顺序是中左右，先访问的元素是中间节点，要处理的元素也是中间节点，所以刚刚才能写出相对简洁的代码，「因为要访问的元素和要处理的元素顺序是一致的，都是中间节点。」 过程如下： 初始化栈，并将根节点入栈； 当栈不为空时： 弹出栈顶元素 node，并将值添加到结果中； 如果 node 的右子树非空，将右子树入栈； 如果 node 的左子树非空，将左子树入栈； // 关键点:前序入栈就输出. class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; result; stack&lt;TreeNode *&gt; st; // 根节点入栈 if (root != nullptr) st.push(root); // 遍历节点 while( ! st.empty())&#123; // 访问 TreeNode *node = st.top(); // 中 st.pop(); if(node != nullptr) // 处理 result.push_back(node-&gt;val); else continue; // 先进后出 st.push(node-&gt;right); // 右 st.push(node-&gt;left); //左 &#125; //或者这么写 // 根节点入栈 if (root) st.push(root); // 遍历节点 while( ! st.empty())&#123; // 访问 TreeNode *node = st.top(); st.pop(); if(node != nullptr) // 先放入中间节点,然后访问左节点,最后访问右节点 result.push_back(node-&gt;val); // 先进后出 if(node-&gt;right) st.push(node-&gt;right); if(node-&gt;left) st.push(node-&gt;left); &#125; return result; &#125;&#125;;// 思路二: 先遍历左孩子,到末尾后回退到右孩子,再找右孩子的左节点.class Solution &#123;public: vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; result; // 保存访问过的节点 stack&lt;TreeNode*&gt; st; // 用于访问节点(遍历) TreeNode* cur = root; while(cur != nullptr || ! st.empty())&#123; if (cur != nullptr)&#123; // 中 result.push_back(cur-&gt;val); st.push(cur); //左 cur = cur-&gt;left; &#125; else&#123; // 右 cur = st.top(); st.pop(); cur = cur-&gt;right; &#125; &#125; return result; &#125;&#125;;// 中序//中序遍历是左中右，先访问的是二叉树顶部的节点，然后一层一层向下访问，直到到达树左面的最底部，再开始处理节点（也就是在把节点的数值放进result数组中），这就造成了「处理顺序和访问顺序是不一致的。// 关键点:出栈再输出class Solution &#123;public: vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; result; // 保存访问过的节点 stack&lt;TreeNode*&gt; st; // 用于访问节点(遍历) TreeNode* cur = root; while(cur != nullptr || ! st.empty())&#123; if (cur != nullptr)&#123; // 访问节点并进栈 st.push(cur); //左 cur = cur-&gt;left; &#125; else&#123; // 处理数据 cur = st.top(); st.pop(); // 中 result.push_back(cur-&gt;val); // 右 cur = cur-&gt;right; &#125; &#125; return result; &#125;&#125;;//思路二:标记法class Solution &#123;public: vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; result; stack&lt;TreeNode*&gt; st; if (root != NULL) st.push(root); while (!st.empty()) &#123; TreeNode* node = st.top(); if (node != NULL) &#123; st.pop(); // 将该节点弹出，避免重复操作，下面再将右中左节点添加到栈中 if (node-&gt;right) st.push(node-&gt;right); // 添加 右 节点（空节点不入栈） st.push(node); // 添加中节点 st.push(NULL); // 中 节点访问过，但是还没有处理，加入空节点做为标记。 if (node-&gt;left) st.push(node-&gt;left); // 添加 左 节点（空节点不入栈） &#125; else &#123; // 只有遇到空节点的时候，才将下一个节点放进结果集 st.pop(); // 将空节点弹出 node = st.top(); // 重新取出栈中元素 st.pop(); result.push_back(node-&gt;val); // 加入到结果集 &#125; &#125; return result; &#125;&#125;;// 后序//思路二: 仅利用栈去判断该节点是否为父结点，创新性思路是每次在栈中压入父节点后压入nullptr，之后再依次压入右子节点和左子节点。(标记法)class Solution &#123;public: vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; if (root == nullptr) return &#123;&#125;; stack&lt;TreeNode*&gt; stk; stk.push(root); vector&lt;int&gt; res; while (!stk.empty()) &#123; TreeNode* node = stk.top(); if (node == nullptr) &#123; // 只有遇到空节点的时候，才将下一个节点放进结果集 stk.pop(); res.push_back(stk.top()-&gt;val);//中 stk.pop(); continue; &#125; // 标记父节点 stk.push(nullptr); // 空节点不入栈 if (node-&gt;right) &#123; stk.push(node-&gt;right);//右 &#125; if (node-&gt;left) &#123; stk.push(node-&gt;left); //左 &#125; &#125; return res; &#125;&#125;;作者：dcoliversun链接：https://leetcode-cn.com/problems/binary-tree-postorder-traversal/solution/a-li-mian-shi-ti-zhi-yong-zhan-qu-zuo-er-cha-shu-d/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。//思路一(取巧):先序遍历是中左右，后续遍历是左右中，那么我们只需要调整一下先序遍历的代码顺序，就变成 中右左 的遍历顺序，然后在 反转result数组，输出的结果顺序就是 左右中class Solution &#123;public: vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123; vector&lt;int&gt; result; stack&lt;TreeNode*&gt; st; // 访问root if (root != nullptr) st.push(root); //遍历 while( ! st.empty())&#123; // 中 TreeNode* node = st.top(); st.pop(); if( node != nullptr)&#123; // 处理 result.push_back(node-&gt;val); &#125; else&#123; // 返回上一节点 continue; &#125; // 左 st.push(node-&gt;left); //右 st.push(node-&gt;right); &#125; reverse(result.begin(), result.end()); return result; &#125;&#125;; 102. 二叉树的层序遍历在 BFS 遍历的基础上区分遍历的每一层，就得到了层序遍历。在层序遍历的基础上记录层数，就得到了最短路径. 此时队列中的结点是 3、4、5，分别来自第 1 层和第 2 层。这个时候，第 1 层的结点还没出完，第 2 层的结点就进来了，而且两层的结点在队列中紧挨在一起，我们无法区分队列中的结点来自哪一层。 因此，在每一层遍历开始前，先记录队列中的结点数量 n（也就是这一层的结点数量），然后一口气处理完这一层的 n 个结点。 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123; vector&lt;vector&lt;int&gt;&gt; result; queue&lt;TreeNode*&gt; qe; if(root) &#123; qe.push(root); qe.push(NULL); &#125; while( ! qe.empty())&#123; vector&lt;int&gt; temp; int len = qe.size(); // 遍历当前队列,不包括新增节点(二叉树的每一层)) for(int i = 0; i &lt; len; i++ )&#123; TreeNode* node = qe.front(); qe.pop(); if(node != nullptr)&#123; temp.push_back(node-&gt;val); if(node-&gt;left) qe.push(node-&gt;left); if(node-&gt;right) qe.push(node-&gt;right); &#125; // else&#123; // &#125; &#125; result.push_back(temp); &#125; return result; &#125;&#125;; 层序遍历的一些变种题目107. 二叉树的层序遍历 II 199. 二叉树的右视图 DFS 与 BFS的运用 637. 二叉树的层平均值 429. N 叉树的层序遍历 589. N 叉树的前序遍历 有用到C++ STL 反向迭代器适配器（reverse_iterator）详解 LeetCode 103. Binary Tree Zigzag Level Order Traversal 之字形层序遍历 LeetCode 515. Find Largest Value in Each Tree Row 计算每一层的最大值 对于最短路径问题，还有两道题目也是求网格结构中的最短路径，和我们讲解的距离岛屿的最远距离非常类似： LeetCode 542. 01 Matrix LeetCode 994. Rotting Oranges 还有一道在真正的图结构中求最短路径的问题： LeetCode 310. Minimum Height Trees 作者：nettee链接：https://leetcode-cn.com/problems/binary-tree-level-order-traversal/solution/bfs-de-shi-yong-chang-jing-zong-jie-ceng-xu-bian-l/来源：力扣（LeetCode） 226. 翻转二叉树关键点在于 每个节点遍历一次 ———-遍历————101. 对称二叉树104. 二叉树的最大深度111. 二叉树的最小深度222. 完全二叉树的节点个数110. 平衡二叉树257. 二叉树的所有路径404. 左叶子之和513. 找树左下角的值如果需要遍历整颗树，递归函数就不能有返回值。如果需要遍历某一条固定路线，递归函数就一定要有返回值！;后序遍历需要根据左右递归的返回值推出中间节点的状态,这种需要有返回值 112. 路径总和———-属性————106. 从中序与后序遍历序列构造二叉树1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 分解成一个子问题:找到中间节点,左右子树的中序&amp;&amp;后序, 每层递归定定义了新的vector（就是数组），既耗时又耗空间class Solution &#123;public: TreeNode* buildTree(vector&lt;int&gt;&amp; inorder, vector&lt;int&gt;&amp; postorder) &#123; int post_len = postorder.size(); // 空节点 if (post_len == 0) return nullptr; // 找到后序遍历的最后一个节点,为中间节点 (左右中) int mid_val = postorder[post_len-1]; TreeNode* root = new TreeNode(mid_val); // 叶子节点 if (post_len == 1) return root; // 找到中序遍历的切割点 int i = 0; for(; i &lt; post_len; i++)&#123; if(inorder[i] == mid_val) break; &#125; // 找到左右子树的中序遍历,和后序遍历 // 关键点:中序和后序的大小是一样的 // 左闭右开区间 // 中序遍历 vector&lt;int&gt; left_inorder(inorder.begin(), inorder.begin() + i); vector&lt;int&gt; right_inorder(inorder.begin() + i + 1, inorder.end()); // 后序遍历 // 舍弃中间节点 postorder.resize(post_len - 1); // 左子树中序遍历的大小 int lo = left_inorder.size(); vector&lt;int&gt; left_postorder(postorder.begin(), postorder.begin() + lo); vector&lt;int&gt; right_postorder(postorder.begin() + lo, postorder.end()); // 查找下一层 // root-&gt;val = mid_val; root-&gt;left = buildTree(left_inorder, left_postorder); root-&gt;right = buildTree(right_inorder, right_postorder); return root; &#125;&#125;; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 优化版class Solution &#123;public: //左开右闭 TreeNode* build(vector&lt;int&gt;&amp; inorder, vector&lt;int&gt;&amp; postorder, int ib, int ie, int pb, int pe)&#123; // 空节点 返回 if(ie - ib == 0) return nullptr; // 找到中间节点, int mid_val = postorder[pe-1]; TreeNode * root = new TreeNode(mid_val); // 找到分割索引 int mid_index = 0; for(; mid_index &lt; ie; mid_index++)&#123; if(inorder[mid_index] == mid_val) break; &#125; //叶子节点 if(ie - ib == 1) return root; // 左右子树的中序\后序 // 中序 int left_ib = ib; int left_ie = mid_index; int right_ib = mid_index + 1; int right_ie = ie; int left_pb = pb; // 终止位置是 需要加上 中序区间的大小size int left_pe = pb + (mid_index - ib); int right_pb = pb + (mid_index - ib); int right_pe = pe - 1; // cout &lt;&lt; "----------" &lt;&lt; endl; // cout&lt;&lt;mid_val&lt;&lt; ' '&lt;&lt;mid_index &lt;&lt;endl; // cout &lt;&lt;"左子树中序: "&lt;&lt; left_ib&lt;&lt;" "&lt;&lt; left_ie&lt;&lt;" 左子树后序: "&lt;&lt;left_pb&lt;&lt;" "&lt;&lt;left_pe&lt;&lt; endl; // cout &lt;&lt;"右子树中序: "&lt;&lt; right_ib&lt;&lt;" "&lt;&lt; right_ie&lt;&lt;" 右子树后序: "&lt;&lt;right_pb&lt;&lt;" "&lt;&lt;right_pe&lt;&lt; endl; root-&gt;left = build(inorder, postorder, left_ib, left_ie, left_pb, left_pe); root-&gt;right = build(inorder, postorder, right_ib, right_ie, right_pb, right_pe); return root; &#125; TreeNode* buildTree(vector&lt;int&gt;&amp; inorder, vector&lt;int&gt;&amp; postorder) &#123; return build(inorder, postorder, 0, inorder.size(), 0, postorder.size()); &#125;&#125;; 12345678910111213141516171819202122232425262728293031323334353637//再次优化版:因为后序是左右中，反过来就需要先构建完右子树再构建左子树//很巧妙利用率后序的特性: [[左子树], [右子树], 根],每次取最后一个节点( post_index--;),优先拿到的是上个节点对应的右树.构建完所有的右子树才会构建左子树(从最下一层的右子树兄弟-左子树开始)class Solution &#123;public: // 根节点所在位置 int post_index; unordered_map&lt;int, int&gt; idx_map; //左闭右闭, 仅分割中序, 左子树[in_left,mid_index - 1] ,右子树[mid_index + 1,in_right] TreeNode* build(vector&lt;int&gt;&amp; postorder, int in_left, int in_right)&#123; // 空节点 返回 if(in_left &gt; in_right) return nullptr; // 找到中间节点, int mid_val = postorder[post_index]; TreeNode * root = new TreeNode(mid_val); // 找到分割索引 int mid_index =idx_map[mid_val]; // 舍弃最后一个节点 post_index--; // 构造右子树 root-&gt;right = build(postorder, mid_index+1, in_right); // 构造左子树 root-&gt;left = build(postorder, in_left, mid_index-1); return root; &#125; TreeNode* buildTree(vector&lt;int&gt;&amp; inorder, vector&lt;int&gt;&amp; postorder) &#123; // 建立 中序 值-下标 map int index = 0; for (auto it : inorder) idx_map[it] = index++; int order_len = postorder.size(); post_index = order_len - 1; return build(postorder, 0, order_len-1); &#125;&#125;; 105. 从前序与中序遍历序列构造二叉树「前序和后序不能唯一确定一颗二叉树！」，因为没有中序遍历无法确定左右部分，也就是无法分割。 123456789101112131415161718192021222324252627282930313233343536//沿用上一题的方法三思路class Solution &#123;public: int pre_index; unordered_map&lt;int, int&gt; idx_map; TreeNode* build(vector&lt;int&gt;&amp; preorder, int left_index, int right_index)&#123; if(left_index &gt; right_index) return nullptr; // 分割点 int mid_val = preorder[pre_index]; int mid_index = idx_map[mid_val]; TreeNode *root = new TreeNode(mid_val); pre_index++; // 先构建完所有的左子树 root-&gt;left = build(preorder, left_index, mid_index-1); //再构建右子树 root-&gt;right = build(preorder, mid_index+1, right_index); return root; &#125; TreeNode* buildTree(vector&lt;int&gt;&amp; preorder, vector&lt;int&gt;&amp; inorder) &#123; pre_index = 0; int order_len = inorder.size(); int index = 0; for (auto it : inorder)&#123; idx_map[it]=index++; &#125; return build(preorder, 0, order_len-1); &#125;&#125;; 654. 最大二叉树617. 合并二叉树——修改与构造——-700. 二叉搜索树中的搜索98. 验证二叉搜索树特性:中序遍历下，输出的二叉搜索树节点的数值是有序(递增)序列 递归踩雷:左子树所有节点小于中间节点，右子树所有节点大于中间节点 123456789101112131415161718192021//递归版class Solution &#123;public: //保存前一个访问的结点 TreeNode *pre = nullptr; bool isValidBST(TreeNode* root) &#123; if (root == nullptr) return true; bool left_flag = isValidBST(root-&gt;left); // 这一操作 每次和前一个节点比较, 验证递增 if(pre &amp;&amp; pre-&gt;val &gt;= root-&gt;val) return false; pre = root; bool right_flag = isValidBST(root-&gt;right); return left_flag &amp;&amp; right_flag; &#125;&#125;; 1234567891011121314151617181920212223242526272829303132333435363738//迭代版class Solution &#123;public: //保存前一个访问的结点 TreeNode *pre = nullptr; bool isValidBST(TreeNode* root) &#123; if (root == nullptr) return true; // 保存访问过的节点 stack&lt;TreeNode*&gt; st; // 遍历树 TreeNode* cur = root; while(cur != nullptr || ! st.empty())&#123; if(cur)&#123; // 存储中间节点 st.push(cur); // 访问左孩子 cur = cur-&gt;left; &#125; else&#123; // 处理中间节点 cur = st.top(); st.pop(); // 判断 if(pre &amp;&amp; pre-&gt;val &gt;= cur-&gt;val) return false; pre = cur; cur = cur-&gt;right; &#125; &#125; return true; &#125;&#125;; 530. 二叉搜索树的最小绝对差在有序数组求任意两数最小值差等价于相邻两数的最小值差 501. 二叉搜索树中的众数236. 二叉树的最近公共祖先12345678910111213141516171819202122//自底向上查找 (后序遍历-回溯)class Solution &#123;public: TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; if (root == nullptr || root == p || root == q) return root; TreeNode* left = lowestCommonAncestor(root-&gt;left, p, q); TreeNode* right = lowestCommonAncestor(root-&gt;right, p, q); // 左右子树找到 if (left != nullptr &amp;&amp; right != nullptr) return root; // 右子树没找到 else if (left != nullptr &amp;&amp; right == nullptr) return left; // 左子树没找到 else if (left == nullptr &amp;&amp; right != nullptr) return right; // 左右子树没找到 else return left; &#125;&#125;; 235. 二叉搜索树的最近公共祖先只要从上到下遍历的时候，cur节点是数值在[p, q]区间中则说明该节点cur就是最近公共祖先 123456789101112131415161718192021222324class Solution &#123;public: // 前序遍历 TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123; // root 在 [p,q] 之间 if (root == nullptr || (root-&gt;val &gt;= p-&gt;val &amp;&amp; root-&gt;val &lt;= q-&gt;val) || (root-&gt;val &gt;= q-&gt;val &amp;&amp; root-&gt;val &lt;= p-&gt;val)) return root; // root 大于 max[p,q], 往左子树走 else if(root-&gt;val &gt; p-&gt;val &amp;&amp; root-&gt;val &gt; q-&gt;val)&#123; TreeNode *left = lowestCommonAncestor(root-&gt;left, p ,q); if (left) return left; &#125; // root 小于 min[p,q], 往右子树走 if(root-&gt;val &lt; p-&gt;val &amp;&amp; root-&gt;val &lt; q-&gt;val)&#123; TreeNode *right = lowestCommonAncestor(root-&gt;right, p ,q); if (right) return right; &#125; return nullptr; &#125;&#125;; ——-二叉搜索树——701. 二叉搜索树中的插入操作450. 删除二叉搜索树中的节点1234567891011121314151617181920212223242526272829class Solution &#123;public: TreeNode* deleteNode(TreeNode* root, int key) &#123; if (root == nullptr) return root; // 第一种情况：没找到删除的节点，遍历到空节点直接返回了 if (root-&gt;val == key) &#123; // 第二种情况：左右孩子都为空（叶子节点），直接删除节点， 返回NULL为根节点 // 第三种情况：其左孩子为空，右孩子不为空，删除节点，右孩子补位 ，返回右孩子为根节点 if (root-&gt;left == nullptr) return root-&gt;right; // 第四种情况：其右孩子为空，左孩子不为空，删除节点，左孩子补位，返回左孩子为根节点 else if (root-&gt;right == nullptr) return root-&gt;left; // 第五种情况：左右孩子节点都不为空，则将删除节点的左子树放到删除节点的右子树的最左面节点的左孩子的位置 // 并返回删除节点右孩子为新的根节点。 else &#123; TreeNode* cur = root-&gt;right; // 找右子树最左面的节点 while(cur-&gt;left != nullptr) &#123; cur = cur-&gt;left; &#125; cur-&gt;left = root-&gt;left; // 把要删除的节点（root）左子树放在cur的左孩子的位置 TreeNode* tmp = root; // 把root节点保存一下，下面来删除 root = root-&gt;right; // 返回旧root的右孩子作为新root delete tmp; // 释放节点内存（这里不写也可以，但C++最好手动释放一下吧） return root; &#125; &#125; if (root-&gt;val &gt; key) root-&gt;left = deleteNode(root-&gt;left, key); if (root-&gt;val &lt; key) root-&gt;right = deleteNode(root-&gt;right, key); return root; &#125;&#125;; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 根据递归返回值 确定节点的父子关系 (自己理解后重新写的)class Solution &#123;public: TreeNode* deleteNode(TreeNode* root, int key) &#123; // 没有找到key if( ! root) return nullptr; // 找到了 if(root-&gt;val == key)&#123; // 判断此时根节点左右孩子的状态 // 只有右孩子 if( ! root-&gt;left &amp;&amp; root-&gt;right)&#123; return root-&gt;right; &#125; // 只有左孩子 if(root-&gt;left &amp;&amp; ! root-&gt;right)&#123; return root-&gt;left; &#125; // 叶子节点 if( ! root-&gt;left &amp;&amp; ! root-&gt;right)&#123; delete root; return nullptr; &#125; // 左右孩子存在 else&#123; // 找到右孩子的最左节点, 将左孩子 放置在 该节点的左侧 TreeNode *cur = root-&gt;right; while (cur-&gt;left != nullptr)&#123; cur = cur-&gt;left; &#125; cout&lt;&lt;cur-&gt;val; cur-&gt;left = root-&gt;left; // 删除根节点 TreeNode *node = root; // 更新根节点 root = root-&gt;right; delete node; return root; &#125; &#125; // 走右子树 else if (root-&gt;val &lt; key)&#123; root-&gt;right = deleteNode(root-&gt;right, key); &#125; //走左子树 else&#123; root-&gt;left = deleteNode(root-&gt;left, key); &#125; return root; &#125;&#125;; 669. 修剪二叉搜索树1234567891011121314151617181920212223242526//递归版class Solution &#123;public: TreeNode* trimBST(TreeNode* root, int low, int high) &#123; if (root == nullptr) return root; // 小于下限 if(root-&gt;val &lt; low)&#123; // 找到满足条件的右孩子 TreeNode *cur = trimBST(root-&gt;right, low, high); return cur; &#125; // 大于上限 else if(root-&gt;val &gt; high )&#123; // 找到满足条件的左孩子 TreeNode *cur = trimBST(root-&gt;left, low, high); return cur; &#125; root-&gt;left = trimBST(root-&gt;left, low, high); root-&gt;right = trimBST(root-&gt;right, low, high); return root; &#125;&#125;; 12345678910111213141516171819202122232425262728293031323334353637383940// 迭代版class Solution &#123;public: TreeNode* trimBST(TreeNode* root, int low, int high) &#123; if (root == nullptr) return root; // 根节点满足条件 while(root-&gt;val &lt; low || root-&gt;val &gt; high)&#123; if(root-&gt;val &lt; low) root = root-&gt;right; else root = root-&gt;left; // 发现整棵树都不满足条件 if(!root) return nullptr; &#125; TreeNode *cur = root; // 左孩子元素小于L的情况 while(cur)&#123; // 若小于,则用 左孩子的右节点代替 while(cur-&gt;left &amp;&amp; cur-&gt;left-&gt;val &lt; low)&#123; cur-&gt;left = cur-&gt;left-&gt;right; &#125; cur = cur-&gt;left; &#125; cur = root; // 右孩子元素大于H的情况 while(cur)&#123; // 若小于,则用 左孩子的右节点代替 while(cur-&gt;right &amp;&amp; cur-&gt;right-&gt;val &gt; high)&#123; cur-&gt;right = cur-&gt;right-&gt;left; &#125; cur = cur-&gt;right; &#125; return root; &#125;&#125;; 108. 将有序数组转换为二叉搜索树538. 把二叉搜索树转换为累加树二叉搜索树的修改与构造算法思想基础的算法： 枚举遍历，排序， 二分查找，递归，回溯 回溯「因为回溯的本质是穷举，穷举所有可能，然后选出我们想要的答案」，如果想让回溯法高效一些，可以加一些剪枝的操作，但也改不了回溯法就是穷举的本质。 适合: (性能分析) 子集问题：一个N个数的集合里有多少符合条件的子集 时间复杂度：O(n * 2^n)，因为每一个元素的状态无外乎取与不取，所以时间复杂度为O(2^n)，构造每一组子集都需要填进数组，又有需要O(n)，最终时间复杂度：O(n * 2^n) 空间复杂度：O(n)，递归深度为n，所以系统栈所用空间为O(n)，每一层递归所用的空间都是常数级别，注意代码里的result和path都是全局变量，就算是放在参数里，传的也是引用，并不会新申请内存空间，最终空间复杂度为O(n) 组合问题：N个数里面按一定规则找出k个数的集合 时间复杂度：O(n * 2^n)，组合问题其实就是一种子集的问题，所以组合问题最坏的情况，也不会超过子集问题的时间复杂度。 空间复杂度：O(n)，和子集问题同理。 排列问题：N个数按一定规则全排列，有几种排列方式 时间复杂度：O(n!)，这个可以从排列的树形图中很明显发现，每一层节点为n，第二层每一个分支都延伸了n-1个分支，再往下又是n-2个分支，所以一直到叶子节点一共就是 n n-1 n-2 * ….. 1 = n!。 空间复杂度：O(n)，和子集问题同理。 切割问题：一个字符串按一定规则有几种切割方式 棋盘问题：N皇后，解数独等等 N皇后 时间复杂度：O(n!) ，其实如果看树形图的话，直觉上是O(n^n)，但皇后之间不能见面所以在搜索的过程中是有剪枝的，最差也就是O（n!），n!表示n (n-1) …. * 1。 空间复杂度：O(n)，和子集问题同理。 解数独 时间复杂度：O(9^m) , m是’.’的数目。 空间复杂度：O(n^2)，递归的深度是n^2 组合问题组合问题、切割问题和子集问题都是类似的问题,可转换成组合问题 如果是一个集合来求组合的话，就需要startIndex，例如：回溯算法：求组合问题！，回溯算法：求组合总和！。 如果是多个集合取组合，各个集合之间相互不影响，那么就不用startIndex，例如：回溯算法：电话号码的字母组合 77. 组合方法一:经典的回溯剪枝-满足题目要求的k个元素 官网方法二:简单来说就是一开始把所有的1放在尾部，比如00111这样，然后按顺序把1往前移动。如果所有的1都在最前头了，比如11100，就留一位1，其余的全部移到末尾，比如10011，然后再重复这个操作，直到所有的1都“被”留在了最前面，即11100，便完成了全部穷举。 12345678910111213141516171819202122232425262728293031// 二进制法class Solution &#123;public: vector&lt;int&gt; temp; vector&lt;vector&lt;int&gt;&gt; ans; vector&lt;vector&lt;int&gt;&gt; combine(int n, int k) &#123; // 初始化 // 将 temp 中 [0, k - 1] 每个位置 i 设置为 i + 1，即 [0, k - 1] 存 [1, k] // 末尾加一位 n + 1 作为哨兵 for (int i = 1; i &lt;= k; ++i) &#123; temp.push_back(i); &#125; temp.push_back(n + 1); int j = 0; while (j &lt; k) &#123; ans.emplace_back(temp.begin(), temp.begin() + k); j = 0; // 寻找第一个 temp[j] + 1 != temp[j + 1] 的位置 t // 我们需要把 [0, t - 1] 区间内的每个位置重置成 [1, t] while (j &lt; k &amp;&amp; temp[j] + 1 == temp[j + 1]) &#123; temp[j] = j + 1; ++j; &#125; // j 是第一个 temp[j] + 1 != temp[j + 1] 的位置 ++temp[j]; &#125; return ans; &#125;&#125;; 216. 组合总和 III17. 电话号码的字母组合回溯法有点像(递归有几种类型,循环是第i个类型有几种选择) 「for循环横向遍历，递归纵向遍历，回溯不断调整结果集」。 39. 组合总和40. 组合总和 II123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; result; vector&lt;int&gt; path; void find(vector&lt;int&gt;&amp; candidates, int target, int startI, vector&lt;int&gt;&amp;use)&#123; if(target == 0)&#123; result.push_back(path); return; &#125; if(target &lt; 0)&#123; return; &#125; for(int i = startI; i &lt; candidates.size(); i++)&#123; // used[i - 1] == 1，说明同一树支candidates[i - 1]使用过 // used[i - 1] == 0，说明同一树层candidates[i - 1]使用过 // 要对同一树层使用过的元素进行跳过 // 循环是第i个类型有几种选择,去掉与之前重复的选择,use[i-1]似乎不必要 // if (i &gt; 0 &amp;&amp; candidates[i] == candidates[i - 1] &amp;&amp; use[i - 1] == 0) &#123; // continue; // &#125; if (i &gt; startI &amp;&amp; candidates[i] == candidates[i - 1] ) &#123; continue; &#125; use[i] = 1; target -= candidates[i]; path.push_back(candidates[i]); find(candidates, target, i+1, use); target += candidates[i]; path.pop_back(); use[i] = 0; &#125; &#125; vector&lt;vector&lt;int&gt;&gt; combinationSum2(vector&lt;int&gt;&amp; candidates, int target) &#123; vector&lt;int&gt; use(candidates.size(), 0); sort(candidates.begin(), candidates.end()); find(candidates, target, 0, use); return result; &#125;&#125;; 131. 分割回文串93. 复原 IP 地址78. 子集「在树形结构中子集问题是要收集所有节点的结果，而组合问题是收集叶子节点的结果」。 90. 子集 II通过排序,比较相邻重复元素是否被访问,达到去重. 491. 递增子序列(回溯套路小陷阱) 本层去重，是指同一个父节点下的本层，而不是整颗树的本层。 父节点的同一层公用一个visit[201]数组(哈希),完成访问登记, 排列问题 每层都是从0开始搜索而不是startIndex 需要used数组记录path里都放了哪些元素了 “树层去重”和“树枝去重”的重要性, 明显看出“树层去重”效率更高(「可以看出在candidates[i] == candidates[i - 1]相同的情况下：」) 树层上去重(used[i - 1] == false)，的树形结构如下： 树枝上去重（used[i - 1] == true）的树型结构如下： 46. 全排列47. 全排列 II—-未做—- 332. 重新安排行程图论扩展 51. N 皇后棋盘的宽度就是for循环的长度，递归的深度就是棋盘的高度，这样就可以套进回溯法的模板里 37. 解数独「二维递归」 贪心「贪心的本质是选择每一阶段的局部最优，从而达到全局最优」 贪心算法一般分为如下四步： 将问题分解为若干个子问题 找出适合的贪心策略 求解每一个子问题的最优解 将局部最优解堆叠成全局最优解 题: 455. 分发饼干376. 摆动序列让序列有尽可能多的局部峰值。 局部最优：删除单调坡度上的节点（不包括单调坡度两端的节点），那么这个坡度就可以有两个局部峰值。 整体最优：整个序列有最多的局部峰值，从而达到最长摆动序列。 53. 最大子序和贪心：「不能让“连续和”为负数的时候加上下一个元素，而不是 不让“连续和”加上一个负数」 1234567891011121314151617int maxsumofSubarray(vector&lt;int&gt;&amp; arr) &#123; // write code here int sum = INT_MIN; int count = 0; for(int i = 0; i &lt; arr.size(); i++)&#123; count += arr[i]; // 负数就没必要在往下加了 if(count &lt; 0)&#123; count = 0; &#125; sum = sum &gt; count? sum : count; &#125; return sum; &#125; 动态规划：arr[i]代表i的累加和，便记录其累加和最大值 动态转移方程：arr[i] = max(arr[i-1]+arr[i] ,arr[i]) 123456789101112int maxsumofSubarray(vector&lt;int&gt;&amp; arr) &#123; // write code here int sum = arr[0]; for(int i = 1; i &lt; arr.size(); i++)&#123; arr[i] = max(arr[i-1]+arr[i], arr[i]); sum = max(sum, arr[i]); &#125; return sum; &#125; 122. 买卖股票的最佳时机 II「局部最优：收集每天的正利润，全局最优：求得最大利润」 55. 跳跃游戏45. 跳跃游戏 II1005. K 次取反后最大化的数组和134. 加油站135. 分发糖果需要考虑两个维度(先考虑其中一个维度，再考虑其他的) 860. 柠檬水找零406.根据身高重建队列注意 数据结构的区别，vector的底层实现也是普通数组（使用vector来做insert的操作，此时「虽然表面上复杂度是O(n^2)，但是其底层都不知道额外做了多少次全量拷贝了，所以算上vector的底层拷贝，整体时间复杂度可以认为是O(n^2 + t * n)级别的，t是底层拷贝的次数」） 动态规划动态规划，英文：Dynamic Programming，简称DP，如果某一问题有很多重叠子问题，使用动态规划是最有效的。 动态规划中每一个状态一定是由上一个状态推导出来的，这一点就区分于贪心，贪心没有状态推导，而是从局部直接选最优的. 核心: 状态转移公式（递推公式） 对于动态规划问题，如下五步曲 确定dp数组（dp table）以及下标的含义 确定递推公式 dp数组如何初始化 确定遍历顺序 举例推导dp数组 题: 509. 斐波那契数70. 爬楼梯746. 使用最小花费爬楼梯62. 不同路径343. 整数拆分96. 不同的二叉搜索树——子序列系列——-674. 最长连续递增序列300. 最长递增子序列该题与674的区别在于子序列的元素可以在位置上不连续。 123456789101112131415int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123; if (nums.size() == 1) return 1; //dp[i] i之前包括i的最长上升子序列数 vector&lt;int&gt; dp(nums.size(), 1); //记录最长上升子序列数 int maxNum = 0; for(int i = 0; i &lt; nums.size(); i++)&#123; for(int j = 0; j &lt; i; j++)&#123; if(nums[i] &gt; nums[j]) dp[i] = max(dp[i], dp[j]+1); maxNum = max(dp[i], maxNum); &#125; &#125; return maxNum; &#125; 优化版 二分区间的选择（来源）： while (left &lt; right) 退出循环的时候有 left == right 成立，因此无需考虑返回 left 还是 right 每一轮区间被划分成 22 部分，理解 区间划分 决定中间数取法（ 无需记忆，需要练习 + 理解 ），在调试的过程中理解 区间和中间数划分的配对关系：划分 [left, mid] 与 [mid + 1, right] ，mid 被分到左边，对应 int mid = left + (right - left) / 2;；划分 [left, mid - 1] 与 [mid, right] ，mid 被分到右边，对应 int mid = left + (right - left + 1) / 2;。 至于为什么划分是这种对应关系，原因在于区间只有 2 个数的时候，如果中间数的取法不对，一旦进入的分支不能使得区间缩小，会出现 死循环。 退出循环的时候有 left == right 成立，此时如果能确定问题一定有解，返回 left 即可，如果不能确定，需要单独判断一次。 12345678910111213141516171819202122232425262728293031323334//二分+动态规划 int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123; int len = nums.size(); if (len == 1) return 1; //dp[i] 长度为 i + 1 的 所有 上升子序列的结尾的最小值,运用了贪心的思想 vector&lt;int&gt; dp(len, 0); //记录长度 int maxNum = 0; dp[0] = nums[0]; for(int i = 1; i &lt; nums.size(); i++)&#123; if(nums[i] &gt; dp[maxNum])&#123; dp[++maxNum] = nums[i]; &#125; else if(nums[i] &lt; dp[maxNum])&#123; // //二分，找到合适插入的位置 int l = 0, r = maxNum; while(l &lt; r)&#123; int mid = l + ((r - l) &gt;&gt; 1); if(dp[mid] &lt; nums[i])&#123; l = mid+1; &#125; else&#123; r = mid; &#125; &#125; dp[l] = nums[i]; &#125; else continue; &#125; return maxNum+1; &#125; 718. 最长重复子数组1143. 最长公共子序列与上一题相比，子序列（原字符串元素相对顺序不变，删除某些字符（也可以不删除任何字符）后组成的新字符串），难度加大.还是要理清dp[i][j]所代表的含义以及对应的递推公式、初始值. 12345678910111213141516171819202122//优化版，只保留相邻两行的状态，空间复杂度降低为O（min(m,n)）class Solution &#123;public: int longestCommonSubsequence(string text1, string text2) &#123; if (text1.size() &lt; text2.size()) &#123; swap(text1, text2); &#125; vector&lt;vector&lt;int&gt;&gt; m (2, vector&lt;int&gt;(text2.size(), 0)); int ans = 0; for (int i = 0; i &lt; text1.size(); ++i) &#123; for (int j = 0; j &lt; text2.size(); ++j) &#123; if (text1[i] == text2[j]) &#123; m[1][j] = j?m[0][j-1]+1:1; &#125; else &#123; m[1][j] = max(m[0][j], j?m[1][j-1]:0); &#125; &#125; swap(m[0], m[1]); &#125; return m[0][text2.size() - 1]; &#125;&#125;; ——01背包——-416. 分割等和子集排序交换类排序冒泡排序每一次把最大的放到后面【确定最大值，放入合适的位置。直至整个数据位置确定完】 123456789101112131415//冒泡 void maopaoSort(vector&lt;int&gt;&amp; a)&#123; //排序位 for(int i = a.size()-1; i &gt; -1; i--)&#123; //待排序区 for(int j = 0; j &lt; i; j++)&#123; if(a[j+1] &lt; a[j])&#123; // a ^ a = 0 ; a ^ 0 = a a[j+1] ^= a[j]; a[j] ^= a[j+1]; a[j+1] ^= a[j]; &#125; &#125; &#125; &#125; 快速排序 挖坑填数: 1．i =L; j = R; 将基准数挖出形成第一个坑a[i]。 2．j–由后向前找比它小的数，找到后挖出此数填前一个坑a[i]中。 3．i++由前向后找比它大的数，找到后也挖出此数填到前一个坑a[j]中。 4．再重复执行2，3二步，直到i==j，将基准数填入a[i]中。 此时，a[i]左边的值 &lt;a[i]右边的值。再排序左区间与右区间，直至左右区间无值。 1234567891011121314151617181920212223242526// 左闭右闭 void quickSort(vector&lt;int&gt;&amp; arr, int l, int r)&#123; int key = arr[l]; int i = l, j = r; while(i &lt; j)&#123; //后往前找到第一个小于key的值 while(j &gt; i &amp;&amp; arr[j] &gt;= key) j--; if(j &gt; i)&#123; arr[i] = arr[j]; &#125; //前往后找到第一个大于key的值 while(j &gt; i &amp;&amp; arr[i] &lt;= key) i++; if(j &gt; i)&#123; arr[j] = arr[i]; &#125; &#125; arr[i] = key; if(i &gt; l) quickSort(arr, l, i-1); if(r &gt; i) quickSort(arr, i+1, r); &#125; 插入类排序直接插入排序分为排序区和未排序区，每次未排序区依次选择一个数，与排序区比较，若排序区的元素比该数大，就插入（元素后移一位，该数放置其前） 123456789101112131415161718//选择排序 void selectInsertSort(vector&lt;int&gt;&amp; a)&#123; for(int i = 1; i &lt; a.size(); i++)&#123; int temp = a[i]; //排序区 for(int j = i-1; j &gt; -1; j--)&#123; //往后移 if(a[j] &gt; temp )&#123; a[j+1] = a[j]; a[j] = temp; &#125;else&#123; break; &#125; &#125; &#125; &#125; 希尔排序将数组分组，在各组中进行直接插入排序。逐渐缩小分组间隙，直至整个数组恰被分成一组. 1234567891011121314void shellSort(vector&lt;int&gt; &amp;a)&#123; int interval = a.size(); for(; interval &gt; 0; interval /= 2)&#123; //每组间隔interval的元素进行选择插入排序 for(int i = interval; i &lt; a.size(); i++)&#123; int temp = a[i]; for(int j = i-interval; j &gt; -1 ;j -= interval) if(temp &lt; a[j])&#123; a[j+interval] = a[j]; a[j] = temp; &#125; &#125; &#125; &#125; 选择类排序简单选择排序分为排序区和未排序区，每次在未排序区找到最小值，放入排序区的后面。 123456789101112131415161718// 选择排序 void selectSort(vector&lt;int&gt; &amp;a)&#123;// i排序区 for(int i = 0; i &lt; a.size(); i++)&#123; int minIndex = i;// 找到未排序区的最小值 for(int j = i+1; j &lt; a.size(); j++)&#123; if(a[j] &lt; a[minIndex])&#123; minIndex = j; &#125; &#125; if(i != minIndex)&#123; a[i] ^= a[minIndex]; a[minIndex] ^= a[i]; a[i] ^= a[minIndex]; &#125; &#125; &#125; 堆排序这位大佬图解很清晰，思路： a.将无需序列构建成一个堆，根据升序降序需求选择大顶堆或小顶堆; b.将堆顶元素与末尾元素交换，将最大元素”沉”到数组末端; c.重新调整结构，使其满足堆定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整+交换步骤，直到整个序列有序。 用数组表示 大顶堆：arr[i] &gt;= arr[2i+1] &amp;&amp; arr[i] &gt;= arr[2i+2] 小顶堆：arr[i] &lt;= arr[2i+1] &amp;&amp; arr[i] &lt;= arr[2i+2] 12345678910111213141516171819202122232425262728293031323334353637383940414243// 堆排序 void swap(vector&lt;int&gt; &amp;a, int i, int j)&#123; a[i] ^= a[j]; a[j] ^= a[i]; a[i] ^= a[j]; &#125; void heap(vector&lt;int&gt;&amp; a, int i, int length)&#123; int curVal = a[i]; for(int k = 2*i+1; k &lt; length; k = k*2+1)&#123; //左右节点是否大于父节点 //先找到左右节点的较大值，与父节点比较。 if( k+1&lt;length &amp;&amp; a[k] &lt; a[k+1]) k++; if(a[k] &gt; curVal)&#123; a[i] = a[k]; //记录替换后的位置 i = k; &#125; //均不大于，满足条件，则返回 else&#123; break; &#125; &#125; a[i] = curVal; &#125; void heapSort(vector&lt;int&gt;&amp; a)&#123;// 创建大顶堆: 从第一个非叶子节点 从下至上，右至左 int length = a.size(); for(int i = length/2-1; i &gt; -1; i--)&#123; heap(a, i, length); &#125; // 交换堆顶与末尾元素，调整堆,逐渐将最大值沉到最后 for(int j = length - 1; j &gt; 0; j--)&#123; swap(a, 0, j); heap(a, 0, j); &#125; &#125; 归并类排序归并排序采用分治策略（将问题分成一些小的问题，然后递归求解；再将每个阶段的结果合并） “治”采用双指针的方式合并。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556////在排序前，先建好一个长度等于原数组长度的临时数组，避免递归中频繁开辟空间void merge(vector&lt;int&gt; &amp;a, int l, int mid, int r, int *temp) &#123; // 双指针 int i = l, j = mid + 1; // 临时数组的索引 int t = 0; // 合并 while (i &lt; mid + 1 &amp;&amp; j &lt; r + 1) &#123; if (a[i] &lt;= a[j]) &#123; temp[t++] = a[i++]; &#125; else &#123; temp[t++] = a[j++]; &#125; &#125; while (i &lt; mid + 1) &#123; temp[t++] = a[i++]; &#125; while (j &lt; r + 1) &#123; temp[t++] = a[j++]; &#125; t = 0; // 拷贝到a for (int k = l; k &lt; r + 1; k++) &#123; a[k] = temp[t++]; &#125;&#125;//归并排序void mergeSort(vector&lt;int&gt; &amp; a, int l, int r, int *temp) &#123; //越界 if (l &gt;= r) return; int mid = (l + r) / 2; //归并左区间 mergeSort(a, l, mid, temp); //归并右区间 mergeSort(a, mid + 1, r, temp); merge(a, l, mid, r, temp);&#125;int main() &#123; vector&lt;int&gt; arr = &#123; 5, 1, 6, 2, 5, 5, 2, 3, 1, 4 &#125;; int *temp = new int[arr.size()]; mergeSort(arr, 0, arr.size() - 1, temp); for (int i = 0; i &lt; arr.size(); i++) &#123; cout&lt;&lt; arr[i] &lt;&lt; " "; &#125; delete[]temp; return 0;&#125; 桶排桶排序划分多个范围相同的区间，每个自区间自排序，最后合并。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;list&gt;using namespace std;void insert(list&lt;int&gt;&amp; bucket,int val)&#123; auto iter = bucket.begin(); while(iter != bucket.end() &amp;&amp; val &gt;= *iter) ++iter; //insert会在iter之前插入数据，这样可以稳定排序 bucket.insert(iter,val);&#125;void BucketSort_1(vector&lt;int&gt;&amp; arr)&#123; int len = arr.size(); if(len &lt;= 1) return; int min = arr[0],max = min; for(int i=1;i&lt;len;++i) &#123; if(min&gt;arr[i]) min = arr[i]; if(max&lt;arr[i]) max = arr[i]; &#125; int k = 10;//k为数字之间的间隔 //向上取整，例如[0,9]有10个数，(9 - 0)/k + 1 = 1; int bucketsNum = (max - min)/k + 1; vector&lt;list&lt;int&gt;&gt; buckets(bucketsNum); for(int i=0;i&lt;len;++i) &#123; int value = arr[i]; //(value-min)/k就是在哪个桶里面 insert(buckets[(value-min)/k],value); &#125; int index = 0; for(int i=0;i&lt;bucketsNum;++i) &#123; if(buckets[i].size()) &#123; for(auto&amp; value:buckets[i]) arr[index++] = value; &#125; &#125;&#125;int main()&#123; vector&lt;int&gt; A=&#123;-100,13,14,94,33,82,25,59,94,65,23,45,27,43,25,39,10,35,54,90,-200,58&#125;; for(auto value:A) cout&lt;&lt;value&lt;&lt;" "; cout&lt;&lt;endl; BucketSort_1(A); for(auto value:A) cout&lt;&lt;value&lt;&lt;" "; cout&lt;&lt;endl; return 0;&#125; 计数排序基数排序常考题参考文章「图文总结」程序员必知必会的十大排序算法]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paperMemo-prepare]]></title>
    <url>%2Farticle%2F5dace05d%2F</url>
    <content type="text"><![CDATA[寻找数据集的网站https://www.visualdata.io/discovery 预处理RealEstate10K下载 RealEstate10K 数据集介绍-【大规模摄像机轨迹视频剪辑数据集】 PS:大小大约7TB 抓取 YouTube 上的视频，并以指定时间戳、帧姿态来剪辑。应用类似于视图合成的模型中，例如，在Google的SIGGRAPH 2018年SIGGRAPH论文《立体放大：使用多平面图像学习视图合成》中，在训练过程中从每个剪辑中采样了三帧帧，两个用于预测模型，第三个作为计算视图合成损失的ground truth 训练网络。 数据集由一组.txt文件组成，格式如下： 1234&lt;Video URL&gt; &lt;frame1&gt; &lt;frame2&gt; &lt;...&gt; 同一个视频的剪辑帧大约90%在训练集、10%在测试集。 每个frame包括3个参数 第1列：时间戳（int，视频开始的微秒数） 第2-6列：相机内在参数（float: focal_length_x, focal_length_y,principal_point_x, principal_point_y），即3*3矩阵K 第7-19列：相机姿态（floats ，以行优先顺序的3x4矩阵，即3*4矩阵P = [R|t] 因此，KP将世界坐标系的(homogeneous) 3D坐标点映射到图片中(homogeneous) 2D点 相机内部特性以与分辨率无关（resolution-independent）的归一化图像坐标表示，其中图像的左上角为（0,0），图像的右下角为（1,1）。 通过像素大小对图像进行缩放，可以调整内在参数得到存储在磁盘上的任何分辨率帧（或在训练之前调整大小）。 对于分辨率为width x height 像素的图像，图像真实比例的K矩阵为 pytube是用于爬虫下载youtube上的视频库 1pip install pytube3 处理代码： 1python preprocess_RealEstate10K.py 补充知识相机模型 （像素坐标，图像坐标，相机坐标，世界坐标）的变换关系 成像的过程实质上是几个坐标系的转换， 也可以被称为射影变换（更多关于射影变换的内容可参考《计算机视觉中的多视图几何》） 。首先空间中的一点由 世界坐标系 转换到 摄像机坐标系 ，然后再将其投影到成像平面 ( 图像物理坐标系 ) ，最后再将成像平面上的数据转换到图像平面 ( 图像像素坐标系 ) 针孔相机模型（最简单）： 相机坐标系（三维坐标系）相机的中心被称为焦点或者光心（principal point），以焦点Oc为原点和坐标轴Xc,Yc,Zc组成了相机坐标系 图像坐标系（二维坐标系）成像平面中，以成像平面的中心O′为原点和坐标轴x′,y′组成了图像坐标系。 由相似三角形得出： $$\left{\begin{array}{l}x = f\frac{X}{Z} \y = f\frac{Y}{Z} \z = f\end{array}\right.$$ 通过扩展坐标维度构建齐次坐标 ，将z线性化$$\left[\begin{array}{c}x\y\end{array}\right] \Leftrightarrow\left[\begin{array}{c}\hat{x}\\hat{y}\\hat{z}\end{array}\right] =\left[\begin{array}{ccc}f&amp;0&amp;0&amp;0\0&amp;f&amp;0&amp;0\0&amp;0&amp;1&amp;0\end{array}\right]\left[\begin{array}{c}X\Y\Z\1\end{array}\right]$$ 具体步骤就是将x和y同时除以一个不为0的z，并且将z作为其添加维度的坐标，通常可以选择z=1。 内参数 与相机自身特性相关的参数，比如相机的焦距、像素大小等； 从成像平面坐标系到像素坐标系的变换。 上面推导中使用的像点坐标p=(x,y)是成像平面坐标系下，以成像平面的中心为原点。而实际像素点的表示方法是以像素来描述，坐标原点通常是图像的左上角，X轴沿着水平方向向左，Y轴竖直向下。 像素是一个矩形块，这里假设其在水平和竖直方向的长度分别为：α和β。所以像素坐标和成像平面坐标之间，相差了一个缩放和原点的平移。 假设像素坐标的水平方向的轴为μ，竖直方向的轴为ν，那么将一个成像平面的坐标(x,y)在水平方向上缩放α倍，在竖直方向上缩放β倍，同时平移((c_x,c_y)，就可以得到像素坐标系的坐标(μ,ν)，其公式如下：$$\begin{array}{c}u = \alpha\cdot x+ c_x \v = \beta \cdot y + c_y\end{array}$$带入$$\left{\begin{array}{c}u = \alpha\cdot f\frac{X}{Z}+ c_x \v = \beta \cdot f\frac{Y}{Z} + c_y\end{array}\right. \Rightarrow \left{\begin{array}{c}u = f_x\frac{X}{Z}+ c_x \v = f_y\frac{Y}{Z} + c_y\end{array}\right. 其中，f_x = \alpha \cdot f,f_y = \beta \cdot f$$ 齐次坐标的形式：$$\left[\begin{array}{c}\mu\\nu\1\end{array}\right] = \frac{1}{Z}\left[\begin{array}{ccc}f_x&amp;0&amp;c_x\0&amp;f_y&amp;c_y\0&amp;0&amp;1\end{array}\right]\left[\begin{array}{c}X\Y\Z\end{array}\right]$$齐次坐标性质：缩放一个常量因子仍然是相等的：$$s(a,b,c)^T=(sa,sb,sc)^T$$ 将Z挪到左边：$$\left[\begin{array}{c}\mu\\nu\1\end{array}\right]=Z\left[\begin{array}{c}\mu\\nu\1\end{array}\right] =\left[\begin{array}{ccc}f_x&amp;0&amp;c_x\0&amp;f_y&amp;c_y\0&amp;0&amp;1\end{array}\right]\left[\begin{array}{c}X\Y\Z\end{array}\right]$$ 相机的内参数矩阵（Camera Intrinsics）K ：$$K=\left[\begin{array}{ccc}f_x&amp;0&amp;c_x\0&amp;f_y&amp;c_y\0&amp;0&amp;1\end{array}\right]$$ K有4个未知数和相机的构造相关，fx,fy和相机的焦距，像素的大小有关；cx,cy是平移的距离，和相机成像平面的大小有关。 相机成像的公式：$$p = KP$$其中，p是图像中像点的像素坐标， K是相机的内参数矩阵， P是下的三维点坐标。 求解相机内参数的过程被称为**标定**，在**SLAM（ simultaneous localization and mapping， 即时定位与地图构建 ）**中可以假定相机的内参是已知的，**而在三维重建中内参数则是未知的**，需要手动的标定（比如使用标定板），也有自标定的方法，不过精度较低 。 外参数 在世界坐标系中的参数，比如相机的位置、旋转方向等。 上式三维点坐标是在相机坐标系下的，相机坐标系会随着相机的移动而改变坐标的原点和各个坐标轴的方向。引入一个稳定不变坐标系：世界坐标系，该坐标系是绝对不变，SLAM中的视觉里程计就是求解相机在世界坐标系下的运动轨迹。 设Pc是P在相机坐标系坐标，Pw是其在世界坐标系下的坐标，可以使用一个 3×3 旋转矩阵R和一个 3×1平移向量t，将Pc变换为Pw ：$$P_c = RP_w + t$$ 其齐次坐标：$$\left[\begin{array}{c}X_c\Y_c\Z_c\1\end{array}\right] = \left[\begin{array}{ccc}R_{11}&amp;R_{12}&amp;R_{13}&amp;t_1\R_{21}&amp;R_{22}&amp;R_{23}&amp;t_2\R_{31}&amp;R_{32}&amp;R_{33}&amp;t_3\0&amp;0&amp;0&amp;1\end{array}\right]\left[\begin{array}{c}X_w\Y_w\Z_w\1\end{array}\right]$$ 化简得：$$\left[\begin{array}{c}X_c\Y_c\Z_c\1\end{array}\right] = \left[\begin{array}{cc}R&amp;t\0^T&amp;1\end{array}\right]\left[\begin{array}{c}X_w\Y_w\Z_w\1\end{array}\right]$$ 相机的外参数（Camera Extrinsics）T ：$$T = \left[\begin{array}{cc}R&amp;t\0^T&amp;1\end{array}\right]$$结合内外参数得出 相机最终的成像矩阵矩阵 ： 从 将真实场景中的三维点投影（ 世界坐标系 ）到二维的成像平面 ( 图像像素坐标系 )$$\left[\begin{array}{c}\mu\\nu\1\end{array}\right] = \left[\begin{array}{ccc}f_x&amp;0&amp;c_x&amp;0\0&amp;f_y&amp;c_y&amp;0\0&amp;0&amp;1&amp;0\end{array}\right]\left[\begin{array}{cc}R&amp;t\0^T&amp;1\end{array}\right]\left[\begin{array}{c}X_W\Y_W\Z_W\1\end{array}\right]$$ p=(μ,ν)是像素坐标系中的像素点； Pc=(Xc,Yc,Zc)是相机坐标系场景中的三维点； 带入外参数，将该坐标变换为世界坐标系Pw=(Xw,Yw,Zw) 。 之后还有一系列畸变矫正、数字化处理等操作暂时不必了解太细。 相机坐标系参数转换 fx, fy: The focal length used to take image in pixels cx, cy: The centre of the image. Ideally it is equal to (height/2, width/2) The focal len in pixels is calculated from the Field of View and Sensor Size of camera, as derived from here: 12345F = A / tan(a) Where, F = Focal len in pixels A = image_size/2 a = FOV/2 Here are the calculation for our synthetic images, with angles in degrees for image output at 288x512p: 12Fx = (512 / 2) / tan( 69.40 / 2 ) = 369.71 = 370 pixelsFy = (288 / 2) / tan( 42.56 / 2 ) = 369.72 = 370 pixels 旋转矩阵 123456789101112zAxis = origin - lookatyAxis = upxAxis = torch.cross(yAxis, zAxis, dim=1)xAxis = xAxis / torch.sqrt(torch.clamp(torch.sum(xAxis * xAxis, dim=1).unsqueeze(1), min=1e-10))yAxis = yAxis / torch.sqrt(torch.clamp(torch.sum(yAxis * yAxis, dim=1).unsqueeze(1), min=1e-10))zAxis = zAxis / torch.sqrt(torch.clamp(torch.sum(zAxis * zAxis, dim=1).unsqueeze(1), min=1e-10))# print("xAxis: ", xAxis.shape)xAxis = xAxis.view([batchSize, 3, 1])yAxis = yAxis.view([batchSize, 3, 1])zAxis = zAxis.view([batchSize, 3, 1])rotMat = torch.cat([xAxis, yAxis, zAxis], dim=2) bug‘No module named ‘quaternion’’conda install -c conda-forge quaternion No module named ‘skimage’conda install scikit-image No module named ‘open3d’conda install -c open3d-admin open3d No module named ‘pytorch3d’项目链接：https://github.com/facebookresearch/pytorch3d ubuntu conda install pytorch3d -c pytorch3d window https://www.cnblogs.com/VVingerfly/p/13502376.html No module named ‘openEXR’主要是window报这个错，因为直接pip install openEXR会出现编译问题。 参考在windows上安装python库–pyexr 先下载对应python版本的OpenEXR库文件 pip install 下载位置\OpenEXR-1.3.2-cp37-cp37m-win_amd64.whl 就可以了。 发生了一个小意外，当时运用openEXR库中的Imath moudle 误导入了imath库， 哈哈哈哈，发现有人用韩文做函数名也是可以的。 AttributeError: Can’t pickle local object ‘Sharpen..create_matrices’参考：https://blog.csdn.net/weixin_43866860/article/details/93890551 把Pytorch的DataLoader模块，当 num_workers设置为0. 因为window没有Ubuntu的fork()调用。 AttributeError: module ‘numpy’ has no attribute ‘float128’参考：https://blog.csdn.net/tianxifeng/article/details/103523076 首先去https://www.lfd.uci.edu/~gohlke/pythonlibs/网站下载编译好的二进制安装包PyOpenGL，在pip安装（但还是没有解决，因此去Ubuntu吧。） Missing key(s) in state_dict: “module.backbone.layers.0.stage_1.layers.0.weight”,去掉字典里的‘module.’ 当前模型框架 数据集由 realsense（现实场景）与cleargrasp（透明物体）两部分组合，其中cleargrasp（透明物体）需要自己生成ground truth 疑问： 单个数据集所给参数不一致，所以单独训练网络？ 担心泛化能力。 每次训练接着上一次训练，运行12个小时的结果（训练时长太长，一个物品5000张图片，训练集有5种物品2.5W张图片）并且运行时间稍长电脑就会卡。 训练Normal时内存不够RuntimeError: CUDA out of memory. Tried to allocate 480.00 MiB (GPU 0; 7.79 GiB total capacity; 4.55 GiB already allocated; 362.38 MiB free; 6.21 GiB reserved in total by PyTorch) (malloc at /opt/conda/conda-bld/pytorch_1587428398394/work/c10/cuda/CUDACachingAllocator.cpp:289) 能否用生成的数据做groud truth? ClearGrasp没有多视角结果图,但是包含大量的透明物体(能够做透明物体的视觉合成) RealEstate10K没有对应的法线轮廓图,迁移过去(细节丢失较为严重,但是对于有孔洞的场景能够表示出来) 透明多视角数据集的构建所需其中Laval数据集(或许可用HDR+ Burst Photography Dataset代替)需要翻墙. http://indoor.hdrdb.com/ 需要和http://vision.gel.ulaval.ca/~jflalonde/ 这位研究员索要,邮箱:jflalonde@gel.ulaval.ca 索要内容如下: title: Academic research application for The Laval Indoor HDR Dataset Dear Prof. Jean-François Lalonde, Thank you for reading!This is from College of Computer Science and Electronic Engineering, Hunan University, China. I am now a master student and is studying and doing research on Computer Vision. I am currently constructing my dataset according to this paper that applies to The Laval Indoor HDR Dataset. This paper is “ Through the Looking Glass: Neural 3D Reconstruction of Transparent Shapes” :https://arxiv.org/abs/2004.10904I am wondering if you could kindly send me the Laval Indoor HDR Dataset and the necessary information about it. I am willing to fill in and sign the terms of use agreement to download the dataset and promise they will be used only for research purposed. Thank you very much for your kind consideration and I am looking forward to your early reply. All the best,Zezu Wang Zezu Wang（王泽祖）a graduate student in computer technology,Hunan University, Changsha, China Emial:zezuwang@hnu.edu.cn zezuwang@gmail.com Laval Indoor scene dataset: Please download the dataset from this link. We use 1499 environment map for training and 645 environment map for testing. Please turn the .exr files into .hdr files, since our renderer does not support loading .exr files yet. Please save the training set and testing set in Envmap/train and Envmap/test separately. 来源：HDR文件格式简介 .hdr HDR的全称是High-Dynamic Range(高动态范围)。在此，我们先解释一下什么是Dynamic Range（动态范围），动态范围是指图像中所包含的从“最亮”至“最暗”的比值，也就是图像从“最亮”到“最暗”之间灰度划分的等级数；动态范围越大，所能表示的层次越丰富，所包含的色彩空间也越广。那高动态范围(HDR)顾名思义就是从“最亮”到“最暗”可以达到非常高的比值。 以HDRsoft的高动态范围（HDR）图像格式保存的光栅图像或数码照片； 用于增强数字图像的色彩和亮度范围； 可以进行处理以修正暗影或洗掉图像的某些区域。 .exr OpenEXR是由工业光魔（Industrial Light &amp; Magic）开发的一种HDR标准。OpenEXR文件的扩展名为.exr，常见的OpenEXR文件是FP16（16bit Float Point，也被称为half Float Point）数据图像文件，每个通道的数据类型是FP16，一共四个通道64bpp，每个通道1个bit位用来标志“指数”，5个bit用来存放指数的值，10个bit存放色度坐标（u，v）的尾数，其动态范围从6.14 × 10 ^ -5到6.41 × 10 ^ 4。 以OpenEXR格式存储的光栅图像，这是由Industrial Light＆Magic开发的一种高动态范围（HDR）图像文件格式； 支持多层图像，有损和无损压缩以及16位和32位像素； 用于存储深光栅图像以获得高质量图形； 由光栅图形编辑程序和成像应用程序使用. Optix Renderer: Please download our Optix-based renderer from this link. There is an Optix renderer included in this repository. But it is the renderer specifically modified to render the two-bounce normal. Please use the renderer from the link to render images. We will refer to the renderer in this repository as renderer-twobounce and the renderer from the link as renderer-general in the following to avoid confusion. Colmap: Please install Colmap from this link. We use Colmap to reconstruct mesh from point cloud. Meshlab: Please install Meshlab from this link. We use the subdivision algorithm in Meshlab to smooth the surface so that there is no artifacts when rendering transparent shape. This is important when the BRDF is a delta function. 环境配置window（一直出错）编译OptiX SDK 6.5.0 VS2015 参考【OptiX】OptiX介绍与示例编译 Optix SDK sample编译 ## ubuntu cmake 123sudo apt install cmake-qt-gui# 打开图形化cmake界面cmake-gui CUDA &amp; OptiX Installing the latest NVidia Driver, CUDA, and OptiX on Linux/Ubuntu 18.04 编译OptiX SDK7.1.0 123456789101112#到.../NVIDIA-OptiX-SDK-7.1.0-linux64-x86_64/SDK/下mkdir buildcd build/#gcc对应版本cmake .. -DCMAKE_C_COMPILER=/usr/bin/gcc-7make -j4显示[100%] Linking CXX executable ../bin/optixHair[100%] Built target optixHair则成功 编译OptiX SDK6.5.0 出现”Found OpenGL: /usr/lib/x86_64-linux-gnu/libOpenGL.soCMake Error at /usr/share/cmake-3.10/Modules/FindPackageHandleStandardArgs.cmake:137 (message):Could NOT find GLUT (missing: GLUT_glut_LIBRARY GLUT_INCLUDE_DIR)” 参考: 在Windows/Ubuntu下安装OpenGL环境（GLUT/freeglut)与跨平台编译（mingw/g++） 1sudo apt-get install build-essential freeglut3 freeglut3-dev binutils-gold 搞定 opencv 下载镜像 ubuntu18.04下编译OpenCV3.4.9 注意一下python的版本,切换成自己常用的,删掉python2 12测试~/opencv-3.4.9/samples/cpp/example_cmake$g++ example.cpp -L /home/pabebe/opencv-3.4.9/build/lib -I /home/pabebe/opencv-3.4.9/build/include/ -lopencv_calib3d -lopencv_objdetect -lopencv_core -lopencv_photo -lopencv_dnn -lopencv_shape -lopencv_features2d -lopencv_stitching -lopencv_flann -lopencv_superres -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_video -lopencv_imgproc -lopencv_videostab -lopencv_ml the DevIL image library 来源:https://zoomadmin.com/HowToInstall/UbuntuPackage/libdevil-dev 12sudo apt-get update -ysudo apt-get install -y libdevil-dev 以下均用的OptiX SDK6.5.0, 因7.1.0会报错 编译 OptixRenderer(renderer-twobounce,论文已经包含的两次折射反射)12cmake-gui如图配置 最后,在build目录下打开终端 123makeormake -j4 出现’’[100%] Linking CXX executable ../../bin/optixRenderer’完成 ### 编译 OptixRenderer(renderer-general) 下载链接 步骤同上. Meshlab参考Ubuntu下安装MeshLab教程 12345678910sudo add-apt-repository ppa:zarquon42/meshlabsudo apt-get updatesudo apt-get install meshlab卸载sudo apt-get remove meshlab移除PPA，输入以下命令：sudo apt-get install ppa-purgesudu ppa-purge ppa:zarquon42/meshlab Colmap参考 COLMAP在Ubuntu18.04下安装 三维重建_COLMAP安装、使用和参数说明（翻译自官方文档） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#依赖sudo apt-get install git cmake build-essential libboost-program-options-dev libboost-filesystem-dev libboost-graph-dev libboost-regex-dev libboost-system-dev libboost-test-dev libeigen3-dev libsuitesparse-dev libfreeimage-dev libgoogle-glog-dev libgflags-dev libglew-dev qtbase5-dev libqt5opengl5-dev libcgal-dev sudo apt-get install libcgal-qt5-devsudo apt-get install libatlas-base-dev libsuitesparse-dev#Ceres Solver优化库安装git clone https://ceres-solver.googlesource.com/ceres-solvercd ceres-solvergit checkout $(git describe --tags) # Checkout the latest releasemkdir buildcd buildcmake .. -DBUILD_TESTING=OFF -DBUILD_EXAMPLES=OFFmakesudo make install#安装colmapgit clone https://github.com/colmap/colmapcd colmapgit checkout devmkdir buildcd buildcmake ..makesudo make install exr文件转hdr文件1234sudo apt install pfstoolssudo apt install pfsviewfor img in *.exr; do pfsin $&#123;img&#125; | pfsout $&#123;img%%.exr&#125;.hdr; donesudo mv *.hdr /media/pabebe/E/download/100samplesDataset/hdr/train/ http://pfstools.sourceforge.net/download.html 生成123456789101112131415161718192021# 生成3000随机透明物体形状python createShape.py --mode train --rs 0 --re 3000# 生成相机参数以及对应depth maps渲染的xmlpython createRenderFilesForDepths.py --mode train --rs 0 --re 3000# 对于每种形状，从不同的视图渲染75个depth maps，并将depth maps融合在一起以生成一个meshpython renderAndIntegrate.py --mode train --rs 0 --re 3000 --renderProgram /home/pabebe/workspace/OptixRenderer-master/build/bin/optixRenderer# 为10个视图重建创建相机姿势python createCamera10.py --mode train --rs 0 --re 3000#创建渲染文件python createRenderFilesRegularized.py --mode train --rs 0 --re 3000 --envRoot /media/pabebe/E/download/100samplesDataset# 一个形状渲染10张图片python renderImage.py --camNum 10 --mode train --rs 0 --re 3000 --renderProgram /home/pabebe/workspace/OptixRenderer-master/build/bin/optixRenderer# 渲染the ground-truth 两次折射或反射后的法线和深度python renderTwoBounce.py --camNum 10 --mode train --rs 0 --re 3000 --renderProgram /home/pabebe/workspace/TransparentShapeDatasetCreation/OptixRenderer/build/bin/optixRenderer#为每个形状创建10个视图visual hull 。python createVisualHull.py --camNum 10 --mode train --rs 0 --re 3000#创建对应的渲染xml python createRenderFileForVH.py --camNum 10 --mode train --rs 0 --re 3000#结合两次折射或反射后的法线和深度渲染visual hull python renderTwoBounceVisualHull.py --camNum 10 --mode train --rs 0 --re 3000 sh: 1: xvfb-run: not found Xvfb是一个在类Unix系统中运行在内存的显示服务器，让你可以没有连接物理显示设备就能运行图形用户界面程序（比如谷歌浏览器）。许多人用Xvfb运行早期版本的谷歌浏览器来做“headless”测试。 sudo apt install xvfb 相机参数camera中有三个参数，position、lookAt、up。 position，设置camera的位置。也就是把摄像机放在哪里。 lookAt，设置camera看向的位置，即摄像机在position的位置看向哪里。若position设置为（500,500,500），lookAt设置为（100,100,100）。其意思就是把camera放在坐标为（500,500,500）的位置，并把摄像头对准（100,100,100）位置看过去。 up。为摄像头的正方向。假设人眼为摄像头，那么摄像头的正方向就是从嘴巴–&gt;眼睛–&gt;头顶的方向为正方向。那么如果设置up为（1,0,0），则说明摄像头正方向（嘴巴–&gt;眼睛–&gt;头顶的方向）正方向和X轴的正方向平行。若up为（-1,0,0），则与X轴的负半轴平行。同理yz轴一致。（up值决定了你是躺着看，还是站着看还是倒立着看） 球坐标系球坐标系是一种利用球坐标(r,θ,φ)来表示一个点 P 在三维空间的位置的三维正交坐标系。 下图描述了球坐标的几何意义：原点O与目标点P之间的径向距离为r，O到P的连线与正z-轴之间的夹角为天顶角θ，O到P的连线在xy-平面上的投影线与正x-轴之间的夹角为方位角φ。 假设 P 点在三维空间的位置的三个坐标是 (r,theta,phi)。那么， 0 ≤ r 是从原点到 P 点的距离， 0 ≤ θ ≤ π 是从原点到 P 点的连线与正 z-轴的夹角， 0 ≤ φ &lt; 2π 是从原点到 P 点的连线在 xy-平面的投影线，与正 x-轴的夹角。当 r=0 时，theta 与 phi 都一起失去意义。当 theta = 0 或 theta = pi 时，phi 失去意义。 训练1normal2 gt 出现 nan值, 说明之前渲染有问题 39\ 参考文章 SLAM入门之视觉里程计(2)：相机模型（内参数，外参数) 讲的很详细 [图像]畸变校正详解 针孔相机投影模型以及畸变模型 多视图几何基础——深入理解相机内外参数 预处理realEstate10K代码，由于是两年前的版本不适用于现在，因此大幅度修改。 相机成像原理：世界坐标系、相机坐标系、图像坐标系、像素坐标系之间的转换 如何使用Typora编辑数学公式]]></content>
      <categories>
        <category>Scientific Research</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理财小知识]]></title>
    <url>%2Farticle%2Fd95dcfe5%2F</url>
    <content type="text"><![CDATA[建议选择稳健型基金，收益率比余额宝高些，风险比黄金低，（战乱买黄金，牢记） 还有一些常识性理财！黄金260多一克的时候，二话不说，纸黄金买买买！拿到多少自己看心情。这个是3月份发的，6月底黄金涨到320一克。三个月时间 将近24%的收益。这种不是每年都有，但是碰到了是万万不能错过的。 人民币兑美元汇率低于6.3左右，去买美元，逐步买入，各家银行都有兑汇的app的，可自助操作，每个客户一年最高可以兑换5万美金。等到1：6.8左右出来！ 上证指数低于2600点，直接买指数基金(上证300)或者混合基金！做到3100左右，卖出。15%-30%的收益是可预期的。 作者：适者生存链接：https://www.zhihu.com/question/338230721/answer/772930310来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。]]></content>
      <categories>
        <category>Finance</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[迁移Ubuntu18.04至新硬盘]]></title>
    <url>%2Farticle%2F2f7fc36c%2F</url>
    <content type="text"><![CDATA[在U盘启动盘-ubuntu下进行 查看分区情况1sudo apt-get install gparted 打开gparted,总共3个硬盘 a是1T机械盘(安装Ubuntu18),b是256G固态盘(安装window),c是1T固态盘 目标:把a中的Ubuntu18移动到c 创建分区 选中/dev/sdc2 , 编辑-&gt;清除所有操作-&gt;’gpt’ ,此时sdc变成未分配的情况. efi分区 swap分区 /分区 点击 √-&gt;’应用所有操作’,结果如下: 复制数据123456sudo su# efidd if=/dev/sda6 of=/dev/sdc1# /dd if=/dev/sda7 of=/dev/sdc3 磁盘检查与创建新uuid三个分区均需要GParted软件-》选中对应分区-》checkGParted软件-》选中对应分区-》new uuid 记录ubuntu各分区的信息 Old disk old uuid new disk new uuid type efi /dev/sda6 E363-0A42 /dev/sdc1 3CA3-7D72 FAT32 swap /dev/sda5 b289a466-5778-4506-b541-50581e90e693 /dev/sdc2 a2ab8de2-49a7-48e2-983c-e3d4b8996b84 Linux Swap / /dev/sda7 38c27326-c630-4f96-a8fb-dc8a7831cc9b /dev/sdc3 4e11cead-f119-494e-b08c-0909caa6bd32 Ext4 更新 grub引导123456789101112131415161718192021222324252627282930313233343536373839404142434445sudo su# 挂载新分区的efi /mount /dev/sdc3 /mntmount /dev/sdc1 /mnt/boot/efi# 挂在虚拟文件系统mount --o bind /dev /mnt/devmount --o bind /proc /mnt/procmount --o bind /sys /mnt/sys# 切换根目录为新分区的/chroot /mnt# 修改对应uuidnano /etc/fstabnano /boot/grub/grub.cfg在grub.cfg中只会出现根分区的uuid，所以直接用“ctrl+\”找出所有表中原根目录uuid的地方替换为新根目录uuid。替换全部A，ctrl+x,回车# grub安装到efi分区grub-install /dev/sdc1Installing for x86_64-efi platform.Installation finished. No error reported.#更新grubupdate-grubSourcing file `/etc/default/grub'Generating grub configuration file ...Found linux image: /boot/vmlinuz-5.4.0-49-genericFound initrd image: /boot/initrd.img-5.4.0-49-genericFound linux image: /boot/vmlinuz-5.4.0-48-genericFound initrd image: /boot/initrd.img-5.4.0-48-genericFound Ubuntu 18.04.5 LTS (18.04) on /dev/sda7Adding boot menu entry for EFI firmware configurationdone# 同步sync# 退出根目录exit# 取消挂载umount /mnt/devumount /mnt/sysumount /mnt/procumount /media/ubuntu/*umount /mnt/boot/efi# 退出rootexit# 重启,屏幕无信号后拔出U盘reboot 重启选择新硬盘中的ubuntu,更新所有系统的引导 12#使grub2得到所有可以启动的系统sudo update-grub 删除原硬盘上的ubuntu引导以及系统12345678su rootcd/boot/grub# 备份cp grub.cfg grub.cfg.backupgedit grub.cfg删除/dev/sda7所在的引导信息从menuentry 'Ubuntu 18.04.5 LTS (18.04) (在 /dev/sda7)'到menuentry 'Windows Boot Manager (在 /dev/sdb1)' 之间的内容 重启，删除给ubuntu的分区 参考https://zhuanlan.zhihu.com/p/126228018 https://www.jianshu.com/p/20b0fdbc2d68 https://blog.csdn.net/u014670893/article/details/94331736 https://www.jianshu.com/p/478567d8b14a]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日期提醒python程序]]></title>
    <url>%2Farticle%2F61f6d1ab%2F</url>
    <content type="text"><![CDATA[why因为英文版ipone没有农历日期提醒（挺不方便的）， 所以实现了个日期提醒python程序。 How to do电脑作为数据库与服务器，每天查询一次“今天是否有需要提醒的事件”，然后推送到ipone上。 ipone作为客户端 -最简单的推送提醒服务-Bark]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习踩坑实录]]></title>
    <url>%2Farticle%2F43ed33f1%2F</url>
    <content type="text"><![CDATA[类型特征one_hot编码来源:Pytorch中，将label变成one hot编码的两种方式 ​ 解释TORCH.SPARSE 总结: 方法一: 先转张量,再编码 但是有个小问题,若取出一列变成张量之后怎么和原来的数据合并呢? 123456789101112import torch(1)label = np.random.randint(0,class_num,size=(batch_size,1))label = torch.LongTensor(label)y_one_hot =torch.zeros(batch_size,class_num).scatter_(1,label,1)print(y_one_hot)(2) ones = torch.sparse.torch.eye(class_num) return ones.index_select(0,label)二维标签先转成向量形式,再one-hot编码,最后转回二维 方法一: 先编码,再转张量 利用np.hstack合并 data = data.reindex(columns=new_col, fill_value=onehot_encoded)不知道fill_value到底需要什么类型…反正ndarrary不行 123456789101112131415# 完整示例from sklearn import preprocessing# 类别data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']values = array(data)print(values)# integer encodelabel_encoder = preprocessing.LabelEncoder()integer_encoded = label_encoder.fit_transform(values)print(integer_encoded)# binary encodeonehot_encoder = preprocessing.OneHotEncoder(sparse=False)integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)onehot_encoded = onehot_encoder.fit_transform(integer_encoded)print(onehot_encoded) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 个人运用def dataPre(): data = pd.read_csv('18_19_各类销量.csv') # print(data) data = data[['类型', '标价', '折扣', '库存', '销量']] class_data = data['类型'] values = np.array(class_data) # print(values) # integer encode label_encoder = preprocessing.LabelEncoder() integer_encoded = label_encoder.fit_transform(values) # print(integer_encoded) # binary encode onehot_encoder = preprocessing.OneHotEncoder(sparse=False) integer_encoded = integer_encoded.reshape(len(integer_encoded), 1) onehot_encoded = onehot_encoder.fit_transform(integer_encoded) # print(onehot_encoded) # onehot_dataframe = pd.DataFrame(onehot_encoded, index=None) # print(onehot_dataframe) # onehot_dataframe.rename(columns=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']) data = data.drop(columns='类型', axis=1) # print('f', data) # new_col = ['类型', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '标价', '折扣', '库存', '销量'] # print(new_col) # data = data.reindex(columns=new_col, fill_value=0) # data = data.reindex(columns=new_col, fill_value=onehot_encoded) # print(data) # 转成narrary合并编码与原数据集 data = np.hstack((integer_encoded, data)) # data = np.hstack((onehot_encoded, data)) # data = pd.merge(data, onehot_dataframe, on='9') print(data) dataFrame = pd.DataFrame(data) dataFrame.to_csv('here.csv') X = [] Y = [] # for i in range(data.shape[0] - sequence): # X.append(np.array(data.iloc[i:(i + sequence), 0:4], dtype=np.float32)) # Y.append(np.array(data.iloc[(i + sequence), 4], dtype=np.float32)) for i in range(data.shape[0] - sequence): # print(data[i:(i + sequence), 0:12]) X.append(np.array(data[i:(i + sequence), :4], dtype=np.float32)) Y.append(np.array(data[(i + sequence), 4], dtype=np.float32)) # print(X[0]) # print(Y[0]) total_len = len(X) train_x, train_y = X[:int(0.7 * total_len)], Y[:int(0.7 * total_len)] test_x, test_y = X[int(0.7 * total_len):], Y[int(0.7 * total_len):] train_loader = DataLoader(dataset=Mydataset(train_x, train_y, transform=transforms.ToTensor()), batch_size=batch_size, ) test_loader = DataLoader(dataset=Mydataset(test_x, test_y), batch_size=batch_size, ) return train_loader, test_loader 12import moduleprint(module.__file__) bugsklearn. DLL load failed: %1 不是有效的 Win32 应用程序从ubuntu换到window执行程序，突然报这个错 不仅重装了虚拟环境，差一点就要重装conda了。。。 解决方案： 删掉对应scikit-learn库 123conda uninstall scikit-learn#别用conda安装，还是会报错pip install scikit-learn 同样的什么库报这个错，用这个方法试试。 ImportError: C extension: No module named ‘pandas._libs.tslib’ not built. If you want to import pandas from the source directory, you may need to run ‘python setup.py build_ext –inplace –force’ to build the C extensions first.12conda uninstall pandaspip install pandas 而后pandas库还有问题，看了下报错信息，貌似缺少six库，再一次安装 1pip install six Microsoft Visual C++ Redistributable is not installed, this may lead to the DLL load failure.It can be downloaded at https://aka.ms/vs/16/release/vc_redist.x64.exe 给了方法，下载安装vc_redist.x64.exe即可 调通了一个虚拟环境，另一个就崩了所以重安anconda. RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same主要原因是输入的数据类型与网络参数的类型不符。 RuntimeError: CUDA out of memory. Tried to allocate 82.00 MiB (GPU 0; 7.93 GiB total capacity; 6.88 GiB already allocated; 49.31 MiB free; 6.92 GiB reserved in total by PyTorch)nvidia-smi查看显存情况 RunTime Error : cuda out of memory 放入的图片尺寸过大,导致内存溢出,调整至256*256.]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Arachne：Core-Aware Thread Management]]></title>
    <url>%2Farticle%2F8a41b866%2F</url>
    <content type="text"><![CDATA[Arachne：核心感知线程管理本文包含在第13届USENIX操作系统设计和实现研讨会(OSDI’18)的会议记录中。 主要分为三个模块： 1. Arachne的设计与评估2. Arachne应用于memcache的优点3. Arachne应用于RAMcloud的优点（理解第一部分就较容易理解第二、三部分）温馨提示： 注意：我们使用术语核心core来表示可以支持独立计算线程的任何硬件机制。在具有超线程的处理器中，我们将每个超线程视为单独的逻辑核心，即使其中一些共享单个物理核心。 摘要Arachne是一个新的用户级线程实现，它为具有极短生命周期(仅几微秒)的应用程序提供低延迟和高吞吐量。Arachne是核心感知的：每个应用程序根据其负载确定它需要多少核心；它总是确切地知道它已经分配了哪些核心，并且它控制它的线程在这些核心上的位置。中央核心仲裁器在应用程序之间分配核心。将Arachne添加到分布式缓存memcached，将符合SLO（服务级别目标）的吞吐量提高了37%，将尾延迟减少了10倍以上，并允许分布式缓存与后台应用程序共存，而几乎没有性能影响。将Arachne添加到RAMCloud存储系统后，其写操作吞吐量提高了2.5倍以上。Arachne线程库经过优化，可将缓存未命中降至最低；它可以在320 ns内在不同的核心上启动新的用户线程(具有负载平衡)。Arachne完全在Linux上的用户级别实现；不需要修改内核。 1. 简介网络和存储技术的进步使数据中心服务能够以极低的延迟运行[5]。因此，近年来开发了各种低延迟服务，包括FaRM[11]、Memcached[23]、MICA[20]、RAMCloud[30]和Redis[34]。它们为同一数据中心内的客户端提供低至5µs的端到端响应时间，以及低至1-2µs的内部请求服务时间。这些系统采用各种新技术来实现低延迟，包括轮询而不是中断、内核旁路和运行至完成[6，31]。 论文的引出： 1.背景及问题的引出，2.该问题的现有解决办法及缺陷见第8节 然而，很难构建同时提供低延迟和高吞吐量的服务。实现低延迟的技术，例如为峰值吞吐量保留内核或使用轮询而不是中断，会浪费资源。多级服务(其中为一个请求提供服务可能需要对其他服务器的嵌套请求(例如复制))为资源利用不足创造了额外的机会，特别是如果它们使用轮询来减少延迟。服务内的后台活动，如垃圾收集，要么需要额外的保留(因此未充分利用)资源，要么冒着干扰前台请求服务的风险。理想情况下，应该可以将面向吞吐量的服务(例如MapReduce分布式计算系统[10]或视频处理[22])与低延迟服务共同定位，以便当低延迟服务不需要时，资源完全被面向吞吐量的服务占用。然而，在实践中很少尝试这样做，因为它会影响延迟敏感型服务的性能。 很难将低延迟和高吞吐量结合起来的原因之一是，应用程序必须使用虚拟资源(线程)管理它们的并行性；它们不能告诉操作系统它们需要多少物理资源(核心)，并且它们不知道已经为它们的使用分配了哪些核心。因此，应用程序无法调整其内部并行度以匹配可供其使用的资源，并且它们无法使用特定于应用程序的知识来优化资源的使用。这可能导致核心的利用率不足和过度使用，从而导致资源利用率低和/或性能不佳。应用程序的唯一方法是将线程固定到核心；这会导致应用程序内的核心利用率不足，并且不会阻止将其他应用程序调度到相同的核心上。 Arachne是一个线程管理系统，通过为应用程序提供对它们正在使用的物理资源的可见性来解决这些问题。我们称这种方法为核心感知线程管理。在Arachne中，应用程序线程完全在用户级别进行管理；它们对操作系统不可见。应用程序通过核心而不是线程与系统协商。核心分配给单独的应用程序专用，并在很长的时间间隔(几十毫秒)内保持分配给应用程序。每个应用程序总是确切地知道它分配了哪些核心，并决定如何在核心上调度应用程序线程。核心仲裁器决定将多少核心分配给每个应用程序，并响应于改变的应用程序需求来调整分配。 主要贡献 用户级线程管理系统在过去已经实现了很多次[39，14，4]，并且Arachne的基本功能是在1990年代早期以调度程序激活的形式为原型[2]。Arachne在以下方面是新颖的： 【·Arachne包含用于估计应用程序运行时所需核心数量的机制。——1.核心评估 ​ Arachne的主要内容即设计内容 ·Arachne允许每个应用程序定义一个核心策略，该策略在运行时确定应用程序需要多少个核心，以及如何将线程放置在可用核心上。——2.核心策略 ·Arachne运行时旨在将缓存未命中降至最低。它使用一种新颖的调度信息表示法，没有就绪队列，这为线程创建、调度和同步提供了低延迟和可伸缩的机制。——3.最小化缓存未命中 ·Arachne提供了比调度器激活更简单的公式，基于每个核心使用一个内核线程。——Arachne runtime ·Arachne完全在内核之外运行，不需要修改内核；核心仲裁器是使用Linux cpuset机制在用户级别实现的。Arachne应用程序可以与不使用Arachne的传统应用程序共存。——5.性能隔离 我们已经用C++实现了Arachne runtime和核心仲裁器，并使用合成基准测试程序以及分布式缓存和RAMCloud存储系统对它们进行了评估。Arachne可以在大约320 ns内在不同的核心上启动一个新线程(具有负载平衡)，应用程序可以在20-30µs内从核心仲裁器获得额外的核心。当Arachne被添加到分布式缓存时，它将尾延迟降低了10倍以上，并允许在低延迟下提高37%的吞吐量。Arachne还改进了性能隔离；后台视频处理应用程序可以与分布式缓存共存，而对分布式缓存的延迟几乎没有影响。当Arachne添加到RAMCloud存储系统时，它将写入吞吐量提高了2.5倍以上。 2. 线程问题Arachne的动机是在创建处理大量非常小的请求的服务时遇到的挑战。这些服务可以针对低延迟或高吞吐量进行优化，但使用由操作系统实现的传统线程很难同时实现这两种功能。 例如，以memcached[23]为例，它是一种广泛使用的内存键值存储。memcached在大约10µs内处理请求。内核线程太昂贵，无法为每个传入请求创建一个新的线程，所以memcached使用固定大小的工作线程池。通过一个单独的调度线程以循环方式将新连接静态分配给工作线程。 当memcached启动时，工作线程的数量是固定的，这会导致几个效率低下的问题。如果memcached可用的核心数量小于工作线程的数量，则操作系统将在单个核心上多路传输工作线程，从而导致发送到取消调度的工作线程的请求出现长时间延迟。为了获得最佳性能，必须为每个工作线程保留一个核心。如果后台任务在低负载期间在机器上运行，它们很可能会干扰memcached工作线程，因为有大量不同的工作线程。此外，在低负载期间，每个工作线程将被轻载，增加其核心将进入具有高延迟唤醒的省电状态的风险。如果memcached可以在低负载期间缩减，以便更密集地使用较少数量的内核线程(和核心)，那么它的性能会更好。 此外，memcached对工作线程的静态连接分配可能会导致倾斜工作负载下的负载不平衡，一些工作线程过载，其他工作线程空闲。这会影响延迟和吞吐量。 RAMCloud存储系统提供了另一个示例[30]。RAMCloud是一个内存中的键值存储，可以在大约2µs内处理小的读请求。像memcached一样，它基于内核线程。一个调度线程处理所有网络通信，并使用内核旁路在NIC中轮询传入的数据包。当请求到达时，调度线程将其分派给一组工作线程中的一个执行；这种方法避免了倾斜工作负载的问题。活动工作线程的数量因负载而异。工作线程的最大数量是在启动时确定的，这会产生与memcached类似的问题。 RAMCloud实现了嵌套请求，导致了资源利用率较低，因为无法使用微秒级的空闲时间。当工作线程收到写请求时，它会将新值的副本发送到备份服务器，并在响应原始请求之前等待这些复制请求返回。所有复制请求都在7-8µs内完成，因此工作线程忙等待它们。如果工作线程要休眠，则需要几微秒才能再次唤醒它；此外，上下文切换开销太高，无法在如此短的时间内完成许多有用的工作。结果，工作线程的核心浪费了70-80%的时间来处理写请求；对于小型写操作，服务器的写吞吐量仅为约150 Kops/秒，而对于小型读操作，则约为1 Mops/秒。 Arachne的目标是提供一个线程管理系统，允许将低延迟和高吞吐量更好地结合在一起。例如，每个应用程序都应该将其工作负载与可用核心相匹配，仅根据需要获取尽可能多的核心，并动态调整其内部并行度，以反映分配给它的核心数量。此外，Arachne应该提供一个用户级线程的实现，该实现对于非常短的线程足够有效，并且允许在短暂的阻塞期间（例如用于嵌套请求的阻塞）完成有用的工作。 尽管一些现有的应用程序将从Arachne中受益，但我们预计Arachne将主要用于线程生存期仅为几微秒的新粒度应用程序。由于当前线程基础设施的低效，现在很难或不可能构建这些应用程序。 3. Arachne综述​ 图1：Arachne架构。核心仲裁器使用应用程序中每个内核线程的一个套接字加一页共享内存与每个应用程序通信。 图1显示了Arachne的整体架构。三个组件一起工作来实现Arachne线程。核心仲裁器由一个独立运行的用户进程加上一个链接到每个应用程序的小库组成。Arachne runtime和核心策略是链接到应用程序中的库。不同的应用程序可以使用不同的核心策略。应用程序还可以用自己的线程库替换Arachne runtime和核心策略，同时仍然使用核心仲裁器。 核心仲裁器是一个用户级进程，它管理核心并将它们分配给应用程序。它从每个应用程序收集有关它需要多少核心的信息，并使用简单的优先级机制在竞争应用程序之间划分可用核心。当应用程序需求改变时，核心仲裁器调整核心分配。第4节详细描述了核心仲裁器。 Arachne runtime创建几个内核线程并使用它们来实现用户线程，这些用户线程由Arachne应用程序使用。Arachne用户线程抽象包含类似于基于内核线程的线程包的工具，包括线程创建和删除、锁和条件变量。然而，用户线程上的所有操作都是完全在用户级别执行的，无需进行内核调用，因此它们比内核线程上的操作快一个数量级。第5节更详细地描述了Arachne runtime的实现。 Arachne runtime与核心策略一起工作，核心策略确定应用程序如何使用核心。核心策略使用Arachne runtime收集的性能信息计算应用程序的核心需求。它还确定哪些用户线程在哪些核心上运行。每个应用程序选择其核心策略。核心策略将在第6节中讨论。 Arachne使用内核线程作为核心的代理。runtime创建的每个内核线程都在单独的核心上执行，并且它在运行时具有对该内核的独占访问权限。当仲裁器将核心分配给应用程序时，它会在该内核上解锁该应用程序的内核线程之一；当从应用程序中移除该核心时，在该核心上运行的内核线程会阻塞。Arachne runtime在每个内核线程中运行一个简单的分派器，它在关联的核心上多路复用几个用户线程。 Arachne对用户线程使用协作多线程模型：runtime不会抢占已经开始执行的用户线程。如果用户线程需要长时间执行而不阻塞，则它必须偶尔调用让步方法，该方法允许其他线程在调用线程继续之前运行。我们期望大多数线程要么阻塞要么快速完成，因此应该很少需要调用让步方法。 线程的用户级实现的一个潜在问题是用户线程可能导致底层内核线程阻塞。例如，如果用户线程调用阻塞一个内核调用或引发页面错误，则可能发生这种情况。这会防止在内核调用或页面错误完成之前内核线程运行其他用户线程。以前的用户级线程的实现试图以各种方式解决这种低效问题，通常涉及复杂的内核修改。 Arachne不会采取任何特殊步骤来处理阻塞的内核调用或页面错误。大多数现代操作系统支持异步I/O，因此可以在不阻塞内核线程的情况下实现I/O。考虑到内存成本低和内存尺寸大，如今分页几乎没有成本效益。现代服务器很少发生页面错误，除了初始加载，例如当应用程序启动或文件映射到虚拟内存时。因此，为了简单起见，Arachne不会尝试利用内核线程因页面错误或内核调用而被阻塞的时间。 注意：我们使用术语核心core来表示可以支持独立计算线程的任何硬件机制。在具有超线程的处理器中，我们将每个超线程视为单独的逻辑核心，即使其中一些共享单个物理核心。 4. 核心仲裁器——管理核心并将它们分配给应用程序本节描述核心仲裁器如何要求对(大多数)系统的核心的控制并在应用程序之间分配它们。核心仲裁器有三个有趣的特性。首先，它使用现有的Linux机制完全在用户级别实现核心管理；它不需要任何内核更改。其次，它与不使用Arachne的现有应用程序共存。第三，在优先级机制和从应用程序抢占核心的方式上，它对核心管理采取了合作的方法。 核心仲裁器作为具有root权限的用户进程运行，并使用Linux cpuset机制来管理核心。cpuset是一个或多个核和一个或多个内存库的集合。在任何给定时间，每个内核线程都恰好分配给一个cpuset，Linux调度器确保该内核线程只在该cpuset中的核心上执行。默认情况下，所有线程都在包含所有核心和所有内存库的cpuset中运行。核心仲裁器使用cpuset将特定的核心分配给特定的应用程序。 核心仲裁器将核心分为两组：托管核心和非托管核心。托管核心由核心仲裁器分配；只有Arachne创建的内核线程在这些核心上运行。非托管核心继续由Linux调度。它们由不使用Arachne的进程使用，也由核心仲裁器本身使用。此外，如果Arachne应用程序在Arachne外部创建新的内核线程(例如，使用std：：thread)，则这些线程将在非托管核心上运行。 当核心仲裁器启动时，它为非托管核心创建一个cpuset(非托管cpuset)，并将系统的所有核心放入该集中。然后，它将每个现有内核线程(包括其自身)分配给非托管cpuset；由这些线程派生的任何新线程也将在此cpuset上运行。核心仲裁器还创建一个对应于每个核心的托管cpuset，它包含该单个内核，但最初没有分配给它的线程。为了将一个核心分配给一个Arachne应用程序，仲裁器从非托管cpuset中删除该核心，并将Arachne内核线程分配给该核心的托管cpuset。当任何Arachne应用程序不再需要某个核心时，核心仲裁器将该核心重新添加到非托管cpuset。 该方案允许Arachne应用程序与其线程由Linux内核管理的传统应用程序共存。Arachne应用程序接收对核心的优先访问，除了核心仲裁器为非托管cpuset保留至少一个核心。Arachne runtime使用仲裁器的库包中的三种方法与核心仲裁器通信： ·setRequestedCores：每当其核心需求发生变化时，由runtime调用；指示应用程序在不同优先级级别所需的核心总数(详细信息见下文)。runtime—所需的核心总数–&gt;核心仲裁器 ·blockUntilCoreAvailable：由内核线程调用以向核心仲裁器标识自身，并将内核线程置于休眠状态，直到为其分配了核心。在内核线程唤醒时，此方法返回分配的核心的标识符。内核线程—&gt;核心仲裁器 ·mustReleaseCore：由runtime定期调用；返回值为true意味着调用的内核线程应该调用lockUntilCoreAvailable以将其核心返回给仲裁器。runtime—-如果true返回(即释放)内核线程对应的核心–à核心仲裁器 通常，Arachne runtime处理与核心仲裁器的所有通信，因此这些方法对应用程序是不可见的。但是，应用程序可以通过直接调用仲裁器库包来实现自己的线程和核心管理 上述方法使用Unix域套接字和共享内存页面的集合与核心仲裁器通信(见图1)。仲裁器库为每个内核线程打开一个套接字。此套接字用于向核心仲裁器发送请求，并且还用于在内核线程没有分配核心时将其置于休眠状态。核心仲裁器使用共享内存页将信息传递到仲裁器库；它由核心仲裁器写入，并且对仲裁器库是只读的。（仲裁器库包—–套接字发送核心请求—à核心仲裁器，核心仲裁器—–共享内存页———-à仲裁器库） 当Arachne runtime启动时，它调用setRequestedCores来指定应用程序的初始条件；setRequestedCores通过套接字将信息发送到核心仲裁器。然后runtime为机器上的每个核心创建一个内核线程；所有这些内核线程都调用blockUntilCoreAvailable。block UntilCoreAvailable通过属于该内核线程的套接字向核心仲裁器发送请求，然后尝试从套接字读取响应。这有两个效果：首先，它通知核心仲裁器内核线程可供其管理(请求包括线程的Linux标识符)；其次，套接字读取将内核线程置于睡眠状态。 此时，核心仲裁器知道应用程序的核心需求及其所有内核线程，并且内核线程都被阻塞。当核心仲裁器决定为应用程序分配核心时，它选择应用程序的阻塞内核线程之一在该核心上运行。它将该内核线程分配给与分配的核心相对应的cpuset，然后通过线程的套接字发回响应消息。这会导致线程唤醒，Linux将在给定的核心上调度线程；blockUntilCoreAvailable方法返回，并将核心标识符作为其返回值。然后内核线程调用Arachne调度程序来运行用户线程。 如果核心仲裁器希望从应用程序中收回核心，则它要求应用程序释放核心。核心仲裁器不会单方面抢占核心，因为核心的内核线程可能处于不方便的状态(例如，它可能已经获得了重要的自旋锁)；突然停止它可能会对应用程序产生重大的性能后果。因此，核心仲裁器在共享内存页面中设置一个变量，指示应该释放哪个(哪些)内核。然后等待应用程序响应。 每个内核线程负责定期通过调用mustReleaseCore来测试共享内存中的信息。Arachne runtime在其调度器中执行此操作。如果mustReleaseCore返回true，那么内核线程将按照第5.4节中所述进行清理，并调用blockUntilCoreAvailable。这会通知核心仲裁器并将内核线程置于休眠状态。在这一点上，核心仲裁器可以将核心重新分配给不同的应用程序。 核心仲裁器和应用程序之间的通信机制故意是不对称的：从应用程序到核心仲裁器的请求使用套接字，而从核心仲裁器到应用程序的请求使用共享存储器。套接字很方便，因为它们允许核心仲裁器在等待请求时休眠；它们还允许应用程序内核线程在等待分配核心时休眠。套接字通信相对昂贵(每个方向几微秒)，但它只在应用程序核心需求发生变化时发生，我们预计这不会很频繁。共享内存页很方便，因为它允许Arachne runtime有效地测试来自核心仲裁器的传入请求；这些测试经常进行(每次通过用户线程调度器传递)，因此重要的是它们速度快并且不涉及内核调用。 应用程序可以将释放核心延迟很短的时间，以便达到方便的停止点，例如在没有锁定的情况下。Arachne runtime不会释放核心，直到在该核心上调用调度器，当用户线程阻塞、让步或退出时会发生这种情况。 如果应用程序未能在超时期间(当前为10ms)内释放核心，则核心仲裁器将强制回收该核心。它通过将核心的内核线程重新分配给非托管cpuset来实现这一点。内核线程将能够继续执行，但由于非托管cpuset中其他线程的干扰，它可能会遇到性能下降。 核心仲裁器使用简单的优先级机制为应用程序分配核心。Arachne应用程序可以请求不同优先级的核心(当前实现支持八个)。核心仲裁器从最高优先级到最低优先级分配核心，因此低优先级应用程序可能不会接收核心。如果在特定级别没有足够的核心用于所有请求，则核心仲裁器在请求应用程序之间平均分配核心。每当应用程序请求改变时，核心仲裁器重复此计算。只要可能，仲裁器就将特定硬件核心的所有超线程分配给相同的应用程序。核心仲裁器还试图将应用程序的所有核心保持在同一套接字上。 此核心分配策略假设应用程序(及其用户)将合作选择优先级：行为不当的应用程序可能会通过请求处于最高优先级的所有核心而使其他应用程序处于饥饿状态。通过要求应用程序在首次连接时向核心仲裁器进行身份验证，并允许系统管理员为每个应用程序或用户设置限制，可以防止反社会行为。我们将这种机制留待将来的工作。 5. The Arachne Runtime ——创建内核线程并使用它们来实现用户线程 本节讨论Arachne runtime如何实现用户线程。runtime的最重要目标是为现代多核心硬件提供快速且可伸缩的用户线程实现。我们希望Arachne支持粒度计算，粒度计算由大量生命周期极短的线程组成。例如，低延迟服务器可能会为每个传入请求创建一个新线程，并且该请求可能只需一两微秒即可处理；服务器可能每秒处理数百万个这样的请求。 5.1 缓存最优化设计Arachne runtime的性能由缓存未命中主导。大多数线程操作(如创建线程、获取锁或唤醒阻塞的线程)都相对简单，但它们涉及核心之间的通信。跨核通信需要缓存未命中。例如，要将值从一个核心传输到另一个核心，必须在源核心上写入该值，并在目标核心上读取该值。这需要大约三次高速缓存未命中时间：写操作可能会导致第一次读取数据的高速缓存未命中；然后写操作将使目标高速缓存中的数据副本无效，这需要大约与高速缓存未命中相同的时间；最后，读操作将导致高速缓存未命中以获取数据的新值。高速缓存未命中可能需要50-200个周期，因此即使一个操作仅需要单个高速缓存未命中，该未命中的成本也可能比该操作的所有其他计算都要高。在我们的服务器上，缓存未命中没有在同一套接字中将值从一个核心传输到另一个核心，只要在同一核心上的用户线程之间进行上下文切换，就需要7-8倍的时间。套接字之间的传输甚至更昂贵。因此，我们在实现用户线程时最重要的目标是将缓存未命中降至最低。 可以通过在高速缓存未命中同时执行其他操作来降低高速缓存未命中的有效成本。例如，如果在彼此的几个指令内发生几个高速缓存未命中，则它们都可以以单个未命中的成本来完成(现代处理器具有乱序的执行引擎，其可以在等待高速缓存未命中的同时继续执行指令，并且每个核心具有多个存储器通道)。因此，额外的高速缓存未命中基本上是空闲的。然而，现代处理器具有大约100条指令的无序执行限制，因此代码必须设计为将可能的缓存未命中集中在彼此附近。 类似地，如果孤立地进行数十纳秒的计算发生在缓存未命中附近，则它实际上可能具有零边际成本；它只会在处理缓存未命中时填充时间。第5.3节将展示Arachne调度器如何使用这种技术来隐藏看似昂贵的代码的成本。 5.2 创建线程许多用户级线程包(如GO[14]中的那个)在与父线程相同的核心上创建新线程；它们使用工作窃取来平衡核心之间的负载。这避免了线程创建时的缓存未命中。然而，工作窃取是一个代价高昂的操作(它需要缓存未命中)，这对于寿命较短的线程尤其明显。工作窃取还会在线程被窃取到未加载的核心之前引入一个时间延迟，这会影响服务延迟。对于Arachne，我们决定在线程创建时执行负载平衡；我们的目标是尽快在未加载的核心上获得一个新线程。通过基于缓存未命中优化此机制，我们能够实现线程创建时间与在父核心上创建子线程的系统竞争。 在线程创建期间可能会发生缓存未命中，原因如下： ·负载平衡：Arachne必须以跨可用核心平衡负载的方式为新线程选择核心；在获取描述当前负载的共享状态时，可能会发生缓存未命中。 ·状态转移：线程的顶级方法的地址和参数必须从父核心转移到子核心。 ·调度：父线程必须向子线程的核心表明子线程是可运行的。 ·线程上下文：线程的上下文由其调用堆栈加上Arachne runtime使用的元数据组成，例如调度状态和线程未运行时保存的执行状态。根据此信息的管理方式，可能会导致额外的缓存未命中。 一个用户线程分配一个线程上下文，且线程上下文和用户线程一样专属于一个特定核心，但核心可包含多个线程上下文 下面我们将描述Arachne如何在四次缓存未命中时间内创建新的用户线程。 为了最小化线程上下文的缓存未命中，Arachne将每个线程上下文绑定到单个内核(该上下文仅由单个内核线程使用)。每个用户线程在创建时都被分配给一个线程上下文，并且线程仅在上下文的关联核心上执行。大多数线程的整个生命周期都在一个核心上。线程仅作为显式迁移的一部分移动到不同的核心。这仅在极少数情况下发生，例如当核心仲裁器回收核心时。线程上下文在线程完成后仍然绑定到其核心，并且Arachne在创建新线程时重用最近使用的上下文。如果线程的生存期较短，则可能已经缓存了新线程的上下文。 ​ 一个核心包含一个64位maskAndCount值 要创建新的用户线程，Arachne runtime必须为线程选择一个核心，并分配与该核心关联的线程上下文之一。这些操作中的每一个都可能导致缓存未命中，因为它们操作共享状态。为了将缓存未命中降至最低，Arachne使用相同的共享状态同时执行两个操作。状态由每个活动核心的64位maskAndCount值组成。该值的56位是指示哪个核心的线程上下文当前正在使用的位掩码，而其余的8位是掩码中1的数量的计数。 在创建新线程时，Arachne使用“两个选择的力量”方法进行负载平衡[26]。它随机选择两个核心，读取它们的maskAndCount值，并选择具有最少活动线程上下文的核心。这可能会导致每个maskAndCount的缓存未命中，但它们将被并发处理，因此总延迟是单个未命中的延迟。然后，Arachne扫描所选核心的掩码位以找到可用的线程上下文，并使用原子比较和交换操作来更新所选核心的maskAndCount。如果比较和交换由于并发更新而失败，Arachne会重新读取所选核心的maskAndCount，并重复分配线程上下文的过程。这种创建机制是可伸缩的：使用大量的核心，可以在不同的核心上同时创建多个线程。 一旦分配了线程上下文，Arachne就会将线程的顶级方法的地址和参数复制到上下文中，并通过在上下文中设置一个字大小的变量以指示线程是可运行的来调度线程的执行。为了最大限度地减少缓存未命中，Arachne使用单个缓存行来保存所有这些信息。这将在具有64字节缓存行的计算机上将参数列表限制为6个单一字参数；较大的参数列表必须通过引用传递，这将导致额外的缓存未命中。 通过这种机制，可以在四次缓存未命中时间内在不同的内核上调用新线程。读取maskAndCount需要一个缓存未命中，传输包含方法地址和参数以及调度标志的行需要三个缓存未命中时间，如第5.1节所述。 maskAndCount变量将Arachne限制为每个内核在给定时间内56个线程。因此，依赖于大量阻塞线程的编程模型可能不适合与Arachne一起使用。 5.3 线程调度线程调度的传统方法使用一个或多个就绪队列来标识可运行的线程(通常每个核心一个队列，以减少争用)，加上每个线程的调度状态变量，该变量指示该线程是可运行的还是阻塞的。从高速缓存未命中的角度来看，这种表示是有问题的。在就绪队列中添加或删除条目需要对多个变量进行更新。即使队列是无锁的，当队列在多个核心之间共享时，这可能会导致多个缓存未命中。此外，我们希望共享是常见的：当线程被唤醒时，必须将线程添加到其核心的就绪队列中，但唤醒通常来自不同核心上的线程。 此外，调度状态变量受竞赛的影响。例如，如果一个线程在条件变量上阻塞，但另一个线程在阻塞线程进入睡眠之前通知该条件变量，则对调度状态变量的争用可能会导致唤醒丢失。这种竞争通常通过控制对状态变量的访问的锁来消除。但是，锁定会导致额外的缓存未命中，因为它是跨核共享的。 为了最大限度地减少缓存未命中，Arachne不使用就绪队列。Arachne 调度器不检查就绪队列，而是重复扫描与当前核心关联的所有活动用户线程上下文，直到找到一个可运行的线程。这种方法被证明是相对有效的，原因有两个。首先，我们期望在给定的时间内只有几个线程上下文被一个核心占用(对于间歇性任务，不需要保持阻塞的线程；可以为每个任务创建一个新线程)。其次，扫描活动线程上下文的成本很大程度上被唤醒的线程的调度状态变量上不可避免的缓存未命中所隐藏。此变量通常由不同的核心修改以唤醒线程，这意味着调度程序必须采取缓存未命中来观察新值。在调度器的缓存中使变量的前一个值无效到可以获取新值之间需要100个或更多的周期；在此期间可以扫描大量的线程上下文。第7.4节评估了这种方法的成本。 Arachne还使用了一种新的无锁机制来调度状态。线程的调度状态用线程上下文中的64位wakeupTime**变量**表示。如果线程的wakeupTime小于或等于处理器的细粒度循环计数器，则调度器认为该线程是可运行的。在将控制转移到线程之前，调度器将其wakeupTime设置为可能的最大值。当线程阻塞时，wakeupTime不需要修改：较大的值将阻止线程再次运行。要唤醒线程，wakeupTime设置为0。这种方法消除了前面描述的争用条件，因为当线程阻塞时wakeupTime不会被修改；因此，访问变量不需要同步。 wakeupTime变量还支持基于计时器的唤醒。如果线程希望休眠给定的时间段，或者如果它希望向某些其他阻塞操作(如条件等待)添加超时，它可以在阻塞之前将wakeupTime设置为所需的唤醒时间。Arachne调度器中的单个测试既可以检测正常解锁，也可以检测基于计时器的解锁。 Arachne使用两种方法将wakeupTime机制导出到应用程序： ·block(Time)将阻塞当前用户线程。time参数是可选的；如果指定了它，wakeupTime将设置为此值(使用比较和交换来检测并发唤醒)。 ·signal(Thread)将给定用户线程的wakeupTime设置为0。——即唤醒用户线程 这些方法使得构造更高级别的同步和调度运算符变得容易。例如，在协作多线程中使用的让步方法允许其他用户线程运行，它只是调用block(0)。 5.4 添加和释放核心当核心仲裁器将新的核心分配给应用程序时，它会唤醒在blockUntilCoreAvailable中阻塞的一个内核线程。内核线程通知新核心的核心策略，如下面第6节所述，然后它进入Arachne调度程序循环。——添加核心 当核心仲裁器决定从应用程序中回收核心时，在核心上运行的Arachne调度器中mustReleaseCore将返回true。内核线程修改其maskAndCount以防止在其上放置任何新线程，然后通知回收的核心策略。如果该核心上存在任何用户线程，Arachne runtime会将它们迁移到其他核心。为了迁移线程，Arachne选择一个新的核心(目标核心)，并使用与线程创建相同的机制在该核心上保留未占用的线程上下文。然后，Arachne将正被迁移的线程的上下文与未占用的上下文交换，使得线程的上下文被重新绑定到目的核心，并且来自目的核心的未使用的上下文被重新绑定到源核心。一旦所有线程都迁移走了，通过调用blockUntilCoreAvailable回收核心上的内核线程。这会通知核心仲裁器该核心不再使用，并将内核线程置于休眠状态。——释放核心 6. 核心策略我们Arachne的目标之一是让应用程序精确控制其核心的使用。例如，在RAMCloud中，中央调度线程通常是性能瓶颈。因此，调度线程独占使用核心是有意义的。此外，同一物理核心上的另一个超线程应该是空闲的(如果同时使用两个超线程，则它们各自的运行速度比只使用一个超线程时慢约30%)。在其他应用程序中，可能希望将特定线程托管在相同核心或套接字的超线程上，或者强制所有低优先级后台线程在单个核心上执行，以便最大化可用于前台请求处理的资源。 Arachne runtime不实现核心使用的策略。这些在单独的核心策略模块中提供。每个应用程序在启动时选择特定的核心策略。编写高性能核心策略可能具有挑战性，特别是对于处理NUMA问题和超线程的策略。我们希望可以开发一小部分可重用的策略来满足大多数应用程序的需求，这样应用程序开发人员就很少需要实现自定义的核心策略。 为了管理核心使用情况，核心策略必须知道哪些核心已分配给应用程序。每当应用程序获得或失去核心时，Arachne runtime都通过调用核心策略中的方法来提供此信息。当应用程序创建新的用户线程时，它会为该线程指定一个整数线程类。核心策略使用线程类来管理用户线程；每个线程类对应于特定的服务级别，例如“前台线程”或“后台线程”。每个核心策略定义自己的一组有效线程类。Arachne runtime将线程类与线程一起存储，但不知道如何使用它们。核心策略使用线程类来管理新线程的放置。创建新线程时，Arachne调用核心策略中的方法getCores，并将其传递给线程类。getCores方法使用线程类来选择线程可接受的一个或多个核心。Arachne runtime使用第5节中描述的“两个选择的能力”机制将新线程放置在其中一个核心上。如果核心策略希望将新线程放置在特定核心上，getCores可以返回包含单个条目的列表。当线程必须作为释放核心的一部分进行迁移时，Arachne还会调用getCores为线程找到新的宿主。Arachne的一个不同寻常的特性是，每个应用程序都负责确定它需要多少核心；我们称之为核心估计，它由核心策略处理。Arachne runtime测量每个核心的两个统计信息，它使核心策略可以使用这些统计信息，以便在核心评估中使用。第一个统计数据是利用率，这是每个Arachne内核线程执行用户线程所花费的时间的平均比例。第二个统计数据是负载因子，它是对该核心上可运行用户线程的平均数量的估计。这两个都是通过Arachne调度循环中的几个简单操作来计算的。 6.1 默认核心策略Arachne目前包含一个核心策略；我们在第7节中对所有性能度量使用了默认策略。默认策略支持两个线程类：Exclusive和Normal。每个独占线程在为该特定线程保留的单独核心上运行；当独占线程被阻塞时，其核心处于空闲状态。独占线程对于长时间运行的轮询调度线程很有用。普通线程共享于与用于独占线程的核心不相交的核心池；可以有多个普通线程同时分配给一个核心。 6.2 核心评估默认的核心策略为每个独占线程请求一个核心，另外为普通线程请求额外的核心。估计正常线程所需的核心需要在核心利用率和快速响应时间之间进行权衡。如果我们试图在100%的时间内保持核心忙碌，负载的波动将产生挂起线程的积压，从而导致新线程的延迟。另一方面，我们可以优化快速响应时间，但这会导致核心利用率低。工作负载越突发，必须浪费的资源就越多，以便获得快速响应。 默认策略使用不同的向上扩展和向下扩展机制。按向上扩展的决定基于负载因子：当运行正常线程的所有核心的平均负载因子达到阈值时，核心策略会将其请求的核心数量增加1。我们选择这种方法是因为负载因子是响应时间的相当直观的代理；这使得用户在需要时更容易指定非默认值。此外，性能测量表明，负载因子优于向上扩展的利用率：单个负载因子阈值适用于各种工作负载，而按向上扩展的最佳利用率取决于工作负载的突发性和总体容量。 另一方面，向下扩展基于利用率。负载因子很难用于向下扩展，因为感兴趣的度量不是当前的负载因子，而是少了一个内核就会出现的负载因子；这很难估计。相反，默认核心策略记录每次增加其请求的核心数量时的总利用率(运行正常线程的所有核心的利用率之和)。当利用率返回到略低于此时的水平时，runtime将其请求的核心数量减少1(“稍微减少”的功能提供滞后以防止振荡)。为每个不同数量的请求核心记录单独的向下扩展利用率。 总体而言，有三个参数控制核心估计机制：用于向上扩展的负载因子，用于核心估计的统计数据平均的间隔，以及用于向下扩展的滞后因子。默认核心策略当前使用的负载因子阈值为1.5，平均间隔为50毫秒，滞后系数为9%的利用率。 7. 评估我们在Linux上用C++实现了Arachne；源代码可以在GitHub[33]上找到。核心仲裁器包含4500行代码，runtime包含3400行，默认核心策略包含270行。 我们对Arachne的评估解决了以下问题： ·Arachne线程基元的效率如何？Arachne与其他线程系统相比如何？ ·Arachne的核心感知线程方法是否为低延迟应用程序带来了显著的好处？ ·Arachne的内部机制，如线程调度的无队列方法，以及核心估计和核心分配的机制，对性能有何贡献？ 表1描述了用于基准测试的机器的配置。 表1：用于基准测试的硬件配置。所有节点都运行Linux 4.4.0。C状态已启用，Meltdown缓解已禁用。启用了超线程(每个内核2个超线程)。未将计算机配置为执行数据包引导(如RSS或XPS)。 7.1 调度基元 表2：调度基元的平均成本。创建、通知和信令是端到端测量的，从一个线程中的启动到目标线程醒来并开始在另一个内核上执行。Arachne在与父线程不同的内核上创建所有线程。 Go总是在父核心上创建Go例程。uThread使用循环方法将线程分配给核心；当它选择父核心时，平均成本下降到250 ns。在“单向产出”中，控制权从让步线程传递到同一内核上的另一个可运行线程。在“空产率”中，没有其他可运行的线程，因此控制权立即返回到让步线程。“线程退出周转”测量从一个线程的最后一个指令到下一个线程的第一个指令在内核上运行的时间。N/A表示线程系统不公开测量的基元。“Arachne RQ”意味着Arachne被修改为使用就绪队列，而不是第5.3节中描述的无队列调度机制。“No HT”意味着每个线程使用一个超线程在单独的内核上运行；每个内核的另一个超线程是不活动的。“HT”表示每个内核的另一个超线程处于活动状态，运行Arachne 调度器。 表2将Arachne中基本线程操作的成本与C++ std：：thread、Go和uThread[4]进行了比较。std：：Thread基于内核线程；Go在语言运行时在用户级别实现线程；uThread使用内核线程来复用用户线程，如Arachne。uThread是GitHub上评价很高的C++用户线程库，并声称具有高性能。度量使用微基准，因此它们代表最佳情况下的性能。 Arachne的线程操作比任何其他系统都快得多，除了uThread的产量更快之外。 Arachne的缓存优化设计执行线程创建的速度是GO的两倍，即使Arachne将新线程放置在与父核心不同的核心上，而GO在父核心上创建新线程。 为了评估Arachne的无队列方法，我们对Arachne进行了修改，使其在每个核心上使用无需等待的多生产者单消费者队列[7]来识别可运行的线程，而不是扫描所有上下文。我们从GitHub上的几个候选者中选择了这个实现，因为它的速度和简单性。表2显示，无队列方法比使用就绪队列的方法快28-40%(在Arachne的就绪队列变体中，我们为线程创建计数了三个额外的缓存未命中)。 图2：线程创建吞吐量作为可用内核的函数。在(a)中，单个线程尽可能快地创建新线程；每个子线程消耗1µs的执行时间，然后退出。在(b)中，为每个内核创建3个初始线程；每个线程创建一个子线程，然后退出。 我们设计了Arachne的线程创建机制，不仅是为了最小化延迟，而且是为了提供高吞吐量。我们运行了两个实验来测量线程创建吞吐量。在第一个实验中(图2(a))，单个“调度”线程尽可能快地创建新线程(例如，如果单个线程轮询网络接口以获取传入请求，则可能会发生这种情况)。一个Arachne线程每秒可以产生500多万个新线程，这是GO速率的2.5倍，至少是std：：Thread或uThread速率的10倍。这个实验演示了在线程创建时执行负载平衡的好处。Go的工作窃取方法会产生显著的额外开销，特别是在线程生命周期较短的情况下，并且父工作队列可能会成为瓶颈。在较低的核心计数下，GO表现出比Arachne更高的吞吐量，因为除了其他可用核心之外，它还在创建者的核心上运行线程，而Arachne仅使用创建者的核心进行调度。 第二个实验使用分布式方法测量线程创建吞吐量，其中许多现有线程中的每个线程都创建一个子线程，然后退出(图2(b))。在本实验中，Arachne和GO的吞吐量都随着可用核心数量的增加而扩展。uThread和std：：thread都没有可扩展的吞吐量；uThread的吞吐量比Arachne或Go低10倍，而std：：thread的吞吐量比Arachne或Go低100倍。Go的线程创建方法在这个实验中工作得很好；每个核心都在本地创建和执行线程，并且不需要窃取工作，因为负载自然地平衡了自己。结果，GO的吞吐量是Arachne的1.5-2.5倍。Arachne的性能反映了表2中线程创建和退出周转的成本，以及并发线程创建之间的偶尔冲突。 图2还包括Arachne的就绪队列变体的测量。Arachne的无队列方法为两个实验提供了比就绪队列变体更高的吞吐量。 7.2 Arachne用于分布式缓存的好处我们修改了分布式缓存[23]版本1.5.6以使用Arachne；源代码可以在GitHub[19]上找到。在修改后的版本(“memcached-A”)中，工作线程池被单个调度线程替换，它等待所有连接上的传入请求。当请求到达时，调度线程创建一个新的Arachne线程，该线程的生存期仅足以处理连接上的所有可用请求。memcached-A使用默认的核心策略；调度线程是“独占”的，工作线程是“正常”线程。 memcached-A在原始分布式缓存上提供了两个好处。首先，它减少了内核线程之间(没有多路复用)和应用程序之间(核心专用于应用程序)之间的性能干扰。其次，memcached-A提供了更细粒度的负载平衡(在单个请求而不是连接的级别)。 表3：memcached实验的配置。Program是用于生成工作负载的基准程序(我们的Memtier版本是在原始版本的基础上修改的)。Key和Value给出数据集中键和值的大小(ETC重新创建Facebook ETC工作负载[3]，它模拟memcached的实际使用)。Items是数据集中对象的总数。PUTs是所有PUTs请求的分数(其他请求是GETs)。Clients是客户端的总数(20+1意味着20个客户端生成了密集的工作负载，另外1个客户端使用较轻的工作负载测量了延迟)。Threades是每个客户端的线程数。Conns是每个客户端的连接总数。Pipeline是在减少工作负载之前每个连接允许的最大未完成请求数。IR Dist是请求间时间分布。除非另有说明，memcached配置了16个工作线程，memcached-A自动在2到15个核心之间扩展。 图3：在实际基准下，Memcached和memcached-A获得的吞吐量作为平均值和第99个百分位数的请求延迟的函数。每次测量在5秒热身后运行30秒。Y轴使用对数刻度。 我们使用分布式缓存执行了三个实验；表3总结了它们的配置。第一个实验真实的测量延迟作为真实条件下负载的函数；它使用Mutilate基准[17，27]来重新创建Facebook ETC工作负载[3]。图3(a)显示了结果。分布式缓存的最大吞吐量比memcached-A高20%。这是因为memcached-A使用更少的2个核心 (一个核心为非托管线程保留，另一个为调度器保留)；此外，memcached-A为每个请求生成一个线程会产生开销。然而，memcached-A的延迟明显低于memcached。因此，如果应用程序有服务级别的需求，memcached-A提供更高的可用吞吐量。例如，如果应用程序要求平均延迟小于100µs，则memcached-A支持的吞吐量比memcached高37.5%(1.1 mops/sec与800 kops/sec)。在第99个百分位数时，memcached-A的延迟范围比memcached低3-40倍。我们发现Linux经常在核心之间迁移memcached线程：在高负载下，每个线程每秒迁移大约10次；在低负载下，线程大约每三次请求迁移一次。迁移增加了开销并增加了多路复用的可能性。 我们Arachne的目标之一是自动适应应用程序负载和可用核心的数量，因此管理员不需要指定配置选项或保留核心。图3(b)显示了memcached在分配给它的核心少于它所需的核心时的行为。对于memcached，16个工作线程仅在8个核心上多路复用；memcached-A被限制为最多8个核心。正如预期的那样，两个系统的最大吞吐量都下降了。Arachne继续高效运行：延迟大约与图3(a)中相同。相比之下，memcached在平均和尾部延迟方面都经历了显著增加，这可能是由于额外的多路复用；由于平均延迟限制为100µs，memcached只能处理300 Kops/sec，而memcached-A处理了780 Kops/sec。 图4：Colocation实验中的memcached性能。请求速率从10kops/sec逐渐增加到1mops/sec，然后下降回10kops/sec。在一些实验中，X264视频编码器[25]使用来自Xiph.org[21]的原始视频文件(Sintel-1280.y4m)并行运行。当memcached-A与X264一起运行时，内核仲裁器为memcached-A分配了它所请求的内核数量；X264不由Arachne管理，因此Linux将其调度在memcached-A未使用的内核上。当memcached使用X264运行时，Linux调度程序确定每个应用程序接收到多少内核。默认情况下，X264为自身设置了一个“非常好”的值10；我们没有在这些实验中更改这一行为。(a)显示分配给memcached-A的内核数量；(b)显示memcached和memcached-A的第99个百分位数的尾部延迟；(c)显示平均延迟，加上请求速率；(d)显示视频解码器单独运行或与memcached或memcached-A一起运行时的吞吐量(在结尾平均4秒)。 第二个实验，Colocation，动态地改变负载以评估Arachne的核心估计器。它还测量了memcached和memcached-A与计算密集型应用程序(X264视频编码器[25])协同定位时的性能。结果如图4所示。图4(a)显示，memcached-A在低负载(调度和一个工作线程)时仅使用2个核心，并且随着负载的增加逐渐增加以使用所有可用核心。memcached-A在负载增加时保持接近恒定的平均和尾部延迟，这表明核心估计器选择了更改其核心请求的好点。memcached的延迟高于memcached-A，并且它随负载变化更大；即使在没有后台应用程序的情况下运行时，memcached的99%延迟也比memcached-A高10倍。memcached-A的结尾延迟实际上在高负载时比低负载时要好，因为有更多的核心可用于吸收突发请求。 当后台视频应用程序与memcached共存时，memcached的延迟翻倍，平均和第99个百分位数都是如此，即使后台应用程序以较低的优先级运行。相比之下，memcached-A几乎完全不受视频应用程序的影响。这表明Arachne的核心感知方法改进了应用程序之间的性能隔离。图4(a)显示了memcached-A在与视频应用程序协同定位时更快地提升了其核心使用率。这表明视频应用程序存在一些性能干扰，但核心估计器检测到了这一点，并更积极地分配核心以进行补偿。 图4(d)显示了视频应用程序的吞吐量。在高负载下，它与memcached-A协同定位时的吞吐量不到与memcached协同定位时的一半。这是因为memcached-A将视频应用程序限制在单个非托管核心中。使用memcached，Linux允许视频应用程序消耗更多的资源，这降低了memcached的性能。 图5：具有核心仲裁器(“memcached-A”，与图4相同)和没有核心仲裁器(“NoArbiter”)的协同定位实验中的平均和尾部延迟。 图5显示专用核心是Arachne性能的基础。对于这个图，我们使用一个没有专用核心的memcached-A变体运行了Colocation实验：不是使用核心仲裁器，而是Arachne通过阻塞和解除信号量上的内核线程进行扩展，并且Linux内核调度了未阻塞的线程。如图5所示，无论使用还是不使用后台应用程序，这都会导致延迟显著增加。其他测量表明，当Linux取消调度内核线程时，但Arachne继续将新用户线程分配给该内核线程，会出现延迟峰值；在高负载突发期间，大量用户线程可能会在取消调度的内核线程上搁置许多毫秒。如果没有核心仲裁器提供的专用核心，memcached-A的性能明显低于未修改的memcached。 图4和图5使用了后台视频应用程序的默认配置，其中它将执行优先级降低到“NICE”级别10。我们还在视频应用程序以正常优先级运行的情况下运行了实验；memcached的平均和尾部延迟增加了约2倍，而memcached-A的延迟几乎完全不受影响。由于空间限制，我们省略了细节。 memcached的最后一个实验是skew，如图6所示。当客户端连接之间的负载不均衡时，这个实验将评估memcached的性能。由于静态缓存了工作线程之间的客户端连接，因此可能会出现热点，其中一些工作线程过载，而另一些工作线程处于空闲状态；这可能会导致整体吞吐量较差。相反，memcached-A对每个请求执行负载平衡，因此性能不受跨客户端连接的负载分布的影响。 图6：当目标负载为1.5mops/sec时，工作负载倾斜对memcached性能的影响。最初，负载平均分布在512个连接上(每个memcached工作处理512/16=32个连接)；随着时间的推移，总负载中越来越多的部分通过增加热门工作连接上的请求速率和降低所有其他连接上的请求速率而被定向到一个特定的“热”工作线程。底部的图表显示了memcached中的总体吞吐量以及过载工作线程的吞吐量。 7.3 Arachne用于RAMCloud的好处 图7：当许多客户端执行100字节对象的连续背靠背写入RPC时，单个RAMCloud服务器的吞吐量是以每秒完成的写入数来衡量的。 图8：RAMCloud和RAMCloud-A在修改的YCSB基准[9]上使用100字节对象的比较。两者都使用12台存储服务器运行。Y轴表示30台独立客户端计算机的聚合吞吐量，每台计算机运行8个线程。 我们还修改了RAMCloud[30]以使用Arachne。在修改的版本(“RAMCloud-A”)中，消除了长时间运行的工作线程池，并且调度线程为每个请求创建了一个新的工作线程。忙于等待嵌套RPCs的线程在轮询循环的每次迭代后都会让步。这允许在等待时间内处理其他请求，这样就不会浪费核心。图7显示RAMCloud-A的写入吞吐量是RAMCloud的2.5倍。在YCSB基准测试9上，对于写操作频繁的YCSB-A工作负载，RAMCloud-A提供的吞吐量比RAMCloud高54%。在只读操作的YCSB-C工作负载上，由于Arachne的线程调用和线程退出的开销，RAMCloud-A的吞吐量比RAMCloud低15%。这些实验表明，Arachne使得在阻塞期间短至几微秒安排其他工作变得切实可行。 7.4 Arachne内部机制本节评估对Arachne的性能至关重要的几种内部机制。如第5.3节所述，Arachne放弃使用就绪队列作为其缓存优化设计的一部分；相反，调度器扫描wakeupTime变量以查找占用的线程上下文，直到找到可运行的线程。因此，当核心充满线程时，它的调度器必须遍历越来越多的上下文。为了评估扫描这些标志的成本，我们测量了发送信号通知特定阻塞线程的成本，同时改变目标核心上其他阻塞线程的数量；图9显示了结果。即使在所有56个线程上下文都被占用的最坏情况下，唤醒线程的平均成本也增加了不到100 ns，这相当于大约一个高速缓存一致性未命中。这意味着避免扫描所有活动上下文的替代实现必须在不引入任何新的缓存未命中的情况下这样做；否则其性能将比Arachne差。图9中Arachne的最差情况性能仍然好于表2中Arachne的就绪队列变体。 图9：随着目标核心上线程数量的增加，发出阻塞线程信号的成本。延迟是从紧接在一个内核上发信号之前直到目标线程在另一个核心上恢复执行为止测量的。 图10：从核心请求到核心获取的延迟的累积分布(a)当核心仲裁器具有可用的空闲核心时，以及(b)当它必须从竞争应用程序收回核心时。 图11显示了需要抢占另一个进程的核心的核心请求的每个步骤的时间。大约80%的时间花费在套接字通信上。 图11：对核心仲裁器的核心请求的时间线。有两个应用程序。这两个应用程序都以单个专用内核开始，而顶级应用程序也以等待放置在内核上的线程开始。顶层应用程序具有比底层应用程序更高的优先级，因此当顶层应用程序请求额外的核心时，底层应用程序被要求释放其核心。 图10和图11显示了Arachne的核心分配机制的性能。图10显示了分配时间的分布，从线程调用setRequestedCores到内核线程在新分配的核心上唤醒为止。在第一种场景下，有一个空闲的核心可供核心仲裁器使用，成本仅仅是将内核线程移动到该空闲核心并解除阻塞的成本。在第二个场景中，必须从较低优先级的应用程序中回收核心，因此成本包括发信号通知另一个进程并等待它释放核心。图10显示，Arachne可以在大约30µs内重新分配核心，即使必须从其他应用程序回收核心也是如此。这使得Arachne能够以毫秒的粒度适应负载的变化。 8. 相关工作在过去的几十年中，已经开发了许多用户级线程包。我们已经将Arachne与Go[14]和uThread[4]进行了比较。Boost光缆[1]、Folly[13]和Seastar[37]实现用户级线程，但不跨多核多路复用用户线程。Capriccio[39]通过将系统调用替换为异步系统调用解决了阻塞系统调用的问题，但它不能扩展到多个核心。Cilk[8]是用于在内核线程上调度任务的编译器和runtime，但不处理阻塞，并且不是核心感知的。Carbon[16]提出使用硬件队列来调度数百个指令粒度的任务，但它需要对硬件进行更改，并且仅限于并行的fork-join模型。在撰写本文时，Wikipedia[40]列出了21个C++线程库。其中，10个仅提供内核线程，3个提供基于编译器的自动并行化，3个是没有发布任何性能数字的商业软件包，5个似乎已失效。上面列出的系统都不支持线程创建时的负载平衡，计算核心需求和符合核心分配的能力，或者实现特定于应用程序的核心策略的机制。 调度器激活[2]类似于Arachne，因为它们将处理器分配给应用程序以高效地实现用户级线程。调度器激活工作的一个主要焦点是在阻塞内核调用期间允许处理器抢占；这导致了大量的内核修改。Arachne专注于其他问题，例如最小化缓存未命中、估计核心需求以及启用特定于应用程序的核心策略。 Akaros[35]和Parlib[15]遵循调度器激活的传统。Akaros是一个为应用程序分配专用核心并使所有阻塞系统调用异步的操作系统；Parlib是用于在专用核心上构建用户调度程序的框架。Akaros提供了类似于Arachne核心仲裁器的功能，但它似乎还没有达到能够支持有意义的性能度量的成熟程度。 核心仲裁器控制用户空间中的进程调度策略，同时将机制留给内核，类似于Hydra中的策略模块[18]。 在多核心机器上管理多线程应用程序的传统方法是组调度[12，29]。在组调度中，每个应用程序单方面确定其线程需求；然后操作系统尝试在不同的核心上同时调度应用程序的所有线程。Tucker和Gupta指出，当系统过载时，组调度导致低效率的多路复用[38]。他们认为，更有效的方法是划分核心，以便每个应用程序都可以独占使用几个核心；然后，应用程序可以调整其并行度以匹配可用的核心。Arachne实现了这种方法。 基于事件的应用程序(如Redis[34]和nginx[28])代表了用户线程的替代方案，以实现高吞吐量和低延迟。Behren等人[39]认为基于事件的方法是一种特定于应用程序的优化形式，这种优化是由于缺乏有效的线程runtime；Arachne提供了高效的线程作为事件的更方便的替代方案。 最近的几个系统，如IX[6]和Zygos[32]，已经将线程调度器与高性能网络堆栈相结合。这些系统与Arachne的目标相同，即将低延迟与高效的资源使用相结合，但它们通过将线程机制耦合到网络堆栈，采用了比Arachne更特殊的方法。Arachne是一种通用机制；它可以与高性能网络堆栈一起使用，例如在RAMCloud中，但也可以在其他情况下使用。 9. 未来工作我们相信，Arachne的核心感知调度方法在其他领域将是有益的。例如，虚拟机可以使用多级核心感知方法，其中应用程序使用Arachne与其它客户操作系统就核心进行协商，而客户操作系统使用类似的方法与虚拟机管理程序进行协商。这将提供比目前的方法更灵活、更有效的核心管理方式，因为虚拟机管理程序将知道每个虚拟机需要多少核心。 对于数据中心规模的应用程序，核心感知调度在集群调度器中也是有益的。集群调度器可以从每个集群机器上的核心仲裁器收集关于核心需求的信息，并使用该信息在机器之间放置应用程序和移动服务。这将允许基于实际的核心需求而不是静态声明的最大需求做出决策。Arachne的性能隔离将允许集群调度程序更积极地运行后台应用程序，而无需担心影响前台应用程序的响应时间。 Arachne有几个方面我们还没有完全探索。我们只有初步的实现核心策略的经验，而我们当前的核心策略并没有解决与NUMA机器相关的问题，例如如何在跨多个套接字的应用程序中分配核心。我们希望能够创建各种可重用的核心策略，以便应用程序开发人员可以实现高线程性能，而不必为每个应用程序编写自定义策略。此外，我们在核心估计参数方面的经验是有限的。我们根据基准应用程序的一些实验选择了当前值。当前参数为我们的基准测试提供了延迟和利用率之间的良好权衡，但我们不知道这些参数是否为所有应用程序的最佳值。 10. 总结操作系统中最基本的原则之一是虚拟化，在虚拟化中，系统使用一组物理资源来实现更大和更多样化的虚拟实体集。然而，只有在虚拟对象的使用和可用的物理资源之间取得平衡时，虚拟化才能起作用。例如，如果虚拟内存的使用超过可用物理内存，系统将在页面抖动下崩溃。 Arachne提供了一种机制来平衡虚拟线程的使用与物理核心的可用性。每个应用程序动态计算其核心需求，并将其传送到中央核心仲裁器，然后中央核心仲裁器在竞争应用程序之间分配核心。核心仲裁器将核心专用于应用程序，并告诉每个应用程序它已经接收到哪个核心。然后，应用程序可以使用该信息来管理其线程。Arachne还在用户级别提供了特别快速的线程实现，这使得即使对于非常短的生存期任务也可以使用线程。总体而言，Arachne的核心感知线程管理方法支持结合低延迟和高吞吐量的粒度应用程序。 相关知识： 1、Runtime：运行时，是objective-c语言动态的核心，objective-c的对象一般都是基于runtime的类结构，达到很多在编译时确定方法推迟到了运行时，从而达到动态修改、确定、交换….属性及方法。它是一套比较底层的纯c语言API，属于1个c语言库，包含了很多底层的c语言API。平时编写的oc代码，在程序运行过程中，其实最终会转换成runtime的c语言代码，object-c需要runtime来创建类和对象，进行消息发送和转发。 2、SLO(server-level object)：服务级别目标，为了确保资源可用并在可接受的水平上运行，就为服务可用性和响应时间等性能设定了目标，然后可通过跟踪服务级别目标来监视这些服务目标，服务级别目标是确保达到定义的服务水平承诺的度量。 3、Tail latency尾延迟：如果在系统中引入实时监控，总会有少量响应的延迟高于均值，我们把这些响应称为尾延迟。程序设计、硬件、操作系统等都会导致尾延迟响应。 4、cpuset：基本功能是限制某一组进程只运行在某些cpu和内存节点上，则系统管理员可动态调整进程运行所在的cpu和内存节点。cpuset必须允许动态调整，并且不影响服务器上其他不相关cpuset中运行的进程。比如：可以将某个cpu动态的加入到某个cpuset，可以从某个cpuset中将某个cpu移除，可以将进程加入到cpuset，也可以将某个进程从一个cpuset迁移到另一个cpuset。 5、NUMA（non uniform memory access architecture）非统一内存访问架构：可以使众多服务器像单一系统那样运转，同时保留小系统便于编程和管理的优点。 6、超线程（hyper-threading）：即在一个实体CPU中，提供两个逻辑线程。超线程技术把多线程处理器内部的两个逻辑内核模拟成两个物理芯片，让单个处理器就能使用线程级的并行计算，进而兼容多线程操作系统和软件。但是当两个线程同时需要某个资源时，其中一个线程必须让出资源暂时挂起，直到这些资源空闲以后才能继续。超线程技术充分利用空闲CPU资源，在相同时间内完成更多的工作，但是超线程的性能并不等于两个CPU的性能。且需要芯片组、操作系统和应用软件的支持才能更好发挥优势。 7、超线程技术与多核体系结构的区别：（1）超线程技术是通过延迟隐藏的方法，提高了处理器的性能，即多个线程共享一个处理单元。因此超线程技术所获得的性能并不是真正意义上的并行。（2）多核处理器是将两个甚至更多的独立执行单元，嵌入到一个处理器内部。每个指令序列（线程）都具有一个完整的硬件执行环境，所以各线程之间就实现了真正意义上的并行。]]></content>
      <categories>
        <category>Scientific Research</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020华为杯数学建模研赛]]></title>
    <url>%2Farticle%2F421938b8%2F</url>
    <content type="text"><![CDATA[“华为杯”第十七届中国研究生数学建模竞赛报名时间： 2020年6月1日8:00——9月10日17:00审核时间： 2020年6月1日8:00——9月13日17:00交费时间： 2020年7月1日8:00——9月14日17:00比赛时间： 2020年9月17日8:00——9月21日12:00 已获国家级二等奖，之后补充解题思路。 对应网站 数学建模网 （赛题发布） 中国研究生创新实践系列大赛官方网站（报名地址） 资源收集 往年赛题 ​ 官网地址 ​ 百度云地址 优秀论文 ​ 百度云地址2004-2018，提取码：hwef， ​ 2019：https://pan.baidu.com/s/18Dvszdv5TD43I3XVhewX_w 提取码：fhks ​ GitHub地址 齐全的建模资源–必看 前人比赛经验分享-内含往年赛题分类 赛题分类（1）神经网络、大数据、机器学习 （2）优化、调度 （3）指标评估体系 2020年“深圳杯”数学建模挑战赛9月10日前报名并提交论文赛题 http://www.m2ct.org/modular-list.jsp?pageType=smxly&amp;menuType=flowUp 参考文章https://www.cnblogs.com/gshang/p/10996587.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[window编译并运行TOY2DAC]]></title>
    <url>%2Farticle%2F71a7f63d%2F</url>
    <content type="text"><![CDATA[二维全波形建模和反演（TOY2DAC） 1. 背景 全波形反演指利用非线性寻优方法反演给定时窗内的波形记录以获取影响地震波传播的相关物性参数(如弹性参数、粘弹性参数、各向异性参数、密度等)的方法。就是利用波场模拟和实际地震资料对比，通过多次迭代使预测波场和实际地震资料匹配一致，求取地下地质参数的一种地震反演方法。从数学上来看，是要建立模型与现有地震数据的非线性关系，一般运用动力学知识。TOY2DAC只包括各向同性的频域建模和反演 2. Package include bin 编译后的二进制文件 doc 说明文档 include 编译期间包含的文件 src 所有的源代码，用Fortran语言和并行MPI指令编写 0README 包含说明如何运行代码的内容 3. 环境 Fortran语言和C语言编译器MUMPS库：大型稀疏LU矩阵分解，同时该库需要安装METIS库MKL库：计算标准顺序和并行线性代数问题ATLAS库：矩阵线性代数运算库 4. 编译 Makefile.inc文件包含的变量：CC,FC,FL分别是C语言编译器，Fortran语言编译器和链接调用；OPTF,OPTC,OPTL,OPTFF分别是调用Fortran编译，C编译，链接和Fortran90编译；OPT_PRE是预处理标志，只有设置标志才能实现双精度编译；INC是代码所有路径；LIB定义了库，ETX定义了二进制名称末尾扩展名。 Makefile文件里面的变量全部定义完成后，只需make命令就可以完成编译工作 5. 理论 TOY2DAC从一个从猜测的m0初值开始，为了解决下式最小值的问题 公式（1） - m表示待恢复的地下参数 - S表示数据集的总数 - ds表示第s个数据集 - us(m)是频域波传播问题的解 - R是将波场us(m)映射到接收机位置的约束算子 公式（2） - A(m)表示二维频域声学(an)各向同性波传播算子 在各向同性的情况下，上式被写作： 公式（3） w是角频率 vp(x)是压力波速度 p(x)是密度 在这种情况下，地下参数m可取以下的值： 1. vp(x):压力波速度的单参数反演 2. ρ(x): 密度的单参数反演 3. [vP (x)，ρ(x)]集合：压力波和密度的多参数反演 5.1 正演问题 正演问题包含在公式2中 TOY2DAC实现了一种四阶离散化方案 公式2相当于一个稀疏的大规模线性系统的解 当数据集变大时，只需要一个LU分解，S线性方程组可以通过正代和反代来求解 5.2 反演问题 反演问题基于一个局部下降函数 公式（4） αk是一个通过线性搜索的比例参数∆mk为下降方向这个下降方向取决于优化算法的选择，最基础的选择如下所示： 公式（5）TOY2DAC实现的是截断式牛顿迭代法 5.3 频域选择问题 高效cpu频率域FWI通常是通过单个频率的连续反转来实现的，即从低频率到高频率 这定义了一个多分辨率框架，减轻了与高频跳周期人工制品相关的反问题的非线性。 高效cpu算法可以通过选择少量的粗采样频率来设计，这样可以减少频率和孔径角密集采样产生的波数冗余。 TOY2DAC包含一个简单的框架，它只运行一组频率。如果需要多个组，TOY2DAC必须启动几次。 6.频域有限差分建模引擎的输入文件6.1 介质参数文件 介质参数文件是包含介质物理属性的二进制文件(直接访问简单精度实数)。它是建模模式下的仿真介质或反演的起始模型。文件的名称应该放在输入文件中。包含的参数有： 各向同性粘声模拟的纵波速度、纵波质量因子、密度 这些文件应该包含nz×nx的值 6.2 acquisition文件 它是一个ASCII码文件，文件的格式如下： 第一列和第二列是z轴和x轴坐标，三四列用不到，第五列表示来自源还是接收器 6.3 mumps input 文件 这个文件是允许管理一些MUMPS处理器的优化选项，一共四个参数： icntl 7：选择MUMPS中的排序算法，一般默认7 icntl 14：优化松弛因子，在4.9以后的版本就不用了 icntl 23：确定每个MPI进程上允许存储LU因子的表的大小 keep 84：一般取最大值16 6.4 toy2dac_input文件 优化该项目的主要文件 mode of the code：选择模式，一般就是1，FWI forward modeling tool： 模式1提供各向同性介质的频域有限差分，模式2在TTI各向异性介质中提供了一个频域有限差分 acquisition：接收文件的名称 6.5 fdfd input文件 优化频域有限差分建模引擎的文件 nz,nx 是坐标 h 是步长 file name是各向同性输入模型文件的名称 pml tunning： pml振幅的值。取90一般 free surface是在介质顶部附加一个自由表面边界条件的附加参数 itypes为震源类型:爆炸(0)或垂直力(1)。ityper为接收机类型:水听器(0)(或垂直检波器(1)，但尚未实现)。这个选项只有在使用Hicks插值时才有可能 slaplace是拉普拉斯常数，即。，用于随时间指数衰减地震波场的频率虚部 6.6 freq management文件 管理频率 第一行表示仿真或FWI频率组中涉及的频率数 第二行表示频率列表 7运行TOY2DAC 7.1输出文件在建模模式下 主要输出文件为接收端数据(复值频域)。接收机位置频域内的数据文件通常称为:data_modeling。这是一个直接访问二进制文件。这些文件的顺序如下:data_bloc_frequency_1 data_bloc_frequency_2 … data_bloc_frequency_N其中N号是由用户在文件freq management中的， 对于每个频段组数据块data_bloc_frequency_i，数据排序如下: data_bloc_source_1 data_bloc_source_2 … data_bloc_source_L 最后，对于每个源块，数据排序如下: data_receiver_1 data_receiver_2 … data_receiver_K 如果每个源有相同数量的接收方，可以使用ximage &lt; data_modeling n1=2*nrec 查看 其中nrec = 接收机数量。 7.2输出文件在FWI模式下 输出文件如下: 这里是列表文本输出日志的标准输出，其中包含几个信息，特别是在问题的情况下…； invparinter : 包含反演过程中的所有中间模型。注意，注意，在用于反演的参数化过程中，模型是按顺序存储的； invparfinal ：包含用于反演的参数化的最终模型； param XX inter ： 包含所有按顺序存储的中间模型，用于参数XX。在各向同性中，XX代表vp、rho和qp；在各向异性中，XX是vp、rho、qp、epsilon、delta和 theta； param XX final ： 包含参数XX的最终模型。在各向同性中，XX代表vp、rho和qp；在各向异性中，XX是vp、rho、qp、epsilon、delta和 theta； iterate *.dat : 包含收敛信息的优化例程输出日志。 文件invparinter, invparfinal, param XX inter和param XX final可以用一个ximage命令来查看:ximage &lt; param_vp_final n1=101 其中101是 nz 的大小。 8.示例本部分介绍了TOY2DAC包中两个可用的模型。这些模板同时考虑了FWI（全波形反演）和建模问题。 高斯扰动模型这个迷你模型非常适合是在用户平台上测试代码，因为它可以在几分钟内运行，并且只需要较小内存。它还可以让用户理解：为其预期结果，FWI在一个简单的类似于boxcard的配置是怎样工作的。此模型由1个目录组成：”run ball template”. 该目录包括了run ball模板包含在模式0下运行TOY2DAC所需的文件，以便计算同质背景下的频域数据和在V_P中有1个周期异常。一旦TOY2DAC编译完成，模型可以通过以下不同的操作来运行： 创建一个本地副本(以保持模板目录干净…) 介质的描述在”vp_ball,qp 和 rho“中。用户可以以ximage的形式绘制他们。例如：（这条指令官方给的不全） 1ximage &lt; vp_ball n1=101 d1=20 d2=20 label1=’depth in m’ label2=’distance in m’ &amp; 查看输入文件后，检查文件”fdfd_input”的“vp_ball qp rho”和在”toy2dac_input”文件中的“mode=0”，然后用户可以运行模型。例如： 1mpirun -n 4 ../bin/toy2dac 程序结束后(在4个处理器上所用时间为几秒钟)，“观察到的数据“存储在文件”data_modeling “中，可以用于反演。 然后用户可以运行FWI程序： 介质的笛卡尔描述在文件”vp_homogeneous,qp and rho. “中。用户可以使用ximage来绘制它们。例如:（这条指令官方给的不全） 1ximage &lt; vp\_homogeneous n1=101 d1=20 d2=20 label1=’depth in m’ label2=’distance in m 查看输入文件后，检查文件”fdfd_input”的“vp homogeneous qp rho” ,观察到的数据文件在”fwi_input” 的第一行被设置为“data modeling”, “toy2dac_input”文件的“mode=1”,，然后用户可以运行模型。例如： 1mpirun -n 4 ../bin/toy2dac 程序结束后(在4个处理器上所用时间为几分钟)，用户可以查看最终的模型。例如：（这条指令官方给的不全） 12ximage &lt; param_vp_final n1=101 d1=20 d2=20 label1=’depth in m’ \\label2=’distance in m’ &amp; 其他二进制文件(中间文件等)也可以在文件terateXXX.dat中查看，其中XXX取决于所选择的优化方法。 Marmousi 模型 这个模型是一个简单的地球物理配置，并且在几分钟内就可以运行。此模板由1个目录组成”run marmousi template “ 该目录包含在模式0中运行TOY2DAC所需的文件，以便在真正的marmousi模型中计算频域数据。一旦TOY2DAC编译完成，模型可以通过以下不同的操作来运行： 创建一个本地副本(以保持模板目录干净…) 介质的描述在”vp_Marmousi_exact,qp 和 rho“中。用户可以以ximage的形式绘制他们。例如：（这条指令官方给的不全） 1ximage &lt; vp_Marmousi_exact n1=141 d1=25 d2=25 label1=’depth in m’ label2=’distance in 查看输入文件后，检查文件”fdfd_input”的“vp_Marmousi_exact l qp rho”和在”toy2dac_input”文件中的“mode=0”，然后用户可以运行模型。例如： 1mpirun -n 4 ../bin/toy2dac 程序结束后(在4个处理器)，“观察到的数据“存储在文件”data_modeling “中，可以用于反演。 然后用户可以运行FWI程序： 介质的笛卡尔描述在文件”vp_Marmousi_init ,qp and rho. “中。用户可以使用ximage来绘制它们。例如:（这条指令官方给的不全） 1ximage &lt; vp_Marmousi_init n1=141 d1=25 d2=25 label1=’depth in m’ label2=’distance in 查看输入文件后，检查文件”fdfd_input”的“vp_Marmousi_init qp rho” ,观察到的数据文件在”fwi_input” 的第一行被设置为“data modeling”, “toy2dac_input”文件的“mode=1”,，然后用户可以运行模型。例如： 1mpirun -n 4 ../bin/toy2dac 程序结束后(在4个处理器上所用时间为几分钟)，用户可以查看最终的模型。例如：（这条指令官方给的不全） 12ximage &lt; param_vp_final n1=141 d1=25 d2=25 label1=’depth in m’ \\label2=’distance in m’ &amp; 其他二进制文件(中间文件等)也可以在文件terateXXX.dat中查看，其中XXX取决于所选择的优化方法。 Ubuntu设置和查看环境变量查看环境变量有三个命令 env env命令是environment的缩写，用于列出所有的环境变量 export 单独使用export命令也可以像env列出所有的环境变量，不过export命令还有其他额外的功能 echo $PATH echo $PATH用于列出变量PATH的值，里面包含了已添加的目录 1&lt;basedir&gt; = /public/home/daizy_ or /public/home/pabebe/software/ 安装intel编译器下载网址：https://software.intel.com/en-us/qualify-for-free-software/student 安装包名：parallel_studio_xe_2020_update1_cluster_edition.tgz 参考：https://www.jianshu.com/p/d5895e1f836f 安装方法： 1234567891011tar -xzvf parallel_studio_xe_2020_update1_cluster_edition.tgzcd parallel_studio_xe_2020_update1_cluster_edition_online./install.sh#在bashrc文件中添加以下三行,vim插入模式 按8再按ivim ~/.bashrcexport PATH=&lt;basedir&gt;/intel/bin:$PATHexport LD_LIBRARY_PATH = &lt;basedir&gt;/intel/compilers_and_libraries_2020.1.217/linux/compiler/lib/intel64:&lt;basedir&gt;/intel/mkl/lib/intel64:$LD_LIBRARY_PATHsource /public/home/andaoer/intel/impi/2019.7.217/intel64/bin/mpivars.shsource ~/.bashrc 12345678cd ~/software/parallel_studio_xe_2020_update1_cluster_edition_online./install.shvim ~/.bashrc#我的export PATH=/public/home/pabebe/intel/bin:$PATHexport LD_LIBRARY_PATH= /public/home/pabebe/intel/compilers_and_libraries_2020.1.217/linux/compiler/lib/intel64:/public/home/pabebe/intel/mkl/lib/intel64:$LD_LIBRARY_PATHsource /public/home/pabebe/intel/impi/2019.7.217/intel64/bin/mpivars.shsource ~/.bashrc 注意事项：1.该安装包中包含了Intel MKL，icc，impi的安装，无需进行这些库的另外安装 ​ 2.学生可用学校邮箱申请免费安装包，申请后1~2天会收到含有激活码的邮件。 ​ 3.无学校邮箱也可直接下载付费安装包，可以免费试用30天 安装parmetis下载 安装包名：parmetis-4.0.3.tar.gz 安装方法： 1234567891011tar -xzvf parmetis-4.0.3.tar.gz把 &lt;basedir&gt;/parmetis-4.0.3/metis/include/metis.h 中的 IDXTYPEWIDTH 改为64（针对64位系统）新建文件夹parmetis403，把 &lt;basedir&gt;/parmetis-4.0.3/makefile 中修改-prefix=/public/home/daizy_/parmetis403（路径默认/usr/local，在超算平台会报错）make configmakemake install将/public/home/daizy_/parmetis403/bin添加到PATH中 123#我的cd ~/software/parmetis-4.0.3export PATH=/public/home/pabebe/software/parmetis403/bin:$PATH 安装scotch下载网址：https://gforge.inria.fr/projects/scotch 安装包名：scotch_6.0.9.tar.gz 参考：https://blog.nickwhyy.top/scotch/ 安装方法： 12345678910111213141516171819202122232425262728293031323334#确认编译环境make --versionwhich lexwhich yacc新建文件夹scotch609,把 makefile 中修改-prefix=/public/home/daizy_/scotch609 # /public/home/pabebe/software/scotch609cd ~/scotch_6.0.9/src# cd ~/software/scotch_6.0.9/src#先看下Makefile.inc.x86-64_pc_linux2.icc有没有被污染ln -s Make.inc/Makefile.inc.x86-64_pc_linux2.icc Makefile.incmake scotch make installcd esmumps make scotch make install修改Makefile.inc文件，添加INC=&lt;impi/include&gt;路径， /public/home/daizy_/intel/impi/2019.7.217/intel64/include删除CFLAGS中的-restrict，LDFLAGS中添加 -lirc # /public/home/pabebe/intel/impi/2019.7.217/intel64/includecd ../make ptscotchmake installcd esmumps make ptscotchmake ptinstall 编译scotch时的makefile.inc文件123456789101112131415161718192021EXE =LIB = .aOBJ = .oMAKE = makeAR = arARFLAGS = -ruvCAT = catCCS = iccCCP = mpiccCCD = iccCFLAGS = -O3 -DCOMMON_FILE_COMPRESS_GZ -DCOMMON_PTHREAD -DCOMMON_RANDOM_FIXED_SEED -DSCOTCH_RENAME -DSCOTCH_PTHREAD -restrict -DIDXSIZE64CLIBFLAGS =LDFLAGS = -lz -lm -lrt -pthreadCP = cpLEX = flex -Pscotchyy -olex.yy.cLN = lnMKDIR = mkdir -pMV = mvRANLIB = ranlibYACC = bison -pscotchyy -y -b y 编译ptscotch时的makefile.inc文件123456789101112131415161718192021EXE =LIB = .aOBJ = .oINC = /public/home/pabebe/intel/impi/2019.7.217/intel164/includeMAKE = makeAR = arARFLAGS = -ruvCAT = catCCS = iccCCP = mpiccCCD = iccCFLAGS = -O3 -DCOMMON_FILE_COMPRESS_GZ -DCOMMON_PTHREAD -DCOMMON_RANDOM_FIXED_SEED -DSCOTCH_RENAME -DSCOTCH_PTHREAD -DIDXSIZE64CLIBFLAGS =LDFLAGS = -lz -lm -lrt -pthread -lircCP = cpLEX = flex -Pscotchyy -olex.yy.cLN = lnMKDIR = mkdir -pMV = mvRANLIB = ranlibYACC = bison -pscotchyy -y -b y bug can’t find -lirc 导入他们自带的intel环境(先导杯曙光超算平台提供) 最好每次都检查一下 12module load compiler/intel/2017.5.239 module list 安装MUMPS下载网址：http://mumps.enseeiht.fr/ 安装包名：MUMPS_5.3.1.tar.gz 参考:https://blog.csdn.net/jiangjjp2812/article/details/49632697 ​ https://blog.csdn.net/weixin_30721899/article/details/96455694 ​ https://www.cnblogs.com/Orien/p/5920285.html ​ https://zhuanlan.zhihu.com/p/136580603 安装方法： 12345678910cd MUMPS_5.3.1 # cd ~/software/MUMPS_5.3.1 #将Make.inc/Makefile.INTEL.PAR复制在MUMP_5.3.1根目录下#需要说明的是，为防止用户在不经意的情况下用cp命令破坏另一个文件，如用户指定的目标文件名已存在，用cp命令拷贝文件后，这个文件就会被新源文件覆盖，因此，建议用户在使用cp命令拷贝文件时，最好使用i选项。cp -i Make.inc/Makefile.INTEL.PAR ./Makefile.inc#修改Makefile.inc中的路径make all lib#编译成功的标识-会在lib目录下生成6个库文件 注意事项：Makefile.inc中路径的修改不仅仅是网上教程的几行，所有库的路径都需要根据自己的环境进行修改，可以根据报错来检查路径是否错误。MUMPS在make过程中基本所有的错误都源于库路径不正确。如果-openmp报错，将Makefile.inc的openmp改为qopenmp 编译MUMPS时的makefile.inc文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121## This file is part of MUMPS 5.3.1, released# on Fri Apr 10 13:52:30 UTC 2020##Begin orderings# NOTE that PORD is distributed within MUMPS by default. It is recommended to# install other orderings. For that, you need to obtain the corresponding package# and modify the variables below accordingly.# For example, to have Metis available within MUMPS:# 1/ download Metis and compile it# 2/ uncomment (suppress # in first column) lines# starting with LMETISDIR, LMETIS# 3/ add -Dmetis in line ORDERINGSF# ORDERINGSF = -Dpord -Dmetis# 4/ Compile and install MUMPS# make clean; make (to clean up previous installation)## Metis/ParMetis and SCOTCH/PT-SCOTCH (ver 6.0 and later) orderings are recommended.## 添加根路径LADIR = /public/home/pabebe/softwaretopdir = $(LADIR)/MUMPS_5.3.1# 添加scotchSCOTCHDIR = $&#123;LADIR&#125;/scotch_6.0.9ISCOTCH = -I$(SCOTCHDIR)/include## You have to choose one among the following two lines depending on# the type of analysis you want to perform. If you want to perform only# sequential analysis choose the first (remember to add -Dscotch in the ORDERINGSF# variable below); for both parallel and sequential analysis choose the second # line (remember to add -Dptscotch in the ORDERINGSF variable below)#LSCOTCH = -L$(SCOTCHDIR)/lib -lesmumps -lscotch -lscotcherr# 添加ptscotch库LSCOTCH = -L$(SCOTCHDIR)/lib -lptesmumps -lptscotch -lptscotcherr -lesmumps -lscotch -lscotcherrLPORDDIR = $(topdir)/PORD/lib/IPORD = -I$(topdir)/PORD/include/LPORD = -L$(LPORDDIR) -lpord#LMETISDIR = /opt/metis-5.1.0/build/Linux-x86_64/libmetis#IMETIS = /opt/metis-5.1.0/include# You have to choose one among the following two lines depending on# the type of analysis you want to perform. If you want to perform only# sequential analysis choose the first (remember to add -Dmetis in the ORDERINGSF# variable below); for both parallel and sequential analysis choose the second # line (remember to add -Dparmetis in the ORDERINGSF variable below)#LMETIS = -L$(LMETISDIR) -lmetis#LMETIS = -L$(LMETISDIR) -lparmetis -lmetis# 添加parmetis库LMETIS = -L$(LADIR)/parmetis-4.0.3/build/Linux-x86_64/libmetis -L$(LADIR)/parmetis-4.0.3/build/Linux-x86_64/libparmetis -lparmetis -lmetis# The following variables will be used in the compilation process.# Please note that -Dptscotch and -Dparmetis imply -Dscotch and -Dmetis respectively.# If you want to use Metis 4.X or an older version, you should use -Dmetis4 instead of -Dmetis# or in addition with -Dparmetis (if you are using parmetis 3.X or older).# 并行-Dptscotch and -Dparmetis ORDERINGSF = -Dscotch -Dmetis -Dpord -Dptscotch -Dparmetis#ORDERINGSF = -DpordORDERINGSC = $(ORDERINGSF)LORDERINGS = $(LMETIS) $(LPORD) $(LSCOTCH)IORDERINGSF = $(ISCOTCH)IORDERINGSC = $(IMETIS) $(IPORD) $(ISCOTCH)#End orderings########################################################################################################################################################PLAT =LIBEXT = .aOUTC = -o OUTF = -o RM = /bin/rm -fCC = mpiiccFC = mpiifortFL = mpiifortAR = ar vr #RANLIB = ranlibRANLIB = echo# Make this variable point to the path where the Intel MKL library is# installed. It is set to the default install directory for Intel MKL.# 添加Intel MKLMKLROOT=/public/home/pabebe/intel/mkl/lib/intel64 SCALAP = -L$(MKLROOT) -lmkl_scalapack_lp64 -lmkl_blacs_intelmpi_lp64#LAPACK = -L$(MKLROOT) -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core#LIBPAR = $(SCALAP) $(LAPACK)SEFTDEF= -L/public/home/pabebe/intel/compilers_and_libraries_2020.1.217/linux/mpi/intel64/lib/LIBPAR = $(SCALAP) $(SEFTDEF)$(LPORD) $(LMETIS) $(LSCOTCH) INCSEQ = -I$(topdir)/libseqLIBSEQ = $(LAPACK) -L$(topdir)/libseq -lmpiseqLIBBLAS = -L$(MKLROOT) -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core LIBOTHERS = -lpthread#Preprocessor defs for calling Fortran from C (-DAdd_ or -DAdd__ or -DUPPER)CDEFS = -DAdd_#Begin Optimized optionsOPTF = -O -nofor_main -DBLR_MT -qopenmp -DGEMMT_AVAILABLEOPTL = -O -nofor_main -qopenmpOPTC = -O -qopenmp#End Optimized options# 添加INCPAR INCPAR = -I$(topdir)/include -I $(LADIR)/parmetis-4.0.3/include -I $(LADIR)/parmetis-4.0.3/metis/includeINCS = $(INCPAR)LIBS = $(LIBPAR)LIBSEQNEEDED = bugerror: “METIS_ERROR” has already been declared in the current scope 将scotch_6.0.9/include/parmetis.h 里 第94-101注释掉，不然编译出错s scotch_6.0.9/include/metis.h(90): error: identifier “SCOTCH_Num” is undefined 将第90行 typedef SCOTCH_Num idx_t;修改为typedef int idx_t; /public/home/pabebe/software/scotch_6.0.9/lib/libptscotch.a(dgraph_band.o): In function _SCOTCHdgraphBand2Coll&#39;: dgraph_band.c:(.text+0xf5): undefined reference to_SCOTCHmemAllocGroup’/public/home/pabebe/software/scotch_6.0.9/lib/libptscotch.a(dgraph_band.o): In function _SCOTCHdgraphBand2Ptop&#39;: dgraph_band.c:(.text+0x7b8): undefined reference to_SCOTCHmemAllocGroup’/public/home/pabebe/software/scotch_6.0.9/lib/libptscotch.a(dgraph_band.o): In function `_SCOTCHdgraphBand’: 一大堆关于scotch未定义的错 Make.inc 在LSCOTCH = -L$(SCOTCHDIR)/lib -lptesmumps -lptscotch -lptscotcherr 后面添加这几个库 -lesmumps -lscotch -lscotcherr ar: two different operation options specified，这个是因为多个库文件要链接时，一定要每个库文件前都有一个 -l 选项 提示缺少metis.h，将metis/include里的同名文件复制到MUMPS/PORD/include中 安装TOOLBOX_OPTIMIZATION123cd TOOLBOX_OPTIMIZATION#cd ~/software/TOOLBOX_OPTIMIZATIONmake 安装 toy2dac下载：https://seiscope2.osug.fr/TOY2DAC,82?lang=fr 参考：https://zhuanlan.zhihu.com/p/136580603 ​ http://bbs.fcode.cn/thread-1562-1-1.html 安装步骤： 12345将&lt;basedir&gt;/toy2dac/src/MAKE.INC/Makefile.inc_THERA 复制到 src目录下，重命名问Makefile.inc修改Makefile,inc的所有路径：LADIR，OPTIM，SCOTCHDIR，LMUMPS，LMKL等等；将-assume -byterecl删除，否则会报错在src目录中make，可在&lt;basedir&gt;/toy2dac/bin目录下生成目标文件toy2dacsp 注意事项： 1make过程中会频繁报错，基本都是路径不正确导致，请检查路径是否正确并手动添加库文件路径。 123#我的cd ~/software/TOY2DAC_V2.6_2019_05_24/srcmake 编译toy2dac时的makefile.inc文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103LADIR = /public/home/pabebe/softwareOPTIM = $(LADIR)/TOOLBOX_OPTIMIZATION############################################ SETUP THE ARCHITECTURE ####################################################################################### structure 32 bits nothing to do# structure LP64 with 32 bits integer# the most used environment openmpi is set for thatIA=_lp64# structure ILP64 with 64 bits integer# require specific openmpi#IA=_ilp64############################################ SET SINGLE PRECISION(sp) VERSUS DOUBLE PRECISION(dp) CODE###########################################EXT=spRM = /bin/rm -fCC = mpiiccFC = mpiifortFL = mpiifortAR = ar vrRANLIB = echo#DOUBLE VERSUS SINGLE PRECISION LU FACTORIZATION:# -D_sp (single precision) # -D_dp (double precision) OPT_PRE = -cpp -D_$(EXT)#OPTIONS COMPILEOPTF = -O3 $(OPT_PRE) # -assume byterecl OPTC = -O3 $(OPT_PRE)OPTL = -O3 $(OPT_PRE) # -assume byterecl#OPTF = -O3 #OPTC = -O3 #OPTL = -O3 #OPTF = -assume byterecl -check all -debug -g -O0 -fp-stack-check -traceback -ftrapuv -implicitnone -warn truncated_source -warn argument_checking \#-warn declarations -warn alignments -warn ignore_loc -warn usage -mcmodel=medium -shared-intel $(OPT_PRE)#OPTC = -I/usr/openwin/include -debug all -CB -traceback#OPTL = -assume byterecl -check all -debug -g -O0 -fp-stack-check -traceback -ftrapuv -implicitnone -warn truncated_source -warn argument_checking \#-warn declarations -warn alignments -warn ignore_loc -warn usage -mcmodel=medium -shared-intel $(OPT_PRE)OPTFF = $&#123;OPTF&#125;#Begin orderingsSCOTCHDIR = $(LADIR)/scotch_6.0.9ISCOTCH = -I$(SCOTCHDIR)/include LSCOTCH = -L$(SCOTCHDIR)/lib -lptesmumps -lptscotch -lptscotcherr -lesmumps -lscotch -lscotcherrtopdir = $(LADIR)/MUMPS_5.3.1IPORD = -I$(topdir)/PORD/include/LPORD = -L$(topdir)/PORD/lib/ -lpordLMETIS = -L$(LADIR)/parmetis-4.0.3/build/Linux-x86_64/libmetis -L$(LADIR)/parmetis-4.0.3/build/Linux-x86_64/libparmetis -lparmetis -lmetis# The following variables will be used in the compilation process.# Please note that -Dptscotch and -Dparmetis imply -Dscotch and -Dmetis respectively.ORDERINGSF = -Dscotch -Dmetis -Dpord -Dptscotch -Dparmetis#ORDERINGSF = -Dmetis -Dpord -DparmetisORDERINGSC = $(ORDERINGSF)LORDERINGS = $(LMETIS) $(LPORD) $(LSCOTCH)IORDERINGSF = $(ISCOTCH)IORDERINGSC = $(IMETIS) $(IPORD) $(ISCOTCH)LMUMPS = -L$(topdir)/lib -lcmumps -lmumps_commonIMUMPS = -I$(topdir)/include## MKL LIBRARY ... ###############################################################################LMKL=-L $(LIBRARY_PATH) -lmkl_intel$(IA) -lmkl_intel_thread -lmkl_core -lmkl_blas95$(IA) -lmkl_scalapack$(IA) -lmkl_blacs_openmpi$(IA) -lmkl_lapack95$(IA) -lifcore -lm -openmp -lpthreadLMKL = -L/public/home/pabebe/intel/mkl/lib/intel64 -L/public/home/pabebe/intel/compilers_and_libraries_2020.1.217/linux/compiler/lib/intel64 -liomp5 -lmkl_intel$(IA) -lmkl_intel_thread -lmkl_core -lmkl_blas95$(IA) -lmkl_scalapack$(IA) -lmkl_blacs_intelmpi$(IA) -lmkl_lapack95$(IA) -lifcore -qopenmp -lpthread -lm LOPTIM=-L $(OPTIM)/lib -lSEISCOPE_OPTIMIOPTIM = -I $(OPTIM)/COMMON/include# 添加INCPAR INCPAR = $(IMUMPS) $(IPORD) -I ../include $(IOPTIM) -I $(LADIR)/parmetis-4.0.3/include -I $(LADIR)/parmetis-4.0.3/metis/include LIBPAR=$(LMUMPS) $(LPORD) $(LMETIS) $(LSCOTCH) $(LMKL) $(LOPTIM) #Parallel:INC = $(INCPAR)LIB = $(LIBPAR)## FOR LIBRARIES BUILD-UPINCL = $(IMUMPS) $(IPORD) -I ../include $(IOPTIM) -I $(LADIR)/parmetis-4.0.3/include -I $(LADIR)/parmetis-4.0.3/metis/include bug ​ gfortran 严格一些，默认情况下，不允许每行超过132列的长度。在Fortran中当程序代码中的一行超过132个字符时，至多可以有39个续行。续行标志固定为“&amp;”。当一行代码的最后一个字符为“&amp;”时，则表道示下一行与本行接续；当一行代码的第一个字符为“&amp;”时，则表示本行与上一行接续。 /public/home/pabebe/software//MUMPS_5.3.1/lib/libcmumps.a(csol_aux.o): undefined reference to symbol ‘__svml_roundf4’ 在makefile最后一行修改为 1$(FL) $(OPTL) $(SUBINV) toy2dac.o $(LIB) -lsvml -lintlc -o $(BIN)/toy2dac$(EXT) 安装Ximage下载：https://pypi.org/project/ximage/#files 运行toy2dac12345678# 以高斯扰动模型为例# run_ball是对 run_ball_template的拷贝cd ~/software/TOY2DAC_V2.6_2019_05_24/run_ball# cd ~/software/TOY2DAC_V2.6_2019_05_24/run_marmousi# 建模mpirun -n 4 ../bin/toy2dacsp# 反演 vp_homogeneous qp rho epsilon delta theta bug 出现无法连接到intel指定库的情况。 intel环境没有设置好]]></content>
      <categories>
        <category>window</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu18.04下python安装并使用Oracle19.8]]></title>
    <url>%2Farticle%2Fa8446d42%2F</url>
    <content type="text"><![CDATA[下载oracle Client所有的系统下载oracle Instant Client 下载 oracle-instantclient19.8-basic-19.8.0.0.0-1.x86_64.rpm oracle-instantclient19.8-sqlplus-19.8.0.0.0-1.x86_64.rpm oracle-instantclient19.5-devel-19.5.0.0.0-1.x86_64.rpm 18.3版本以后不用建软链接，已经存在。 12345678910 sudo apt-get install alien# rpm 转 deb sudo alien oracle-instantclient19.8-basic-19.8.0.0.0-1.x86_64.rpmsudo alien oracle-instantclient19.8-sqlplus-19.8.0.0.0-1.x86_64.rpmsudo alien oracle-instantclient19.5-devel-19.5.0.0.0-1.x86_64.rpm# 安装sudo dpkg -i oracle-instantclient19.8-basic_19.8.0.0.0-2_amd64.deb sudo dpkg -i oracle-instantclient19.8-sqlplus_19.8.0.0.0-2_amd64.deb sudo dpkg -i oracle-instantclient19.5-devel_19.5.0.0.0-2_amd64.deb 配置环境12345678910111213141516sudo gedit ~/.bashrc# oracle pathexport ORACLE_HOME=/usr/lib/oracle/19.8/client64export PATH=$PATH:$ORACLE_HOME/binexport LIBRARY_PATH=$LIBRARY_PATH:$ORACLE_HOME/libexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ORACLE_HOME/libexport ORACLE_SID=orcl# 下面两行是解决编码问题，如果不设置下面两行，从oracle导出中文数据会出现乱码export LANG="zh_CN.UTF-8"export NLS_LANG=AMERICAN_AMERICA.UTF8source ~/.bashrc# 存在就不用建立sudo mkdir -p /usr/lib/oracle/19.8/client64/lib/network/admin bug — libaio.so.1: cannot open shared object file 1sudo apt-get install libaio-dev 填写tnsnames.ora文件oracle数据库网络配置文件，通过这个配置文件才能建立对数据库的连接。 /usr/lib/oracle/19.8/client64/lib/network/admin(该路径默认放 tnsnames.ora, sqlnet.ora and oraaccess.xml)下新建tnsnames.ora文件，内容如下： 123456789101112131415161718192021222324#该文件用于配置数据库连接地址#数据库访问地址别名,直接用该名字来指定连接ORCL=(DESCRIPTION = (ADDRESS_LIST =#通讯协议，主机(在本机则为127.0.0.1或localhost)，端口(oracle数据库服务端口号) (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521)) ) (CONNECT_DATA =#数据库实例名称 (SERVICE_NAME = orcl) ))#可以配置多个数据库地址#platform-test=#(DESCRIPTION =# (ADDRESS_LIST =# (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.0.19)(PORT = 1521))# )# (CONNECT_DATA =# (SERVICE_NAME = orcl)# )#) 并修改权限:1sudo chmod a+w *.ora 测试进人sqlplus不能使用上下键查看历史命令，安装rlwrap解决 123$ sudo apt-get install rlwrap#在~/.bashrc中添加别名alias sqlplus='rlwrap sqlplus' 12345678910# 不以任何用户登录，启动sqlplus, 但不连接数据库sqlplus /nolog# 然后输入账号密码conn / as sysdba# sqlplus sys/password as sysdba# or(本机使用oracale,默认账号密码)sqlplus scott/tiger@ORCL# orsqlplus scott/tiger@127.0.0.1:1521/orcl bug — ORA-12162: TNS:net service name is incorrectly specified ORACLE_SID没有指定！将.bash中添加具体的ORACLE_SID bug — Connect failed because target host or object does not exist 上面的环境没有配置好，在检查一遍。 参考文章通过python连接Oracle error while loading shared libraries: libaio.so.1: cannot open shared object file: No such file or d ORA-12162: TNS:net service name is incorrectly specified 错误解决 Oracle案例05——ORA-12162: TNS:net service name is incorrectly specified 在oracle中，sqlplus / nolog是做什么用的]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python语法奇奇怪怪小合集]]></title>
    <url>%2Farticle%2Fe58acc82%2F</url>
    <content type="text"><![CDATA[pandas默认读取excel时第一行为默认索引行，不作为数据存在。.read_csv(&quot;test.cvs&quot;,header=None)#取消将第一行作列属性 第一列默认为数据 1234567891011data_table = pd.read_excel('data.xlsx')# 读取一列x_list = data_table['X坐标']# 读取多列x_y_z_list = data_table[['X坐标', 'Y坐标', 'Z坐标']]# DataFrame类型修改指定单元格的值#整数索引df.iloc[i][j] = x#对于混合位置和索引，使用.ix。但是你需要确保你的索引不是整数，否则会引起混淆。df.ix[0, 'COL_NAME'] = x # 在pandas的1.0.0版本开始，移除了Series.ix and DataFrame.ix 方法。 生成excel时-有小坑123456dataframe = pd.DataFrame(data)#这样默认生成时，excel文件会自带行列索引，#等读取时，第一行为列索引不计入数据，但是第一列会计入数据导致数据错位。dataframe.to_excel('data.xlsx') #所以最好是去除掉行索引dataframe.to_excel('data.xlsx', index=False) pandas条件组合筛选和按范围筛选 DataFrame多条件筛选 DataFrame的数据查询 / 提取 python 把几个DataFrame合并成一个DataFrame——merge,append,join,conca pandas 用excelwriter生成表格，运行正常但是没有生成文件？目的是为了多条数据从指定行写入数据（python字典） 原始代码 12345writer = pd.ExcelWriter(filepath)df1 = pd.DataFrame(random_wolk_parameters, index=[0])df1.to_excel(excel_writer=writer, startrow=0)df2 = pd.DataFrame(pso_parameters, index=[0])df2.to_excel(excel_writer=writer, startrow=3) 修改后成功代码 12345with pd.ExcelWriter(filepath) as writer: df1 = pd.DataFrame(random_wolk_parameters, index=[0]) df1.to_excel(excel_writer=writer, startrow=0, index=False) df2 = pd.DataFrame(pso_parameters, index=[0]) df2.to_excel(excel_writer=writer, startrow=2, index=False) 成功得有点莫名。。(看with的用法-ctrl+鼠标点击直达,大概能理解了.) At least one sheet must be visiblemaybe是写入的数据有问题 TypeError: sequence item 0: expected str instance, numpy.int64 found“ “.jion(str), jion分割的必须是字符串!!,如果传入的列表内都是str则没问题,但我们传的列表内是含有int的!所以会报类型错误参考 seaborn【数据分析】seaborn的 heatmap热力图的cmap参数选项 cmap图集 项目requirements.txt当前虚拟环境1pip freeze &gt; requirements.txt 当前项目1234# 安装pip install pipreqs# 在当前目录生成pipreqs . --encoding=utf8 --force 注意 --encoding=utf8 为使用utf8编码，不然可能会报UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xae in position 406: illegal multibyte sequence 的错误。 --force 强制执行，当 生成目录下的requirements.txt存在时覆盖。 安装1pip install -r requirements.txt _、--和__xx__的区别来源：python— 、--和__xx__的区别 _ 在类的方法或属性前面添加，意味着该方法或属性不该被调用，不属于API。类似于C++中类的私有方法 --真正作用是用来避免子类覆盖其内容，防止子类重写，若子类重写后，只能在该子类的内部中使用。这个方法不能被重写，它只允许在该类的内部中使用。 __xx__经常是操作符或本地函数调用的magic methods。 在特殊的情况下，它只是python调用的hook。例如，init()函数是当对象被创建初始化时调用的;new()是用来创建实例。 字典与匿名函数的巧妙组合python中没有switch/case以及三目运算符 优雅实现switch/case 12345678910111213141516171819202122232425262728293031# 情况1: 范围判断conditions = lambda x: &#123; x &lt; -1: 0, -1 &lt;= x &lt;= 1: 0.5, x &gt; 1: 1&#125;# 返回第一个满足条件的值 0.5num = conditions(0.25)[True]print(num)# 返回最后一个不满足条件的值 1num = conditions(0.25)[False]print(num)# 情况2: 映射对应程序段def select_train(): t = 0def select_test(): t = 1def select_eval(): t = 2 def select_result(goal): condition_list = &#123; 'train': select_train, 'test': select_test, 'eval': select_eval, &#125; # 搜寻不到输出后面字符串 print(condition_list.get(goal, '必须是 train / test / eval 这三种类型'))select_result('train') with语句需要事先做一些设置，事后做一些清理．（类似于try/excption/finally） 12with open(r'c:\test.txt', 'r') as f: data = f.read() with后面接的对象返回的结果赋值给f。此例当中open函数返回的文件对象赋值给了f；with会自已获取上下文件的异常信息。 模块调用python只用另一模块中的类， 为什么不包含在类中的代码也会被执行？ 因为引用了其他模块的函数，但是该模块里面有不是包含在函数中的代码，你在引用该模块中dao的函数时候会先执行被引用模块的代码。 深拷贝与浅拷贝-巨坑大佬写的很清楚：Python List的赋值方法 Python中关于对象复制有三种类型的使用方式，赋值、浅拷贝与深拷贝。 赋值：对象的赋值就是简单的对象引用，他们指向同一片内存，b是a的别名，是引用（同一个内存地址）。 浅拷贝.copy()： 浅拷贝会创建新对象，其内容是原对象的引用。二者包含的元素的地址是相同的。是它仅仅只拷贝了一层，在a中有一个嵌套的list，如果我们修改了它，情况就不一样了。 深拷贝.deepcopy()：深拷贝拷贝了对象的所有元素，包括多层嵌套的元素。因而，它的时间和空间开销要高。因为深拷贝出来的对象根本就是一个全新的对象，不再与原来的对象有任何关联。 二维列表定义与赋值1234#错误写法 consume_list = [[0] * list_col] * list_row consume_list[i][j] = dis * value #发现bug ---- 尝试给其中一个元素赋值,整个列表的第j列都被赋值,导致结果不正确 参考：python二维列表list赋值时整列重复赋值问题 原因：本质上是“浅拷贝”的锅，二者包含的元素的地址是相同的。上面的定义手法是将第一行的元素的地址给了下面行，所以改变的时候，会出现整列一起改变的情况。 12# 正确写法 --- 每一行创建不同的元素consume_list = [[0] * list_col for i in range(list_row)] 二维数组定义与初始化 123456# 方法一：current_food = np.ones((row, col)) * init_value# 方法二：#先生成一个list 再转换成数组 ；0 是 数组初始化的值 ；数组较大 时候 效率较慢consume_list = [[0] * list_col for i in range(list_row)]a = np.array(consume_list) 代码精炼绘制三维图1234567891011121314151617181920212223242526272829303132333435import matplotlib.pyplot as plt#设置画布fig = plt.figure()ax = fig.add_subplot(projection='3d')# 三维散点图#对应点的颜色和尺寸（可设置不同）color_map = []size_map = []ax.scatter3D(x_data, y_data, z_data, c=color_map, s=size_map, cmap='Blues')ax.set_xlabel('X', fontsize=16)ax.set_ylabel('Y', fontsize=16)ax.set_zlabel('Z', fontsize=16)plt.show()# 三维曲面图# 0-43.65等距分成1165份x_data = np.linspace(0, 43.65, 1165)y_data = np.linspace(0, 58.2, 876)#用于三维曲面的分格线座标（必须要有）x, y=np.meshgrid(x_data, y_data)#z坐标数据（二维数组）z = np.array(data)ax.contour3D(x, y, z, 150, cmap='rainbow')# ax.plot_trisurf(x, y, z, 50, cmap='rainbow')plt.show()# 等高线图#填充颜色plt.contourf(x, y, z, 10, alpha=0.6, cmap='rainbow')plt.contourf(x, y, z, 10, alpha=0.6)#绘制等高线C = plt.contour(x, y, z, 3, colors='black')#显示各等高线的数据标签plt.clabel(C, inline=True, fontsize=15, colors='y')plt.show() 按照优先级快排算法(升序)12345678910111213141516171819def partition(arr, low, high, rule): i = low pivot = rule[high] for j in range(low, high): if rule[j] &lt;= pivot: # ≤最后一个元素的所有元素依次放在左边索引0~i的位置 arr[i], arr[j] = arr[j], arr[i] rule[i], rule[j] = rule[j], rule[i] i = i + 1 # 然后将最后一个元素放在索引i的位置 arr[i], arr[high] = arr[high], arr[i] rule[i], rule[high] = rule[high], rule[i] return idef quickSort(arr, low, high, rule): if low &lt; high: pi = partition(arr, low, high, rule) quickSort(arr, low, pi - 1, rule) quickSort(arr, pi + 1, high, rule) 双栈A*算法参考： 图算法 - 只需“五步” ，获取两节点间的所有路径（非递归方式） 求两点间所有路径的遍历算法 无向连通图中两点间所有路径的算法 可实现图中任意两点所有路径以及（优先级排序后的最少节点-距离终点最近/最短路径-距离起点and终点最近）的路径 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144# 找寻起点与终点的最少节点的路径def way_finding(start, end): # 计算完直接读取，避免重复计算 # 节点之间消耗度（舒适度、饱食度） # consume_list = pd.read_excel('consume_list.xlsx') consume_list = pd.read_excel('consume_list_1.xlsx') dis_list = pd.read_excel('dis_list.xlsx') # print(dis_list.iloc[0, 0]) # print(dis_list.iloc[0, 1]) # print(dis_list.iloc[5, 0]) # print(dis_list.iloc[0, 5]) # print(dis_list.iloc[5, 5]) print('消耗表的大小：', consume_list.shape) print('距离表的大小：', dis_list.shape) file = open('./node_map.txt', 'r') node_map = eval(file.read()) file.close() file = open('./2.txt', 'w') # print(node_map) # 约束 # 死亡条件 dead_condition = -5 # 终点条件 destination_condition = -3 # 存放当前已选择节点 的主栈 main_stack = [start] # 存放接下来可连接的点 的辅栈 side_stack = [node_map[start]] # 舒适度栈,饱食度栈 food_stack = [10.0] temp_stack = [10.0] count = 0 min_dis = float('inf') # 当主栈不为空 while len(main_stack) &gt; 0: # print('主栈', main_stack) # print('辅栈', side_stack) # 弹出当前可以连接的 辅栈栈顶节点 尝试加入主栈 side_top = side_stack.pop() # 主栈栈顶 current_main_top = main_stack[-1] current_food = food_stack[-1] current_temp = temp_stack[-1] id_current_main_top = int(current_main_top) print('id_current_main_top:%d,当前饱食度:%f,当前舒适度%f' % (id_current_main_top, current_food, current_temp), main_stack) str_1 = 'id_current_main_top:%d,当前饱食度:%f,当前舒适度%f' % (id_current_main_top, current_food, current_temp) + str( main_stack) + '\n' file.write(str_1) # 找下一个主栈栈顶 # 当栈顶节点不为空 if len(side_top) &gt; 0: # 辅栈栈顶 main_top = side_top[0] id_main_top = int(main_top) type_main = type_date.iloc[id_main_top] supply_main = energy_data.iloc[id_main_top] consume_main = consume_list.iloc[id_current_main_top][id_main_top] print('从%d点到%d点要消耗%f的能量(无论是食物还是温度),该顶点提供%d能量' % (id_current_main_top, id_main_top, consume_main, supply_main)) file.write('从%d点到%d点要消耗%f的能量(无论是食物还是温度),该顶点提供%d能量\n' % (id_current_main_top, id_main_top, consume_main, supply_main)) # 人物存活约束 if current_food - consume_main &gt;= dead_condition and current_temp - consume_main &gt;= dead_condition: # 辅栈栈顶节点加入主栈栈顶 main_stack.append(main_top) # 消耗能量 current_food -= consume_main current_temp -= consume_main # 补充食物或温度 if type_main: current_food += supply_main else: current_temp += supply_main food_stack.append(current_food) temp_stack.append(current_temp) # 辅栈加入 栈顶节点接下来可连接的点 side_stack.append(side_top[1:]) # 去除掉辅栈中(主栈已经存在的节点),避免回路 if len(node_map[main_top]) &gt; 0: side_top = [] for v in node_map[main_top]: if v not in main_stack: side_top.append(v) side_stack.append(side_top) # 不满足人物存活条件 else: # 辅栈中去掉当前辅栈栈顶节点 side_stack.append(side_top[1:]) # print('辅栈', side_stack) # 如果走不通,去除主栈的栈顶顶点 else: main_stack.pop() food_stack.pop() temp_stack.pop() # 栈顶为终点并且满足终点约束and不走回头路约束（路径不包含回路或环）便输出这条路径 if len(main_stack) &gt; 0 and main_stack[-1] == end \ and food_stack[-1] &gt;= destination_condition and temp_stack[-1] &gt;= destination_condition: # if len(main_stack) &gt; 0 and main_stack[-1] == end: count += 1 dis_sum = 0 for i in range(len(main_stack) - 1): # 距离 current_node = int(main_stack[i]) next_node = int(main_stack[i + 1]) dis_sum += dis_list.iloc[current_node, next_node] # print('%d %d: ' % (current_node, next_node), dis_list.iloc[current_node, next_node]) if min_dis &gt; dis_sum: min_dis = dis_sum index_min_dis = count save_str = "******** 当前最小距离为：%f, 出现在第 %d 条, 节点数是%d, 到达终点时饱食度: %f,舒适度: %f,路径是 " \ % (min_dis, index_min_dis, len(main_stack), current_food, current_temp) + str( main_stack) print(save_str) file.write(save_str) print("=====FOUND=====", count) save_result = "该人物从起点到终点（经过的食物点和篝火点的次数最少,用序号表示）的路线为：: " + str(main_stack) + \ ' \n途经 %d 个节点,到达终点时饱食度: %f,舒适度: %f' % (len(main_stack), current_food, current_temp) \ + ' 此时距离为：%f 米' % dis_sum print(save_result) result_file = open('./moni2-2_result_file.txt', 'w') result_file.write(save_result) result_file.close() file.close() break pop_stack(main_stack, side_stack)def pop_stack(main_stack, side_stack): main_stack.pop() if len(side_stack) &gt; 0: side_stack.pop() way_finding('0', '587') 遗传算法参考： geatpy教程 geatpy库笔记 python运筹优化（三）：遗传算法和Geatpy使用实践 12 参考文章python— 、--和__xx__的区别 Python3 之 with语句（高效、便捷） Python中如何优雅地使用switch语句 Python switch/case语句实现方法 为什么python的函数没被调用就被执行了？ Python List的赋值方法]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装Ubuntu18.04后的优化]]></title>
    <url>%2Farticle%2Fe0fdde43%2F</url>
    <content type="text"><![CDATA[安装Ubuntu18.04后的优化https://launchpad.net/~rikmills 设置 root密码12sudo passwd root #输入密码并确认 锁屏不熄屏长按window键 + L 即可常亮锁屏。短按就是取消常亮锁屏。 取消自动挂起与锁屏setting-&gt;电源 关闭“无操作时屏幕变暗,自动挂起” -&gt;息屏”从不” etting-&gt;隐私 关闭”锁屏” 文件夹创建桌面快捷方式12# ln -s [绝对路径] ~/桌面/快捷方式名称ln -s /data/long.com/ ~/桌面/long 修改grub配置(时间以及启动顺序)win10直接从bios读时间，ubuntu是biso+8个小时。win10用的rtc ，ubuntu用的utc，我的ubuntu时间是准的。 是用同一个时间计算方式，以window为准。 12345678timedatectl set-local-rtc true sudo gedit /etc/default/grub #选择grub启动等待时间，默认是10秒GRUB_TIMEOUT=5 #(任何数值）#修改win10和ubuntu18.04双系统启动顺序并统一时间GRUB_DEFAULT=2#保存并退出sudo update-grub 重启电脑 更新源ubuntu下安装软件，一般都是通过命令sudo apt-get install package来安装想要的软件，这个命令一般都是从一个叫做/etc/apt/source.list文件里找下载地址，而默认的ubuntu也就是新安装的ubuntu，下载软件包都是从ubuntu官网下载,也就是这个source.list包含的是ubuntu官网配置的地址。但这个ubuntu官网不在国内，而在国外，也就是要下载个包，还要从国外网站下，所以这样下载速度自然就慢了。还好国内也有自己的镜像源，比如清华镜像源，阿里镜像源，这些镜像源包含了咱们想要下的软件包。这样下载软件就不必在国外网下，而直接从国内网站下载，这样下载速度就快了很多。 寻找国内镜像源清华的镜像源 然后下滑找到ubuntu，点击旁边的问号.然后选择相应的ubuntu版本，我用的是18.04版本的，并复制下面字段。 修改首先拷贝一份/etc/apt/sources.list文件 12sudo cp -v /etc/apt/sources.list /etc/apt/sources.list.backupsudo gedit /etc/apt/sources.list 然后全选并删除里面的内容，添加镜像源。 123456789101112131415161718192021222324# 清华源# 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse 123456789101112# 阿里源deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 123456789101112# 中科大源deb https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-security main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiversedeb-src https://mirrors.ustc.edu.cn/ubuntu/ bionic-proposed main restricted universe multiverse 12sudo apt update sudo apt upgrade 遇到的问题sudo apt upgrade E: 无法获得锁 /var/lib/dpkg/lock-frontend - open (11: 资源暂时不可用) E: 无法获取 dpkg 前端锁 (/var/lib/dpkg/lock-frontend)，是否有其他进程正占用它？ 强制解锁 1sudo rm /var/lib/dpkg/lock-frontend 指定用户sudo免密码操作终端 1sudo nano /etc/sudoers 在%sudo ALL=(ALL:ALL) ALL 的下一行添加你的用户名 ALL=(ALL:ALL) NOPASSWD:ALL然后按 ctrl+x 保存离开 开机自动挂载windows磁盘ubuntu14.04开机自动挂载windows磁盘的配置方法 挂载磁盘的信息是保存在 /etc /fstab 这个文件里面,我们注意到其中又这么一行注释 这个就是对下面没有注释的信息的解释 ：分别表示:原来在文件系统的位置，加载点位置，类型，参数等，其中以#是注释符号，相当于C语言中的 // 注释,可以使用man fstab来查看各个参数的定义 123#先备份sudo cp /etc/fstab /etc/fstab_backup df 先用 df命令查看要自动挂载磁盘信息（查看之前先手动挂载想要开机自动挂载的磁盘，要不然显示不出来） 123456sudo gedit /etc/fstab#修改如下# window D disk/dev/sdb2 /media/pabebe/D ntfs defaults,locale=zh_CN.UTF-8 0 0# window E disk/dev/sdb3 /media/pabebe/E ntfs defaults,locale=zh_CN.UTF-8 0 0 保存，退出，重启系统 开机自启动脚本systemctl自定义service执行shell脚本时报错code exited status 203 EXEC ubuntu18.04 使用systemd方式添加开机运行sh脚本 ubuntu 18.04开机自启动脚本 准备好你的sh脚本文件路径:~/VScodeWorkspace/mountDisk.sh 给予权限 1chmod 777 ~/VScodeWorkspace/mountDisk.sh 挂载磁盘脚本-mountDisk.sh 123456789101112131415161718192021222324252627282930313233343536373839404142#!/bin/sh# 挂载硬盘到指定目录（放在 /【根目录】/media/用户名/下）mymount()&#123; echo "check and create mount directory!" if [ ! -d "/media/pabebe/d" ] then mkdir /media/pabebe/D fi echo "start mount win disk!!" sudo mount /dev/sdb2 /media/pabebe/D echo "mount over!Have fun"&#125;myumount()&#123; echo "start umounting win disk!!" sudo umount /media/pabebe/D echo "all down bye!"&#125;cd /#mymount #创建博客桌面快捷键if [ -e "/home/pabebe/桌面/blog" ]then sudo rm /home/pabebe/桌面/blogfiln -s /media/pabebe/D/Pabebezz.github.io/source/_posts /home/pabebe/桌面/blogecho "blog 可以快捷访问啦"exit 0#echo "mount or umount win disk?please type m/u"# read M_U# if [ "$M_U" = "m" ]; then# mymount# else# myumount# fi#shel l脚本需要注意的地方就是if这个条件这里[]和then要是在同一行那么就得加上;，#还有就是 中间的判断要和中括号有空格，比如[ 判断条件 ] 创建一个service文件进入/etc/systemd/system/，创建一个autoMountDisk.service文件，内容如下： 12345678[Unit]Description=for quickly access blog source #这里填简介[Service]ExecStart=/home/pabebe/VScodeWorkspace/mountDisk.sh # 这里填sh文件路径 [Install]WantedBy=multi-user.target 启动12345678# 重新加载配置文件sudo systemctl daemon-reload # service文件改动后重新转载sudo systemctl enable autoMountDisk.service #设置开机启动# 不重启，立即启动服务sudo systemctl start autoMountDisk.service＃查看运行状态sudo systemctl status autoMountDisk.service 关于service文件里的一些选项，在这里有详细的说明。 问题autoMountDisk.service: Failed to execute command: Exec format error autoMountDisk.service: Failed at step EXEC spawning /home/pabebe/VScodeWorkspace code=exited, status=203/EXEC 解决方案: systemctl执行脚本时需要知道脚本的解释器 在脚本的开头加上 1#!/bin/sh Message: invalid argument: can’t kill an exited process 解决方案:crontab的运行环境变量和终端手动执行的环境变量不一致导致的，然后我在/usr/bin/路径下又放置了一个浏览器驱动 ubuntu指定时间运行脚本crontab命令行方法 使用Ubuntu的Cron固定时间执行Python脚本 Linux使用crontab定时任务执行python文件小记 自动生成cron命令 Crontab使用记录 12345678910111213141516sudo apt-get install cronsudo service cron startcrontab -e # 在打开的文件中添加 生成的cron命令* * * * * /bin/bash /home/pabebe/workspace/clockIN.sh &gt;/workspace/crontab_result.log 2&gt;&amp;1# *****表示每年每月每天每时每分 , 中间是执行指令, 将输出记录在/workspace/crontab_result.log 中.#2&gt;&amp;1的意思是把错误的输出也输出到标准输出（2表示错误，2&gt;表示错误输出，&amp;表示等同于，1表示正确）# 之后 Ctrl+O保存,回车确认,Ctrl+X退出# 成功便输出#crontab: installing new crontabsudo service cron restart# 查看service cron status python库方法 APSchedule crontab模块 截图软件-flameshotUbuntu 18.04默认带的版本是0.51 无法标注文字,要0.6+才可以添加文字标注 1234sudo add-apt-repository ppa:rikmills/bionicsudo apt-get updatesudo apt install flameshotflameshot -v #显示为0.6.0 设置&gt;设备&gt;键盘，设置一个自定义快捷键（拉到最下面）命令填写：flameshot gui 截完图后保存Ctrl+S，复制到剪贴板 Ctrl+C QQ·Linux版下载deepin-wine环境https://mirrors.tuna.tsinghua.edu.cn/deepin/pool/non-free/d/ http://mirrors.aliyun.com/deepin/pool/non-free/d/ https://github.com/zq1997/deepin-wine 12345678910111213wget -O- https://deepin-wine.i-m.dev/setup.sh | sh#超简单安装微信QQ等Wine软件#例如安装微信，替换对应的包名就行sudo apt-get install deepin.com.wechat应用 包名TIM deepin.com.qq.officeQQ deepin.com.qq.imQQ轻聊版 deepin.com.qq.im.light微信 deepin.com.wechat百度网盘 deepin.com.baidu.pan迅雷极速版 deepin.com.thunderspeedWinRAR deepin.cn.com.winrar ## 安装网易云音乐 12wget http://d1.music.126.net/dmusic/netease-cloud-music_1.2.1_amd64_ubuntu_20190428.debsudo dpkg -i netease-cloud-music_1.2.1_amd64_ubuntu_20190428.deb 解锁网易云音乐原理:找到其他有版权或者可以听的外链代替本身,便可以通过一个客户端听大家的歌. 项目地址: https://github.com/nondanee/UnblockNeteaseMusic window版： 12345678# 开启服务器e:cd E:\UnblockNeteaseMusic# -p 后面是端口号node app.js -p 80# 打开网易云音乐，设置-》工具-》自定义代理-》服务器127.0.0.1 -》端口 80# 重启即可 Ubuntu版： ### 寻找网易云服务器的IP 12ping music.163.com＃记住该ip,后面启动需要 ### 自签发证书 根据进阶配置 1234567891011121314# 生成 CA 私钥openssl genrsa -out ca.key 2048# 生成 CA 证书 ("YOURNAME" 处填上你自己的名字)openssl req -x509 -new -nodes -key ca.key -sha256 -days 1825 -out ca.crt -subj "/C=CN/CN=UnblockNeteaseMusic Root CA/O=YOURNAME"# 生成服务器私钥openssl genrsa -out server.key 2048# 生成证书签发请求openssl req -new -sha256 -key server.key -out server.csr -subj "/C=CN/L=Hangzhou/O=NetEase (Hangzhou) Network Co., Ltd/OU=IT Dept./CN=*.music.163.com"# 使用 CA 签发服务器证书openssl x509 -req -extfile &lt;(printf "extendedKeyUsage=serverAuth\nsubjectAltName=DNS:music.163.com,DNS:*.music.163.com") -sha256 -days 365 -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt 将服务器私钥 (server.key) 和服务器证书 (server.crt) , CA 证书 (ca.crt) 拷贝到仓库中覆盖原有文件 ### 添加证书 根据Linux 客户端食用指南 12345# 项目根目录打开终端# 拷贝至系统sudo cp ca.crt /usr/local/share/ca-certificates/# 更新sudo update-ca-certificates ### 添加host 根据deepin/ubuntu 配置记录 123456# 本地 为 127.0.0.1sudo gedit /etc/hosts127.0.0.1 music.163.com127.0.0.1 interface.music.163.com#&lt;Your-Server-IP&gt; music.163.com#&lt;Your-Server-IP&gt; interface.music.163.com 配置后,访问https://music.163.com/,火狐会出现&quot;警告：面临潜在的安全风险&quot;,点击&quot;高级&quot;-&gt;&quot;接受风险并继续&quot; ### 添加默认启动参数 1234cd /usr/share/applicationsls | grep neteasesudo gedit netease-cloud-music.desktop 在Exec这一行末尾增加 --ignore-certificate-errors ### 启动 12# 修改 hosts 前通过 ping music.163.com 获得网易云服务器 IP地址59.111.181.60 sudo node app.js -p 80:443 -f 59.111.181.60 启动好服务器后,打开客户端 网页版https://music.163.com/,先安装[脚本](https://greasyfork.org/zh-CN/scripts/382285-neteasemusic-ui-unlocker),就可以享受了 桌面版version1.2.1,打开可能刚开始还是灰的,但是过一会可以了. 可以看到客户端进行操作时,服务器会出现’MITM &gt; music.163.com (ssl)’,enjoy~ 开机自启动autoUnblockNeteaseMusic.sh脚本，内容如下： 12#!/bin/shsudo node (路径)app.js -p 80:443 -f 59.111.181.60 进入/etc/systemd/system/，创建一个autoUnblockNeteaseMusic.service文件 12cd /etc/systemd/system/sudo gedit autoUnblockNeteaseMusic.service 内容如下： 12345678910[Unit]Description=for enjoying musicAfter=network.targetWants=network.target[Service]ExecStart=..../UnblockNeteaseMusic/autoUnblockNeteaseMusic.sh(修改这里的路径)[Install]WantedBy=multi-user.target 12345678# 重新加载配置文件sudo systemctl daemon-reload # service文件改动后重新转载sudo systemctl enable autoUnblockNeteaseMusic.service #设置开机启动#检验是否出错sudo systemctl start autoUnblockNeteaseMusicsudo systemctl status autoUnblockNeteaseMusicsudo systemctl stop autoUnblockNeteaseMusic 固定图标到任务栏（双图标问题）Ubuntu 18.04 如何固定图标到任务栏 安装搜狗输入法1234567sudo apt install fcitx-bin #安装fcitx-binsudo apt update --fix-missing #修复fcitx-bin安装失败的情况sudo apt install fcitx-bin #重新安装fcitx-binsudo apt install fcitx-table #安装fcitx-table 然后去搜狗官网下载好给予linux的搜狗输入法deb安装包 12345678cd 下载 #若在根目录sudo dpkg -i sogoupinyin*.deb #安装搜狗拼音sudo apt install -f #修复搜狗拼音安装的错误sudo dpkg -i sogoupinyin*.deb #重新安装搜狗拼音dpkg命令：dpkg 是Debian package的简写，为”Debian“ 操作系统 专门开发的套件管理系统，用于软件的安装，更新和移除。所有源自"Debian"的Linux的发行版都使用 dpkg, 例如"Ubuntu". 输入法安装成功后要重新进入系统生效，重新登录或重启。 问题在ubuntu系统下，安装好sogou拼音之后，用了一段时间之后，输入拼音之后，老是出现繁体字，很烦。 解决办法 按住shift 不放，同时，按下ctrl 和F键，会出现“繁简转换”-已启用简体中文 即可 安装stardict 屏幕取词神器123456789sudo apt-get install stardict# 到 http://download.huzheng.org/zh_CN/ 牛津英汉词典# 文件名：stardict-oxford-gb-2.4.2.tar.bz2# 解压文件sudo tar -xjvf stardict-oxford-gb-2.4.2.tar.bz2 # 假设已cd到文件所在目录# 移动文件到 /usr/share/stardict/dic/sudo mv stardict-oxford-gb-2.4.2 /usr/share/stardict/dic/# 重启stardict即可使用 安装Typora（不推荐）方法一：直接在应用商店里下载并安装 创建图标 Ubuntu中的DashBoard中软件启动器均存贮在/usr/share/applications这个目录， 12cd /usr/share/applicationssudo gedit typora.desktop 打开需要编辑的文本内容为： 1234567891011121314151617[Desktop Entry]Encoding=UTF-8Name=Typora#Exec=/home/innovation/typora/Typora#Icon=/home/innovation/typora/resources/app/asserts/icon/icon_256x256@2x.pngExec=/snap/typora-alanzanattadev/2/usr/share/typora/TyporaIcon=/snap/typora-alanzanattadev/2/usr/share/typora/resources/app/asserts/icon/icon_256x256@2x.pngCategories=Application;Development;Java;IDEType=Application#Terminal=1 最后右上角保存退出就OK （推荐）方法二如下： 12345678910111213sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAEwget -qO - https://typora.io/linux/public-key.asc | sudo apt-key add -#add Typora's repositorysudo add-apt-repository 'deb https://typora.io/linux ./'sudo apt-get update#install typorasudo apt-get install typora 通过搜索行搜索typora，然后点击 typora 图标 问题Typora 在 Ubuntu18.04 上面不显示 Markdown 加粗语法 在 Typora’s github.css 里面，将 body 修改为如下内容 12345body &#123; font-family: "Open Sans Regular","Open Sans","Clear Sans","Helvetica Neue",Helvetica,Arial,sans-serif; color: rgb(51, 51, 51); line-height: 1.6;&#125; github.css 是这个主题的css文件打开方式：文件-&gt;偏好设置-&gt;外观-&gt;打开主题文件夹 安装小飞机1sudo add-apt-repository ppa:hzwhuang/ss-qt5 浏览器代理修改发行版本 Ubuntu 18(bionic)的包在它的官网里还没有，因此要改成17(artful)或其他的版本，详见其官网中Technical details about this PPA的介绍 打开”软件和更新”–&gt;”其他软件”,找到”http://ppa.launchpad.net/hzwhuang/ss-qt5/ubuntu bionic Release”,编辑，将发行版 bionic-&gt;artful，如图 12sudo apt-get update #命中成功sudo apt-get install shadowsocks-qt5 有些文章是修改list文件，但是有点小错误。 1234567sudo vim /etc/apt/sources.list.d/hzwhuang-ubuntu-ss-qt5-bionic.list deb http://ppa.launchpad.net/hzwhuang/ss-qt5/ubuntu xenial main # deb-src http://ppa.launchpad.net/hzwhuang/ss-qt5/ubuntu xenial #但是 xenial 的Ｘ要大写。。 # 即 deb http://ppa.launchpad.net/hzwhuang/ss-qt5/ubuntu Xenial main # deb-src http://ppa.launchpad.net/hzwhuang/ss-qt5/ubuntu Xenial 跟着这位大佬配置下去 Ubuntu使用Shadow socks-qt5 其中系统网络代理那里可以选择“自动”,可能没手动的快 全局代理若需要全局代理则需要更多的步骤，参考链接： https://www.wx-smile.com/128 https://www.xiaobaibk.com/xiao-bai-395.html https://www.xiaobaibk.com/xiao-bai-396.html https://blog.csdn.net/jackyzhousales/article/details/88552900 利用Privoxy实现终端下全局代理,建议用以下方法 ps: PAC模式国内网站不代理，国外代理 https://huangweitong.com/229.html http://blog.hehos.top/centos-7-an-zhuang-shadowsocks-ke-hu-duan/ https://www.cnblogs.com/sonictl/p/11714513.html 123456789sudo apt install privoxysudo gedit /etc/privoxy/config# 搜索forward-socks5添加转发代理ip (第1365行)forward-socks5t / 127.0.0.1:1080 . #自选这条# orforward-socks5 / 127.0.0.1:1080 .# 搜索listen-address，确认有这一行（去注释，第783行）listen-address 127.0.0.1:8118 配置环境变量，让终端也能走代理 123456789101112131415161718192021222324252627282930313233343536gedit ~/.bashrc#添加以下内容global_proxy()&#123; proxy_adress="http://127.0.0.1:8118" export https_proxy=$proxy_adress export http_proxy=$proxy_adress export ftp_proxy=$proxy_adress echo "https_proxy is "$https_proxy echo "config success" curl "http://pv.sohu.com/cityjson?ie=utf-8" echo -e '\n'&#125;global_unproxy()&#123; unset https_proxy unset http_proxy unset ftp_proxy echo "https_proxy is "$https_proxy echo "delete config success" curl "http://pv.sohu.com/cityjson?ie=utf-8" echo -e '\n'# curl ip.gs&#125;source ~/.bashrc#sudo systemctl restart privoxysudo service privoxy startsudo service privoxy status#启动全局代理global_proxy#关闭全局代理global_unproxy# 验证curl "http://pv.sohu.com/cityjson?ie=utf-8"curl www.google.comcurl ip.gs 至此，在终端任何HTTP连接都走代理。 bug privoxy[1051]:Wrong number of parameters for forward-socks5t in configuration file. forward-socks5t / 127.0.0.1:1080 . 后面的那个点一定要有 更换Ubuntu主题（Gnome）配置Mac OS主题 下载插件 gnome插件地址https://extensions.gnome.org 点进去，在网页的顶端有以下文字： 12To control GNOME Shell extensions using this site you must install GNOME Shell integration that consists of two parts: browser extension and native host messaging application.Click here to install browser extension（点它在火狐上安装）. See wiki page for native host connector installation instructions. 插件页的左上角会出现 on/off，若使用该插件则点on User Themes ：改变Gnome主题必要插件 Dash to Dock ：类似与mac底部dash的插件 12# 若安装system-monitorsudo apt-get install gir1.2-gtop-2.0 gir1.2-networkmanager-1.0 gir1.2-clutter-1.0 system-monitor：系统资源显示 Removable Drive Menu：U盘快速操作。插入U盘或移动硬盘，可以执行打开、弹出等操作 123456789#设置gnome插件sudo apt install gnome-tweak-tool gnome-shell-extensions chrome-gnome-shellsudo apt-get install gtk2-engines-murrine gtk2-engines-pixbufsudo add-apt-repository ppa:dyatlov-igor/sierra-themesudo apt updatesudo apt install sierra-gtk-theme # point releases# git master branc# sudo apt install sierra-gtk-theme-git #./install.sh Mac OS图标 12# cd到下载路径sudo unzip -o Cupertino-iCons-master.zip -d /usr/share/icons 应用内搜索“优化”或Tweak 窗口-》放置-调为左，也就是x - + 放在每个窗口的左边 扩展-》User themes -open 扩展-》Dash to dock -&gt;维修的标识-》按需调整 shell的主题是指启动器和顶栏的样式 安装Teamviewer（远程控制）设置固定密码 登录同一账号，将所有使用该账号密码登录的设备均添加到同一个分组“我的计算机”下，设置该账户“轻松访问”。 “其他”-》“选项”-》“安全性”-》“个人密码”-》设置密码 添加设备时，填入ID号与上述密码，分入同一个分组“我的计算机”下 ubuntu下安装Teamviewer及使用 Psensor-CPU\GPU性能监控123456sudo apt-get install lm-sensors hddtempapt-get install psensorsensors-detect一路yessensors运行Psensor，从桌面应用程序菜单来获得图形视图。 Psensor - 用于Linux的图形硬件温度监控工具 英伟达显卡监控工具nvtop123456789101112131415# 安装依赖sudo apt install cmake libncurses5-dev libncursesw5-dev git # 下载源码git clone https://github.com/Syllo/nvtop.gitmkdir -p nvtop/build &amp;&amp; cd nvtop/buildcmake .. # 如果报错"Could NOT find NVML (missing: NVML_INCLUDE_DIRS)"# 则执行下边的语句，否则跳过cmake .. -DNVML_RETRIEVE_HEADER_ONLINE=True # 编译makesudo make install 出现 Ubuntu中Failed to initialize NVML: Driver/library version mismatch 更新一下驱动 12ubuntu-drivers devicessudo apt install nvidia-driver-460(所推荐的驱动包)]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paperUnderstanding-ClearGrasp]]></title>
    <url>%2Farticle%2F2d17733a%2F</url>
    <content type="text"><![CDATA[Learning to See Transparent ObjectsWednesday, February 12, 2020 Posted by Shreeyak Sajjan, Research Engineer, Synthesis AI and Andy Zeng, Research Scientist, Robotics at Google Optical 3D range sensors, like RGB-D cameras and LIDAR, have found widespread use in robotics to generate rich and accurate 3D maps of the environment, from self-driving cars to autonomous manipulators. However, despite the ubiquity of these complex robotic systems, transparent objects (like a glass container) can confound even a suite of expensive sensors that are commonly used. This is because optical 3D sensors are driven by algorithms that assume all surfaces are Lambertian, i.e., they reflect light evenly in all directions, resulting in a uniform surface brightness from all viewing angles. However, transparent objects violate this assumption, since their surfaces both refract and reflect light. Hence, most of the depth data from transparent objects are invalid or contain unpredictable noise. Transparent objects often fail to be detected by optical 3D sensors. Top, Right: For instance, glass bottles do not show up in the 3D depth imagery captured from an Intel® RealSense™ D415 RGB-D camera. Bottom: A 3D visualization via point clouds constructed from the depth image. Enabling machines to better sense transparent surfaces would not only improve safety, but could also open up a range of new interactions in unstructured applications — from robots handling kitchenware or sorting plastics for recycling, to navigating indoor environments or generating AR visualizations on glass tabletops. To address this problem, we teamed up with researchers from Synthesis AI and Columbia University to develop ClearGrasp, a machine learning algorithm that is capable of estimating accurate 3D data of transparent objects from RGB-D images. This is made possible by a large-scale synthetic dataset that we are also releasing publicly today. ClearGrasp can work with inputs from any standard RGB-D camera, using deep learning to accurately reconstruct the depth of transparent objects and generalize to completely new objects unseen during training. This in contrast to previous methods, which required prior knowledge of the transparent objects (e.g., their 3D models), often combined with maps of background lighting and camera positions. In this work, we also demonstrate that ClearGrasp can benefit robotic manipulation by incorporating it into our pick and place robot’s control system, where we observe significant improvements in the grasping success rate of transparent plastic objects. ClearGrasp uses deep learning to recover accurate 3D depth data of transparent surfaces. A Visual Dataset of Transparent ObjectsMassive quantities of data are required to train any effective deep learning model (e.g., ImageNet for vision or Wikipedia for BERT), and ClearGrasp is no exception. Unfortunately, no datasets are available with 3D data of transparent objects. Existing 3D datasets like Matterport3D or ScanNet overlook transparent surfaces, because they require expensive and time-consuming labeling processes. To overcome this issue, we created our own large-scale dataset of transparent objects that contains more than 50,000 photorealistic renders with corresponding surface normals) (representing the surface curvature), segmentation masks, edges, and depth, useful for training a variety of 2D and 3D detection tasks. Each image contains up to five transparent objects, either on a flat ground plane or inside a tote, with various backgrounds and lighting. Some example data of transparent objects from the ClearGrasp synthetic dataset. We also include a test set of 286 real-world images with corresponding ground truth depth. The real-world images were taken by a painstaking process of replacing each transparent object in the scene with a painted one in the same pose. The images are captured under a number of different indoor lighting conditions, using various cloth and veneer backgrounds and containing random opaque objects scattered around the scene. They contain both known objects, present in the synthetic training set, and novel objects. Left: The real-world image capturing setup, Middle: Custom user interface enables precisely replacing each transparent object with a spray-painted duplicate, Right: Example of captured data. The ChallengeWhile the distorted view of the background seen through transparent objects confounds typical depth estimation approaches, there are clues that hint at the objects’ shape. Transparent surfaces exhibit specular reflections, which are mirror-like reflections that show up as bright spots in a well-lit environment. Since these visual cues are prominent in RGB images and are influenced primarily by the shape of the objects, convolutional neural networks can use these reflections to infer accurate surface normals, which then can be used for depth estimation. Specular reflections on transparent objects create distinct features that vary based on the object shape and provide strong visual cues for estimating surface normals. Most machine learning algorithms try to directly estimate depth from a monocular RGB image. However, monocular depth estimation is an ill-posed task, even for humans. We observed large errors in estimating the depth of flat background surfaces, which compounds the error in depth estimates for the transparent objects resting atop them. Therefore, rather than directly estimating the depth of all geometry, we conjectured that correcting the initial depth estimates from an RGB-D 3D camera is more practical — it would enable us to use the depth from the non-transparent surfaces to inform the depth of transparent surfaces. The ClearGrasp AlgorithmClearGrasp uses 3 neural networks: a network to estimate surface normals, one for occlusion boundaries (depth discontinuities), and one that masks transparent objects. The mask is used to remove all pixels belonging to transparent objects, so that the correct depths can be filled in. We then use a global optimization module that starts extending the depth from known surfaces, using the predicted surface normals to guide the shape of the reconstruction, and the predicted occlusion boundaries to maintain the separation between distinct objects. Overview of our method. The point cloud was generated using the output depth and is colored with its surface normals. Each of the neural networks was trained on our synthetic dataset and they performed well on real-world transparent objects. However, the surface normal estimations for other surfaces, like walls or fruits, were poor. This is because of the limitations of our synthetic dataset, which contains only transparent objects on a ground plane. To alleviate this issue, we included some real indoor scenes from the Matterport3D and ScanNet datasets in the surface normals training loop. By training on both the in-domain synthetic dataset and out-of-domain real word dataset, the model performed well on all surfaces in our test set. Surface Normal estimation on real images when trained on a) Matterport3D and ScanNet only (MP+SN), b) our synthetic dataset only, and c) MP+SN as well as our synthetic dataset. Note how the model trained on MP+SN fails to detect the transparent objects. The model trained on only synthetic data picks up the real plastic bottles remarkably well, but fails for other objects and surfaces. When trained on both, our model gets the best of both worlds. ResultsOverall, our quantitative experiments show that ClearGrasp is able to reconstruct depth for transparent objects with much higher fidelity than alternative methods. Despite being trained on only synthetic transparent objects, we find our models are able to adapt well to the real-world domain — achieving very similar quantitative reconstruction performance on known objects across domains. Our models also generalize well to novel objects with complex shapes never seen before. To check the qualitative performance of ClearGrasp, we construct 3D point clouds from the input and output depth images, as shown below (additional examples available on the project webpage). The resulting estimated 3D surfaces have clean and coherent reconstructed shapes — important for applications, such as 3D mapping and 3D object detection — without the jagged noise seen in monocular depth estimation methods. Our models are robust and perform well in challenging conditions, such as identifying transparent objects situated in a patterned background or differentiating between transparent objects partially occluding one another. Qualitative results on real images. Top two rows: results on known objects. Bottom two rows: results on novel objects. The point clouds, colored with their surface normals, are generated from the corresponding depth images. Most importantly, the output depth from ClearGrasp can be directly used as input to state-of-the-art manipulation algorithms that use RGB-D images. By using ClearGrasp’s output depth estimates instead of the raw sensor data, our grasping algorithm on a UR5 robot arm saw significant improvements in the grasping success rates of transparent objects. When using the parallel-jaw gripper, the success rate improved from a baseline of 12% to 74%, and from 64% to 86% with suction. Manipulation of novel transparent objects using ClearGrasp. Note the challenging conditions: textureless background, complex object shapes and the directional light causing confusing shadows and caustics) (the patterns of light that occur when light rays are reflected or refracted from a surface). Limitations &amp; Future WorkA limitation of our synthetic dataset is that it does not represent accurate caustics), due to the limitations of rendering with traditional path-tracing algorithms. As a result, our models confuse bright caustics coupled with shadows to be independent transparent objects. Despite these drawbacks, our work with ClearGrasp shows that synthetic data remains a viable approach to achieve competent results for learning-based depth reconstruction methods. A promising direction for future work is improving the domain transfer to real-world images by generating renders with physically-correct caustics and surface imperfections such as fingerprints. 运行项目https://github.com/Shreeyak/cleargrasp 1python eval_depth_completion.py -c config/config.yaml bug无法定位软件包 libhdf5-10 无法定位软件包 libhdf5-cpp-11 因为Ubuntu18.04源没有对应包，只有Ubuntu16.04有，所以在 /etc/apt/sources.list 文件中像下面这样添加一行: 1deb http://security.ubuntu.com/ubuntu xenial-security main universe 用在 AMD64 上 libhdf5-10_1.8.16+docs-4ubuntu1.1_amd64.deb 的下载页面 fatal error: GL/glu.h: 没有那个文件或目录 include &lt;GL/glu.h&gt; 1sudo apt-get install libglu-dev g++: warning: /usr/include/hdf5/serial/ linker input file unused because linking notdone 12sudo make cleansudo make depth2depth.cpp:11:10: fatal error: hdf5.h: 没有那个文件或目录#include “hdf5.h” 确认环境配置好。 123cd api/depth2depth/gapsexport CPATH="/usr/include/hdf5/serial/" # Ensure this path is same as read from output of `find /usr -iname "*hdf5.h*"`echo $CPATH 附加depth2depth algorithm-Deep Depth Completion of a Single RGB-D Image]]></content>
      <categories>
        <category>Scientific Research</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu各种命令详解]]></title>
    <url>%2Farticle%2F79acc1fa%2F</url>
    <content type="text"><![CDATA[Ubuntu各种命令详解查询架构12345678uname -a# Linux **** 5.4.0-38-generic #42~18.04.1-Ubuntu SMP Mon Jun 15 09:48:10 UTC 2020 x86_64 x86_64 x86_64 GNU/Linuxarch# 显示操作系统架构类型 x86_64 dpkg --print-architecture #amd64# dpkg 的命令可用于查看 Debian/ Ubuntu 操作系统是 32 位还是 64 位# 如果当前 Linux 是 64 位则输出 amd64，是 32 位则会输出 i386。 设置或查看环境变量 1234567891011# 加到PATH末尾export PATH=$PATH:/path/to/your/dir# 加到PATH开头export PATH=/path/to/your/dir:$PATHenvenv命令是environment的缩写，用于列出所有的环境变量export单独使用export命令也可以像env列出所有的环境变量，不过export命令还有其他额外的功能echo $PATHecho $PATH用于列出变量PATH的值，里面包含了已添加的目录 压缩命令zip12345# 压缩文件（对于目录失效）#压缩：zip good.zip good1 good2# 解压：unzip good.zip tar12345678910#打包： tar -cf soft.tar soft#解包：tar -xf soft.tar soft压缩目录#打包压缩：tar czvf usr.tar.gz /home#解压缩：tar xzvf usr.tar.gz 参数说明x是解压，c 是压缩z指gz文件，j指bz文件f指定文件 添加/删除源123456789101112#添加PPAsudo add-apt-repository ppa:zarquon42/meshlab #源名#安装工具sudo apt-get install ppa-purge #移除PPA，输入以下命令： sudo ppa-purge ppa:zarquon42/meshlab #源名 orsudo add-apt-repository -r ppa:user/ppa-name#然后进入 /etc/apt/sources.list.d 目录，将相应 ppa 源的保存文件删除。#最后同样更新一下：sudo apt-get update 添加/删除包123apt-get --purge remove &lt;package&gt; # 删除软件及其配置文件apt-get autoremove &lt;package&gt; # 删除没用的依赖包dpkg -l |grep ^rc|awk '&#123;print $2&#125;' |sudo xargs dpkg -P # 清理dpkg的列表中有“rc”状态的软件包 参考文章tar命令 (xzvf xjvf)详解]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu使用Visual Profiler]]></title>
    <url>%2Farticle%2Fed84546b%2F</url>
    <content type="text"><![CDATA[Ubuntu使用Visual Profiler配置java环境123456789101112131415161718//卸载OpenJDKsudo apt-get purge openjdk/openjdk*sudo apt-get clean/autoclean//安装jre、jdksudo apt install openjdk-8-jre-headlesssudo apt install openjdk-8-jdk-headless//添加环境变量sudo vim ~/.bashrc#set oracle jdk environmentexport JAVA_HOME=/usr/lib/jvm/jdk1.8.0_191 ## 这里要注意目录要换成自己解压的jdk 目录export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH source ~/.bashrc//验证java -version//如果你安装了多个版本的jdk，你可以通过以下命令在这些版本之间切换sudo update-alternatives –config java 使用nvvp1nvvp 出现Visual Profiler图形化界面 nvprof命令使用常用度量标准123456789101112nvprof --query-metrics # 查看所有能用的参数命令nvprof 计时统计工具 --metrics achiveed_ocupancy 内核占用率 --metrics gld_throughput 全局加载吞吐量 --metrics gld_efficiency 全局内存读取效率 --metrics gst_efficiency 全局内存载入效率 --metrics gld_transactions 全局内存加载事务效率 ...最常用的有:achieved_occupancy 占用率（每个SM在每个cycle能够达到的最大active warp数目占总warp的比例）gld_throughput 全局加载吞吐量（较高的load throughput也不一定就有较高的性能）gld_efficiency 全局内存读取效率（我们确切需要的global load throughput与实际得到global load memory的比值） bugnvprof –metrics gld_throughput ./multiply ./test/a_15360_15360.mtx ./test/b_15360_2.mtx ./outnvprof nvprof –metrics achieved_occupancy ./multiply ./test/a_15360_15360.mtx ./test/b_15360_2.mtx ./out Make sure cudaProfilerStop() or cuProfilerStop() is called before application exit to flush profile data. 解决方法在程序末尾加cudaDeviceReset()或者cudaProfilerStop() 在runtime API下，添加 12345#include "cuda_profiler_api.h"cudaProfilerStart();//划分出您需要profile(多数情况下是指用来测定你所编写的应用程序的运行效率的一个程序)的部分cudaDeviceSynchronize();cudaProfilerStop(); 在dariver API下则为，添加 12345#include "cudaProfiler.h"cuProfilerStart();...cudaDeviceSynchronize();cuProfilerStop(); 这个方法是visual profiler适用的，nsight的profiler功能可能不适用。 在你的程序结束前, 请至少调用如下两种之一, 再退出.(1)cudaDeviceSynchronize();cudaDeviceReset();或者(2)cudaDeviceSynchronize();cudaProfilerStop(); 注意别漏了cudaDeviceSynchronize();不加上面任意一种而直接退出将导致各种奇葩问题, 例如看不到部分数据, 看不到时间线之类的. cudaDeviceReset重置当前线程所关联过的当前设备的所有资源.如在调用cuda的过程中出现中途错误，需要提前退出程序，可以调用这个cudaDeviceReset来清空之前所关联过得所有资源。 猜想: 可能也能清空当前线程和device的映射关系 ERR_NVGPUCTRPERM - The user does not have permission to profile on the target device. 123456# 既然是没有权限，则采用sudo来解决which nvprof#出现nvprof所在路径： /usr/local/cuda-10.1/bin/nvprofsudo /usr/local/cuda-10.1/bin/nvprof --metrics gld_throughput # +执行程序sudo /usr/local/cuda-10.1/bin/nvprof --metrics gld_throughput ./multiply ./test/a_15360_15360.mtx ./test/b_15360_2.mtx ./outnvprofsudo /usr/local/cuda-10.1/bin/nvprof -o result.nvcc -f --metrics gld_throughput ./multiply_TSM2_V3 ./test/a_30720_30720.mtx ./test/b_30720_2.mtx ./out 参考文章GPU世界论坛 Ubuntu18.04安装jdk环境 Ubuntu 18.04安装Java JDK8三种方式 CUDA：（五）Nvidia Visual Profiler (Nvidia自带内核执行代码分析软件) CUDA入门（四）Visual Profiler profiler和Nsight分析问题 NVIDIA Profiling Tools nvprof]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paperMemo-图片质量评价指标]]></title>
    <url>%2Farticle%2Fe3c77110%2F</url>
    <content type="text"><![CDATA[SSIM结构相似性指数（structural similarity index，SSIM）是一种用于量化两幅图像间的结构相似性的指标。与L2损失函数不同，SSIM仿照人类的视觉系统（Human Visual System,HVS）实现了结构相似性的有关理论，对图像的局部结构变化的感知敏感。SSIM从亮度、对比度以及结构量化图像的属性，用均值估计亮度，方差估计对比度，协方差估计结构相似程度。SSIM值的范围为0至1，越大代表图像越相似。如果两张图片完全一样时，SSIM值为1。 给定x,y两张图片，两者之间的照明度(luminance)、对比度 (contrast) 和结构 (structure)分别如下公式所示： 定义： 令α,β,γ均为1因此，SSIM的表达式为： 其中，μx是x的平均值，σ2x是x的方差，μy是y的平均值，σ2y是y的方差，σxy是x 和 y 的协方差，c1=(k1L)2，c2=(k2L)2是两个用于维持稳定的常数，避免出现除零的情况，L 为像素值的范围，表示B-bit的图像的L值为2B-1。一般情况下，k1=0.01,k2=0.03 PSNR峰值信噪比(Peak Signal to Noise Ratio, PSNR)是一种评价图像质量的度量标准。因为PSNR值具有局限性，所以它只是衡量最大值信号和背景噪音之间的图像质量参考值。PSNR的单位为dB，其值越大，图像失真越少。一般来说，PSNR高于40dB说明图像质量几乎与原图一样好；在30-40dB之间通常表示图像质量的失真损失在可接受范围内；在20-30dB之间说明图像质量比较差；PSNR低于20dB说明图像失真严重。 给定一个大小为m×n的灰度图 I 和噪声图 K，均方误差(MSE, Mean Square Error)公式如下： 定义： 其中，MAX2I 为图片可能的最大像素值，即B-bit的图像的MAX2I值为2B-1。一般地，针对 uint8 数据，最大像素值为255,；针对浮点型数据，最大像素值为1。 有三种方法来计算彩色RGB图像的PSNR：分别计算 RGB 三个通道的 PSNR，然后取平均值；或者计算RGB各个通道的均方差的均值，然后统一求PSNR；或者把RGB转化为 YCbCr，然后只计算 Y(亮度)分量的PSNR。 LPIPS学习感知图像块相似度(Learned Perceptual Image Patch Similarity, LPIPS)也称为“感知损失”(perceptual loss)，用于度量两张图像之间的差别。来源于CVPR2018的一篇论文《The Unreasonable Effectiveness of Deep Features as a Perceptual Metric》，该度量标准学习生成图像到Ground Truth的反向映射强制生成器学习从假图像中重构真实图像的反向映射，并优先处理它们之间的感知相似度。LPIPS 比传统方法（比如L2/PSNR, SSIM, FSIM）更符合人类的感知情况。LPIPS的值越低表示两张图像越相似，反之，则差异越大。 给定Ground Truth图像参照块x和含噪声图像失真块x0，感知相似度度量公式如下： 其中，d为x0与x之间的距离。从L层提取特征堆(feature stack)并在通道维度中进行单位规格化(unit-normalize)。利用向量wl来放缩激活通道数并计算L2距离。最后在空间上平均，在通道上求和。 基于学习的相似度得分函数公式如下： 给定Ground Truth图像参照块x和含噪声图像失真块x0的距离d0、Ground Truth图像参照块x和含噪声图像失真块x1的距离d1，在顶部训练一个网络G（包含2个32通道FC-ReLU层、1通道FC层和sigmoid层）映射到得分h。]]></content>
      <categories>
        <category>Scientific Research</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu18.04下深度学习环境与blog搭建]]></title>
    <url>%2Farticle%2Facdf71cc%2F</url>
    <content type="text"><![CDATA[本机系统：Ubuntu18.04 本机显卡型号查询 1lspci | grep -i nvidia 查看该显卡是否支持cuda https://developer.nvidia.com/cuda-gpus 更新NVIDIA驱动添加 Graphic Drivers PPA 123sudo add-apt-repository ppa:xorg-edgers/ppa #添加ppa源sudo add-apt-repository ppa:graphics-drivers/ppa #添加ppa源sudo apt-get update 12ubuntu-drivers devicessudo apt install nvidia-driver-440(所推荐的驱动包) or 打开 Software &amp; Updates，选择 Additional Drivers，一般需要加载一定时间，会出现多个驱动，选择最新的也就是版本号最大的 NVIDIA-Driver，点击应用，需要等待一点时间生成应用，完成便成功安装了驱动 查看NVIDIA驱动版本 12nvidia-smi # 显示驱动版本440和驱动的CUDA版本10.2（和运行CUDA不同） or 1sudo dpkg --list | grep nvidia-* or 1cat /proc/driver/nvidia/version CUDA与cuDNN只是深度学习环境，装了conda就没必要单独装cuda什么的了，虚拟环境有指令可以包含进去。 但是CUDA的其他文件可能没有, 比如nvcc.因此我想安装完整的CUDA,。另外, 如果驱动满足, 这里的cudatoolkit版本&lt;=系统, 也能正常使用. 完整的CUDA安装CUDA Toolkit Archive （Ubuntu18.04 下载runfile版本） cuda10.1(选择这个版本的原因，是因为cudnn在2020.5.26都没有对应的版本) 123wget http://developer.download.nvidia.cn/compute/cuda/10.1/Prod/local_installers/cuda_10.1.243_418.87.00_linux.runsudo sh cuda_10.1.243_418.87.00_linux.run 安装完后，在.bashrc文件末尾添加环境变量 1234567sudo gedit ~/.bashrcexport PATH=$PATH:/usr/local/cuda-10.1/bin export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.1/lib64 export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/cuda-10.1/lib64 source ~/.bashrc 测试 1234567nvcc --version #出现Cuda compilation tools, release 10.1, V10.1.243cd /usr/local/cuda/samples/1_Utilities/deviceQuery sudo make./deviceQuery#出现deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.1, NumDevs = 1Result = PASS https://share.weiyun.com/zMGMSFEE ## cuDNN cuDNN是用于神经网络的GPU库, 有些python包依赖cuDNN才能运行. 官网说明 官网cuDNN Archive下载如图文件，依次安装。 123sudo cp cuda/include/cudnn.h /usr/local/cuda-版本/include sudo cp cuda/lib64/libcudnn* /usr/local/cuda-版本/lib64sudo chmod a+r /usr/local/cuda-版本/include/cudnn.h /usr/local/cuda-9.0/lib64/libcudnn* 安装后查看版本： 1cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2 (可选)用sample验证CUDNN（需要安装dev和doc两个deb） 修改cudnn.h的include “…”为include &lt;…&gt;，否则下面编译会报错 123cd /usr/src/cudnn_samples_v7/mnistCUDNN # 如果没有操作权限就cp到可操作的位置make clean &amp;&amp; make./minstCUDNN 删除旧版cuda10.1 与 cudann8.0.412cd /usr/local/cuda/binsudo ./cuda-uninstaller 因为GPU为3090,所以需要升级cuda 1234sudo apt-get remove cudasudo apt --purge remove "*cublas*" "cuda*"sudo apt-get autocleansudo apt-get remove cuda* 12cd /usr/local/sudo rm -r cuda-10.1 安装新版cuda11.1+cudnn8.0.51234sudo wget https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda_11.1.0_455.23.05_linux.runsudo sh cuda_11.1.0_455.23.05_linux.run注意因为之前安装好了nvidia 驱动,所以不需要安装驱动啦. 修改对应环境变量. 官网cuDNN Archive下载cudnn8.0.4 cuDNN Library for Linux (x86_64) 然后j解压,复制文件： 123sudo cp cuda/include/cudnn.h /usr/local/cuda-11.1/include sudo cp cuda/lib64/libcudnn* /usr/local/cuda-11.1/lib64sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn* 验证安装结果：1cat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2 安装Miniconda点击Anaconda 镜像使用帮助，下载Miniconda （Miniconda3-py37_4.8.2-Linux-x86_64.sh）就可以了。 12345678910111213141516# 进入下载目录# cd Downloads/cd 下载# 执行安装 bash Miniconda3-py37_4.8.2-Linux-x86_64.sh 遇到Do you accept the license terms? [yes|no]回车q键退出阅读licenseyesMiniconda3 will now be installed into this location:/home/用户名/miniconda3回车默认Do you wish the installer to initialize Miniconda3by running conda init? [yes|no]yes 完成后关闭该终端，再一次打开终端 测试是否安装成功 12345678conda --version#添加国内镜像，进入清华镜像源anaconda页面conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/freeconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/mainconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forgeconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda conda config --set show_channel_urls yes conda常用命令pytorchGPU为所创建的虚拟环境名字 创建虚拟环境 1conda create -n pytorchGPU python=3.7.6 激活虚拟环境 1conda activate pytorchGPU 退出当前虚拟环境 1conda deactivate 删除虚拟环境操作1conda remove -n pytorchGPU --all 1234567891011conda info ＃查看conda的信息（是否有镜像库）conda clean -i ＃清除缓存索引conda list #查看安装了哪些包。conda env list 或 conda info -e #查看当前存在哪些虚拟环境conda update conda #检查更新当前condapython --version #查看python版本 对虚拟环境中安装额外的包使用命令conda install -n your_env_name [package]即可安装package到your_env_name中 删除环境中的某个包使用命令conda remove --name your_env_name package_name 即可 配置深度学习环境 Anaconda Cloud官网提供了各种包的安装命令，可以搜索并安装到我们创建的虚拟环境中，例如搜索pytorch，执行便可安装 再一次检查镜像源： 123sudo gedit ~/.condarc# windowC:\Users\user_name\.condarc 配置文件修改如下： channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/simpleitk/ - defaults show_channel_urls: true 12conda info ＃查看conda的信息（是否有镜像库）conda clean -i ＃清除缓存索引 安装GPU版pytorch，在官网http://pytorch.org/选一个你的当前的配置 1234conda create -n pytorchGPU python=3.7.6conda activate pytorchGPUconda install pytorch torchvision cudatoolkit=10.1 #去掉-c pytorch安装的时候才会默认从清华源下载相应的包 测试12345678910111213141516#在VScode里面测试import torchimport torchvisionfrom torch.backends import cudnn# TEST 出现tensor([1.], device='cuda:0')x = torch.Tensor([1.0])xx = x.cuda()print(xx)# CUDA cuDNN test ,出现２个trueprint(torch.cuda.is_available())print(cudnn.is_acceptable(xx))#输出当前GPU型号gnlook = torch.cuda.current_device()print(torch.cuda.get_device_name(gnlook)) ## 出现错误 Torch not compiled with CUDA enabled 不知道是什么原因，清华源下载的是cpu版pytorch 我认为是没有检测到安装好的英伟达驱动程序，所以检查好驱动版本后重启电脑，重新安装pytorch（删掉这个虚拟环境，再来）。 IDE-VScode推荐Visual Studio Code，轻量快速，在终端激活环境，便可直接运行程序 ##安装 1.进入官网，直接下载压缩包。（我的是64位） https://code.visualstudio.com/Download 12cd 下载sudo dpkg -i code_1.35.0-1559611369_amd64.deb 解压完成，在全部应用的区域就可以看到VS Code的图标了，直接点击打开 配置ubuntu18.04+VSCode+Python安装 ubuntu18.04- +vscode c++使用时的三个配置文件 pylint路径设置VSCode中pytorch出现’torch’ has no member ‘xxx’的错误 setting中python.linting.pylintPath : /home/用户名/miniconda3/pkgs/pylint-2.5.3-py37hc8dfbb8_0/bin/pylint 保存后便无报错。 注意：该方法必须是用conda安装pylint,而不是pip安装的。可以通过pip uninstall pylint 卸载，再conda重装pylint 美化VSCode配置FiraCode字体 下载字体 到FiraCode字体的GitHub页面 找到下面的Download链接下载最新字体 解压缩下载文件，并进入ttf文件夹 选中所有字体文件，右键选择安装 配置字体 打开vscode的配置页面，并搜索font 修改editor.fontFamily配置项的内容为：&apos;Fira Code Retina&apos;, &apos;Microsoft Yahei UI&apos;。由于Fira Code字体不支持中文，这里配置微软雅黑为第二字体 配置后重启vscode vscode对于交互式ipynb文件的问题：Interactive window with Matplotlib and notebook option IDE-PyCharm1sudo snap install [pycharm-professional|pycharm-community] --classic 最好利用edu邮箱申请专业版，功能多且免费，Community Edition不包括Jupyter笔记本集成。 在学生授权有效期间可以下载安装任何 JetBrains Toolbox 下任何新版本开发工具，并使用 JetBrains 帐号激活。理论上只要邮箱不回收，就可以一直用。每次申请都是一年，一年后继续申请就好了 IDEA 学生授权申请方式（免费） Ubuntu上安装PyCharm及设置 优化代码模板PyCharm –&gt; 选择File –&gt; Settings –&gt; Editor –&gt; Code Style –&gt; File and Code Templates –&gt; Python Script 1234567#!/usr/bin/env python# -*- coding: UTF-8 -*-'''=================================================@Author ：Pabebe@Date ：$&#123;DATE&#125; $&#123;TIME&#125;@Description ：==================================================''' 连接github配置路径 File | Settings | Version Control | GitHub 配置github账号密码 git ubuntu默认配置好了，window自己配置git路径。 推送项目至版本库/github VCS–&gt;Import into Version Control–&gt;Share Project on GitHub/create git repository 克隆项目 VCS -&gt; Get from Version Control -&gt; Git .gitignore 相应规则 ### 生成requirements.txt (1)会将环境中的依赖包全都加入，如果使用的全局环境，则下载的所有包都会在里面，不管是不时当前项目依赖的，如下图 1pip freeze &gt; requirements.txt (2)推荐，只加入项目所依赖的包 1234# 安装pip install pipreqs# 在当前目录生成pipreqs ./ --encoding=utf8 --force --encoding=utf8 为使用utf8编码，不然可能会报UnicodeDecodeError: ‘gbk’ codec can’t decode byte 0xae in position 406: illegal multibyte sequence 的错误。 --force 强制执行，当 生成目录下的requirements.txt存在时覆盖。 使用 requirements.txt 1pip install -r requirements.txt pytorch 网络结构可视化pytorch 的模型结构可视化方法： （1）使用 tensorboardX（不太直观） （2）使用 graphviz 加上 torchviz （依赖于 graphviz 和 GitHub 第三方库 torchviz，线条比较死板） （3）使用微软的 tensorwatch （TensorWatch 是一个调试和可视化工具，专为 Microsoft Research 的数据科学，深度学习和强化学习而设计。只能在 jupyter notebook 中使用，图片比较美观，但有时候会出现一些莫名的错误） （4）使用 netron 可视化工具（.pt 或者是 .pth 文件,对pytorch模型的支持不友好） ## 使用第二种 12pip install torchviz# 该指令同时安装 graphviz, torchviz 使用demo 12 使用第三种12pip install tensorwatch#该指令同时安装 plotly-4.9.0 pydotz-1.5.1 retrying-1.3.3 tensorwatch-0.9.1 使用demo 12 LINUX下查看点云图Ubuntu18版本缺失？ LINUX下查看点云图————point cloud（.ply .vtk .pcd） 所以还是安装cloudcompare 1234567# 科学上网，这条命令自动安装latest stable版本sudo snap install cloudcompare#open pointcloud viewercloudcompare.ccViewer#open the main software cloudcompare.CloudCompare Bolgubuntu下搭建Hexo+GitHub博客 Ubuntu16 升级nodejs版本 参考链接Ubuntu 搭建深度学习环境（直接安装anaconda，就不需要再繁琐安装cuda、cudann了） Pycharm没有菜单栏 conda安装Pytorch下载过慢解决办法(11月26日更新ubuntu下pytorch1.3安装方法) ubuntu自带截图工具–方便好用 Ubuntu 18.10 下安装CUDA10/CUDA10.1 PyCharm设置代码模板：自动生成文件名、作者、创建日期等信息 pytorch 网络结构可视化方法汇总（三种实现方法详解） Pytorch神经网络结构图可视化（Ubuntu+torchviz+graphviz） Pytorch神经网络结构可视化模块–Tensorwatch 通过pycharm使用git和github的步骤（图文详解） python生成requirements.txt的两种方法]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paperUnderstanding&Reconstruction-3D Photography using Context-aware Layered Depth Inpainting]]></title>
    <url>%2Farticle%2Fce73fd06%2F</url>
    <content type="text"><![CDATA[1 论文介绍1.1 方法概述该论文提出了一种将单张RGBD图像转换为多视角合成的3D照片的方法，给定上下文区域和现有RGB-D信息，来预测（修补）合成区域颜色值和深度值。 预处理阶段：给定输入的 RGB-D 图像（深度图除了来自双摄像头的不同视角，或者深度相机，或者用普通的RGB图通过DPSNet估计出来），首先将输入的 RGB-D 图的深度通道归一化到 0-1 之间，如图1.1(a-b)所示。并对深度图进行双边中值滤波来锐化以使得边缘更细化，如图1.1(c-d)所示。再基于此图片生成初始 LDI（Layered Depth Image）。然后再根据给定阈值(论文中定义为10 )判断相邻像素的视差，找到深度不连续像素，最后删除短的不连续边（包括孤立的和悬空的片段，size&lt;10像素)，得到最终的深度不连续边集合，如图1.1(e-f)所示。 图1.1 预处理步骤图 分割阶段：每次选择一条深度不连续边借助填补算法来修复背景，首先在深度不连续处断开 LDI 像素连接，得到 (前景、背景) 轮廓像素，如图1.2(b)所示。合成区域就在背景轮廓附近，如图1.2(c)所示红色区域所需要修复的部分。“联系上下文”，根据背景轮廓周围的像素来推测红色块原本隐藏的部分。使用分水岭算法初始化颜色和深度值，再使用深度学习的方法填补该合成区域。由于检测到的深度边缘在遮挡边界附近可能没有很好的对齐，所以将合成区域扩大了5个像素。这种策略有助于减少合成区域中的artifacts。 图1.2 分割图 修复阶段：给定颜色、深度、提取以及连接的深度边缘作为输入，随机选择其中一个边作为子问题。首先使用边缘修复网络修复合成区域中（红色区域）的深度边缘，然后将修复后的深度边缘与语境颜色连接在一起，并应用颜色修复网络生成用以修复的颜色。类似地，将修复后的深度边缘与语境深度连接起来，并应用深度修复网络生成修复深度。 多层修复阶段：在deep-complex的情况下，使用一次inpainting模型的效果是不完美的，因为inpainting深度边缘不连续区域过程中仍会出现空白(hole)，如图1.3(b)所示。因此，多次应用inpainting模型，直到没有进一步的inpainted深度边缘生成，可彻底消除这些artifacts，如图1.3(c)所示。 图1.3 多次修复效果图 合成阶段：通过将所有修复好的颜色和深度值重新集成到原始 LDI 中，形成最终的 3D 纹理网格。使用网格表示可以快速渲染新的视图，而无需对每个视角进行推理，因此文章算法得到的3D表示可以在边缘设备上通过标准图形引擎轻松渲染。 1.2 网络架构论文中的网络架构如图2.1，将整个修补工作由三个子网络组成，分别是边缘修复网络、颜色修复网络、深度修复网络。 （1）将上下文区域的边作为输入，使用边修复网络预测合成区域中的深度边，先预测边信息能够推断 (基于边的) 结构信息，有助于约束 (颜色和深度的) 内容 预测。 （2）再以边缘修复网络提供的物体结构信息和上下文区域的颜色，使用颜色修复网络预测合成区域中的颜色。 （3）最后再使用同样的方法预测合成区域中的深度信息。 图2.1 网络架构 边缘修复模型由一个边缘生成器和一个鉴别器网络组成。SN→IN表示先进行光谱归一化(SN)，再进行实例归一化(IN)。ResnetBlock由2个卷积层、指定的超参数和一个block输入和输出之间的跳跃连接组成。 而深度和颜色的渲染网络由一个标准的U-Net架构和部分卷积层构成。其中，下图内PConv表示部分卷积层, BatchNorm表示BN。我们添加上下文和合成区域作为PConv层的局部掩码。 将三个模型的合成区域的输入深度和RGB值设置为0。对于深度和颜色的修复模型，合成区域的输入边缘值同样被设为0，而对于边缘修复网络，则保持不变。 1.3 项目说明main.py:执行3D照片修复 mesh.py:关于上下文感知深度的函数 mesh_tools.py:在mesh.py中使用的一些常见函数 utils.py:一些用于图像预处理，数据加载的常用函数 networks.py:修复模型的网络架构 ImageRename.py:按0000xx.png的格式重命名RealEstate10K数据集图片 Image文件夹保存实验数据（随机挑选10张样例作演示） Video文件夹保存生成的3D视频（只放入样例，理由如上） MiDaS 文件夹下 run.py:执行深度估计 monodepth_net.py:深度估计模型的网络结构 MiDaS_utils.py:深度估计中的一些常见函数 相关环境 Linux ( Ubuntu 18.04.4 LTS) Miniconda Python 3.7.7 PyTorch 1.5.0 其他的 Python 依赖项： 12345678opencv-python==4.2.0.32vispy==0.6.4moviepy==1.0.2transforms3d==0.3.1networkx==2.3cynetworkxscikit-imagepyyaml 安装 运行以下指令开始安装： 12345678910#已有现成的pytorch环境，可跳过conda create -n 3DP python=3.7 anacondaconda activate 3DPconda install pytorch==1.4.0 torchvision==0.5.0 cudatoolkit==10.1.243 -c pytorch# 激活虚拟环境conda activate pytorchGPUcd 项目目录pip install -r requirements.txtpip install pyyaml 其中安装 cynetworkx报错 ModuleNotFoundError: No module named ‘Cython’ ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output. ModuleNotFoundError: No module named ‘decorator’ ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output. 1234# cynetworkx是networkx包的cython端口，用于创建、操作和 复杂网络的结构、动力学和功能的研究# cynetworkx需要以下依赖pip install Cythonpip install decorator 下载模型权值: 123# +x 是添加执行文件权限chmod +x download.sh./download.sh 运行示例1python main.py --config argument.yml 3D照片的生成将需要2-3分钟，将取决于可获得的计算资源 如果想改变默认配置。请阅读document .md并修改argument.yml 。 实验需要tizifanguoqu下载 https://raw.githubusercontent.com/richzhang/PerceptualSimilarity/master/models/weights/v0.1/alex.pth 一般实验均包括以下三个方面： 量化实验(与其他的方法做对比) Ablation study 消融实验(网络各个组件进行对比，那一部分贡献最大) 可视化结果 经过以上实验后，该模型在日常的大部分场景图片中都能够生成效果炫酷、惊艳的3D照片，该论文方法在SSIM和PSNR上都有较好的性能，其优越的LPIPS评分表现出更好的感知质量。但仍然存在下面三个缺点： 对于复杂或者稀疏结构的场景（如4.3节中的路灯），不能得到满意的结果。 该论文模型不能很好地处理反光/透明表面（如4.3节中的透明花瓶） 生成时间过长，通常情况下在本人电脑上处理时间为 4-6 分钟，具体取决于可用的计算资源。 本人认为导致这些结果的原因有四个： 应该是现有的单图像深度估计算法(如MegaDepth)通常难以处理稀疏和复杂的结构，并可能产生过于平滑的深度地图。 由于使用了显式深度映射，RGB颜色信息与深度信息需要进行一些处理操作来对齐。在此过程中，深度信息损失过多。 从单一的一张图片生成多个视角的视频序列所能利用的信息量太少，导致生成结果细节丢失严重，补充不到位。 模型过于复杂，当遇到深度不连续边数量过多时，需要多次迭代才能完成。]]></content>
      <categories>
        <category>Scientific Research</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paperTranslate-TSM2: Optimizing Tall-and-Skinny Matrix-Matrix Multiplication on GPUs]]></title>
    <url>%2Farticle%2F503fa364%2F</url>
    <content type="text"><![CDATA[TSM2: Optimizing Tall-and-Skinny Matrix-Matrix Multiplication on GPUsPublication: ICS ‘19: Proceedings of the ACM International Conference on SupercomputingJune 2019 Pages 106–116 论文链接：https://doi.org/10.1145/3330345.3330355 源码链接：https://GitHub.com/codyjrivera/tsm2-imp 摘要线性代数运算已广泛用于大数据分析和科学计算中。在优化具有规则形状输入的GPU上的线性代数运算方面，已经完成了许多工作。但是，当输入不是常规形状时，很少有工作专注于充分利用GPU资源。当前的优化缺乏考虑充分利用内存带宽和计算能力的优势，因此它们只能实现次优性能。在本文中，我们提出了一种在GPU上高效的高瘦矩阵乘法算法-TSM2。它着重于优化无规则输入的线性代数运算。我们实施提出的算法并在三种不同的Nvidia GPU微体系结构上进行测试：开普勒，麦克斯韦和帕斯卡尔。实验表明，我们的TSM2将计算速度提高了1.1到3倍，与当前的最新技术相比，内存带宽利用率提高了8％-47.6％，计算能力利用率提高了7％-37.3％。我们用TSM2取代了K均值和基于算法的容错（ABFT）中的原始矩阵运算，并实现了高达1.89倍和1.90倍的加速。 1 介绍矩阵乘法((GEMM))是大数据分析和科学计算中应用最广泛的线性代数运算之一。由于多种因素(如算法、输入数据等)的影响，GEMM的输入矩阵在不同的应用中大小或形状往往是不同的。例如，许多现代的高度可伸缩的科学仿真包针对流体动力学的领域，如有限元法，需要用较小的输入矩阵来计算大量的GEMM。人工神经网络(ANN)涉及使用GEMM与中小输入矩阵。矩阵分解使用GEMM和大尺寸的输入矩阵[2,12,20,21]。因此，除了在过去几十年里已经被广泛优化的大规模输入外，中小型输入的GEMM也引起了最近研究人员的大量关注。例如，[14]提出了MAGMA-Batched，它的目标是将小的输入矩阵批处理成更大的矩阵，从而利用gpu上针对大输入大小的高度优化实现。[16]提出了利用现代CPU架构上的体系结构和指令级优化来加速小输入的GEMM。 虽然以往的研究主要集中在优化不同矩阵尺寸的GEMM，但大多数研究都假设输入矩阵是规则的。换句话说，他们在作品中提到的尺寸通常是指输入矩阵的两个维度。例如，一个小矩阵意味着它的宽度和高度都很小，它们的大小也很接近。然而，对于非规则形状的GEMM的优化工作做得并不多。例如，有一种特殊的不规则形状输入，其中两个维度的大小有显著的差异，即。,又高又瘦。据我们所知，对于带有粗细输入的GEMM还没有进行充分的研究和优化。粗细输入在许多应用程序中都有使用。例如，最近高度优化的K-means实现[1,13]使用GEMM作为其核心计算，由于中心体的数量通常远远小于输入数据点的数量，因此输入大小通常很小。也,当GEMM用于编码校验和许多ABFT应用程序(9ś11,17、18、22、28ś30),输入通常涉及一个又高又瘦的校验和权重矩阵。 以前为优化使用规则形状输入的GEMM所做的努力可能不适用于非规则形状输入。例如，[9]表明，使用供应商高度优化的线性代数库(例如cuBLAS[19])计算带有瘦长输入的GEMM比将瘦长输入矩阵分解成若干向量然后应用矩阵-向量乘法要慢。然而，可以很容易地看到，这种解决方案不是很有效，因为GPU访问输入矩阵中的元素的次数比需要的多。虽然可以通过将许多瘦而高的输入矩阵分组成类似于所提出的方法的大型输入矩阵来优化性能，但是在某些情况下这种分组方法是不可行的。例如，在用户流中，粗细输入矩阵可以一次一个地从生产者进程生成。将其中几个分组成一个大矩阵需要延长等待时间，这不适用于时间敏感的应用程序。另一方面，如果输入矩阵很大(例如，正形大矩阵与瘦长矩阵之间的乘法) ，内存空间可能会限制可以将其放入内存的总矩阵数。 在这项工作中，我们的目标是在GPU平台上使用瘦而高的输入来优化GEMM的计算，因为许多使用GEMM的应用程序都部署在GPU上。因此，我们的优化可以大大有利于这些应用。我们工作想法是：当输入矩阵大小regular-shaped(例如,一个nn矩阵乘以一个nn矩阵,输入矩阵中的每个元素加载到GPU需要O(n)计算),计算时间通常超过内存访问时间(特别是大型矩阵)。然后GEMM操作是计算限制的。然而,当输入矩阵的大小是高高瘦瘦的(nn矩阵乘以一个nk的矩阵，其中k远小于n, k矩阵的每个元素为只使用O(k)时间平均计算),根据k和执行之间的比率GPU峰值计算能力和内存峰值吞吐量,GEMM计算可以是计算(compute-bound)或内存(memory-bound)受限的。当k变小时，它受限于内存;否则，它将受限于计算。要使用瘦而高的输入来优化GEMM，设计同时考虑计算和内存受限情况的算法至关重要。 本文的主要贡献包括: 我们研究了当前最先进的GEMM实现的局限性。在基准测试中，我们发现GPU资源的利用率低是导致输入太窄或太大时性能低下的主要原因。 我们设计了一个基于GPU优化的针对于双精度和单精度瘦高输入的GEMM算法。我们将优化后的版本称为TSM2。利用输入大小和硬件结构特点的知识，我们重新设计了计算算法，以确保在有内存限制的情况下有高的内存带宽利用率，在有计算限制的情况下有高的计算性能。实验结果表明，与最先进的cuBLAS库相比，我们的TSM2可以获得1.1x-3倍的加速。我们还将K-means和ABFT应用中的原有GEMM操作替换为TSM2，并实现最高1.89x和1.90x的整体速度提升。 2 背景2.1瘦高型矩阵输入的定义在这项工作中，我们将范围限制为在gpu上瘦高输入的GEMM。瘦高输入尺寸意味着，对于两个输入矩阵，至少有一个矩阵是瘦高输入的(一个维度比另一个维度小得多)。例如，输入矩阵A的大小为2048020480和矩阵B的大小为204802在我们的工作中被认为是瘦高输入。在本文中，我们重点研究了具有一个规则的大输入矩阵和一个瘦高输入矩阵的GEMM的优化问题。本文将矩阵A称为较大的输入矩阵(nn)，将矩阵B (nk)称为瘦高型输入矩阵。我们选择这种输入的大小和形状，是因为我们相信它可以暴露各种瘦高输入的大部分挑战，所以本文介绍的设计思想和优化技术可以很容易地应用于其他稍有修改的情况。此外，我们选择让较大的矩阵是方形的，只是为了简化表示。我们的优化可以与其他非方形输入达到类似的效果。 2.2 cuBLAScuBLAS库为GPU优化的最常用的标准线性代数库之一是由Nvidia开发的。cuBLAS是许多大数据和科学计算应用的核心计算库。例如，它是MAGMA异质线性代数库[15,23,24]、cuLA库[6]、cuDNN深度学习库[5]的GPU计算库。通过Nvidia的深度优化，cuBLAS库能够在许多用例中提供最先进的性能。例如，使用大的规则形状的输入矩阵，他们的GEMM实现可以达到GPU[3]的接近峰值的性能。 然而，我们发现GEMM子程序在某些输入矩阵大小为[11]的情况下没有得到充分优化。例如，在瘦高输入情况下，当前最佳实现中的GEMM操作(运行在NVIDIA Tesla K40c GPU上的cuBLAS 9.0)在k = 2时平均只使用了理论峰值内存带宽的不到10%(图5 (a) - (b))。当k = 16时，相同的GEMM操作平均只使用理论峰值内存带宽的20%以下(图5 (g) - (h))。输入维度越大，资源利用率越低。通过比较两种输入的大小，可以看出，对于k值较小的输入，计算占用了较高的内存带宽(接近内存限制)。另一方面，对于k值较大的输入，计算会使用较高的计算能力(接近于计算限制)。但是，由于我们无法分析GEMM在非开源cuBLAS库中的实现，因此很难准确地描述它们的计算特性。 3 优化设计3.1 对输入大小的洞察对于规则型GEMM (nn矩阵乘以nn矩阵)，输入矩阵大小为O(n2)，计算时间复杂度为O(n3)，因此在整个计算过程中，输入矩阵中的每个元素都被使用O(n)次。由于加载数据从GPU的芯片DRAM(即。对于GPU来说，这类问题的一个常见的优化是通过使用快速的片上内存**(如缓存、寄存器)来实现数据重用，从而最小化每个元素加载到GPU的次数，从而避免了大量的数据加载操作。**随着负载数量的减少，优化的GEMM趋向于计算限制。例如，当前cuBLAS库中的GEMM实现在gpu[3]上可以达到近乎裸机的性能。然而，与常规形状的GEMM不同，当输入大小为瘦而高时，输入矩阵的大小仍然是O(n2)，但是计算时间复杂度是O(n2k)。因此，输入矩阵中的每个元素平均使用k次: ​ 根据k的大小和目标GPU的峰值计算能力和内存吞吐率，TSM2可以是计算限制的，也可以是内存限制的。当k变小时，计算趋向于内存限制。否则，问题将趋向于计算限制。在这两种情况下，问题总是在内存限制和计算限制，因此设计针对这两种情况都进行优化的算法是至关重要的。 3.2 算法设计算法设计作为优化的核心，起着非常重要的作用。首先，我们需要考虑如何将TSM2的工作负载转换为CUDA的编程模型(即,线程层次结构)。 虽然工作负载可以很容易地分解成许多独立的较小的工作负载，但是仍然需要仔细考虑工作负载的分布，因为任何不必要的性能损失都会严重地导致GPU资源的利用率不足。我们的设计考虑了以下几个因素: (1)全局内存访问的总次数; (2)全局内存吞吐量的效率; (3)全局内存吞吐量利用率; (4)总体工作量的并行性; (5)片内存储器利用率; (6)流式多处理器(SM)利用率; (7)计算和内存绑定情况的优化。 为了获得良好的性能，在GPU的每个SM中必须存在足够数量的活动线程，以确保正确的指令和内存访问延迟隐藏。因此，在我们的算法中，我们通过将矩阵**A的n行分配给n个不同的线程来分配工作负载。每个向量矩阵乘法被分配给一个线程(即(A[i,:]*B))**。其优点有三:1)保证了高并行度和高SM占用率;2)由于矩阵A的元素个数远大于矩阵B，这种分布保证了有利于矩阵A的最小内存访问次数;3)它还支持高内存访问效率和吞吐量，因为所有对矩阵A的内存访问都是自然合并的(假设矩阵按惯例存储在column-major(列优先)中)。 对于分配给每个线程的向量-**矩阵乘法，为了进一步减少对矩阵A**的内存访问次数，我们使用矢量积计算代替常规的内积式计算。如Alg. 1所示，如果我们使用内积，矩阵A的每个元素被重复引用k次。另一方面，如果我们使用Alg. 2中所示的外积，则矩阵A的每个元素只被引用一次。(请注意，正如我们将在后面的部分中讨论的，当k大于某个阈值时，由于每个线程可用的资源有限，矩阵a中的元素仍然需要被引用多次，但它仍然比使用内积低得多)。对于大的矩阵A来说，这样做的好处是显著的，因为它大大减少了整个GEMM计算过程中全局内存访问的总数。而且，与内积相比，矢量积不会给矩阵B带来任何额外的内存访问。外部产品的唯一成本是持有k个中间结果的额外寄存器。但是，通过适当的调优，与额外的内存访问相比，它们只会带来很少的性能影响。 3.3 高效的芯片外内存访问优化内存密集型应用的一个关键因素是确保高芯片内存访问效率。根据GPU模型类型或运行时配置,全局内存(ofchip)访问的线程在相同的变形可以合并到128字节或32字节处理[4]如果他们访问相同地址分为128字节或32字节段全局内存,则高效使用内存带宽。否则，GPU仍然在128字节或32字节的处理中加载内存。 但它可能包含存储在邻居地址中的未请求数据，这将导致频繁的内存访问。由于每个线程读取矩阵A的一行，并且按照惯例将矩阵存储在column-major中，因此，当相同warp访问元素中的线程位于不同行的不同列上时，内存访问自然会合并在一起。因此，在矩阵a上实现了100%的内存访问效率。而在矩阵B上，所有线程同时访问同一个元素，导致单个内存包含一个被请求的元素和多个未请求的邻居元素。因此，只有128/8字节= 6.25%或8字节/32字节= 25%的内存访问效率达到访问64位双精度浮点数。尽管矩阵B中元素的总数很少，但是考虑到每个元素需要被访问n次，这种不合理的访问模式仍然会极大地影响整体性能。为了提高对矩阵**B的访问效率，我们在GPU中使用了共享内存。**由于它位于芯片上，共享内存给我们的速度L1缓存，它是完全可编程的。一个线程块中的线程可以使用共享内存来共享数据。因此，共享内存的一个关键优势是它消除了数据加载模式和数据使用模式之间的一致性需求，这使我们能够以最有效的方式加载全局内存，并保持我们使用数据的方式与以前一样。 通过使用共享内存访问矩阵B，我们可以减少总的内存访问次数，并合并内存访问。如Alg. 3所示，对于每个迭代，我们现在让一个线程块协同工作，以一种合并兼容的方式(第13-15行)将一个矩阵B块获取到共享内存中，而不是让线程单独地请求它们需要的元素。然后在计算期间，每个线程通过共享内存引用矩阵B中的元素，而不是从全局内存中分别加载它们。这减少了从全局内存访问矩阵B的总次数(每个元素从n到n/t1)。此外，同一线程块中的线程(同warp)逐列获取矩阵B中的元素，从而能合并式内存访问。这大大提高了矩阵B的内存访问效率，达到100%。在Alg. 3中，我们还引入了三个参数:t1、t2和t3。这些参数用于调整性能，将在后面的部分中进行讨论。 3.4 优化共享内存的使用虽然速度很快，但是在使用[7]之前，仍然需要将共享内存中的元素加载到寄存器中。它的访问速度直接影响到系统的整体性能。为了快速并行访问，共享内存被划分为几个相同大小的内存库。不同的线程可以同时访问不同的内存库。因此，与单个内存库的吞吐量相比，整个b内存banks可以将总体共享内存吞吐量提高至多b倍。但是，如果同一warp中的x个线程从同一存储库访问不同的数据，就会发生x-way bank冲突，每个请求都会发生x-way bank 冲突，这极大地降低1/x的访问吞吐量。 在我们的算法中，同一线程中的线程块将数据从全局内存一列一列地加载到共享内存中，以支持快速合并的全局内存访问。然后，线程在计算期间逐行访问共享内存中的数据。我们如何在共享内存中存储元素将影响到如何从内存bank访问这些元素，从而影响到共享内存的吞吐量。我们有两种方法在共享内存中存储矩阵**B:**列主存储和行主存储。要在这两种方式中做出选择，我们需要分析和比较哪一种方式带来的总体bank冲突最少。为了简单起见，我们假设矩阵B的每一块的大小是t1*t2, t1是banks b的总数量的乘积。 对于以列为主的存储，矩阵B的一个块的同一列中的元素(32位words或64位words)存储在连续的存储banks中。对共享内存与b banks,每一个t1的一列元素存储在连续b banks中，每个bank存储最多t1/b的元素和最多同时访问（warp size / b）个线程。如果（warp size / b）大于1，这可能导致bank冲突。 对于以行为主存储器，矩阵B的同一行中的元素存储在连续的存储banks中。因此，同一列的元素存储在（b/t2）个不同的 bank 中，每个bank存储来自同一列的（t1*t2/b）元素。由于每个bank的一列元素数是原来的t2倍，所以每个bank在同一时间访问的线程数最多是原来的t2倍: （warp size / b） t2，这也可能导致bank冲突. 在现代的Nvidia gpu上，warp size被fixed到32，banks的总数也是32[4]，所以列主存储器不会引起banks冲突，因为每个bank最多只能有一个线程访问。行主存储器会导致多达t2-way bank conlict，这会将总体共享内存吞吐量降低到峰值吞吐量的1/t2。如图1所示，我们使用列主存储器(左侧)和行主存储器(右侧)将一个64*2矩阵块加载到共享内存中。当使用列主存储器时，在同一warp上的线程访问不同的banks，因此不发生bank冲突。另一方面，当使用行主存储器时，32个元素被存储在16个bank中，导致2-way bank conflict. 图1:在共享内存中存储64*2的矩阵B时，将列-主(左)和行-主(右)存储进行比较。蓝色和黄色的方块代表第一列和第二列中的元素。当32个线程访问一列中的32个元素时(例如，第一列的元素0到31)，主列存储不会带来bank冲突，而行主列存储产生2-way bank conflict.，这会减少一半的吞吐量。 在我们的算法，当访问共享内存中的元素进行计算时，一个warp的线程每次访问相同元素。虽然多个线程正在访问一个 bank ，但它们访问的是相同的元素，因此只启动一次广播，这不会导致 bank conflict。这对两种存储方式都是一样的。因此，我们选择列主存储，因为它不会带来bank conflict，并可能带来最高的共享内存吞吐量。 3.5 计算内存重叠与访问延迟在执行过程中，对于每个指令的发出时刻，每个warp调度器都会选择一个合适的warp并将其发送到相应的组件中执行。只有当下一条指令的所有操作数都准备好时，warp才有资格使用。但是，如果warp从全局内存中加载数据，则需要几百个周期才能准备好执行。为了隐藏这种长时间的延迟，我们可以增加每个SM中线程的数量，以确保始终存在合适的warps[25]，或者在数据加载和数据使用操作之间放置独立的指令，以便warps也可以在内存加载期间执行。第一种方法要求我们调整每个线程块的片上资源使用。我们将在下一节中讨论。在本节中，我们的目标是在数据加载和数据使用操作之间添加独立的指令。 在Alg. 3中显示，第13-15和18-20行从全局内存加载数据，第21-23行在数据加载后使用数据。然而，由于数据依赖，中间没有独立的指令，所以一旦每个warp发出全局内存访问请求，它必须等待被请求的元素准备好，然后才能进行计算。 因此，为了添加独立的指令，我们使用数据预取来混合相邻迭代之间的数据加载和使用。具体来说，我们不让每个迭代加载将用于当前迭代的数据，而是让当前迭代所需的数据由前一个迭代加载，这样它的计算就不会被数据加载阻塞(因为数据已经准备好了)。在进行计算时，它还加载将用于下一次迭代的数据。通过数据加载和计算的重叠，可以显著提高内存带宽和SM的利用率。我们将数据预取应用到矩阵A和b中。 如Alg. 4所示，我们使用数据预取设计我们的TSM2。在第4行和第5行，我们分配了两组t3寄存器来存储矩阵A元素的当前块和矩阵A元素的下一个块，用于预取。在第6行和第8行，我们分配t2寄存器的数据预取的元素在矩阵B,分配t2*t1存储当前加载的矩阵B, 注意我们不能在寄存器存储当前矩阵B,因为元素在矩阵B需要在计算线程间共享。 在核心计算迭代之前(第20-40行)，我们将矩阵A和B的当前块预加载到寄存器和共享内存中(第13-19行)，这样我们一进入计算循环，计算就可以立即开始，而不会受到任何数据依赖关系的阻碍。主要的计算在第28-30行。为了重叠计算和内存访问,我们在计算之前初始化下一行的加载(第21-23行矩阵B，第25-27行矩阵A)。我们使用两个循环载入矩阵A和B,因为我们想要为两个矩阵灵活地调整加载速度(tile size)。我们将在下一小节中讨论这个问题。图2和图3显示了使用数据预取的优化TSM2的一次迭代。LD C和ST C代表加载矩阵C初始值和将结果存储回矩阵C .每一次迭代，我们展示三个sub-iterations来载入矩阵B。我们在计算的同时加载下一个矩阵B的块(tile)来提高内存带宽利用率。在每次迭代结束时插入一个线程同步。对于最内部的迭代，我们每次都从矩阵A中进行实际计算和预加载元素。请注意，每个矩形的长度并不能准确地表示实际的执行时间长度，并且在实际计算中，LD nextA与LD nextB的数量之比不一定是2。此外，我们显示一个线程块与四个线程只是为了说明建议。我们将在下一小节中讨论，不同的参数值可以影响每个部件的长度以及LD nextA和LD nextB的数量之比。特别是LD nextA和Compute的执行时间，它会影响计算的特性(即内存限制或计算限制)。另外，为了简单起见，我们忽略了在这个figure中每个迭代的下一次块存储到当前块存储之间移动数据的部分。 3.6 参数定义在Alg. 3和Alg. 4中，我们引入了三个可调参数:t1、t2和t3。在本节中，我们首先讨论每个参数如何控制TSM2的计算。然后，我们介绍我们的性能模型，该模型估计特定的性能指标如何随这些参数变化。最后，我们解释了我们的策略，选择这些参数的值，以实现高的GPU资源利用率和优化的整体性能。请注意以下讨论都是基于Alg. 4。 3.6.1参数行为首先，我们将每个参数的行为如下： \1. t1矩阵B的一个tile的行数，为了最大限度地利用可用的活动线程，并避免由于warp偏差而导致任何低效的线程执行, 我们让每个线程块中的所有线程参与获取矩阵B的元素。为了快速合并的全局内存访问,我们让每个线程获取一行,所以t1也是每个线程块的线程总数。另外，因为我们让n个线程参与计算，所以线程块的总数可以计算为: n/t1。 \2. t2指定了矩阵C中每个线程一次处理的元素数。它用于将整个工作负载划分为几个较小的工作负载，这些工作负载由每个线程迭代处理。更小的工作负载使每个线程的SM资源使用更少，这允许我们保持更高的SM占用。然而，划分工作负载意味着我们需要为每个小工作负载重复加载矩阵A。所以，这是一种交易。t2还影响了我们算法核心部分的总内存取数与计算操作的比例，这使得我们可以调整计算以适应计算或内存的限制(稍后将详细讨论)。 \3. t3指定了矩阵A中每个线程一次读取的元素数量。由于获取的元素彼此独立，因此可以在不阻塞彼此的情况下完成，因此可以使用t3调整内存加载并发性。 3.6.2性能指标估计在本节中，我们将介绍基于参数的性能模型，该模型用于评估三个重要的性能指标:SM占用率、内存带宽利用率和计算能力利用率。这些估计将用于优化总体性能。 \1. 最大SM占用估算 根据这些参数，我们可以计算每个SM的最大占用率，即每个SM的最大活动线程数。(有些工作也使用了最多数量的warp，这与我们的作品相似。我们发现在我们的性能模型中使用max线程更一致。我们还选择线程块大小作为该值的被除数，以确保预期的线程数是活动的。)这种占用主要受最大硬件允许线程数(HW _MAX)和每个线程的片上内存利用率限制。我们首先计算每个线程使用的寄存器总数。由于nvcc编译器可以优化寄存器利用率，所以我们使用最大寄存器数来估计这个值。首先，CUDA初始设置使用的寄存器数量相对来说是固定的，我们将这个数量表示为c。我们通过在线分析获得它的数量。然后，我们需要两组t2寄存器来存储矩阵B的元素，用于下一次的tile抓取和当前的tile计算。请注意，虽然矩阵B的当前块存储在共享内存中，但它仍然需要被传输到寄存器中进行计算。接下来，我们需要t2寄存器来保存矩阵c的中间结果。最后，我们需要两组t3寄存器来存储矩阵A的元素，用于下一次磁片抓取和当前磁片计算。所以寄存器的总数是 至于共享内存，通过为每个线程块分配共享内存，我们计算每个线程用于一致计算的平均共享内存数量。因为每个线程块分配的共享内存的大小是t1*t2，我们将在前面讨论设置t1 = threads_per_threadblock，所以平均分配给每个线程的共享内存是 因此，最大SM占用率可以计算为: 在上面的计算中，RSM和SSM表示每个SM的最大可用寄存器和共享内存。 \2. 估计最大内存带宽利用率 其次，我们估计当计算是内存限制时，我们的算法的最大内存带宽利用率。在这种情况下，在我们的算法中，加载矩阵A的元素占主导地位，而不是延迟点的计算。因此，我们可以使用每个SM的最大并发全局内存访问数来估计最大内存带宽利用率。它可以被计算为： 请注意，为了简单起见，我们这里只考虑对矩阵A的内存访问。由于大多数内存访问都是针对矩阵A的，因此这只会带来较小的不准确性。 然后，与[25,27]类似，我们使用Little ‘s Law计算每SM所需的最小并发内存访问数，以实现最大的内存带宽利用率: latencymem是平均的全局内存访问延迟，在我们的模型中，它被认为是一个常数，并且是通过在线proiling获得的。估计内存带宽利用率为: \3. 评估最大计算能力使用 然后，我们估计了计算限制时算法的最大计算能力利用率。在这种情况下，在我们的算法中，浮点数的计算占主导地位，而不是内存访问。因此，我们可以使用每个SM的最大并发浮点操作数来估计最大的计算能力利用率。可以计算为: 然后，与[25]相似，我们使用Little’s Law计算每SM需要的并发loating point操作的最少数量，以实现最大的计算能力利用： latencycomp是我们计算中的浮点操作的平均延迟，它在我们的模型中被认为是一个常数，是通过在线分析获得的。因此，估计的计算能力利用率为: \4. 确定计算或内存界限 给定参数和规格GPU，我们可以确定当前的计算是内存还是计算限制。这主要是由Alg. 4的最内部循环(第24 - 34行)决定的。内存加载指令(第25-27行)与计算(第28- 30行)重叠。因为第31-33行取决于内存加载结果，所以它充当内存加载和计算的隐式同步点。这两部分所花费的时间将决定当前计算是计算限定还是内存限定。因此，我们首先估计计算和内存访问所需的时间如下： 然后，通过比较这两种时间开销，我们可以确定当前的计算是计算限制还是内存限制。 我们可以看到，当r大于1时，计算是计算界。否则，计算将受到内存限制。此外，由于我们使用t2将原始工作负载划分为几个较小的工作负载，因此这个比率由t2决定。通过调整t2，可以在计算和内存之间切换实际的计算。通过令r = 1计算两种情况的边界，得到t2的阈值: 同样，我们也可以估计原始问题的计算特性，即工作负载没有被划分为更小的工作负载。在这种情况下，t2总是被赋给k，因此，通过比较k和t2threshold，我们可以估计出计算特性。如果k大于t2threshold，那么原来的问题是计算限制。否则，它是内存限制的。 很容易看出，根据t2和k的取值，可以看出当前问题和原问题的计算特性不同，从而影响整体性能。我们在下一节中讨论这个。 3.6.3选择参数在选择参数时，我们首先要确定的是我们应该优化计算还是优化内存带宽。这取决于给定的GPU上给定的TSM2计算应该是计算还是内存的限制。在最后一节中，我们提出通过比较k和t2threshold来估计这个特性，这样我们就可以调整参数，使计算朝着正确的方向进行优化。 在原来的问题是内存限制(k &lt;= t2threshold)的情况下，我们需要将实际计算也保持为内存限制(让1&lt; t2 &lt;k)，并优化内存带宽利用率。另一方面，如果原问题是计算限制(k &gt;t2threshold)，我们首先尝试保持实际计算的计算限制(设t2threshold&lt;=t2 &lt;=k)，并优化计算功率的利用。然而，在给定GPU上的et2threshold过高的情况下，我们也尝试优化它的内存界限(让1&lt; t2&lt;t2threshold)，并输出性能更好的结果参数。 Alg. 5给出了t2和t3的参数优化过程。我们首先确定第一行的计算特性。如果是内存限制，我们将对从全局内存中访问所需元素的总时间成本进行优化(第4行)，否则，我们将对总计算时间(第9行)或内存访问时间(第14行)进行优化。请注意，为了简单起见，我们只计算访问矩阵A的内存访问总数，因为访问矩阵B的内存访问总数比访问矩阵A的内存访问总数少得多，所以这种简化只会带来较小的误差。此外，考虑到对矩阵B的总访问次数会带来一个额外的参数(t1)，这可能很难优化，因为t1也与线程组织有关，很难进行基于模型的估计。内存带宽利用率项(Utilmem)和计算能力利用率项(Utilcomp)是使用前面提到的公式计算的。由于我们的优化目标中有两个参数(t2和t3)，所以我们使用梯度下降(GD)进行优化。在GD中，根据我们的经验，我们将t2和t3的初始值都设置为1，步长设置为0.1。停止阈值设置为1e-4，因为我们不需要非常精确的精度。inal t2和t3四舍五入为最接近的整数。 为了优化t1，我们发现它只控制每个线程块中的线程数。由于线程的总数被固定为n，所以t1只决定这些线程是如何组织成线程的块。存在权衡:如果t1较大，那么对矩阵B中元素的总访问次数就会减少，但是，大的线程块意味着需要大量的线程参与相同的同步，这可能会对性能产生影响。另一方面，如果t1较小，则对矩阵B元素的总访问次数较高，但较小的线程块使调度更加灵活和有效。由于理论上难以确定t1的最优值，因此我们采用在线实验的方法来选择最优值。特别地，一旦确定了t2和t3，我们将基准测试不同的t1值，可以像前面提到的那样划分MaxOccupSM，并选择性能最好的t1。因为我们固定每个线程的共享内存数量 (Sthread = t2 bytes_per_element)，尽管t1似乎对共享内存分配(或最大SM占用)有直接影响，但实际上它对共享内存的影响有限。 4 实验在我们的异构实验平台集群Darwin上对我们优化的TSM2进行了评估。 我们使用单GPU卡在一个GPU节点上运行每个测试。我们使用三种不同的微架构对三种常用的现代Nvidia gpu进行测试:Kepler、Maxwell和Pascal。 对于Kepler GPU，我们使用Tesla K40c，它有1430 GFLOPS峰值双精度性能和288 GB/s内存带宽。 对于Maxwell GPU，我们使用Tesla M40，它有213 GFLOPS峰值双精度性能和288 GB/s内存带宽。 对于Pascal GPU，我们使用Tesla P100，它有4600 GFLOPS峰值双精度性能和720 GB/s内存带宽。 我们使用CUDA C实现了TSM2的单点和双精度输入。为了更好地控制寄存器分配，我们禁用了编译器自动运行。为了进行比较，我们将TSM2与当前最新的cuBLAS 9.0库和最新的BLASX库[26]中的GEMM进行比较。 另外，我们尝试将我们的工作与KBLAS[8]进行比较，但是由于它的GEMM内核是基于cuBLAS的，所以它的性能与cuBLAS相同，所以我们省略了它的结果。每个测试重复多次，以减少误差和定时使用CUDA事件API。我们通过计算FAMD指令的性能来度量性能。我们还使用nvprof在命令行上测量全局内存吞吐量，并使用–metrics gld_throughput选项。 此外，我们使用–metrics gld_efficiency 选项来验证在我们的优化过程中实现了100%的全局内存访问效率(由于页面限制，我们省略了对效率验证结果的表示)。 4.1 实验环境 我们的输入矩阵是用随机的浮点数(0到1)初始化的。大输入矩阵的大小从10240∗10240到30720∗30720。瘦长的输入矩阵的大小范围从10240∗k到30730∗k，其中k等于2、4、8和16。 4.2 不同优化组合的测试我们使用cuBLAS 9.0中的GEMM作为比较基线。 我们在TSM2中应用不同的优化组合，并与在cuBLAS和BLASX中的GEMM进行比较。 我们总共有四个版本的TSM2: V0: Alg. 1中描述的最简单的内积版本; V1: Alg. 2中的外部产品版本。 该版本从算法级上减少了全局内存访问的总数; V2:基于Alg. 2中的外部生产版本，我们增加了共享内存的使用，这使得对矩阵B的全局内存访问更加有效; V3:基于Alg. 2中的外部产品版本和共享内存的使用，我们添加了数据预取。 这是我们优化实现的最佳版本，Alg. 4中对此进行了描述。 由于页面空间的限制，我们只在K40c GPU上显示结果。我们的优化在其他gpu上也有类似的表现。为了评估我们的优化，我们需要确定我们的程序是由哪个资源限制的。由于t2threshold (k40c) 40，对于给定的k值，计算总是内存限制的。优化参数为:t2 = k, t3 = 4, t1 = 128。这些参数只适用于最后的TSM2版本。图4显示了不同版本在单精度和双精度下的加速效果。从结果中，我们可以看到TSM2-V0的性能非常差，这是因为在内部积版本中需要更多的全局内存访问。 另一方面，TSM2-V1与TSM2-V0(快2.2倍- 4.7倍)相比，显著提高了性能，因为它需要更少的全局内存访问次数。TSM2-V2进一步提高了对矩阵B的全局内存访问的效率，这对整体性能起着至关重要的作用。此外，在一个线程块内的线程之间共享矩阵B的块也减少了对矩阵B的总内存访问次数，这导致了额外的1.1x到2.1x的加速。最后，TSM2-V3中引入的数据预取进一步缓解了内存访问瓶颈，从而带来了额外的1.3倍- 3.5倍的加速。 4.3内存吞吐量分析图5显示了K40c GPU上TSM2-V3、cuBLAS和BLASX单精度和双精度的内存吞吐量。结果表明，与cuBLAS相比，TSM2的GPU内存带宽利用率提高了12.5% - 26.6%(平均17.6%)，与BLASX相比提高了20.1% - 38.8%(平均24.3%)。 4.4不同微处理机架构测试除了开普勒微结构，我们还进行了新的马克斯韦尔和帕斯卡gpu的测试。与Kelper GPU类似，我们得到t2threshold (m40) 6和t2threshold (p100) 50 Tesla m40具有较慢的计算能力，因此k = 16时的输入计算是计算限制。我们的参数优化过程也输出有利于计算优化的参数:t2 = 8, t3 = 4, t1 = 256。如图6所示，我们的优化实现在Tesla M40上实现了1.1x -1.9x (avg. 1.47x)加速，与cuBLAS 9.0中的GEMM函数相比，计算功耗提高了7%到37.3% (avg. 20.5%)。因为P100有更强的计算能力，我们可以看到k = 16时的计算是受内存限制的。我们的参数优化过程也输出有利于内存优化的参数:t2 = 4, t3 = 4, t1 = 128。如图7所示，我们的优化实现在Tesla P100上实现了1.1x - 3.0x(平均2.15x)的加速，与cuBLAS中的GEMM函数相比，内存带宽利用率提高了17%到47.6%(平均34.7%) 5 展示在本节中，我们将使用两个真实的应用程序来展示TSM2带来的性能优势。 5.1 K-means经典的Lloyd K-means算法是大数据分析中最常用的聚类方法之一。 它的核心计算是计算每个数据点与每个质心之间的距离。 下面是计算这个距离的优化方法。 首先，可以通过 来计算数据点x与质心y之间距离的平方。 然后，通过将所有计算聚集在一起，我们可以使用更多有效的向量向量乘法(||x ||2 + ||y||2)和GEMM (xy)。 这种优化被广泛应用于经典的Lloyd s K-means算法在gpu和cpu上的最新实现中。例如，Nvidia[1]提供的实现使用cuBLAS GEMM例程计算距离(即计算xy)。当质心的数目很小时，这个计算就变得瘦高型(n×d by d×k, n是数据点的数目，k是质心的数目，d是每个数据点和质心的维数)。与计算||x ||2和||y||2相比，计算xy占用了(O(d(n + k)) vs. O(ndk))的大部分计算时间，因此其性能对整个算法至关重要。 在这里，我们将[1]中的GEMM例程替换为我们的TSM2。我们设置质心数量k = 16，数据点维数d = 4096，并将数据点n的数量从1k改为262k。每个数据点的每个维数都是随机生成的双loating点，范围从0到1.我们比较了irst 100迭代的执行时间。结果如图8所示。使用我们的TSM2，我们在Nvidia Tesla K40c上加速K-means 1.06x - 1.89x(平均1.53x)。 5.2 ABFT矩阵校验和编码矩阵校验和编码是ABFT中最重要的运算之一[10,11,22,28,30]。 它的计算包括让一个矩阵(或更高编码密度的矩阵块)乘以一系列预先定义的向量，从而得到矩阵行或列的加权和。通常的选择是使用两个向量。当把这两个向量组合在一起时，计算就变成了一个瘦高的矩阵-矩阵乘法。GPU上最常见的选择是使用cuBLAS。在这里，我们通过使用cuBLAS和我们的TSM2来比较校验和编码性能。结果如图9所示。正如我们所看到的，我们的TSM2在Nvidia Tesla K40c上显著地将校验和编码计算从1.10x提高到1.90x加速(avg. 1.67x)。我们注意到当矩阵很小的时候会出现加速振荡的情况。这主要是由于负载平衡的变化，因为不同的输入矩阵大小是给定的。我们将在以后的工作中对此进行优化。 6 结论在这项工作中，我们首先分析了当前的GEMM在最新cuBLAS库中的性能。 我们发现，当输入形状是瘦高型的，当前的实现缺乏充分利用的计算能力或内存带宽。然后，我们发现了优化tall-and-skinny GEMM的潜在挑战，因为它的工作负载可能在计算绑定和内存绑定之间变化。接下来，我们重新设计了一个优化的瘦高的GEMM与几个优化技术集中在GPU资源的利用。最后，实验结果表明，我们的优化实现可以在三种现代GPU微架构上实现1.1x -3倍的加速。]]></content>
      <categories>
        <category>Scientific Research</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paperMemo-3dShapeMeasurement]]></title>
    <url>%2Farticle%2F4b571488%2F</url>
    <content type="text"><![CDATA[主题本次调研主题是 “3D形状测量” 学科融合一、摄影测量 摄影测量是指运用摄影机和胶片组合测量方针物的形状、大小和空间位置的技术，它使用光学摄影机获取的像片，经过处理以获取被摄物体的形状、大小、位置、特性及其相互关系。 ​ 重视的是几何量的量测信息（物体的位置、大小和形状等），首要任务是用于测绘各种比例尺的地形图、树立数字地面模型，为各种地理信息体系和土地信息体系供给基础数据。摄影测量学要解决的两大问题是几何定位和影像解译。几何定位就是断定被摄物体的大小、形状和空间位置。几何定位的根本原理源于测量学的前方交会办法，它是根据两个已知的摄影站点和两条已知的摄影方向线，交会出构成这两条摄影光线的待定地面点的三维坐标。影像解译就是断定影像对应地物的性质。 当被测物体的尺寸或摄影间隔小于100米时的摄影测量称之为近景摄影测量。随着数字传感器技术的发展，尤其是CCD器件和CMOS器件的迅速发展，使用CCD(或CMOS)像机不需要胶片就可直接获得被测物的数字影像，这种直接基于数字影像的近景摄影测量称为数字近景摄影测量。 二、计算机视觉测量 计算机视觉是使用计算机及相关设备对生物视觉的一种模仿。 ​ 首要重视的是对物体进行描绘、识别和理解，它的首要任务就是经过对采集的图片或视频进行处理以获得相应场景的三维信息，就像人类和许多其他类生物每天所做的那样。是一门关于怎么运用照相机和计算机来获取咱们所需的，被摄影对象的数据与信息的学识。形象地说，就是给计算机设备上眼睛（照相机）和大脑（算法），让计算机能够感知环境。 机器视觉体系是计算机学科的一个分支，是指经过机器视觉产品（即图画吸取设备，分CMOS和CCD两种）将被吸取方针转换成图画信号，传送给专用的图画处理体系，根据像素分布和亮度、颜色等信息，改变成数字化信号；图画体系对这些信号进行各种运算来抽取方针的特征，进而根据判别的成果来操控现场的设备动作。 三、摄影测量和视觉测量的差异 1、起点不同导致根本参数物理含义的差异：摄影测量中的外部定向是断定影像在空间相对于物体的位置与位置（将物体先平移再旋转），而计算机视觉则是物体相对于影像的位置与位置来描绘问题（将摄像机先旋转再平移）。 2、因为两者不同的起点导致根本公式的差异：摄影测量中最为根本的是共线方程，而视觉测量中最为根本的公式是用齐次坐标表明的投影方程。 3、数学处理算法的不同：摄影测量渊源于测绘学科，基于非线性迭代的最小二乘法平差求解贯穿于数字近景摄影测量的全过程，而计算机视觉着重矩阵分解，总是设法将非线性问题转换为线性问题，尽可能避免求解非线性方程。 四 现有商业化测量产品新拓三维 SmartRay 五 研究趋势 虽然数字近景摄影测量与计算机视觉有各种各样的差异，但在重视点方面，和理论基础方面是共同的，并且随着最近20年的发展，人工智能，智能城市，大数据等在各个范畴的应用，让一切都有了不同的改变。 ​ 学术会议和出版论文集等交流方式让学科间的交流逐渐增加，两个学科的交叉也越来越多。比方，数字近景摄影测量中的许多根本概念与办法来自影像处理与计算机视觉（如数字图画处理的某些算法、编码标志的自动识别）；反过来，摄影测量中的一些特征理论和办法又为视觉测量所采用（如全体光束法平差算法、像机自标定原理和办法等），而两者的结合也给学科及人类科技发展带来了协助。所以，视觉系统和摄影测量这两种学科逐渐相互融合并优势互补是发展的必然趋势。 文献2010 Fast Phase-based Stereo Matching Method for 3D Shape Measurement作者：Dong Li ; Huijie Zhao ; Hongzhi Jiang 来源： 2010 International Symposium on Optomechatronic Technologies文章链接：https://ieeexplore.ieee.org/document/5687348源码链接：无 方法： 三维形状测量模型，连同校准板，如图所示。DLP投影机的分辨率是1024x768。两台黑白CCD相机的分辨率都是2048x2048。校准板由铝合金制成。由于标定板具有较高的平整度表面，因此可以利用标定板的三维重建来评价三维形状测量精度。 提出了一种基于相位的立体匹配方法，该方法利用极线校正，将双立体几何变换为极标准几何。利用相移技术计算相位，通过沿水平极线搜索最近的相位，简化了立体匹配。（类似于双目测距） 利用DLP投影仪将正弦条纹图形投影到物体表面，利用两台CCD相机捕捉变形的条纹图形图像。 实施极线矫正。极线校正是基于线性针孔模型,根据公式构造极线矫正前后像平面坐标对应关系 采用双线性插值方法计算经过校正的绝对相位图 进行立体匹配。对于左侧图像上的一个点，利用所描述的外极标准几何特征，沿水平外极线搜索最近的相位，即右侧图像上具有相同垂直坐标的一条直线。 结果： 贡献： 提出了一种利用极线校正的快速相位立体方法。与之前的方法相比，该方法将立体匹配时间缩短了20%。在高平整度平面的三维重建中，三维形状测量精度可达0.0178mm。因此，该方法适用于速度快、精度高的应用场合。 缺点： 重建效果较差，丢失了较多的细节 2019 A Calibration Method of 3D Shape Measurement System Using 3D Scanner, Turn-table and Arm-robot作者： Hiroyuki Ukida ; Tomoyo Sasao ; Kenji Terada 来源： 2019 58th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)文章链接：https://ieeexplore.ieee.org/document/8860071源码链接：暂无 方法： 所提出的系统是由一个三维扫描仪，一个手臂机器人和一个转台。 为了准确地测量三维形状，提出了一种测量系统设备位移的方法来校准。 固定机械手臂与转台中心的距离 对于臂-机器人坐标系的每个轴，臂-机器人与已知位移的轴平行移动。这个动作在给定的时间内迭代。 以已知角度旋转转台，每次移动时用3D扫描仪估计球体标记的中心前沿的坐标。 得到“球中心轨迹坐标”。从球面标记的测量中心坐标分布出发，用最小二乘法估计一个由中心坐标支持的平面。该平面为转台的参考平面，其表面法向量为转台的旋转轴。 将所有球面标记中心坐标投影到估计的参考平面，并从投影坐标估计该平面上的圆。估算出投影轨迹坐标的直线，然后根据直线的倾斜度估算出每个轴的旋转角度。将三维扫描仪坐标系中的一个坐标转换为arm-robot坐标系中的坐标 坐标映射，然后将各个面结合到同一个坐标中。 结果： 贡献： 针对传统木偶形状三维测量系统 提出了一种三维形状测量系统的标定方法。 缺点： 由于操作人员和操作环境的影响，手动操作可能会产生较大的误差 所估计的深度图中也会影响位置估计 2020 TOWARDS UNDERSTANDING SPECIATION BY AUTOMATED EXTRACTION AND DESCRIPTION OF 3D FORAMINIFERA（有孔虫类） STACKS作者： Wenshu Zhang ; Thomas Ezard ; Alex Searle-Barnes ; 来源：2020 IEEE Southwest Symposium on Image Analysis and Interpretation (SSIAI)文章链接： https://ieeexplore.ieee.org/document/9094611源码链接：暂无 方法： 在分析浮游有孔虫标本时，巨大的三维数据量限制了对遗传物种形成的理解，提出了一种端到端的神经网络架构来解决这一问题。观察到的化石是浮游有孔虫，这是一种单细胞生物，大量生活在世界海洋中。每个孔的大小和形状在其生命旅程的每个阶段都有完整的记录。在本研究中，我们分析了各种个体有孔虫来研究它们之间的差异，并与人工标记的ground truth进行比较。从图像序列中自动重建每个样本的独立腔室，(ii)使用形状特征来描述不同类型的物种。通过处理包含9GB点的3D样本的数据集，表明物种形成现在确实可以被分析，从形态学特征的自动分析导致了对生命起源的新见解。 结果： 贡献： 利用计算机视觉演算法来重建有孔虫形状，可视化断层扫描的内部特征，分析形状意味着理解空间排列，以了解影响物种形成的重要因素。 提出了一个端到端自动测量有孔虫形状的框架。 缺点： 标本的数量和形态的多样性不够，导致易出现预估错误。 待看 3D Shape Measurement of Translucent Objects Using Laser Rangefinder （半透明形状） Improving 3D reconstruction accuracy in wavelet transform profilometry by reducingshadow effects （提高精度） 3D Environment Measurement and Reconstruction Based on LiDAR （利用激光雷达测量环境） Reconstruction of Realistic 3D Surface Model and 3D Animation from Range Images Obtained by Real Time 3D Measurement System ECG: Edge-aware Point Cloud Completion with Graph Convolution（2020，图神经网络生成点云边缘） PointGrow: Autoregressively Learned Point Cloud Generation with Self-Attention（2020，点云自我生成）]]></content>
      <categories>
        <category>Scientific Research</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习-GAN]]></title>
    <url>%2Farticle%2Ff3e3799%2F</url>
    <content type="text"><![CDATA[理解生成器与判别器相互博弈的过程。 经过多次反复训练迭代之后，最终希望能够达到生成样本分布拟合于真实样本分布的状态，并且判别器分辨不出样本是生成的还是真实的（判别概率均为0.5） 生成模型大概有两种玩法： 密度（概率）估计：就是说在不了解事件概率分布的情况下，先假设随机分布，然后通过数据观测来确定真正的概率密度是怎样的。 样本生成：这个就更好理解了，就是手上有一把训练样本数据，通过训练后的模型来生成类似的「样本」。 在应用上，这套 GAN 理论最火的构架是 DCGAN（深度卷积生成对抗网络/Deep Convolutional Generative Adversarial Network），反卷积，DCGAN目的是创造图片，其实就类似于把一组特征值慢慢恢复成一张图片。 参考链接通俗理解生成对抗网络GAN 交叉熵损失函数 GAN学习指南：从原理入门到制作生成Demo 独家 | GAN之父NIPS 2016演讲现场直击：全方位解读生成对抗网络的原理及未来（附PPT）]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习-强化学习]]></title>
    <url>%2Farticle%2Fda29b4e7%2F</url>
    <content type="text"><![CDATA[强化学习基本概念强化学习被认为是实现人工智能的通用框架 强化学习使得机器人具备在环境中自主动作的能力 每个动作都能影响机器人在环境中的状态 动作的好坏由状态对应的激励信号决定 累计激励： 目标：学习选择动作的策略使得将来的累计激励最大化 监督学习与强化学习监督学习目标 f(x-&gt;y)x:数据 y:预测目标存在y的标注信息且y对x无影响 强化学习目标 π(s-&gt;a)s:状态 a:动作不存在a的标注信息且a对s有影响 V、Q函数V函数衡量了机器人在状态s期望获得的累计激励 Q函数衡量了机器人在状态s采取动作a之后期望获得的累计激励 Policy函数Policy函数代表某种选择动作的策略π(s)，或条件概率分布π(a|s)，负责根据状态s选择最优的动作a a=π(s) 基于Q函数的策略：• 选择动作使得累计激励的期望最大 π*(s) = argmaxQ(s,a) 强化学习的主要模式Value-based RL(基于价值的) 学习Q函数Q(s,a) 选择使Q函数取最大值的动作 Policy-based RL(基于策略的) 学习Policy函数π(a|s) 从Policy函数采样动作 贝尔曼方程 Q函数的递归关系采用贝尔曼方程 【缺图】 基于Q函数的强化学习的弊端复杂性方面：• 只能对简单离散的动作空间进行建模• 无法应对连续的动作空间(例如：方向盘的转动角度)灵活性方面：• 选择动作的策略Policy由Q函数直接决定（硬策略）• 无法对策略的随机性进行建模 深层策略网络Deep Q-Network: 先学习Q函数，然后估计最佳策略Policy Gradient: 直接学习最佳策略 训练过程： 基于当前策略运行一段时间(直至产生激励) 若为高激励，则增加选择当前动作的概率 若为低激励，则降低选择当前动作的概率 模拟学习基于带标签的数据训练策略网络 优点：网络收敛快 缺点：探索能力不足，容易过拟合 反（逆向）强化学习强化学习：激励函数已知 反强化学习：激励函数未知，结合专家示例进行学习（与对抗学习GAN存在本质关联） 策略对应生成器 激励对应鉴别器]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-聚类]]></title>
    <url>%2Farticle%2Fbe746f28%2F</url>
    <content type="text"><![CDATA[基本概念在“无监督学习” 任务中研究最多、 应用最广。 聚类目标：将数据集中的样本划分为若干个通常不相交的子集（“簇” ， cluster） 聚类既可以作为一个单独过程（用于找寻数据内在的分布结构） ， 也可作为分类等其他学习任务的前驱过程。 应用：1，分析数据内在结构；2，作为有监督学习的预处理部分，发掘数据的隐藏模式 监督信号类别 任务标注 中间激励 无 输出 离散 分类 聚类 连续 回归 降维 策略 模仿学习 强化学习 聚类性能指标（聚类结果的“簇内相似度”（intra-cluster similarity） 高，且“簇间相似度”（inter-clustersimilarity）低 ） 外部指标：将聚类结果与某个“参考模型”（只用于测试评判） 进行比较 内部指标（划分依据）：基于簇内和簇间相似度直接考察聚类结果 a=SS （一致）、b=SD（不一致） c=DS、d=DD（若一致） 外部指标 ([0,1]区间内,越大越好 ) Jaccard系数（Jaccard Coefficient, JC） FM指数(Fowlkes and Mallows Index, FMI) Rand指数（Rand Index, RI） 内部指标 考虑聚类结果的簇C划分 ，定义：簇 C内样本间的平均距离(簇内距离) 、簇 C 内样本间的最远距离(簇内距离)、簇C_i与簇 C_j最近样本间的距离(簇间距离)、簇 C_i与簇 C_j中心点间的距离(簇间距离) DB指数(Davies-Bouldin Index, DBI) (簇内距离) Dunn指数(Dunn Index, DI) (簇间距离) 距离度量性质:非负性、同一性、对称性、直递性 闵可夫斯基距离(Minkowski distance)p=2: 欧氏距离(Euclidean distance).p=1： 曼哈顿距离(Manhattan distance) 分类基于原型的聚类(Prototype-based clustering)• 主要特点：先对原型进行初始化，然后进行迭代更新• 常见算法： k-Means算法，高斯混合模型基于密度的聚类(Density-based clustering)• 主要特点：从样本密度的角度来考察样本间的关系• 常见算法： DBSCAN算法层次聚类(Hierarchical clustering)• 主要特点：在不同层次对样本进行划分，形成树形的聚类结构• 常见算法： 逐次聚合算法 k-Means算法E值在一定程度上刻画了簇内样本围绕簇均值向量的紧密程度，值越小，则簇内样本相似度越高。 算法流程(迭代优化)：人工选取簇的个数，初始化每个簇的均值向量(中心)repeat 簇划分(聚类)； 更新每个簇的中心 until 当前均值向量均未更新 不足： 簇的数目k需要人为指定；对簇中心的初始化比较敏感；破坏数据内在结构 ps: 硬聚类：样本只从属于一个簇，如K-means 软聚类：样本以该概率从属于多个簇,如高斯混合模型、EM模型 混合模型是概率化的k-Means算法 基于密度的聚类 DBSCAN算法（举例）簇的定义：密度相连样本组成的集 算法的核心：由核心对象搜寻密度可达的所有样本 Agglomerative(逐次聚合)算法算法过程(自底向上的层次聚类)：• 首先，将样本中的每一个样本看做一个初始聚类簇；• 然后在算法运行的每一步中找出距离最近的两个聚类簇进行合并，该过程不断重复，直到达到预设的聚类簇的个数。 • 基于层次的聚类• 生成不同层次的簇-树状图]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习-领域自适应]]></title>
    <url>%2Farticle%2F2d45afe4%2F</url>
    <content type="text"><![CDATA[迁移学习(transfer learning)给定源域的数据和任务，提高目标域的任务性能 领域自适应(domain adaptation)• 任务相同• 数据域不同(光照，姿势，图像风格)• 源域数据有标签， 目标域数据没有标签(或标签很少) 易混淆概念无监督领域自适应 Unsupervised DA：• 源域有标签，目标域没有标签监督领域自适应 Supervised DA (fine-tune)：• 源域有标签，目标域有少量标签无监督迁移学习 Unsupervised transfer learning：• 源域和目标域都没有标签，比较少见半监督学习 Semi-supervised learning：• 没有数据域或任务的差别• 来源于同一个数据域的少量标签和大量无标签数据 领域自适应方法分类基于样本的方法 Instance-based method：• 改变源域标签数据的样本权重• 与目标域数据相近的源域数据有更高的权重 基于特征的方法 Feature-based method：• 将源域与目标域数据映射到共通的特征空间 提取源域和目标域的共通特征• 部分特征是和数据域相关的• 其它特征是数据域之间共通的 基于伪标签的方法 Pseudo-label-based method：• 以目标域数据中可信度高的预测结果作为伪标签来训练模型 伪标签• 目标域中可信度高的预测通常是对的• 可信度比较高的样本可以作为伪标签对模型进行自训练]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习-RNN（比较浅）]]></title>
    <url>%2Farticle%2Fc91fc4b%2F</url>
    <content type="text"><![CDATA[面对序列信号（语音、视频）如何建模无法保留时序信息； 无法建模长期依赖关系 ； 通用性差； 序列模型需要满足：• 可处理变长输入序列• 能够学习长期的依赖关系• 保留序列本身的时序信息 RNNRecurrent Neural Network(递归神经网络) 误差函数对于ℎ0的梯度包含𝑊ℎℎ和非线性激活函数的多次方计算：• 𝑊ℎℎ过大导致梯度爆炸(exploding gradient)• 𝑊ℎℎ过小会导致梯度消失(vanishing gradient) 思路：设计更复杂的递归单元(recurrent unit/cell)来保留长期关系]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[环境配置版本备忘录]]></title>
    <url>%2Farticle%2F724e4936%2F</url>
    <content type="text"><![CDATA[Labtop深度学习环境 NVIDIA Driver Version: 430.39 cuda 10.1 cudann 7.6.4 python 3.7.5 参考文章：Pytorch在win10下搭建cuda版本的环境 ​ Pytorch在Windows下的环境搭建以及模型训练 Desktop(in laboratory)window cuda 10.2 python 3.7.6]]></content>
      <categories>
        <category>tiny knowledge</category>
      </categories>
      <tags>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-决策树]]></title>
    <url>%2Farticle%2Fae9520f1%2F</url>
    <content type="text"><![CDATA[剪枝分类器剪枝分类器是指，对于d次维的输入变量x，任意选定其中一维，通过将其与给定阈值相比较来进行分类的线性分类器 剪枝分类器的要素：• 一个输入维度• 一个阈值 决策树决策树是最符合人类决策机制的模型之一 决策树： 剪枝分类器经过一层一层累积，形成树状的结构 • 分叉节点：剪枝分类器• 叶节点：判断结果 预测流程 数据样本从根节点进入决策树 数据节点在分支节点进行判定，根据判定结果导入该节点的子节点 数据样本若到达分支节点，重复第2步；若到达叶节点，得到最终判定结果 叶节点的输出判定• 每个叶节点保存了一部分训练数据的子集• 训练数据子集的类型分布决定了叶节点的输出概率 决策树学习决策树学习过程就是树枝不断分裂长成大树的过程 （剪枝分类器的组合） 决策树学习：不断根据属性划分训练数据的过程 关键在于如何选择最优划分属性。一般而言，随着划分过程不断进行，我们希望经过分支结点划分后的样本尽可能属于同一类别，即“纯度” (purity)越来越高 经典的属性划分方法：– 信息增益– 增益率– 基尼指数 评价指标-信息熵“信息熵” 是度量样本集合纯度最常用的一种指标，假定当前样本集合D中第k类样本所占的比例为 ， 则的信息熵定义为 信息增益 增益率基尼指数剪枝处理 为什么剪枝– “剪枝” 是决策树学习算法对付“过拟合” 的主要手段– 可通过“剪枝” 来一定程度避免因决策分支过多， 以致于把训练集自身的一些特点当做所有数据都具有的一般性质而导致的过拟合 剪枝的基本策略– 预剪枝– 后剪枝 剪枝依据-决策树泛化性能– 留出法：预留一部分数据用作“验证集” 以进行性能评估– 交叉验证法 预剪枝 决策树生成过程中， 对每个结点在划分前先进行估计， 若当前结点的划分不能带来决策树泛化性能提升， 则停止划分并将当前结点记为叶结点， 其类别标记为训练样例数最多的类别 预剪枝优缺点 优点– 降低过拟合风险– 显著减少训练时间和测试时间开销 缺点– 欠拟合风险：有些分支的当前划分虽然不能提升泛化性能， 但在其基础上进行的后续划分却有可能导致性能显著提高。 预剪枝基于“贪心” 本质禁止这些分支展开， 带来了欠拟合风险 后剪枝 先从训练集生成一棵完整的决策树， 然后自底向上地对非叶结点进行考察， 若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升， 则将该子树替换为叶结点 后剪枝的优缺点 优点– 后剪枝比预剪枝保留了更多的分支， 欠拟合风险小， 泛化性能往往优于预剪枝决策树 缺点– 训练时间开销大：后剪枝过程是在生成完全决策树之后进行的，需要自底向上对所有非叶结点逐一考察 连续属性的处理与离散属性不同， 若当前结点划分属性为连续属性，连续属性还可作为后代结点的划分属性 1.png) 2.png) 多变量决策树• 分支节点根据多个属性的线性组合（一个节点由多个属性和对应权重决定）来进行判定 集成学习指将多个性能较低的“弱” 分类器通过适当组合而形成高性能的“强” 分类器的方法 多个模型的组合性能高于单个模型的性能-》模型之间的多样性越大，组合性能越好 Boosting学习法对多个弱学习器依次进行学习；每个弱学习器是对前一个弱学习器的强化 通过样本权重的变换来生成多样化的训练数据 Bagging学习法对多个弱学习器进行独立学习；通过训练样本的随机采样来生成多样化的模型 随机森林(random forest)随机森林 = bagging学习 + 决策树 随机性的目的：确保决策树组合的多样性• 数据集的随机性(bagging学习法)• 分支节点属性的随机性]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并行算法分析]]></title>
    <url>%2Farticle%2F515eae05%2F</url>
    <content type="text"><![CDATA[并行与并发的区别 并行是指多个事件在同一时刻发生; 而并发是指多个事件在同一时间间隔内发生。 分布式计算与并行计算的区别 SMP与 AMP的区别 并行计算机的互联方式 先序树遍历如何在PRAM模型上实现并行化 1，构建单链表 2，做前缀求和 3，每个顶点的输出顺序的值 注意点共享内存访问冲突问题的解决（利用忙等待、互斥）]]></content>
      <categories>
        <category>Parallel Algorithm</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机视觉]]></title>
    <url>%2Farticle%2F746b0d51%2F</url>
    <content type="text"><![CDATA[定义计算机利用相机和计算能力来感知现实世界 2.5维：在平面上浮凸出来的一个空间，可以想象是浮雕所处于的一种空间（伪3D） 2.5维：在平面上浮凸出来的一个空间，可以想象是浮雕所处于的一种空间（伪3D） 2.5D是从一个视角去看的，像素之间没有距离的概念，3D是从多视角去看的，有距离的概念 实现方案传统算法 HOG、金字塔、SIFT 神经网络 CNN 数据集 IMAGENET（李飞飞团队）https://v.qq.com/x/page/z0399f36dv1.html有关介绍 分类几何视觉（3D\2D） 语义识别（分类、检测、提取） 基础图像的采样与量化 如何训练神经网络关键Activation FunctionsData PreprocessingWeight InitializationBatch NormalizationBabysitting the Learning ProcessHyperparameter OptimizationoptimizationRegularizationTransfer Learning 环境CPU vs GPUDeep Learning FrameworksCaffe / Caffe2Theano / TensorFlowTorch / PyTorch TensorFlow is a safe bet for most projects. Not perfect but has huge community, wide usage. Maybe pair with high-level wrapper (Keras, Sonnet, etc) I think PyTorch is best for research. However still new, there can be rough patches. Use TensorFlow for one graph over many machines Consider Caffe, Caffe2, or TensorFlow for production deployment Consider TensorFlow or Caffe2 for mobile 激活函数 红色区域存在饱和(f(x)*f`(x)=0)神经元,黄色区域均为非饱和神经元 sigmoid激活函数1.饱和神经元将会使得梯度消失 2.Sigmoid输出不是以零为中心的 3.exp() is a bit compute expensive 由于使用sigmoid激活函数会造成神经网络的梯度消失和梯度爆炸问题，所以许多人提出了一些改进的激活函数，如：用ReLU、Leaky-ReLU、P-ReLU、R-ReLU、Maxout等替代sigmoid函数。 tanh(x)激活函数1.值均在[-1,1]之间 2.以零为中心点（这点很优秀） 3.仍然会在饱和时使得梯度消失 ReLU激活函数1.非饱和(在正区域)2.非常计算效率3.在实践中，收敛速度比sigmoid/tanh快得多(例如6x)4.实际上比sigmoid更合理 但是不是以零为中心点，并且容易出现死亡神经元 Leaky-ReLU激活函数1.不饱和2.计算效率高3.在实践中比sigmoid/tanh收敛得快得多!(例如6 x)4.不存在死亡神经元 Parametric Rectifier (PReLU) f(x) = max(ax, x) ELU激活函数1.继承ReLU的所有好处2.接近于零的平均输出3.负饱和状态与Leaky-ReLU相比，对噪声有一定的鲁棒性 但是计算中需要exp(),意味着计算量较高 Maxout激活函数1.没有点积的基本形式——&gt;非线性？2.泛化ReLU和Leaky-ReLU3.线性!不饱和!没有死亡神经元! 实际使用Use ReLU. Be careful with your learning ratesTry out Leaky ReLU / Maxout / ELUTry out tanh but don’t expect muchDon’t use sigmoid 数据预处理使用PCA和数据增强使得数据以0为中心 就是尽可能的让输入和输出服从相同的分布，这样就能够避免后面层的激活函数的输出值趋向于0 网络参数初始化 很小的随机数（在小型神经网络中表现可以，但在深层网络存在问题） 何凯明对ReLU的初始化方法 批归一化位置：通常插入在全连接层或卷积层之后，在非线性之前。 作用：使得数据的分布更符合高斯或正态分布 开始训练尝试输出每个epoch的损失值(是否下降、下降速率)、精准度 尝试学习率按（一定规律）衰减 找到合适的超参（1）交叉验证集 （2）随机查找 or 网格查找(大概确定范围) （3） 正则化 （4）可视化工具 梯度下降随机梯度下降小批量SGD 会有噪声 动量梯度下降 牛顿动量 以下算法查看大佬解析深度学习优化算法解析(Momentum, RMSProp, Adam) Adam适应性梯度算法添加了基于每个维度的历史平方和的梯度元素的缩放 RMSPropL-BFGS- Usually works very well in full batch, deterministic mode i.e. if you have a single, deterministic f(x) then L-BFGS will probably work very nicely - Does not transfer very well to mini-batch setting. Gives bad results. Adapting L-BFGS to large-scale, stochastic setting is an active area of research. 实际使用1.Adam is a good default choice in most cases 2.If you can afford to do full batch updates then try outL-BFGS (and don’t forget to disable all sources of noise) 正则化主因：数据链不够大 or 多样性不足 目的：提高模型泛化能力 1.给损失函数增加正则项 2.Dropout（随机删除） 总结Activation Functions (use ReLU)Data Preprocessing (images: subtract mean)Weight Initialization (use Xavier init)Batch Normalization (use)Babysitting the Learning processHyperparameter Optimization(random sample hyperparams, in log space when appropriate) Optimization ​ - Momentum, RMSProp, Adam, etc - Regularization ​ - Dropout, etc -Transfer learning ​ -Use this for your projects! 任务小作业（小组的形式 各自合作共同大项目） 复现一篇相关论文并完成10页的实验报告（类似论文） 1、presentation部分按小组完成一个计算机视觉方向的文献（多篇）阅读，讲解并提交一份文献综述报告；2、project 每个人完成一个（会下发题目），展示并讲解，提交源代码和实验报告。 所选论文Learning Efficient Single-stage Pedestrian Detectors by Asymptotic Localization Fitting 论文链接：http://openaccess.thecvf.com/content_ECCV_2018/html/Wei_Liu_Learning_Efficient_Single-stage_ECCV_2018_paper.html 源代码：https://github.com/liuwei16/ALFNet Is Faster R-CNN Doing Well for Pedestrian Detection? 论文链接：https://arxiv.org/abs/1607.07032 源代码：https://github.com/zhangliliang/RPN_BF/tree/RPN-pedestrian ​ https://github.com/longcw/faster_rcnn_pytorch ​ https://github.com/CharlesShang/TFFRCNN 参考链接https://www.cnblogs.com/wangxiaocvpr/p/5747095.html Is Faster R-CNN Doing Well for Pedestrian Detection?论文阅读 Learning Efficient Single-stage Pedestrian Detectors by Asymptotic Localization Fitting 行人检测/人体检测综述 行人检测（Pedestrian Detection）论文整理 激活函数及其作用以及梯度消失、爆炸、神经元节点死亡的解释 深度学习优化算法解析(Momentum, RMSProp, Adam)]]></content>
      <categories>
        <category>Computer Vision</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并行计算机组成]]></title>
    <url>%2Farticle%2F517840f3%2F</url>
    <content type="text"><![CDATA[定义并行计算机就是由多个处理单元组成的计算机系统，这些处理单元相互通信和协作，能快速，高效地求解大型复杂问题。 需求满足在平台金字塔顶端对性能需求最强的应用程序，对运算速度的无止境追求 发展历程 云计算（着重在软件-》网格运算）是并行计算（硬件）的一种发展形势 考虑到功耗，cpu散热，摩尔定律中晶体管的数量（当前还在上升）、CPU频率（大概3.8GHZ，超频4.2GHZ）受限。 结构并行计算机体系机构= 计算机体系结构 + 计算机通信 编程模型： 共享存储、消息传递、数据并行 计算机性能执行时间（execution time）- 响应时间 性能 = 1/执行时间 吞吐率（Throughput） 即带宽-单位时间内完成的任务数量 程序执行时间：是指用户的响应时间 (访问磁盘和访问存储器的时间， CPU时间， I/O时间以及操作系统的开销)CPU时间：它表示CPU的工作时间，不包括I/O等待时间和运行其它任务的时间。 Amdahl定律 - 加速比（只改进一部分，则系统所获得的加速比有上限） 并行计算的提升，受到了程序中必须串行执行部分的限制 经典的Amdahl定律并不适用于规模可扩展的系统，加速比曲线理论与实际不一致。 为什么CPU不能通过成千上万个线程来加速？CPU的架构和GPU不一样，CPU就算是采用超线程技术，一个核也只能开两个线程，4核就8个线程，如果强行开10000个线程实际上也是软系统层面的虚拟线程 参考资料CMU并行体系结构与编程的网址 学校教材]]></content>
      <categories>
        <category>Parallel Computing</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英文摘要写作]]></title>
    <url>%2Farticle%2Fcb8609cd%2F</url>
    <content type="text"><![CDATA[摘要简介 摘要( abstract) 也称为内容提要，通常在学术论文中都必须附有摘要，其位子应放在论文的正文之前，对整个论文内容的概述。无论对专业读者还是对非专业读者而言，摘要都是一个非常重要的文件。 摘要如果和论文一起发表，则被称为一次性出版物摘要，主要用于帮助读者评价文章内容及其潜在作用，使读者不必阅读全文就可以了解论文的内容。除此之外，摘要也可以被单独收入文摘机构出版的摘要期刊如：生物学文摘(Biological Abstract)、化学文摘（Chemical Abstract）等，称为二次性出版物摘要。此类脱离论文独立成篇的摘要主要用于方便读者检索文摘、收集信息，帮助研究者寻找新的研究领域。 摘要的定义摘要的英文术语：有两个词汇，一个是 abstract, 一个是 summary 根据美国国家标准学会 ( American National Standards Institute ) 于1971年通过并颁布的《美国国家文摘写作标准》 （American National Standards for Writing Abstracts）规定，abstract 不应与 summary 混同。 Abstract 对一篇论文的主要内容以精炼的文字进行高度概括，使读者不必阅读论文全文即可迅速了解论文内容，或者让读者对即将阅读的文章有思想准备，或者让读者判断是否有通读全文的必要。文中只对论文信息进行浓缩，而不加主观评论或解释，可以脱离原文而独立成篇。字数通常在100 – 150 个词左右，更确切地说，约为原文长度的1% - 5%(有的杂志规定摘要平均为全文的 3% - 5% )。现在越来越多的用法是 abstract。尤其是放在索引资料中一律要用abstract 这个术语，在论文的题目下也通常要用这个词。 Summary (概要) 与 abstract 无明显差别。严格地说，summary 一般附在论文的后面，对论文的主要结论和成果进行再叙述。其前提是读者已经通读的全文，通过summary 来巩固论文的主要论点和成果。在某些论文中，用summary取代正文中的conclusion部分。Summary是论文的“缩影”，可以概括论文的全部内容，只是在删繁就简上下功夫，字数长短不一，少则两三句话，多则500个单词甚至更长.美国的一些高校规定,说是论文提要(summary)以250词左右为宜，而博士论文提要以350词左右为宜。博士会议论文的提要一般规定为300 – 500词或1000个印刷符号。 至于究竟采用什么形式，要根据征稿简则而定。一般说来，国际学术会议论文集要求按Summary方式来写摘要，而正式出版发行的刊物要求不禁一致。对于个别论文还见有前面为Abstract,结尾又有一个Summary，这多半是由于文章过长，内容又多，后面的Summary相当于该文的缩写。 摘要的种类摘要分为两类，一类是说明性摘要(Descriptive/Indicative Abstract),一类是资料性摘要（Informative Abstract）。 1.2.1 说明性摘要(Descriptive/Indicative Abstract) 如同迈克尔.艾利（Michael Alley）所说，“一篇说明性摘要是段落形式的目录，是读者手中的一份简要地图。”从这句话中可以清楚地了解说明性摘要的作用。说明性摘要只向读者指出论文的主要议题是什么，不涉及具体的研究方法和结果，但无法给读者提供更多的详细信息。它一般是用于综述性文章，也用于讨论、评论性文章，尤以介绍某学科近期发展动态的论文居多。常出现“…is studied”, “…is investigated”, “…is discussed”字样。时态多用现在时或现在完成时。其篇幅也较短，大多在100-150字之间。以下是一篇说明性摘要的样例： Ten widespread diseases that are hazards in isolated construction camps can be prevented by removing or destroying the breeding places of flies, mosquitoes and rats, and by killing their adult forms. 由于说明性摘要仅限于陈述论文的主要议题且篇幅较小，主要用于评述性论文。 1.2.2 资料性摘要（Informative Abstract） 资料性摘要适用于专题研究论文和实验报告型论文。 资料性摘要的优点是比说明性摘要能提供多得多的信息，它应该尽量完整和准确地体现原文的具体内容，特别要强调指出研究的方法和结果，结论等。其篇幅较长，大多在150-250字之间。根据原文长度，也有多达500字的。通常，这一类的摘要反映了论文的基本面貌，能够代替阅读论文全文。 Ten widespread diseases that are hazards in isolated construction camps can be prevented by removing or destroying the breeding places of flies, mosquitoes and rats, and by killing their adult forms. The breeding of flies is controlled by proper disposal of decaying organic matter, and of mosquitoes by destroying or draining pools, or spraying them with oil. For rats, only the indirect methods of rat-resistant houses and protected food supplies are valuable. Control of adult forms of both insects and rodents requires use of poisons. Screens are used for insects. Minnows can be planted to eat mosquito larvae. 如何写摘要摘要的位置摘要的位置是确定的，一般在作者工作单位的下方。如： Cultural Differences Between China and U.S.A. (标题) ​ Xu Ying (署名) Hunan University （Changsha，Hunan， 410082） （工作单位） Abstract: （摘要） Key words: (关键词) 写作要点 长度：有专家认为150-200个词之间；文章长度的五分之一。 有些刊物会规定摘要的篇幅不能超过一定的字数，如：在80-100之间，再投稿应查询。 若刊物没有规定长度时，可参阅已发表的文章长度。 参加国际会议的论文摘要有字数限制，一般要求200-500个词之间，约1000个印刷符号。 （美国化学文献、医学文献的论文摘要规定在200个词以内。） 不要重复论文中的句子。 避免例举大堆数据。 一般只是一个段落，不要将其分为数段。 不要使用祈使句、感叹句、公式、表格等。 完成论文后再写摘要。 一般使用第三人称或被动语态。 语言需简明扼要。 下面请看一篇论文摘要 This paper deals with the English syllabus for graduate students in China. The paper first reviews the history of the graduate English teaching, then discusses the shortcomings in the syllabus and finally proposes some suggestions for its revision. Key words: syllabus, graduate English teaching 阅读下面文章，然后写出一段80个词左右的摘要。最后再参阅提供的英语摘要。 These days, there is a common belief among parents that schools are no longer taking any notice of students’ spelling. But, no school I have taught in has ever ignored spelling or considered it unimportant as a basic skill. There are, however, vastly different ideas about how to teach it, or how much importance it must be given over general language development and writing ability. The problem is , how to encourage a child to express himself freely and confidently in writing without holding him back with the complexities of spelling. If spelling becomes the only focal point of his teacher’s interest, clearly a bright child will be likely to “play safe”. He will tend to write only words within his spelling range, choose to avoid adventurous language. That’s why teachers often encourage the early use of dictionaries and pay attention to content rather than technical ability. I was once shocked to read on the bottom of a sensitive piece of writing about a personal experience. “This work is terrible! There are too many spelling errors and your writing is hard to read.” It may have been a sharp criticism of the pupil’s technical abilities in writing, but it was a sad remark from the teacher who had omitted to read the essay, which contained some beautiful expressions of the child’s deep feelings. The teacher was not wrong to draw attention to the errors, but if his attention had centered on the child’s ideas, an expression of his disappointment with the presentation would have given the pupil more motivation to seek improvement. 摘要的内容 摘要的写作必须准确、明晰、简洁，概述与细节描述之间需要相互平衡，相互补充。内容取舍的标准首先是对论文本身重点的理解，其次应该考虑到读者阅读的方式。资料性摘要的内容通常包括： 背景知识或文献回顾 （Background Information / Literature Review） 研究的主要目的和范围 (Principal Purpose) 研究方法 （Methodology） 研究的主要结果（Results） 结论和建议 （Conclusions and Recommendation） 例1： This article discusses some possible roles for self-access pathways, particularly in cultures which have no tradition of self-study. It suggests how pathways might influence the design and running of self-access centre, and gives an illustration of how pathways were designed and employed in a centre in China. Feedback is based on a mini-survey distributed to thirty users. ( ELT Joural Vol.51/1 January 1997 Oxford Univ. Press, 1997) 例2： The science taught in the classroom should be reasonably up-to – date. What is taught should place emphasis first on the principles and major concepts of science rather than on the applications of scientific knowledge. The instructional techniques comprise laboratory work which is introduced in such a manner as to emphasize science as a process— to reveal through practice that science involves inquiry, discovery, and experimentation. The paper suggests that college science programs should be revised with a view to preparing teachers to handle science in secondary and elementary schools. 常用表达方法描述目的，介绍相关知识 This The paper thesis article study survey project research investigation present study work advances the view that… advocates … analyzes … argues that … contains deal with … discusses … develops … explains the reason why … expresses … focuses ( attention ) on the fact that … holds that … includes … investigates the features of … makes a comparative study upon the … offers … presents … proposes that … reviews … states … supports … The chief major main primary principal aim goal objective object proposal purpose of this of the paper study project research survey work is to investigate … discuss … evaluate … examine … determine … measure … reveal the cause of … This research is designed study project investigation The experiments on … were made The author attempts intends The author’s endeavor is to determine … measure the amount of … evaluate … calculate … obtain the result of … obtain some knowledge of … explain the reason why … outline the framework of … 描述观察角度： a. …from the angle of … b. … in the light of the context that … c. to view something at a different angle / from various angles d. from the point of view of … e. from the perspective of … 描绘方法： a. Detailed information has been acquired by the authors using … b. This is theory based on the idea that … c. Several sets of experiments have been performed to test the validity of … d. The method used in our study is known as … e. The technique the author adopted is referred to as … f. The approach taken in the investigation is called … g. The experiments consisted of four steps, which are described in … 描述结果： a. The results show / indicate that … b. The results are as follows: c. The analysis of the samples indicates that … d. We found that … e. Data suggested that … f. It is shown that … g. Based on / upon the outcome ​ findings ​ results of the research , points out believes concludes declares that … suggests recommends asks that … (从句中用虚拟语气) h. the author i. the results / findings / observations have shown that … j. The outcome has proved that … k. The data obtained seem to be very similar to those reported earlier by … 描述结论： a. In conclusion, the result shows … b. To sum up, we have revealed … c. It can be concluded / acknowledged that … d. The examination / investigation proves that … e. In summing up it may be stated that … f. All the preliminary results throw light on the nature of … g. These findings of the research have naturally led the author to the conclusion that … 练习Read the following passages first and then write an abstract of 60 to 80 words. Passage One The use of the word “imitation” reminds me that I should make some more comments on the risk of people imitating what they see on TV in the Way of crime of violence. First there was always a risk of children acting out according to what they saw from a TV program, which could be dangerous. For example I remember a woman who was a head of a primary school telling me that she had happened to look out of her window when the children were in the playground and had seen them putting a small boy on a chair with a rope round his neck under the branch of a tree; fortunately she was in time to stop them before the child was hanged. I remember a film of no particular merit in which the hero who was imprisoned had escaped by killing his guard, the technique of doing shown in detail. This was the kind of scene which we should cut for the reasons. In films for young people and adults we always tried to keep off the screen any details of criminal techniques, such as how to open a locked door with a piece of wire, or how to open a safe; if we were consulted before production I used to advise that the details should not be shown. When I gave talks in prisons about film censorship I invariably had full support for this; since fathers who were in prison for criminal offenses did not want their children to embark on crime. Every time I gave a talk in a prison someone used to mention the French film Rififi made by Jules Dassin in 1954. This remarkable film showed in great detail a robbery of a jeweler’s shop, the robbery sequence lasting about half an hour and being backed only by natural sound — one of the most brilliant film sequences of all time. I remember our discussions at the time. We took into account the fact that the robbery was accomplished only with the use of elaborate and obviously expensive equipment, and that only the most experienced and skilled criminals could possibly imitate it; we believed therefore that it was relatively safe. When talking in prisons some years later I learned that there had been several robberies in which the techniques had been copied, so perhaps we were wrong. Passage Two We have recently heard a great deal about the bad effects of computers on our social and economic organizations. In industry, computers mean automation, and automation means unemployment. Computers in the United States have already begun to displace workers whose tasks are simple. The variety of jobs,formerly done only by humans, that the machine can perform more rapidly, accurately, and economically, increases with each new generation of computers. If we follow this trend, we will be faced with mass unemployment for all but a handful of highly trained professionals, who will then be more powerful and overworked than they are now. What can we do about it? It is foolish to dream of reversing history. We cannot pass laws forbidding the advancement of science and technology. The computing machines are here, and they will grow because engineers want to build them, and politicians want their help in the process of government. In short, they will develop and become popular because they enable us to complete tasks that could never before have been undertaken, no matter how many unskilled laborers we might have set to work. Computers will continue to increase our intelligence for just the same reason that engines continue to strengthen our muscles. The question we must ask in not whether we shall have computers or not have computers, but rather, since we are going to have them, how we can make the most human and intelligent use of them. 说明以上内容是郝老师上课总结给我们的，分享给大家用于学习。 版权归属于她，请勿盗用。 我的摘要模板资料性摘要 背景知识或文献回顾 （Background Information / Literature Review） 研究的主要目的和范围 (Principal Purpose) 研究方法 （Methodology） 研究的主要结果（Results） 结论和建议 （Conclusions and Recommendation） ps:针对考试：注意答题纸，除了剩余空间，背面也要写4行，不要太多。若文章较难（看不懂），将每段的首句、尾句写入summary中。以上几点，范文出现几点，写几点。 ​ The article advances the view that …(文献回顾,文章讲了啥) ​ The chief aim of this research is to investigate/discuss that… （研究目的），from the angle of … （角度）.The approach taken in the investigation is called…(研究方法). It is shown that … ​ It can be concluded that … （研究结论）, There are some recommendation given by the authors. First of all,(建议1).In addition,(建议2).What’s more,(建议3).（建议）]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作系统总结]]></title>
    <url>%2Farticle%2F8ce3e425%2F</url>
    <content type="text"><![CDATA[《计算机操作系统》复习大纲 第一章 绪论 1.掌握操作系统的基本概念、主要功能、基本特征、主要类型； 2.理解分时、实时系统的原理； 第二章 进程管理 1.掌握进程与程序的区别和关系； 2.掌握进程的基本状态及其变化； 3.掌握进程控制块的作用； 4.掌握进程的同步与互斥； 5.掌握多道程序设计概念； 6.掌握临界资源、临界区、掌握信号量，PV操作的动作； 第三章 处理机调度 1.掌握作业调度和进程调度的功能； 2.掌握简单的调度算法：先来先服务法、时间片轮转法、优先级法； 3.掌握评价调度算法的指标：吞吐量、周转时间、平均周转时间、带权周转时间和平均带权周转时间； 4.掌握死锁；产生死锁的必要条件；死锁预防的基本思想和可行的解决办法； 5.掌握进程的安全序列，死锁与安全序列的关系； 第四章 存储器管理 1.掌握用户程序的主要处理阶段； 2.掌握存储器管理的功能；有关地址、重定位、虚拟存储器、分页、分段等概念； 3.掌握分页存储管理技术的实现思想； 4.掌握分段存储管理技术的实现思想； 5.掌握页面置换算法。 第五章 设备管理 1.掌握设备管理功能； 2.掌握常用设备分配技术； 3.掌握使用缓冲技术的目的； 第六章 文件管理 1.掌握文件、文件系统的概念、文件的逻辑组织和物理组织的概念； 2.掌握目录和目录结构；路径名和文件链接； 3.掌握文件的存取控制；对文件和目录的主要操作 第七章 操作系统接口 1.掌握操作系统接口的种类； 2.掌握系统调用的概念、类型和实施过程。 计算机操作系统复习知识点汇总 第一章 1、操作系统的定义、目标、作用 操作系统是配置在计算机硬件上的第一层软件，是对硬件系统的首次扩充。 设计现代OS的主要目标是：方便性，有效性，可扩充性和开放性. OS的作用可表现为： a. OS作为用户与计算机硬件系统之间的接口；（一般用户的观点） b. OS作为计算机系统资源的管理者；（资源管理的观点） c. OS实现了对计算机资源的抽象. 2、脱机输入输出方式和SPOOLing系统（假脱机或联机输入输出方式）的联系和区别 脱机输入输出技术Off-Line I/O是为了解决人机矛盾及CPU的高速性和I/O设备低速性间的矛盾而提出的.它减少了CPU的空闲等待时间，提高了I/O速度. 由于程序和数据的输入和输出都是在外围机的控制下完成的，或者说，它们是在脱离主机的情况下进行的，故称为脱机输入输出方式；反之，在主机的直接控制下进行输入输出的方式称为联机（SPOOLing）输入输出方式 假脱机输入输出技术也提高了I/O的速度，同时还将独占设备改造为共享设备，实现了虚拟设备功能。 3、多道批处理系统需要解决的问题 处理机管理问题、内存管理问题、I/O设备管理问题、文件管理问题、作业管理问题 4**、OS具有哪几个基本特征?它的最基本特征是什么? a. 并发性Concurrence,共享性Sharing,虚拟性Virtual,异步性Asynchronism. b. 其中最基本特征是并发和共享. c. 并发特征是操作系统最重要的特征，其它三个特征都是以并发特征为前提的。 5、并行和并发 并行性和并发性是既相似又有区别的两个概念， 并行性是指两个或多个事件在同一时刻发生； 而并发性是指两个或多少个事件在同一时间间隔内发生。 6、操作系统的主要功能，各主要功能下的扩充功能 a. 处理机管理功能： 进程控制，进程同步，进程通信和调度. b. 存储管理功能： 内存分配，内存保护，地址映像和内存扩充等 c. 设备管理功能：缓冲管理，设备分配和设备处理，以及虚拟设备等 d. 文件管理功能：对文件存储空间的管理，目录管理，文件的读，写管理以及共享和保护 7、操作系统与用户之间的接口 a. 用户接口：它是提供给用户使用的接口，用户可通过该接口取得操作系统的服务 b. 程序接口：它是提供给程序员在编程时使用的接口，是用户程序取得操作系统服务的唯一途径。 第二章 1、进程的定义、特征，进程实体的组成 进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。 进程具有结构特征、动态性、并发性、独立性和异步性。 进程实体由程序段、相关的数据段和PCB三部分构成。 2、进程的三种基本状态及其转换 运行中的进程可能具有就绪状态、执行状态、阻塞状态三个基本状态。 进程三个基本状态转换图— P38 3**、引入挂起状态的原因，具有挂起状态的进程转换** a. 终端用户的请求 b. 父进程请求 c. 负荷调节的需要 d. 操作系统的需要 具有挂起状态的进程转换图— P39 4、创建进程的主要步骤 a. 为一个新进程创建PCB，并填写必要的管理信息。 b. 把该进程转入就绪状态并插入就绪队列之中。 5、进程控制块（PCB）的作用 PCB是进程实体的一部分，是操作系统中最重要的记录型数据结构。PCB中记录了操作系统所需的用于描述进程情况及控制进程运行所需的全部信息。因而它的作用是使一个在多道程序环境下不能独立运行的程序含数据，成为一个能独立运行的基本单位，一个能和其它进程并发执行的进程。 为什么说PCB是进程存在的唯一标志? 在进程的整个生命周期中，系统总是通过其PCB对进程进行控制，系统是根据进程的PCB而不是任何别的什么而感知到该进程的存在的，所以说，PCB是进程存在的唯一标志。 6、进程控制块的组织方式 链接方式、索引方式 7、原语的定义、组成、作用 原语是由若干条指令组成的，用于完成一定功能的一个过程，与一般过程的区别在于：它们是“原子操作”，它是一个不可分割的基本单位，在执行过程中不允许中断。原子操作在管态下执行，常驻内存。 原语的作用是为了实现进程的通信和控制，系统对进程的控制如不使用原语，就会造成其状态的不稳定性，从而达不到进程控制的目的。 8、引起创建进程的事件 用户登录、作业调度、提供服务、应用请求 9、引起进程终止的事件 正常结束、异常结束、外界干预 10、引起进程阻塞和唤醒的事件 请求系统服务、启动某些操作、新数据尚未到达、无新工作可做 11、临界资源和临界区 临界资源是指每次仅允许一个进程访问的资源。 属于临界资源的硬件有打印机、磁带机等,软件有消息缓冲队列、变量、数组、缓冲区等。 诸进程间应采取互斥方式，实现对这种资源的共享。 每个进程中访问临界资源的那段程序称为临界区（Critical Section）不论是硬件临界资源，还是软件临界资源，多个进程必须互斥地对它进行访问。 12、同步机制应遵循的规则 空闲让进、忙则等待、有限等待、让权等待 13、进程通信的类型 高级通信机制可归结为三类：共享内存系统、消息传递系统以及管道通信系统。 14、线程的定义、属性在多线程OS中，通常是在一个进程中包含多个线程，每个线程都是作为利用CPU的基本单位，是花费最小开销的实体。 线程具有下述属性：（1）轻型实体—线程中的实体基本上不拥有系统资源，只是有一点必不可少的、能保证其独立运行的资源。 （2）独立调度和分派的基本单位 （3）可并发执行。（4）共享进程资源。 15、进程和线程的比较 a. 调度性。在传统的操作系统中，拥有资源的基本单位和独立调度、分派的基本单位都是进程，在引入线程的OS中，则把线程作为调度和分派的基本单位，而把进程作为资源拥有的基本单位； b. 并发性。在引入线程的OS中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间，亦可并发执行，因而使OS具有更好的并发性； c. 拥有资源。无论是传统的操作系统，还是引入了线程的操作系统，进程始终是拥有资源的一个基本单位，而线程除了拥有一点在运行时必不可少的资源外，本身基本不拥有系统资源，但它可以访问其隶属进程的资源； d. 系统开销。由于创建或撤销进程时，系统都要为之分配和回收资源，如内存空间等，进程切换时所要保存和设置的现场信息也要明显地多于线程，因此，操作系统在创建、撤销和切换进程时所付出的开销将显著地大于线程。 第三章 1、高级调度与低级调度的区别 高级调度又称为作业调度或长程调度，调度对象是作业，作业调度往往发生于一个（批）作业运行完毕，退出系统，而需要重新调入一个（批）作业进入内存时，故作业调度的周期长；低级调度又称为进程调度和短程调度，调度物件为进程（或内核级线程），进程调度的运行频率最高，是最基本的一种调度，多道批处理、分时、实时三类OS中必须配置这种调度。 引入中级调度的主要目的：是为了提高系统资源的利用率和系统吞吐量 2、低级调度的功能 保存处理机的现场信息、按某种算法选取进程、把处理器分配给进程 3、进程调度方式 （1）非抢占方式—实现简单、系统开销小、适用于大多数的批处理系统环境 （2）抢占方式——原则：优先权原则、短作业（进程）优先原则、时间片原则 4、同时具有三级调度的调度队列模型当在OS中引入中级调度后，人们可把进程的就绪状态分为内存就绪和外存就绪，类似的阻塞状态也可以同样划分。 5、三大调度算法 在ＯＳ中调度实质是一种资源的分配。 先来先服务和短作业（进程）优先调度算法、高优先权优先调度算法、基于时间片的轮转调度算法。 6**、高响应比优先调度算法 优先权＝等待时间＋要求服务时间＼要求服务时间 响应比＝等待时间＋要求服务时间＼要求服务时间＝响应时间＼要求服务时间 7**、最低松弛度优先调度算法即LLF算法 该算法是根据任务紧急（或松弛）的程度，来确定任务的优先级。涉及到计算题，参照课本Ｐ１０２仔细研究。 8**、何谓死锁？产生死锁的原因和必要条件是什么？ a.死锁是指多个进程因竞争资源而造成的一种僵局，若无外力作用，这些进程都将永远不能再向前推进； b.产生死锁的原因有二，一是竞争资源，二是进程推进顺序非法； c.必要条件是: 互斥条件，请求和保持条件，不剥夺条件和环路等待条件。 9、处理死锁的基本方法** （１）预防死锁—破坏产生死锁的四个必要条件中的一个或几个条件 （２）避免死锁—破坏产生死锁的四个必要条件 （３）检测死锁—通过系统设置的检测机构，及时检测出死锁的发生 （４）解除死锁—撤销或挂起一些进程 10、预防死锁的方法 a.摒弃”请求和保持”条件 b.摒弃”不剥夺”条件 c.摒弃”环路等待”条件 11 解除死锁 a资源剥夺法，b撤销进程 第四章 1、存储器按存储量、速度怎么划分？ 对于通用计算机而言，存储层次至少应具有三级：最高层为CPU寄存器、中间为主存、最底层为辅存，较高档点的根据具体功能还可细分为：寄存器；高速缓存、主存储器、磁盘缓存；固定硬盘、可移动存储介质等6层。 主存储器（简称内存或主存）：容量一般为数十MB到数GB，其访问速度远低于CPU执行指令的速度。为此引入寄存器和高速缓存，寄存器访问速度最快，价格昂贵，容量不大；高速缓存容量大于或远大于寄存器，从几十KB到几十MB，访问速度快于主存储器。 2、程序的装入方式 绝对装入方式、可重定位装入方式、动态运行时装入方式 3、程序的链接方式分类 静态链接、装入时动态链接、运行时动态链接 4**、对换的定义、分类、实现** 对换是把内存中暂时不能运行的进程或者暂时不用的程序和数据调到外存上，以便腾出足够的内存空间，再把已具备运行条件的进程或进程所需要的程序和数据调入内存。 以整个进程为单位，称为“整体对换”或“进程对换”；以“页”或“段”为单位，分别称为“页面对换”和“分段对换”，又称为“部分对换” 为了实现进程对换，系统必须能实现三方面的功能：对换空间的管理、进程的换出，以及进程的换入。 5、页面与页表 分页存储管理是将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页 由于进程的最后一页经常装不满一块而形成不可利用的碎片，称为“页内碎片”。 系统为每个进程建立一张页面映像表，简称页表。页表的作用是实现从页号到物理块号的地址映射。 6**、分页系统的地址变换机构** 涉及到图形，分别是P132和P133 7、分段存储管理方式的引入原因 引入分段存储管理方式，主要是为了满足用户和程序员的一些需要： 方便编程、信息共享、信息保护、动态增长、动态链接 8、分段系统的基本原理 在分段存储管理方式中，作业的地址空间被划分为若干个（二维）段，每个段定义了一组逻辑信息，逻辑地址由段号和段内地址组成。每个段在表中占有一个表项，其中记录了该段在内存中的起始地址（又称为“基址”）。段表是用于实现从逻辑段到物理内存区的映射。 9、分段和分页的主要区别 a. 分页和分段都采用离散分配的方式，且都要通过地址映射机构来实现地址变换，这是它们的共同点； b. 对于它们的不同点有三，第一，从功能上看，页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率，即满足系统管理的需要，而不是用户的需要；而段是信息的逻辑单位，它含有一组其意义相对完整的信息，目的是为了能更好地满足用户的需要； c. 页的大小固定且由系统确定，而段的长度却不固定，决定于用户所编写的程序； d. 分页的作业地址空间是一维的，而分段的作业地址空间是二维的. 10、虚拟存储器的特征及其内部关联 a. 虚拟存储器具有多次性，对换性和虚拟性三大主要特征； b. 其中所表现出来的最重要的特征是虚拟性，它是以多次性和对换性为基础的，而多次性和对换性又必须建立在离散分配的基础上。 11、最佳置换算法和先进先出置换算法 涉及到关键的作图和计算答题，参照课本P150 12、最近最久未使用（ＬＲＵ）置换算法 13、请求分段系统的地址变换过程 涉及到关键的考试内容，请参考课本P156 图4-33仔细研究 14、分段保护 采取以下措施保证信息安全：越界检查、存取控制检查、环保护机构 第五章 １、I/O设备按使用特性、传输速率、信息变换、共享属性如何分类 按设备的使用特性分类：存储设备（又称外存、后备存储器、辅助存储器）；输入输出设备（又可具体划分：输入设备（键盘、鼠标、扫描仪、视频摄像、各类传感器）、输出设备（打印机、绘图仪、显示器、数字视频显示设备、音响输出设备）、交互式设备） 按传输速率分类：低速设备（键盘、鼠标、语音的输入输出设备）；中速设备（行式打印机、激光打印机）；高速设备（磁带机、磁盘机、光盘机）。 按信息交换的单位分类：块设备（磁盘）；字符设备（交互式终端、打印机） 按设备的共享属性分类：独占设备；共享设备（磁盘）；虚拟设备 2、设备控制器的组成 设备控制器由以下三部分组成：（1）设备控制器与处理机的接口，该接口用于实现CPU与设备控制器之间的通信，提供有三类信号线：数据线、地址线和控制线。（2）设备控制器与设备的接口，可以有一个或多个接口，且每个接口连接一台设备。每个接口都存在数据、控制和状态三种类型的信号。（3）I/O逻辑，用于实现对设备的控制。其通过一组控制线与处理机交互，处理机利用该逻辑向控制器发送I/O命令，I/O逻辑对收到的命令进行译码。 3、I/O通道设备如何引入 虽然在ＣＰＵ和I/O设备之间增加了设备控制器后，已能大大减少CPU对I/O的干预，但当主机配置的外设很多时，CPU的负担仍然很重，为此，在ＣＰＵ和设备控制器之间又增设了通道。 I/O通道是一种特殊的处理机，它具有执行I/O指令的能力，并通过执行通道（I/O）程序来控制I/O操作。 4**、有哪几种I/O控制方式？各适用于何种场合？** I/O控制方式：程序I/O方式、中断驱动I/O控制方式、DMAI/O控制方式、I/O通道控制方式。程序I/O方式适用于早期的计算机系统中，并且是无中断的计算机系统；中断驱动I/O控制方式是普遍用于现代的计算机系统中；DMA I/O控制方式适用于I/O设备为块设备时在和主机进行数据交换的一种I/O控制方式；当I/O设备和主机进行数据交换是一组数据块时通常采用I/O通道控制方式，但此时要求系统必须配置相应的通道及通道控制器。 5、DMA控制器的组成 DMA控制器由三部分组成：主机与DMA控制器的接口、DMA控制器与块设备的接口、I/O控制逻辑。 6**、为了实现主机与控制器之间成块数据的直接交换，需设置ＤＭＡ控制器中四类寄存器 DR：数据寄存器，暂存从设备到内存或从内存到设备的数据 MAR：内存地址寄存器 DC：数据计数器，存放本次CPU要读或写的字（节）数 CR：命令\状态寄存器，接收从CPU发来的I/O命令，或相关控制信息，或设备状态 7**、缓冲的引入原因 操作系统引入缓冲机制的主要原因可归结为以下几点：（1）缓和CPU与I/O设备间速度不匹配的矛盾；（2）减少对CPU的中断频率，放宽对中断响应时间的限制；（3）提高CPU与I/O设备之间的并行性。 8、缓冲池的组成、工作方式 三个队列：空缓冲队列、输入队列、输出队列 四种工作缓冲区：（1）用于收容输入数据的工作缓冲区；（2）用于提取输入数据的工作缓冲区；（3）用于收容输出数据的工作缓冲区；（2）用于提取输出数据的工作缓冲区； 缓冲区工作方式参照图P176 图5—15 9**、SPOLLing系统的定义、组成、特点** SPOOLing系统是对脱机I/O工作的模拟，其必须有高速随机外存（通常采用磁盘）的支持。SPOOLing系统主要有以下四个部分： （1）输入井和输出井，为磁盘上开辟的两大存储空间，分别模拟脱机输入/出时的磁盘，并用于收容I/O设备输入的数据和用户程序的输出数据； （2）输入缓冲区和输出缓冲区，在内存中开辟，分别用于暂存由输入设备和输出井送来的数据； （3）输入进程SPi和输出进程SPo，分别模拟脱机输入/出时的外围控制机，用于控制I/O过程； （4）I/O请求队列，由系统为各个I/O请求进程建立的I/O请求表构成的队列。 SPOLLing系统的特点：提高了I/O的速度；将独占设备改造为共享设备；实现了虚拟设备功能。 第六章 1、文件的定义、属性 文件是指由创建者所定义的、具有文件名的一组相关信息的集合，可分为有机构文件和无结构文件。 文件的属性包括：文件类型、文件长度、文件的物理位置、文件的建立时间 2、文件类型按用途、文件中数据的形式、存取控制属性、组织形式和处理方式如何划分？ 按用途分类：系统文件、用户文件、库文件 按文件中数据的形式分类：源文件、目标文件、可执行文件 按存取控制属性分类：只执行文件、只读文件、读写文件 按组织形式和处理方式划分：普通文件、目录文件、特殊文件 3、有结构文件按不同方式组织形成哪几种文件？ 顺序文件、索引文件、索引顺序文件 4、顺序文件的适用场合、优缺点 最佳适用场合是在对诸记录进行批量存取时。 批量存取时对顺序文件的存取速率是所有逻辑文件中最高的；只有顺序文件能存储在磁带上，并能有效地工作。 在交互应用场合，顺序文件表现出来的性能很差；如果想增加或删除一个记录都比较困难。 5、对目录管理的要求有哪些？ 对文件目录的管理有以下要求： a 实现“按名存取” b 提高对目录的检索速度 c 文件共享 d 允许文件重名]]></content>
      <categories>
        <category>Computer Operating</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[英语笔试笔记]]></title>
    <url>%2Farticle%2F2a1314f5%2F</url>
    <content type="text"><![CDATA[时间分配写作（25分钟写完，5分钟看听力文章） 听力（30分钟） 阅读理解：先仔细阅读，再长篇阅读，最后段落翻译。选词填空能做就做。 高级词替换thinkhave been convinced that… be of the opinion that…cling to the perspective that… ( 坚持认为… )maintain contend assertargue assume claim many a sea ofmultitudes ofimmense amounts ofnumerous innumerable plentiful people we usprivate individuals (人们)youngsters and teenagers（年轻人们）all children and adults （所有孩子和成年人们-》所有人）experts and professors （专家和教授们）parents kids offspring （父母孩子及其子孙后代）businessman （商人们）youngsters on campus （大学生们） veryexceedingly（ adv. 非常；极其；极度地；极端 ）distinctly（ adv. 明显地；无疑地，确实地 ）strikingly（ adv. 显著地，突出地，引人注目地 ）more thanextraordinarily（ adv. 极其，极端地；奇怪地 ）outstandingly （ adv. 非常，极其；优异，极好地；格外地 ） importantsignificantcrucialcriticalindispensableplay a crucial role in sth. Andsimilarlyequallylikewiseat the same time 万用句型（1）主语从句这可以写在文章任何位置，用于拉长句子。 显而易见、众所周知 It proves self-evident thatIt has been found thatIt seems beyond dispute thatIt seems universally acknowledged thatIt has been widely accepted thatIt becomes generally agreed that （2）定语从句这可以写在任何一句话的后面，用于补充说明。 显而易见、众所周知 a which is really beyond dispute.b which has been widely accepted.c which has provoked the public’s widespread concern. 例如 He is a good student,which has provoked the public’s widespread concern. （3）万能状语这可以放在句子的任意位置 as every one can see（众所周知） with the rapid advance of science and technology（随着科学和技术的快速发展） in our contemporary society（在当今社会，如今 = today） in the general routine of everyday living（在我们日常生活中） （4）插入语 to be frank（坦白说） as a matter of fact （事实上） from my perspective（在我看来） needless to say（显而易见）in my judgment（在我看来） to tell the truth（坦白说） （5）强调句型It is… that… 直接套进去就好，注意时态。 作文中所有的句子都可以写成强调句型，但是不能强调谓语，其他句子成分都可以被强调. 例：I met a crazy dog in the street yesterday. 转换为： 强调 昨天 It was yesterday(所强调的部分) that I met a crazy dog in the street . 强调 我 It was I(所强调的部分) that met a crazy dog in the street yesterday. 强调 在街上 It was in the street (所强调的部分) that I met a crazy dog yesterday. 加工重点句作文老师一定会看的四句话： 第一段、第二段、第三段的第一句、第一段的最后一句 一个句子用一个句型加工就好了。 作文这些模板句里面的词用上面的高级词替换掉，然后再换掉整个句型，生成自己的模板 （1）谚语警句类第一段：引出主题（一句话）+ 解释你对这句话的理解 （二句话） 第一句 A Nowadays（换掉）, there remains（换掉） an increasing（换掉） interest in the topic（换掉） about…; B Recently the issue of…has been in the limelight / brought into focus; C What is your idea as to the topic about…? It is my belief that …; D It looks beyond dispute that the issue about … has caused wide publicattention. 第二、三句 the meaning of the saying seems that … 比如：不要草率做决定the meaning of the saying seems that if you hope to do something successfully, please think it carefully. That is to say, it is foolish to decide it quickly. 第二段： 举例 A Although（换掉） so abundant cases can support（换掉） my simple view（换掉）, the following one is most favorable（换掉）.B Examples to prove the view are abundant. The most persuasive one is thecase of sb.C Such impressive cases/stories are not rare in our daily life, yet the followingone is definitely typical. …之后举一个详细的例子【我（我叔叔）有一个善良热情（责任感强、有耐心）的朋友（邻居）xxx,他怎么怎么样 要切题】。 第三段： 总结 第一句 Under no circumstances can we fail to pour attention into the importance/seriousness of the fact that It is really high time that due attention cannot have failed to paid to theissue. So crucial/grave is sth that it should have caused our attention. It is the fact of sth that really has a great influence on our study and life. 第二、三句话具体措施（国家政府、家长老师、个人三方面措施）for one thing / for another;on one hand / on the other hand; Eg. Write an essay on happiness by referring to the saying “Happiness is notthe absence of problems, but the ability to deal with them.” You can citeexamples to illustrate your points and then explain how you can develop yourability to deal with problem and be happy.措施一父母采取措施Parents are supposed to spend more time educating their kids to do sthEg. to be happy facing difficulties.to put eggs in different baskets.（鸡蛋放在不同的篮子里）措施二Awareness about sth could be cultivated to make ourselves lead a healthy andfavorable life. 最后一句：喊口号！1) Only by taking these action can people have a more brilliant and gloriousfuture.2) So shouldn’t human beings pay much attention to the meaningfulsaying/problem?3) So under no account could people divert attention from the issue of sth.4) The more actively people face the issue, the more happily they will lead theirlife. （2）图画图表类第一段 第一二句主语从句引出描述图画或图表 It seems beyond dispute that in the vivid cartoon/chart …A son is telling his father that he is … while his father is saying that … 第三句总结图画中心思想 Simple as the cartoon looks, its meaning behind is really so far reaching:If you desire to do something great, you have to do it from small things. 第二段原因分析或举例 The majority of people would agree that sth has caused serious problems. It is superficially a simple phenomenon, but when subjected to analysis, ithas its fundamental reasons. There stand at least two reasons, from my perspective, for the presentphenomenon. However, recognizing a problem is the first step in finding a solution.to begin with 原因一in addition 原因二in the end 原因三 第三段解决问题 第一句 1.Therefore, it is imperative for us, people in all walks, to take drasticmeasures to reverse this disturbing trend.2.If we do not desire the trend to become a reality in the future, positive stepsmust be taken to put an end to sth right now.3.My suggestion, to put an end to the negative situation, are the followingsteps.4.The most important thing, confronted the current situation, is not to say, butinstead to do. 第二、三句话具体措施 for one thing / for another;on one hand / on the other hand;措施一父母采取措施Parents are supposed to spend more time educating their kids to do sth.Eg. to do little things well.措施二Awareness about sth could be cultivated to make ourselves lead a healthy andfavorable life.Eg. doing current things 第四句 1) Only by taking these action can people have a more brilliant and gloriousfuture.2) So shouldn’t human beings pay much attention to the meaningfulsaying/problem?3) So under no account could people divert attention from the issue of sth.4) The more actively people face the saying/issue, the more happily they willlead their life （3）论述类这类文章是论述自己的观点，跟第一类警句文章雷同，所以不再赘述. 举例：信息大爆炸是件好事吗？国企 or 外企国内读大学 or 国外读大学工作 or 考研就业 or 创业 （4）书信类举例：求职信1.大学快要毕业了，需要找工作，写一封求职信说明申请工作的原因和自己能胜任的理由2.推荐一个旅游景点 称呼文中已给出便照写.文中未给出：dear sir or madam /dear Mr. president/ professor/ editor 第一段:自我介绍+写作目的自我介绍：I am senior from the department of in university.写作目的：I am, to be frank, writing the letter in order to…(文中一定给出） 第二段:按文中要求来写比如推荐旅游景点There, to begin with, are so many beautiful flowers and trees on campus. You,undoubtedly, will enjoy it.In addition, the university is quite famous among Chinese for it has a historyabout 100 years long.Consequently, a sports meeting is held there and you could think about takingpart in it and make some new friends with some foreigners. 第三段a. 文中已经做出要求一句话来写文中要求的内容第二句话表示感谢或期待回信b. 未给出要求，则是：表示感谢+ 期待回信表示感谢：A. My thanks to you for your generous assistance are beyond words.B. Words fail me when I desire to express my sincere gratitude to you for yourkind consideration my requirement/application/complaint.C. I take the opportunity to show my heartfelt appreciation for your generousassistance you rendered me.17期待回信：A I am looking forward to your reply.B I look forward to a favorable reply at your earliest convenience.C Your prompt attention to my ……. would be highly appreciated.落款yours truly,Liming 我的警句类模板It is in the topic about… that there remains an growing interest in our contemporary society. (两句话解释警句) the meaning of the saying seems that…,which is distinctly beyond dispute. That is to say,… Adequately as immense amounts of cases can sustain my standpoint, the following one, from my perspective,is most favorable.（之后举一个详细的例子）【我（我叔叔）有一个善良热情（责任感强、有耐心）的朋友（邻居）xxx,他怎么怎么样 要切题】。 Therefore, it is indeed high time that due attention cannot have failed to paid to the issue.（国家政府、家长老师、个人三方面措施）First of all,(措施1).In addition,(措施2).What’s more,(措施3). The more actively private individuals confront the issue, the more happily they will lead their life. 我的图画类模板图表类 It seems beyond dispute that…(描述图画/表) in the vivid cartoon/chart. Simple as the cartoon looks, its meaning behind is really so far reaching.(点出背后的寓意或问题) Superficially as the phenomenon is, it has its fundamental reasons when subjected to analysis. There stand at least three reasons, from my perspective, for the present phenomenon. First of all,(原因1).In addition,( 原因2).What’s more,( 原因3). Therefore, it is indeed high time that due attention cannot have failed to paid to the issue. (若字数不够，加些措施).The more actively private individuals confront the issue, the more happily they will lead their life. 我的论述类模板It is in the topic about… that there remains an growing interest in our contemporary society. some people think that(观点1).whereas others argue that(观点2). As far as I am concerned, I agree with the opinion that(自己的观点).…which is distinctly beyond dispute. /in the general routine of everyday living. Adequately as immense amounts of cases can sustain my standpoint, the following one, from my perspective,is most favorable.（之后举一个详细的例子）【我（我叔叔）有一个善良热情（责任感强、有耐心）的朋友（邻居）xxx,他怎么怎么样 要切题】。 或者说明原因 Superficially(tough) as the phenomenon(choose) is, it has its fundamental reasons when subjected to analysis(inclined to sth). There stand at least three reasons, from my perspective, for the present phenomenon. First of all,(原因1).In addition,( 原因2).What’s more,( 原因3). Therefore, it is indeed high time that due attention cannot have failed to paid to the issue.（国家政府、家长老师、个人三方面措施）First of all,(措施1).In addition,(措施2).What’s more,(措施3). The more actively private individuals confront the issue, the more happily they will lead their life. 我的书信类模板Dear sir ​ I am student from the department of…. I am, to be frank, writing the letter in order to…(文中一定给出） 中间尽量和前面的模板挂钩 Words fail me when I desire to express my sincere gratitude to you for your kind consideration my requirement/application/complaint. I look forward to a favorable reply at your earliest convenience. yours truly, XXX 翻译①以意群为单位读句子， 确定句子时态②确定句子的主干、从而确定句型和语态③先翻译主干，非主干部分通过定语、状语、同位语的方式呈现④注意句子间的逻辑关系，加逻辑关系词 英语多被动 多长句 将汉语的短句改成长句方法如下: （1）非谓语动词谁的意思最重要,谁做谓语.其他动词做非谓语 （2）从句 （3）连词 综合举例 选词填空 传统阅读10min一篇 先读第一段及第二段的首句,了解文章中心(小于2min) 然后”出题顺序与行文顺序一致” 带着问题找答案,直接定位. 题型分类: 主旨题(和传统的主旨题不一样) :无论题干问什么 四个选项中当中和文章中心最接近的选项为正确答案,这题即为主旨题. 细节题 :除主旨题以外都是细节题 [定位句(关键词(时间地点人名)\ 顺序)+前后句] 细节题的正确答案一定来自文中的某句话(大概率是匹配字数最多). 长篇阅读15min (1)看大标题与小标题(了解文章中心 推测大概内容以及作者态度) (2)题的定位词 (3)如上词都没有,则常用动词 adj adv (4)文章中心词不能拿来定位 (5)重叠选项,得出答案(注意找出明显定位词后,阅读一下该句意思是否和题干一致) (6)有时间的话查漏补缺 . 听力 主旨题: 选项多为n \ 动名词 \ 概括性的词 数字题: 涉及到时间\金钱\数量 大部分即听即得,有时候要算. 观点态度题: 细节题:所听即所得 一定要预读 寻找中心词，推测文章大概内容 纵横对比，猜题目问题]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动化脚本]]></title>
    <url>%2Farticle%2F1fbb7b95%2F</url>
    <content type="text"><![CDATA[自动开关机设置12345::在1800s（即30分钟）后自动关机::shutdown -s -t 1800shutdown -s -t 10800::取消自动关机shutdown -a AutoXue123456::连接夜神模拟器adb connect 127.0.0.1:62001::开始自动运行e:cd E:\AutoXue-masterpython -m xuexi technologyXue123456::连接mumu模拟器adb connect 127.0.0.1:7555::开始自动运行e:cd E:\technologyPower-masterpython adb.py 完整版1234567891011121314151617181920212223242526::打开appium、夜神模拟器e:cd E:\AutoXuepython startAppiumAndNox.py::连接夜神模拟器adb connect 127.0.0.1:62001::挑战答题cd E:\AutoXue\2python -m xuexi::视听学习cd E:\AutoXue\3python videoArticle.py::打开appium、夜神模拟器::start /d "C:\Program Files\Appium\" Appium.exe::start /d "D:\Nox\bin\" Nox.exe::视听学习::E:::cd E:\AutoXue\4::python startApp.py::python adb.py cmd 运行Anaconda环境示例1234#这句话是关键，调用Anaconda环境CALL D:\Anaconda3\Scripts\activate.bat D:\Anaconda3#在指定虚拟环境内运行python程序activate generalPython &amp;&amp; D: &amp;&amp; cd D:\PyCharm Community Edition 2019.3.4\workspace\clockIN\ &amp;&amp; python signIN.py &amp;&amp;pause UnblockNeteaseMusic12::-p 后面是端口号node E:\UnblockNeteaseMusic\app.js -p 80 win10定时任务https://blog.csdn.net/weixin_41712808/article/details/81567328 excel成绩表中自动将等级转换为分数12345678910111213141516171819202122232425262728293031323334353637383940414243Private Sub Worksheet_BeforeDoubleClick(ByVal Target As Range, Cancel As Boolean) StdGradeColumn = 1 'standard中的等级列 StdScoreColumn = 2 'standard中的等级对应的分数列 GradeNumber = 5 'standard中的等级个数，自己可以任意设置多个等级 TotalNum = 86 '学生总数 StartNum = 2 '开始行号 For i = StartNum To TotalNum + StartNum - 1 GradeColumn = 2 '等级列 ScoreColumn = 7 '分数列，这列的分数将自动计算 For k = 0 To 3 Set std = Worksheets("管理信息作业完成情况").Cells(i, GradeColumn + k) For j = 2 To GradeNumber + 1 SelectI = 1 Set Table = Worksheets("standard").Cells(j, StdGradeColumn) If StrComp(std.Value, Table.Value, 1) = 0 Then '比较文本 SelectI = j Exit For End If Next j Worksheets("管理信息作业完成情况").Cells(i, ScoreColumn + k) = Worksheets("standard").Cells(SelectI, StdScoreColumn) Next k Next i calColumn = 6 '总结果 GradeColumn = 7 '计算第7列至第10列 For i = StartNum To TotalNum + StartNum - 1 score = 0 For k = 0 To 3 score = score + Worksheets("管理信息作业完成情况").Cells(i, GradeColumn + k).Value Next k Worksheets("管理信息作业完成情况").Cells(i, calColumn) = score Next i End Sub QQ企业邮箱附件批量下载123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import poplibimport emailimport timefrom email.parser import Parserfrom email.header import decode_headerimport tracebackimport sysimport telnetlibclass c_step4_get_email: # 字符编码转换 @staticmethod def decode_str(str_in): value, charset = decode_header(str_in)[0] if charset: value = value.decode(charset) return value # 解析邮件,获取附件 @staticmethod def get_att(msg_in): # import email attachment_files = [] for part in msg_in.walk(): # 获取附件名称类型 file_name = part.get_filename() if file_name: h = email.header.Header(file_name) # 对附件名称进行解码 dh = email.header.decode_header(h) filename = dh[0][0] if dh[0][1]: # 将附件名称可读化 filename = c_step4_get_email.decode_str(str(filename, dh[0][1])) # 下载附件 data = part.get_payload(decode=True) # 在指定目录下创建文件，注意二进制文件需要用wb模式打开 att_file = open('./work/' + filename, 'wb') attachment_files.append(filename) att_file.write(data) # 保存附件 att_file.close() return attachment_files @staticmethod def run_ing(): # 如果是QQ企业邮箱则输入：登录密码 ，普通邮箱输入授权码 # POP3服务器需要对应的地址和端口号 # 输入邮件地址, 口令和POP3服务器地址: email_user = 'XXXXXX' # 此处密码是授权码,用于登录第三方邮件客户端 password = 'XXXXXX' pop3_server = 'pop.exmail.qq.com' # 连接到POP3服务器,有些邮箱服务器需要ssl加密，可以使用poplib.POP3_SSL try: telnetlib.Telnet('pop.exmail.qq.com', 995) server = poplib.POP3_SSL(pop3_server, 995, timeout=10) except: time.sleep(5) server = poplib.POP3(pop3_server, 110, timeout=10) # 身份认证: server.user(email_user) server.pass_(password) # 返回邮件数量和占用空间: print('Messages: %s. Size: %s' %server.stat()) # list()返回所有邮件的编号: resp, mails, octets = server.list() # 可以查看返回的列表类似[b'1 82923', b'2 2184', ...] print(mails) index = len(mails) # 遍历邮件 for i in range(1, index + 1): resp, lines, octets = server.retr(i) # lines存储了邮件的原始文本的每一行, # 邮件的原始文本: msg_content = b'\r\n'.join(lines).decode('utf-8') # 解析邮件: msg = Parser().parsestr(msg_content) # 获取邮件时间,格式化收件时间 print(msg.get("Date")[0:24]) date1 = time.strptime(msg.get("Date")[0:24], '%a, %d %b %Y %H:%M:%S') # 邮件时间格式转换 date2 = time.strftime("%Y%m%d", date1) # 如果收件时间在20200520之后就下载附件 if date2 &gt; '20200520': # 获取附件 c_step4_get_email.get_att(msg) server.quit() print("下载附件完成")if __name__ == '__main__': origin = sys.stdout # 在log文件里查看输出的信息 f = open('./log.txt', 'w') sys.stdout = f try: c_step4_get_email.run_ing() except Exception as e: s = traceback.format_exc() print(e) tra = traceback.print_exc() sys.stdout = origin f.close()]]></content>
  </entry>
  <entry>
    <title><![CDATA[英语口语考试笔记]]></title>
    <url>%2Farticle%2F851220dd%2F</url>
    <content type="text"><![CDATA[六级口语考试 话题六级口试从头到尾只围绕一个话题进行深度讨论 自我介绍个人基本信息（姓名、籍贯…）、教育信息（所在大学专业与年级…）、个人拓展信息（性格、兴趣爱好、特长等…）、其他信息 自我介绍模板 自我介绍补充句 填充词 高能加分句 我的自我介绍1（It is my pleasure to introduce myself. ）My name is Wang zezu.（I'm from Changsha,Hunan Province.）I am a graduate student from HunNan University,majoring in Computer Science.I am highly proficient in computer programming. In my spare time,I like listening music,especially pop music.（That's pretty much about me.Thank you very much!） 1220秒My name is Wang zezu.I am a graduate student from HunNan University,majoring in Computer Science.I am highly proficient in computer programming. In my spare time,I like listening music,especially pop music. 语音基础部分元音：气流从口腔流出不受阻碍的音 问答题话题从3个方面进行展开： （1）现象 （2）原因 （3）结论 注意事项 同意对方观点12I agree with you...You can say that again... 高级补充 不同意对方观点12I have something different to say...I may not agree with you. 高级补充 引出自己观点12In my opinionwhat I want to say is that... 询问别人的观点12what's your opinion...what do you think... 强势自信碾压句型在论述完成自己观点加上以下句型 123Am I making myself clear?Are you asking me something about...?Have I given enough information? 万能模板第一次问答模板 一句话回答+拓展 最后一部分回答模板 回答（原因、论点）-》解释说明（1-2句）-》举例说明（1-2句） Topic Sentence -&gt;Supporting Ideas&gt; Examples 拓展句型三大模型WH 句型what who when where why how I + 动词 + 名词 +With my … + During my time off / when I’m feeling happy/down/bored + at school/home…/to many foreign countries + to enrich myself/kill time/loosen up/have fun/enjoy myself/expand my horizons 个人经历拓展I remenber when I was a kid ,I did something … .I thought it was so I started to(用于衬托喜好).It made me into a _ person. opinion扩展模式12345As far as I'm concerned..I strongly support the idea that..As far as I know..Personally I think..In my view.. 卡片陈述题模板1123There are some ideas concerning(问题)Firstly,(举例1).Secondly,(举例2).Thirdly,(举例3).in a word,(总结观点). 模板2123When asked about(问题),the majority of people say that(观点1).But as for me,(自己的观点).So how to solve the problem is worth paying attention to.First of all,(措施1).In addition,(措施2).What's more,(措施3).It's high time that we did something to(解决问题). 模板3123Nowadays,people are becoming increasingly aware of the significance of(主题词).From my point of view, (陈述观点).In the first place,(分论点1).In the second place,(分论点2)Taking account of all these factors,we may draw the conclusion that(重述观点) . 模板41234Different people have different views on(谈论主题).some people think that(观点1).whereas others argue that(观点2).as far as I am concerned, I agree with the opinion that(自己的观点).For one thing,I firmly believe that(原因1).For another,(原因2).Taking all these factors into consideration,we may come to the conclusion that (自己的观点). 我的模板1234Nowadays,people are becoming increasingly aware of the significance of(主题词)/When talked about(问题),the majority of people say that(观点1).But as for me,(自己的观点)./as far as I am concerned, I agree with the opinion that(自己的观点).So how to solve the problem is worth paying attention to.First of all,(措施1).In addition,(措施2).What's more,(措施3).It's high time that we did something to(解决问题). 万能句型12__ can enhance（提升/加强） someone's___ （能力）__ can cultivate （培养/锻炼/陶冶） someone's___（能力） 1__ keeps someone posted about(知道) the lastest___ （了解最新的..） 1___is good/bad for someone's ___（发展好坏） 1___is good way to express someone's(某种情感) towards___ 1___brings someone___(名词) 1___adds spice(调味料) to someone's life. 1___ helps someone get a better picture of ..对什么有更好的认识 1___is a necessary part of life. 1___has a positive/negative influence/effect on ___. 1___can fullfill people's___ 个性化素材准备 小组讨论1 问候 ，2 陈述自己的观点， 3 问问题 hello, I am glad to do the pair work with you. anything else to say about this topic 考试话题分布 卡片问题预测大学教育 大学生活 职场工作 找工作 男女平等 退休生活 尊敬的人 学习或生活习惯 城市的发展建设 废物循环利用 应对压力 禁言 常考素材 讨论预测机器人 过度医疗 扶老人 家庭关系 高科技课堂 校园养动物 电子支付 成为领导好还是被领导好]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络总结]]></title>
    <url>%2Farticle%2F72b93d83%2F</url>
    <content type="text"><![CDATA[协议体系OSI，TCP/IP，五层协议的体系结构OSI分层 （7层）：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。 TCP/IP分层（4层）：网络接口层、网际层、运输层、应用层。 五层协议 （5层）：物理层、数据链路层、网络层、运输层、应用层。 各层协议及功能 功能 协议 设备 应用层 允许访问OSI环境的手段，提供各种应用程序接口（应用协议数据单元APDU） FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS 表示层 对数据进行翻译、加密和压缩 （表示协议数据单元PPDU） JPEG、MPEG、ASII 会话层 建立、管理和终止会话 （会话协议数据单元SPDU） NFS、SQL、NETBIOS、RPC 传输层 提供端到端的可靠报文传递和错误恢复 （段Segment） TCP、UDP、SPX 网络层 负责数据包从源到宿的传递和网际互连 （包Packet） 寻址、路由选择 IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP 路由器 数据链路层 将比特组装成帧和点到点的传递（帧Frame） 差错校验、链路管理、媒介访问控制 PPP、FR、HDLC、VLAN、MAC 网桥，交换机 物理层 通过媒介传输比特,确定机械及电气规范 （比特Bit） RJ45、CLOCK、IEEE802.3 中继器，集线器，网关 主机间通信过程 交换机、路由器、网关的概念以及用途1）交换机在计算机网络系统中，交换机是针对共享工作模式的弱点而推出的。交换机拥有一条高带宽的背部总线和内部交换矩阵。交换机的所有端口都挂接在这条背部总线上，当控制电路收到数据包以后，处理端口会查找内存中的地址对照表以确定目的MAC（网卡的硬件地址）的NIC（网卡）挂接在哪个端口上，通过内部 交换矩阵迅速将数据包传送到目的端口。目的MAC若不存在，交换机才广播到所有的端口，接收端口回应后交换机会“学习”新的地址，并把它添加入内部地址表中。 交换机工作于数据链路层。交换机内部的CPU会在每个端口成功连接时，通过ARP协议学习它的MAC地址，保存成一张 ARP表。在今后的通讯中，发往该MAC地址的数据包将仅送往其对应的端口，而不是所有的端口。因此，交换机可用于划分数据链路层广播，即冲突域；但它不能划分网络层广播，即广播域。 交换机被广泛应用于二层网络交换，俗称“二层交换机”。 交换机的种类有：二层交换机、三层交换机、四层交换机、七层交换机分别工作在OSI七层模型中的第二层、第三层、第四层和第七层，并因此而得名。 2）路由器路由器（Router）是一种计算机网络设备，提供了路由与转送两种重要机制，可以决定数据包从来源端到目的端所经过的路由路径（host到host之间的传输路径），这个过程称为路由；将路由器输入端的数据包移送至适当的路由器输出端(在路由器内部进行)，这称为转送。路由工作在OSI模型的第三层——即网络层，例如网际协议。 路由器的一个作用是连通不同的网络，另一个作用是选择信息传送的线路。 路由器与交换器的差别，路由器是属于OSI第三层的产品，交换器是OSI第二层的产品(这里特指二层交换机)。 3）网关网关（Gateway），网关顾名思义就是连接两个网络的设备，区别于路由器（由于历史的原因，许多有关TCP/IP 的文献曾经把网络层使用的路由器（Router）称为网关，在今天很多局域网采用都是路由来接入网络，因此现在通常指的网关就是路由器的IP），经常在家庭中或者小型企业网络中使用，用于连接局域网和Internet。 网关也经常指把一种协议转成另一种协议的设备，比如语音网关。 在传统TCP/IP术语中，网络设备只分成两种，一种为网关（gateway），另一种为主机（host）。网关能在网络间转递数据包，但主机不能 转送数据包。在主机（又称终端系统，end system）中，数据包需经过TCP/IP四层协议处理，但是在网关（又称中介系统，intermediate system）只需要到达网际层（Internet layer），决定路径之后就可以转送。在当时，网关gateway）与路由器（router）还没有区别。 在现代网络术语中，网关（gateway）与路由器（router）的定义不同。网关（gateway）能在不同协议间移动数据，而路由器（router）是在不同网络间移动数据，相当于传统所说的IP网关（IP gateway）。 网关是连接两个网络的设备，对于语音网关来说，他可以连接PSTN网络和以太网，这就相当于VOIP，把不同电话中的模拟信号通过网关而转换成数字信号，而且加入协议再去传输。在到了接收端的时候再通过网关还原成模拟的电话信号，最后才能在电话机上听到。 对于以太网中的网关只能转发三层以上数据包，这一点和路由是一样的。而不同的是网关中并没有路由表，他只能按照预先设定的不同网段来进行转发。网关最重要的一点就是端口映射，子网内用户在外网看来只是外网的IP地址对应着不同的端口，这样看来就会保护子网内的用户。 4）网络接口卡（网卡）的功能（1）进行串行/并行转换。 （2）对数据进行缓存。 （3）在计算机的操作系统安装设备驱动程序。 （4）实现以太网协议。 5）网桥的作用网桥是一个局域网与另一个局域网之间建立连接的桥梁 计算机网络性能指标速率: 连接在网络上的主机在数字信道上传送数据位数的速率, b/s kb/s Mb/s Gb/s 吞吐量：是单位时间内通过网络的总数据量b/s Mb/s 时延：是数据（一个报文或分组，甚至比特）从网络或链路的一段传送到另一端所需要的时间。 发送时延：是从发送数据帧的第一个比特算起，到该帧的最后一个比特发送完毕所需的时间。发送时延=数据帧长度(b) /信道带宽(b/s) [信道带宽就是数据率] 传播时延：电磁波在信道中需要传播一定的距离而花费的时间。往返时延等于两倍的端到端传播时延传播时延=信道长度(m)/电磁波在信道上的传播速率(m/s) 处理时延：主机或路由器处理所收到的分组的时间。排队时延：分组在输入队列中排队等待处理，在输出队列中等待转发，就形成了排队时延。 总时延=发送时延+传播时延+处理时延+排队时延 信道利用率： TCP每发送一个窗口，需要进行等待确认信息回来，所以每发送完一个窗口，最快需要经过一个往返时延才可以发送下一个窗口（确认信息很小不考虑发送时延），所以在一个传输轮次中，包含一个发送时延和一个往返时延，而传输的数据量是一个窗口的大小（这里不考虑TCP、IP首部和帧的构成)所以最大吞吐量为一个窗口的大小除以一个传输轮次的时间 多种协议ARP 地址解析协议1：首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。 2：当源主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机IP地址，源主机MAC地址，目的主机的IP地址。 3：当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址。 4：源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。广播发送ARP请求，单播发送ARP响应。 RARP 逆地址解析协议作用是完成硬件地址到IP地址的映射，主要用于无盘工作站，因为给无盘工作站配置的IP地址不能保存。工作流程：在网络中配置一台RARP服务器，里面保存着IP地址和MAC地址的映射关系，当无盘工作站启动后，就封装一个RARP数据包，里面有其MAC地址，然后广播到网络上去，当服务器收到请求包后，就查找对应的MAC地址的IP地址装入响应报文中发回给请求者。因为需要广播请求报文，因此RARP只能用于具有广播能力的网络 ICMP协议 因特网控制报文协议它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。 TFTP协议 简单文件传输协议TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。 HTTP协议 超文本传输协议是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。 DHCP协议 动态主机配置协议是一种让系统得以连接到网络上，并获取所需要的配置参数手段。一个局域网的网络协议，使用UDP协议工作，用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。 NAT协议网络地址转换属接入广域网(WAN)技术，是一种将私有（保留）地址转化为合法IP地址的转换技术， CSMA/CD协议 带有冲突检测的载波侦听多路存取 ， 是一个无法进行双全工的协议 。 先听后发 边听边发， 冲突停发 随机重发 CSMA/CD总线网中的计算公式： 最短数据帧长(bit)/数据传输速率(Mbps)=2*(两站点间的最大距离(m)/传播速度) 信号传播时延(μs)= 两站点间的距离(m)÷信号传播速度(200m/μs)，并且：数据传输时延 (s)=数据帧长度(bit)÷数据传输速率(bps) IP地址分类A类地址：以0开头， 第一个字节范围：0~127（1.0.0.1 - 126.255.255.254）； 缺省子网掩码：255.0.0.0 B类地址：以10开头， 第一个字节范围：128~191（128.0.0.1 - 191.255.255.254）； 缺省子网掩码：255.255.0.0 C类地址：以110开头， 第一个字节范围：192~223（192.0.0.1- 223.255.255.254）； 缺省子网掩码：255.255.255.0 10.0.0.0—10.255.255.255， 172.16.0.0—172.31.255.255， 192.168.0.0—192.168.255.255。（Internet上保留地址用于内部） 网络地址：IP地址与子网掩码相与 主机地址：将掩码取反，然后与运算） 子网划分自定义子网掩码(用于划分子网) 将一个网络划分为若干子网，希望每个子网拥有不同的网络地址或子网地址。因为IＰ是有限的，实际上我们是将主机地址分为两个部分：子网网络地址、子网主机地址。形式如下： 未做子网划分的ip地址：网络地址＋主机地址做子网划分后的ip地址：网络地址＋（子网网络地址＋子网主机地址） 等分成N个子网，子网掩码往右移动logN位。 网络前缀 掩码 点分十进制的地址化成二进制记法，1的个数就是网络前缀的个数。 TCP的三次握手与四次挥手三次握手（1）server处于Listen状态，表示服务器端的某个SOCKET处于监听状态，可以接受连接了； （2）当client端socket执行connect连接时，首先发送SVN报文到server，进入SVN_SENT状态，等待server发送ACK； （3）server接受到SVN进入SVN_RCVD状态，（很短暂，一般查询不到），发送SVN+ACK给client端； （4）client端接受到server的ACK，发送ACK给server，server接收到后进入established状态，client也进入established状态。 四次挥手：（1）client发起断开连接，给server发送FIN，进入FIN_WAIT1状态，表示client想主动断开连接；（2）server接受到FIN字段后，会继续发送数据给client端，并发送ACK给client端，表明自己知道了，但是还没有准备好断开，请等我的消息；（3） 当server确定自己的数据已经发送完成，就发送FIN到client；（4）client接受到来自server的FIN，发送ACK给server端，表示可以断开连接了，再等待2ms，没有收到server端的数据后，表示可以正常断开连接。 TCP/IP补充： 最大传输单元 （MTU, IP层下面数据链路层所限定的帧格式中数据字段的最大长度，与IP数据报首部中的总长度字段有关系 ）限制了数据帧的最大长度。以太网的MTU为1500字节，最小帧为64字节。 以太网规定帧间最小间隔为9.6 微秒 ,相当于96比特时间；以太网取51.2微秒做争用期 ,相当于512比特时间. 在IP网络中 DNS（域名系统） 是负责主机IP地址与主机名称之间的转换协议，ARP（地址解析协议） 是负责IP地址与MAC地址之间的转换协议。 TCP报文 一个TCP报文段分为首部和数据两部分。首部由固定部分和选项部分组成，固定部分是20字节。TCP首部的最大长度为60。首部固定部分字段： IP数据报由首部 和数据 两部分组成。首部由固定部分和可选部分 组成。首部的固定部分有20字节。可选部分的长度变化范围为1——40字节。固定部分的字段： 字段名 位数（bit） 字段名 位数 版本 4 Ipv4 首部长度 4（表示的最大数为15个单位，一个单位表示4字节） 服务类型 8 以前很少用 总长度 16 （首部和数据部分的总长度，因此数据报的最大长度为65535字节，即64KB，但是由于链路层的MAC都有一定的最大传输单元，因此IP数据报的长度一般都不会有理论上的那么大，如果超出了MAC的最大单元就会进行分片） 标识 16 （相同的标识使得分片后的数据报片能正确的重装成原来的数据报） 标志 3 （最低位MF=1表示后面还有分片，MF=0表示这是若干个数据报片的最后一个中间位DF=0才允许分片） 片偏移 片偏移指出较长的分组在分片后，某片在原分组中的相对位置，都是8字节的偏移位置 生存时间 数据报在网络中的生存时间，指最多经过路由器的跳数 协议 8 （指出该数据报携带的数据是何种协议，以使得目的主机的IP层知道应将数据部分上交给哪个处理程序）如ICMP=1 IGMP=2 TCP=6 EGP=8 IGP=9 UDP=17 Ipv6=41 OSPF=89 首部校验和 这个部分只校验首部，不包括数据部分，计算方法：将首部划分为多个16位的部分，然后每个16位部分取反，然后计算和，再将和取反放到首部校验和。接收方收到后按同样的方法划分，取反，求和，在取反，如果结果为零，则接收，否则就丢弃 源地址 32 目的地址 32 UDP数据报 用户数据报UDP由首部和数据部分组成。首部只有8个字节，由4个字段组成，每个字段都是两个字节。 字段名 字节 字段名 字节 源端口 2 目的端口 2 长度 2 检验和 2 （检验首部和数据，加12字节的伪首部） RTT与RTORTT: 发送一个数据包到收到对应的ACK，所花费的时间 RTO: 发送数据包，启动重传定时器，重传定时器到期所花费的时间，称为RTO 对于segment的重传，重传的时间RTO设定是非常重要的，如果设置太短，可能会导致并没有丢包而重传，如果设置太长了，可能因为等待ACK而浪费掉很多时间，牺牲传输的效率。 [RFC6298] 习题内有例题 第一次RTO计算方法, 假设RTT = R SRTT = R RTTVAR = R/2 RTO = SRTT + max(G, K*RTTVAR) , K = 4 后续的RTO计算,假设当前的RTT为R’ RTTVAR = (1 - beta)RTTVAR + beta|SRTT - R’| 计算平滑RTT和真实RTT的差距，切记这个地方的SRTT是上一次的SRTT SRTT = (1 - alpha)SRTT + alphaR’ 计算平滑RTT RTO = SRTT + max(G, K*RTTVAR) alpha = 1/8 beta = 1/4 流量控制利用滑动窗口实现流量控制，如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。 TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口控测报文段（携1字节的数据），那么收到这个报文段的一方就重新设置持续计时器。 拥塞控制及其方法防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素。 拥塞控制代价：需要获得网络内部流量分布的信息。在实施拥塞控制之前，还需要在结点之间交换信息和各种命令，以便选择控制的策略和实施控制。这样就产生了额外的开销。拥塞控制还需要将一些资源分配给各个用户单独使用，使得网络资源不能更好地实现共享。 几种拥塞控制方法：慢开始(slow-start )、拥塞避免(congestion avoidance )、快重传( fastretransmit )和快恢复( fastrecovery )。 慢开始和拥塞避免发送方维持一个拥塞窗口cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。 发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 慢开始算法：当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。 每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。 另，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量（如何设置ssthresh）。慢开始门限ssthresh的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。 拥塞避免算法：让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。过程图如下： 快速重传：那就是收到3个相同的ACK。TCP在收到乱序到达包时就会立即发送ACK，TCP利用3个相同的ACK来判定数据包的丢失，此时进行快速重传，快速重传做的事情有： 把ssthresh设置为cwnd的一半 把cwnd再设置为ssthresh的值(具体实现有些为ssthresh+3) 重新进入拥塞避免阶段。 快速恢复 当收到3个重复ACK时，把ssthresh设置为cwnd的一半，把cwnd设置为ssthresh的值加3，然后重传丢失的报文段，加3的原因是因为收到3 再收到重复的ACK时，拥塞窗口增加1。 收到新的数据包的ACK时，把cwnd设置为第一步中的ssthresh的值。原因是因为该ACK确认了新的数据，说明从重复ACK时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态。 常见问题TCP和UDP的区别？ 区别 TCP UDP 1.连接 面向连接 面向非连接 2.可靠性 可靠 非可靠 3.有序性 有序 不保证有序 4.速度 慢 快 5.量级 重量级 轻量级 6.拥塞控制或流量控制 有 没有 7 面向对象 面向字节流，无记录边界 面向报文，有记录边界 8 传播方式 只能单播 可以广播或组播 9.应用场景 效率低，准确性高 效率高，准确性低 对应协议 方式 功能 端口号 FTP TCP 定义了文件传输协议 21 Telnet TCP 一种用于远程登陆的端口，用户可以以自己的身份远程连接到计算机上，可提供基于DOS模式下的通信服务。 23 SMTP TCP 邮件传送协议，用于发送邮件。 25 POP3 TCP 它是和SMTP对应，POP3用于接收邮件。 110 HTTP TCP 是从Web服务器传输超文本到本地浏览器的传送协议。 DNS UDP 用于域名解析服务，将域名地址转换为IP地址 53 SNMP UDP 简单网络管理协议，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势 161 TFTP UDP 简单文件传输协议 69 为什么TIME_WAIT状态还需要等2*MSL秒之后才能返回到CLOSED状态呢？（Max SegmentLifetime，最大分段生存期） 因为虽然双方都同意关闭连接了，而且握手的4个报文也都发送完毕，按理可以直接回到CLOSED状态（就好比从SYN_SENT状态到ESTABLISH状态那样），但是我们必须假想网络是不可靠的，你无法保证你最后发送的ACK报文一定会被对方收到，就是说对方处于LAST_ACK状态下的SOCKET可能会因为超时未收到ACK报文，而重发FIN报文，所以这个TIME_WAIT状态的作用就是用来重发可能丢失的ACK报文。 为什么TCP连接要建立三次连接？为了防止失效的连接请求又传送到主机，因而产生错误。如果使用的是两次握手建立连接，假设有这样一种场景，客户端发送了第一个请求连接并且没有丢失，只是因为在网络结点中滞留的时间太长了，由于TCP的客户端迟迟没有收到确认报文，以为服务器没有收到，此时重新向服务器发送这条报文，此后客户端和服务器经过两次握手完成连接，传输数据，然后关闭连接。此时此前滞留的那一次请求连接，网络通畅了到达了服务器，这个报文本该是失效的，但是，两次握手的机制将会让客户端和服务器再次建立连接，这将导致不必要的错误和资源的浪费。 如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。 为什么TCP断开连接要4次挥手？TCP协议是一种面向连接的、可靠的、基于字节流的传输层通信协议，是一个全双工模式： 1、当主机A确认发送完数据且知道B已经接受完了，想要关闭发送数据口（当然确认信号还是可以发），就会发FIN给主机B。 2、主机B收到A发送的FIN，表示收到了，就会发送ACK回复。 3、但这是B可能还在发送数据，没有想要关闭数据口的意思，所以FIN与ACK不是同时发送的，而是等到B数据发送完了，才会发送FIN给主机A。 4、A收到B发来的FIN，知道B的数据也发送完了，回复ACK， A等待2MSL以后，没有收到B传来的任何消息，知道B已经收到自己的ACK了，A就关闭链接，B也关闭链接了。 确保数据能够完成传输。 如果已经建立了连接，但是客户端突然出现故障了怎么办？TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。 在浏览器中输入www.baidu.com后执行的全部过程 从网络模型的角度来分析问题的，主要涉及应用层：DNS,HTTP,传输层：TCP,网络层：IP和路由选择协议：RIP,OSPF(内部网关协议),BGP(外部网关协议）和数据链路层：ARP。 1、客户端浏览器通过DNS解析到www.baidu.com的IP地址220.181.27.48，通过这个IP地址找到客户端到服务器的路径。客户端浏览器发起一个HTTP会话到220.161.27.48，然后通过TCP进行封装数据包，输入到网络层。 2、在客户端的传输层，把HTTP会话请求分成报文段，添加源和目的端口，如服务器使用80端口监听客户端的请求，客户端由系统随机选择一个端口如5000，与服务器进行交换，服务器把相应的请求返回给客户端的5000端口。然后使用IP层的IP地址查找目的端。 3、客户端的网络层主要做的是通过查找路由表确定如何到达服务器，期间可能经过多个路由器，这些都是由路由器来完成的工作，我不作过多的描述，无非就是通过查找路由表决定通过那个路径到达服务器。 4、客户端的链路层，包通过链路层发送到路由器，通过邻居协议查找给定IP地址的MAC地址，然后发送ARP请求查找目的地址，如果得到回应后就可以使用ARP的请求应答交换的IP数据包现在就可以传输了，然后发送IP数据包到达服务器的地址。 HTTP的长连接和短连接HTTP的长连接和短连接本质上是TCP长连接和短连接。HTTP属于应用层协议. 短连接:浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。 长连接:当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的 TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。 TCP短连接: client向server发起连接请求，server接到请求，然后双方建立连接。client向server发送消息，server回应client，然后一次读写就完成了，这时候双方任何一个都可以发起close操作，不过一般都是client先发起 close操作.短连接一般只会在 client/server间传递一次读写操作 TCP长连接: client向server发起连接，server接受client连接，双方建立连接。Client与server完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。 RIP使用UDP，OSPF使用IP，而BGP使用TCP。这样做有何优点？为什么RIP周期性地和临站交换路由器由信息而BGP却不这样做？答：RIP只和邻站交换信息，使用UDP无可靠保障，但开销小，可以满足RIP要求； OSPF使用可靠的洪泛法，直接使用IP，灵活、开销小； BGP需要交换整个路由表和更新信息，TCP提供可靠交付以减少带宽消耗； RIP使用不保证可靠交付的UDP，因此必须不断地（周期性地）和邻站交换信息才能使路由信息及时得到更新。但BGP使用保证可靠交付的TCP因此不需要这样做。 运输层协议与网络层协议的区别？网络层协议负责的是提供主机间的逻辑通信 运输层协议负责的是提供进程间的逻辑通信 数据链路层协议可能提供的服务？成帧、链路访问、透明传输、可靠交付、流量控制、差错检测、差错纠正、半双工和全双工。最重要的是帧定界（成帧）、透明传输以及差错检测。 静态路由和动态路由有什么区别？静态路由是由管理员手工配置的，适合比较简单的网络或需要做路由特殊控制。而动态路由则是由动态路由协议自动维护的，不需人工干预，适合比较复杂大型的网络。 路由器能够自动地建立自己的路由表，并且能够根据实际实际情况的变化适时地进行调整。动态路由机制的运作依赖路由器的两个基本功能：对路由表的维护；路由器之间适时的路由信息交换。 在Linux环境中怎么配置一条默认路由？在linux上可以用“route add default gw&lt;默认路由器 IP&gt;”命令配置一条默认路由。 习题TCP拥塞控制TCP的拥塞窗口cwnd大小与传输轮次n的关系如下所示： （1）试画出如图5-25所示的拥塞窗口与传输轮次的关系曲线。 （2）指明TCP工作在慢开始阶段的时间间隔。 （3）指明TCP工作在拥塞避免阶段的时间间隔。 （4）在第16轮次和第22轮次之后发送方是通过收到三个重复的确认还是通过超市检测到丢失了报文段？ （5）在第1轮次，第18轮次和第24轮次发送时，门限ssthresh分别被设置为多大？ （6）在第几轮次发送出第70个报文段？ （7）假定在第26轮次之后收到了三个重复的确认，因而检测出了报文段的丢失，那么拥塞窗口cwnd和门限ssthresh应设置为多大？ （4）在第16轮次和第22轮次之后发送方是通过收到三个重复的确认还是通过超时检测到丢失了报文段？ 在第16轮次是通过收到三个重复的确认（因为cwnd减少到原来的一半，继续进行拥塞避免操作）而检测到丢失了报文段，第22轮次是通过超时检测（因为cwnd重新赋值为1，继续进行慢开始操作）而检测到丢失了报文段。 （5）在第1轮次，第18轮次和第24轮次发送时，门限ssthresh分别被设置为 32 、21、13 （6）在第几轮次发送出第70个报文段？第7，因为（1+2+4+8+16+32+33）&gt; 70 （7）假定在第26轮次之后收到了三个重复的确认，因而检测出了报文段的丢失，那么拥塞窗口cwnd和门限ssthresh应设置为 8/2=4 TCP报文主机A向主机B连续发送了两个TCP报文段，其序号分别为70和100。试问： （1） 第一个报文段携带了多少个字节的数据？ （2） 主机B收到第一个报文段后发回的确认中的确认号应当是多少？ （3） 如果主机B收到第二个报文段后发回的确认中的确认号是180，试问A发送的第二个报文段中的数据有多少字节？ （4） 如果A发送的第一个报文段丢失了，但第二个报文段到达了B。B在第二个报文段到达后向A发送确认。试问这个确认号应为多少？ 解：（1）第一个报文段的数据序号是70到99，共30字节的数据。 （2）确认号应为100. （3）80字节。 （4）70 TCP超时重传假定TCP在开始建立连接时，发送方设定超时重传时间是RTO=6s。 （1）当发送方接到对方的连接确认报文段时，测量出RTT样本值为1.5s。试计算现在的RTO值。 （2）当发送方发送数据报文段并接收到确认时，测量出RTT样本值为2.5s。试计算现在的RTO值。 解：根据RFC6298 RTT(1) = 1.5s SRTT(1) = RTT(1) = 1.5s RTTVAR(1) = 1.5/2 = 0.75 RTO = 1.5 + 4*0.75 = 4.5s 所以现在RTO的值为4.5s 接着计算第二步 RTT (2) = 2.5 RTTVAR(2) = 3/4 0.75 + 1/4 |1.5 - 2.5| = 13/16 SRTT(2) = 7/8 1.5 + 1/82.5 = 1.625 RTO = 1.625 + 4 * 13/16 = 4.875 IP分片1一个UDP用户数据的数据字段为8192季节。在数据链路层要使用以太网来传送。试问应当划分为几个IP数据报片？说明每一个IP数据报字段长度和片偏移字段的值。 答：6个 数据字段的长度：前5个是1480字节，最后一个是800字节。 片偏移字段（ 片偏移就是某片在原分组的相对位置，以8个字节为偏移单位）的值分别是：0，185（1480/8），370 （2960/8），555 （4440/8），740 （5920/8）和925 （7400/8）. 因为UDP用户数据报的数据字段为8192字节，所以数据报文的长度是8192+upd首部8字节=8200。 所以第6个数据报片使8200-1480*5=800 注意：链路层具有最大传输单元MTU这个特性，它限制了数据帧的最大长度 以太网的MTU为1500字节，一般IP首部为20字节，UDP首部为8字节，数据的净荷（payload）部分预留是1500-20-8=1472字节。如果数据部分大于1472字节，就会出现分片现象。 1一个数据报长度为4000字节（固定首部长度）。现在经过一个网络传送，但此网络能够传送的最大数据长度为1500字节。试问应当划分为几个短些的数据报片？各数据报片的数据字段长度、片偏移字段和MF标志应为何数值？ 答：IP数据报固定首部长度为20字节 总长度(字节) 数据长度(字节) MF 片偏移 原始数据报 4000 3980 0 0 数据报片1 1500 1480 1 0 数据报片2 1500 1480 1 185 数据报片3 1040 1020 0 370 IP数据报1主机A发送IP数据报给主机B，途中经过了5个路由器。试问在IP数据报的发送过程中总共使用了几次ARP？ 答：6次，主机用一次，每个路由器各使用一次。 ARQ协议 假定使用连续ARQ协议中，发送窗口大小事3，而序列范围[0,15],而传输媒体保证在接收方能够按序收到分组。在某时刻，接收方，下一个期望收到序号是5. 试问： （1）在发送方的发送窗口中可能有出现的序号组合有哪几种？ （2）接收方已经发送出去的、但在网络中（即还未到达发送方）的确认分组可能有哪些？说明这些确认分组是用来确认哪些序号的分组。 路由选择1234567891011121314151617假定网络中的路由器B的路由表有如下的项目（这三列分别表示“目的网络”、“距离”和“下一跳路由器”）N1 7 AN2 2 CN6 8 FN8 4 EN9 4 F现在B收到从C发来的路由信息（这两列分别表示“目的网络”和“距离” ）：N2 4N3 8N6 4N8 3N9 5试求出路由器B更新后的路由表（详细说明每一个步骤）。 解：路由器B更新后的路由表如下： N1 7 A 无新信息，不改变 N2 5 C 相同的下一跳，更新 N3 9 C 新的项目，添加进来 N6 5 C 不同的下一跳，距离更短，更新 N8 4 E 不同的下一跳，距离一样，不改变 N9 4 F 不同的下一跳，距离更大，不改变 1234567891011121314151617181920212223242526272829设某路由器建立了如下路由表：目的网络 子网掩码 下一跳------------------------------------------------------------------128.96.39.0 255.255.255.128 接口0128.96.39.128 255.255.255.128 接口1128.96.40.0 255.255.255.128 R2192.4.153.0 255.255.255.192 R3*（默认） - R4现共收到5个分组，其目的站IP地址分别为：（1）128.96.39.10（2）128.96.40.12（3）128.96.40.151（4）192.4.153.17（5）192.4.153.90试分别计算其下一跳。 解：（1）分组的目的站IP地址为：128.96.39.10。先与子网掩码255.255.255.128相与，得128.96.39.0，可见该分组经接口0转发。 （2）分组的目的IP地址为：128.96.40.12。 ① 与子网掩码255.255.255.128相与得128.96.40.0，不等于128.96.39.0。 ② 与子网掩码255.255.255.128相与得128.96.40.0，经查路由表可知，该项分组经R2转发。 （3）分组的目的IP地址为：128.96.40.151，与子网掩码255.255.255.128相与后得128.96.40.128，与子网掩码255.255.255.192相与后得128.96.40.128，经查路由表知，该分组转发选择默认路由，经R4转发。 （4）分组的目的IP地址为：192.4.153.17。与子网掩码255.255.255.128相与后得192.4.153.0。与子网掩码255.255.255.192相与后得192.4.153.0，经查路由表知，该分组经R3转发。 （5）分组的目的IP地址为：192.4.153.90，与子网掩码255.255.255.128相与后得192.4.153.0。与子网掩码255.255.255.192相与后得192.4.153.64，经查路由表知，该分组转发选择默认路由，经R4转发。 网络前缀12以下的地址前缀中哪一个地址和2.52.90.140匹配？请说明理由。（1）0/4；（2）32/4；（3）4/6；（4）80/4 答：（1）2.52.90.140与11110000 00000000 00000000 00000000逐比特相“与”和0/4匹配 （2）2.52.90.140与11110000 00000000 00000000 00000000逐比特相“与”和32/4不匹配 （3）2.52.90.140与11110000 00000000 00000000 00000000逐比特相“与”和4/6不匹配 （4）2.52.90.140与11110000 00000000 00000000 00000000逐比特相“与”和80/4不匹配 CRC校验1生成多项式:G(X)=X4+X3+1，要求出二进制序列10110011的CRC校验码。 （1）G(X)=X4+X3+1,二进制比特串为11001;(有X的几次方，对应的2的几次方的位就是1) （2）因为校验码4位，所以10110011后面再加4个0，得到101100110000，用“模2除法”(其实就是异或)即可得出结果； 余数就是 FCS（帧校验序列 ，俗称帧尾 ） （3）CRC^101100110000得到101100110100。发送到接收端； （4）接收端收到101100110100后除以11001(以“模2除法”方式去除),余数为0则无差错； 码分多址CDMA通信1234567共有4个站进行码分多址CDMA通信。4个站的码片序列为：A：（-1 –1 –1 +1 +1 –1 +1 +1） B：（-1 –1 +1 -1 +1 +1 +1 -1）C：（-1 +1 –1 +1 +1 +1 -1 -1） D：（-1 +1 –1 –1 -1 –1 +1 -1）现收到这样的码片序列：（-1 +1 –3 +1 -1 –3 +1 +1）。问哪个站发送数据了？发送数据的站发送的1还是0？ 答：S·A=（＋1－1＋3＋1－1＋3＋1＋1）／8=1， A发送1 S·B=（＋1－1－3－1－1－3＋1－1）／8=－1， B发送0 S·C=（＋1＋1＋3＋1－1－3－1－1）／8=0， C无发送 S·D=（＋1＋1＋3－1＋1＋3＋1－1）／8=1， D发送1 数据链路层11、假定站点A和B在同一个10Mb/s以太网网段上。这两个站点之间的传播时延为225比特时间。现假定A开始发送一帧，并且在A发送结束之前B也发送一帧。如果A发送的是以太网所容许的最短的帧，那么A在检测到和B发生碰撞之前能否把自己的数据发送完毕？换言之，如果A在发送完毕之前并没有检测到碰撞，那么能否肯定A所发送的帧不会和B发送的帧发生碰撞？（提示：在计算时应当考虑到每一个以太网帧在发送到信道上时，在MAC帧前面还要增加若干字节的前同步码和帧定界符） 答： 设在t=0时A开始发送，在t=（64+8(MAC帧要加8个字节同步码和帧开始定界符)）*8=576比特时间，A应当发送完毕。t=225比特时间，B就检测出A的信号。只要B在t=224比特时间之前发送数据，A在发送完毕之前就一定检测到碰撞，就能够肯定以后也不会再发送碰撞了。如果A在发送完毕之前并没有检测到碰撞，那么就能够肯定A所发送的帧不会和B发送的帧发生碰撞（当然也不会和其他站点发生碰撞）。 12、在上题中的站点A和B在t=0时同时发送了数据帧。当t=255比特时间，A和B同时检测到发生了碰撞，并且在t=255+48=273比特时间完成了干扰信号的传输。A和B在CSMA/CD算法中选择不同的r值退避。假定A和B选择的随机数分别是rA=0和rB=1。试问A和B各在什么时间开始重传其数据帧？A重传的数据帧在什么时间到达B？A重传的数据会不会和B重传的数据再次发生碰撞？B会不会在预定的重传时间停止发送数据？ 答：t=0时，A，B开始传输数据； ​ t=225比特时间，A和B同时检测到发生碰撞； t=225+48=273比特时间，完成了干扰信号的传输； 开始各自进行退避算法： A： 因为rA=0，则A在干扰信号传输完之后立即开始侦听 t=273+225（传播时延）=498比特时间，A检测到信道开始空闲 t=498+96（帧间最小间隔）=594比特时间，A开始重传数据 —–第一问A的重传时间 t=594+225 （传播时延）=819比特时间，A重传完毕 —-第二问A重传的数据帧到达B的时间 B： 因为rB=1，则B在干扰信号传输完之后1倍的争用期，即512比特时间才开始侦听 t=273+512=785比特时间，B开始侦听 若侦听空闲，则 t=785+96（帧间最小间隔）=881比特时间，B开始重传数据 若侦听费空闲，则继续退避算法 又因为t=819比特时间的时候，A才重传数据完毕，所以B在785比特时间侦听的时候，肯定会侦听信道非空闲，即B在预定的881比特时间之前侦听到信道忙， 所以，第四问的答案：B在预定的881比特时间是停止发送数据的。 即第三问A重传的数据不会和B重传的数据再次发生碰撞。 计算机网络性能计算1通信信道带宽为1Gb／s，端到端时延为10ms。TCP的发送窗口为65535字节。试问:可能达到的最大吞吐量是多少? 信道的利用率是多少? 往返时延等于两倍的端到端传播时延，即20ms=0.02s发送时延等于窗口数据量除以带宽，即655358/10^9秒TCP每发送一个窗口，需要进行等待确认信息回来，所以每发送完一个窗口，最快需要经过一个往返时延才可以发送下一个窗口（确认信息很小不考虑发送时延），所以在一个传输轮次中，包含一个发送时延和一个往返时延，而传输的数据量是一个窗口的大小（这里不考虑TCP、IP首部和帧的构成)所以最大吞吐量为一个窗口的大小除以一个传输轮次的时间，即655358/(65535*8/10^9+0.02)=25.54Mbit/s信道利用率为25.54Mbit/s/1000Mbit/s=2.55% 参考文章计算机网络——计算机网络常见面试题总结 在浏览器中输入URL后执行的全部过程的个人总结 计算机网络考试 复习时你应该要看的几道题！ TCP-IP详解: RTT和RTO的计算方法 计算机网络学习笔记——第三章课后题答案详解 子网划分及子网掩码计算方法 子网划分详解]]></content>
      <categories>
        <category>Computer Networking</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国际交流实用英文写作]]></title>
    <url>%2Farticle%2F37c8b7ce%2F</url>
    <content type="text"><![CDATA[书信齐头式、改良齐头式、半齐头式或缩进式 Main Section 示例 邮件格式与书信类似 内容 示例 The Opening(前言) （1）直抒主要想法 （2）在第一段再次重述并阐释目的 The Body(主体) （1）讲述主要内容 （2）提供更多信息，逻辑地解释、讨论主题 The Closing(结尾) （1）展示欺骗与关心 （2）请求~~ （3）表示感谢 Skillpositive and polite negative formal(正式)（1）选择正确的词句 （2）句子结构尽量采用高级表达，如非谓语结构…]]></content>
      <categories>
        <category>English</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10【uefi+gpt】安装or删除双系统Ubuntu16.04/18.04]]></title>
    <url>%2Farticle%2Fb234d6bf%2F</url>
    <content type="text"><![CDATA[相关环境Win10【原先是legacy bios引导+mbr分区】后来重装系统后改为【uefi引导+gpt分区】 Ubuntu16.04 (考虑到稳定性，程序员永远别用最新的…) 随着时间推移 18.04也ok，操作类似 微星主板（头一回看见有可视化界面的Bios） Win10安装在SSD上，Ubuntu安装在HD上 所以这篇文章本质上是（uefi+gpt）版的win10安装双系统Ubuntu16.04，若不和本文相符，绕道… labtop备注F2 进入bois 修改后到没有选项的首页 按Esc 选 Yes 按 Enter F12 进入 boot选项界面 备份一切有关搭建的举动，备份好重要的数据，再进行操作。 查看Win10启动方式（重要，避坑）按Win图标键+X键，点命令提示符(管理员) 输入bcdedit回车，然后找path开头的行，结尾是exe的话就是Legacy，结尾是efi的话就是UEFI 方法二 ：Dos命令框运行输入命令：msinfo32 传统即为legacy ，UEFI就会显示UEFI 所以我的win10就是legacy BIOS启动方式 但是后来重装变了，UEFI的好处的不用再考虑磁盘主分区个数的问题，读取数据也加快了。 确定磁盘分区表格式（重要，避坑） 制作U盘启动盘ps: 本文最后是制作UEFI的启动盘，方法类似 （1）准备4G以上U盘一个 （2）下载软碟通（UltraISO）、Ubuntu16.04的镜像文件、以及分区助手（DiskGenius）。 ​ 链接：https://pan.baidu.com/s/1RlF49Ol9XNQf7_vwyTfIiw​ 提取码：ejh3 如果你还是要参考本文，请制作bios模式不是UEFI的启动盘。。现在大多数默认UEFI （3）按如下经验开始制作 使用UltraISO（软碟通）制作U盘启动盘完整教程 准备Ubuntu的磁盘区（1）想清楚你准备划多少G给ubuntu，因为确定之后就不要扩展/压缩卷了，因为容易将磁盘变成动态盘(有坑) （2） 采用压缩卷的方式，我划了300G（300*1024），因为后期Ubuntu要训练深度学习所以划多一些。 （3）划重点 动态磁盘转基本磁盘 因为Ubuntu不识别动态磁盘（跳坑了几天….） 可以看到上边“磁盘0”（也就是我即将放置Ubuntu的地方）为动态磁盘（绿色标识），再后续安装的过程导致识别不出该机械盘的分区情况。 解决办法： 分区助手（DiskGenius）有“动态盘转基本磁盘”的功能，但是操作之前，最好也备份数据。 进入BIOS设置U盘启动微星主板的Bios和一般的不一样，so 仅供参考 ‘设置U盘先启动“的含义是指调整Bios读取路径的优先级，先读取U盘的操作系统镜像，by the way 启动模式最好也设置成UEFI 保存后自动进入U盘选择界面 解决：efi usb device has been blocked by the current security policy问题描述：U盘装系统或者其他操作时，是因为BIOS安全策略，出现上述错误无法进入后续步骤。解决方法：按F2（Fn+F2）进入BIOS，在secure Boot 中security选择disable。解决！ 微星主板-》setting-&gt;安全启动-》禁止 不识别uefi的启动盘修改主板bios为uefi架构而不是Legacy+uefi 解决u盘启动时进入不了Ubuntu安装界面参考https://blog.csdn.net/cheneykl/article/details/79111618 需指定英伟达驱动 因为是多系统启动盘，步骤稍稍不同 window读取启动盘，修改\multiboot\ubuntu-18.04.4-desktop-amd64\grub.cfg中 123456该行ubuntu-18.04.4-desktop-amd64/ubuntu-18.04.4-desktop-amd64.iso boot=casper noprompt floppy.allowed_drive_mask=0 ignore_uuid 添加 quite splash nomodeset变更为ubuntu-18.04.4-desktop-amd64/ubuntu-18.04.4-desktop-amd64.iso boot=casper quite splash nomodeset noprompt floppy.allowed_drive_mask=0 ignore_uuid 重启即可 安装安装好后不要升级为18.04，不然你会后悔的！！！ 第一个可以不用勾 （重点）其他选项千万不要选”共存“ 之前是legacy的时候，因为U盘默认UEFI启动的，所以在ubuntu安装的时候出现了不兼容的情况，此时千万不要点”在UEFI模式下进行“，因为这样会回不去Window系统，最终可能导致两个系统都崩了。。 （重点）分区在Ubuntu磁盘划分情况，与window的分区情况大致相同。 如出现不一致或者不识别磁盘，找度娘。 看过了网络上大多数文章，才确定的分区，这一步确实很重要。 而且有很多人都说错了或者文章太老，不适合现在了。 我的分区如下（引用参考文章的，我觉得他说的比较清楚）： 1、swap交换空间（我选择的大小是16G） swap是linux的虚拟内存，具体分的空间大小因个人电脑的内存而定，2g电脑分4g，4g内存的电脑分4~6个g即可，8g电脑分8~10g即可。 大小：与电脑内存一致即可，最小不能低于电脑的一半。 新分区类型：主分区（或逻辑分区，推荐） 新分区的位置：空间起始位置 用于：交换空间 2、efi系统分区（我选择的大小是1G，你想再多点也想，该区适用于升级的） 大小：512MB，系统的引导文件都在这里。最好不要小于256MB 新分区类型：逻辑分区 新分区的位置：空间起始位置 用于：EFI系统分区 3、“/”（主要活动区） 大小：剩余的全部空间 新分区类型：逻辑分区 新分区的位置：空间起始位置 用于：Ext4日志文件系统 挂载点：/ 在安装启动引导器的设备一栏，选择efi系统分区所对应的设备。 这样分区的原因与好处： “/home”的作用是作为默认工作目录，下载的文件以及用户平时保存的工作文档都会存储在该目录下，因此应分配足够大的空间。“/usr”为所有软件的默认安装目录，因此也要分配足够大的空间。 “/usr”、“efi系统分区”、“/home”，“/usr”都是挂载在“/”下的目录。安装双系统时只建立“/”分区，则ubuntu系统的“efi系统分区”、“/home”、“/usr”都可以使用“/”的全部储存空间，这样不容易出现使用一段时间后“/home”，“/usr”存储空间不足的问题 efi系统分区包含系统引导文件，它的作用和boot引导分区一样，但是boot引导是默认grub引导的，而efi显然是UEFI引导的。不要按照那些老教程去选boot引导分区，也就是最后你的挂载点里没有“/boot”这一项，否则你就没办法UEFI启动两个系统了。 swap分区 efi分区 / 分区 引导器挂载在efi所在分区。 后续细节创建用户，用于Ubuntu登入 键盘布局（中国或美国随意） 检验点击“立即重启”后，拔出U盘 此时可能会出现直接进入window的情况，重启，在Bios出现的那瞬间按下F11（或许F12）出现Bios目录 删除（1）下载 EasyUEFI （2）在（window下）该软件下删除Ubuntu引导（打开EasyUEFI-》管理EFI启动项-》选择Ubuntu-》选择右边工具栏里的“删除”图标），之后重启电脑，此时应该默认window启动。 （3）在window磁盘管理器下删除给ubuntu的分区 重启后，再检查一下是否还存在Ubuntu引导文件 若还在，跟这篇文章来 ：彻底删除Ubuntu EFI分区及启动项 用记事本这个骚操作学到了嘿嘿~（window10更新后这个办法不可以了） &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD https://www.jianshu.com/p/893c31c4fb19 （用管理员版的PowerShell）https://www.jianshu.com/p/893c31c4fb19 （用管理员版的PowerShell） bb992a239d762f17b178aecda703ee03eda91250 疑问（1）为什么本系统里面存在win7的引导，但是并没有看见呢？ 重装了一遍系统之后就没有了，猜测这台电脑可能是从win7升上来的。 安装Ubuntu18.04后的优化 安装Window后的优化安装ext2fsd(目前不可行)Windows系统读写ext2/3/4文件系统的工具 ext2fsd是国人发起的项目，主页 http://www.ext2fsd.com/ 下载 http://sourceforge.net/projects/ext2fsd/ 安装好后启动Ext2 Volume Manager，右键你想读写的分区，选择“配置Ext2卷属性” 如果你只想读取的话，那么保留默认的“设置为只读，不可写”，否则取消。语种编码default即可，或者选择utf-8。 盘符设置根据自己需要进行选择，保存并退出。 配了盘符，一般情况下，这个时候就可以直接用系统自带的资源管理器对文件进行访问以及修改了。 最令人兴奋的是，文件读写速度基本上和NTFS没差。 修改完文件后，为了防止误操作，可以右键选择“更改装配点盘符”，删除分配的盘符，这样资源管理器就看不到了。 选择菜单，“工具与设置”&gt;“配置文件系统驱动”，还可以对驱动进行设置。 缺点:由于采用了安装系统服务的形式，首次使用后服务会随系统启动而自动开启，而且不能制作成portable形式，便携性不佳。 参考文章Typora 在 Ubuntu18.04 上面不显示 Markdown 加粗语法 ubuntu18.04配置镜像源 解决：efi usb device has been blocked by the current security policy UEFI 模式下win10安装ubuntu16.04双系统教程 UEFI+GPT双硬盘安装Win10+Ubuntu16.04双系统 windows系统安装ubuntu双系统及分区方案 win10下Ubuntu 双系统安装（解决关机卡死问题和WiFi问题） win10安装ubuntu18.04 LTS双系统 Win10+Ubuntu双系统删除Ubuntu方法解释 Win10+Ubuntu双系统删除Ubuntu方法 – UEFI Win10环境下安装Ubuntu 18.04 LTS超详教程 Ubuntu18.04(Gnome)环境，十分钟配置Mac OS主题 在Ubuntu18.04.2LTS上使用wine安装qq，微信，迅雷，百度网盘，网易云音乐等软件 Ubuntu18.04 无法安装Shadowsocks-Qt5 的解决办法 安装stardict 屏幕取词神器 双系统，Ubuntu18.04下win10磁盘只读的解决办法 Windows系统读写ext2/3/4文件系统的工具「ext2fsd」]]></content>
      <categories>
        <category>window</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重装win10并改变分区类型]]></title>
    <url>%2Farticle%2F62a72a03%2F</url>
    <content type="text"><![CDATA[重装win10并改变类型为（uefi+gpt） U盘启动盘制作网上一大堆，搜下 我已经做好了。 重启插上，调节Bios为U盘优先（具体可以看参考文章） 安装ing 到系统版本选择上图界面后，按下Shift+F10调出命令提示符，如下图。 输入diskpart命令后按回车键，进入DISKPART工具，如下图所示 输入list disk命令后按回车键，查看电脑当前可用硬盘，编号为0、1、2……如果你只有一块硬盘，则只有0号磁盘；有两 块硬盘，则还会显示1号磁盘，以此类推，如下图所示 输入select disk x（x为上述硬盘编号），选择你要进行分区操作的硬盘，如果只有一块硬盘，输入select disk 0后按回车键 即可，如下图所示。 执行clean命令清除该硬盘上的所有分区（新硬盘无需此步骤），此时会清除所有硬盘数据，如下图所示。 执行convert gpt命令将该硬盘转换成GPT分区表，如下图所示。 创建EFI分区，执行create partition efi size=512（分区大小为200MB），如下图所示。 创建MSR分区，执行create partition msr size=512（微软系统保留分区），如下图所示。 创建主分区，执行create partition primary size=xxx（具体大小根据你的要求而定，作为系统分区来说，如果有足够空间，可以留出大于100GB即102400MB的空间，命令为create partition primary size=102400，方便系统有足够周转空间），如图下所示。 这是专业版Win的序列号，可以在网上找序列号，或者后面在利用网上的软件生成。 选择自定义安装，因为我们还要将系统准确安装在SSD上 结果~~ 完成 问题找不到任何设备驱动程序请确保安装媒体包 更换U盘接口 参考文章U盘安装WIN10时显示 windows无法安装到这个磁盘 选中的磁盘采用GPT分区形式 （Legacy+MBR）转（UEFI+GPT） win10系统安装]]></content>
      <categories>
        <category>window</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[制作多系统U盘启动盘]]></title>
    <url>%2Farticle%2F48db235e%2F</url>
    <content type="text"><![CDATA[预先准备（1）16GB U盘 后来用8GB（实际上只有7.43G）的U盘同时安装window10与Ubuntu18.04刚好够，还剩1GB多。 （2）YUMI （本机选择UEFI版本0.0.1.9） 版本选择根据window的引导模式决定（命令行msinfo32查看） https://www.pendrivelinux.com/yumi-multiboot-usb-creator/ （3）Win 10 IOS(镜像) 下载 WIN10 系统镜像教程 WIN10 系统镜像网站 下载后并校验：下载完成后务必进行SHA1校验（推荐使用iHasher），与上面网站所给值核对一致后再使用。 （4）Ubuntu16.04 LST(镜像) ubuntu-16.04.6-desktop-amd64.iso Ubuntu官网 http://releases.ubuntu.com/xenial/ 制作过程除了制作多合一的系统引导盘外，YUMI 还能让你创建保留的存储空间，不至于在做成启动盘后白白浪费了 U 盘剩余的容量。 大致流程： Step1：选择 U 盘或移动硬盘的盘符 Step2：选择你要制作的 Windows 系统或者 Linux 发行版 Step3：选择对应的 ISO 镜像文件 Step4：设置要保留的存储空间 (可选) 最后，按下 「Create」即开始制作 值得注意的是，YUMI 每次只能加入一个 Windows 或 Linux 系统的引导。如果你要制作多个系统，那么就要重复执行多次该软件和上述的步骤来增加操作系统。 具体操作： （1）备份好你的U盘数据后，再格式化U盘，注意文件系统格式为FAT32 安装Window（2）启动YUMI 第一步，选择你要写入的U盘盘符，下图中是F，如果是第一次可以勾选格式，如果U盘有数据，要先备份保存（因为我们之前自己格式化了，所以这里就不需要勾选“Format F:Drive”）；第二步选择镜像的发行版，这里我想安装的是Window；第三步是选择镜像文件，然后点击“Create”按钮，等待完毕就可以了。 等待写入ing… 安装Uubuntu第4步的预设空间是创建保留的存储空间（具体看官网说明） 所以我计算了下空间（window 5G，ubuntu5G，还剩余4G刚好够），所以拉到最大~~ 接下来操作都一样~ 确认后，不需要其他操作了，直到显示下图为止。单击finish，U盘就做好了。 让我们瞅瞅引导界面 链接两篇博文重装win10并改变分区类型 win10【uefi+gpt】安装or删除双系统Ubuntu16.04 参考文章YUMI-简单实用的多系统引导U盘制作工具 如何利用YUMI制作多引导多系统USB启动盘 YUMI-一款强大的多系统引导U盘刻录软件 关于Linux的U盘安装与启动 YUMI - 简单制作 Windows 与 Linux 多系统启动盘 (免费多合一U盘制作工具)]]></content>
      <categories>
        <category>window</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刷题记录]]></title>
    <url>%2Farticle%2Ffe644ae0%2F</url>
    <content type="text"><![CDATA[CFF真题【 201909-2 】小明种苹果（续） 思路１．发生苹果掉落和疏果是两种不同的操作 发生苹果掉落（5 3） 疏果（5 -3） ２．一棵树可能出现多次苹果掉落的情况 比如：3 5 2 1(对于一棵树来说 有３个操作，原来有５个苹果，第一次掉落后还剩２个，第二次掉落后还剩１个) ３．当发生苹果掉落的苹果树的棵树大于等于３时才可能形成连续的三个苹果树 注意 a可能是10^6 所以采用long long 源代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;typedef long long ll;int main()&#123; //定义长整型 ll n; cin&gt;&gt;n; ll *appleDrop = new ll [n]; ll lostNum = 0,lostCon = 0,sum = 0; //初始化掉落苹果数组 memset(appleDrop,0,n*sizeof(appleDrop)); //输出数组初始化情况 // for(int i=0;i&lt;n;i++) cout&lt;&lt;appleDrop[i]; // cout&lt;&lt;endl; for(ll i=0;i&lt;n;i++)&#123; // 第 i 棵苹果的操作 ll number; cin &gt;&gt; number; //这颗苹果树有多少苹果 ll apple; cin &gt;&gt; apple; number--; while(number--)&#123; //疏果或重新统计 ll lost; cin &gt;&gt; lost; if(lost &lt;= 0)&#123; //疏果 apple += lost; &#125;else&#123; //重新统计 if(apple &gt; lost)&#123; apple = lost; appleDrop[i] = 1; &#125; &#125; &#125;//end of while //总数 sum += apple; //掉落数 if(appleDrop[i]) lostNum++; &#125;//end of for// 掉落苹果数组情况// for(int i=0;i&lt;n;i++) cout&lt;&lt;appleDrop[i];// cout&lt;&lt;endl; //连续三颗苹果树掉落 for(int i=1;i&lt;n-1;i++)&#123; if(appleDrop[i-1]&amp;&amp;appleDrop[i]&amp;&amp;appleDrop[i+1])&#123; lostCon++; &#125; &#125; //首尾特殊情况 if(appleDrop[n-2]&amp;&amp;appleDrop[n-1]&amp;&amp;appleDrop[0]) lostCon++; if(appleDrop[n-1]&amp;&amp;appleDrop[1]&amp;&amp;appleDrop[0]) lostCon++; cout&lt;&lt;sum&lt;&lt;" "&lt;&lt;lostNum&lt;&lt;" "&lt;&lt;lostCon; delete []appleDrop; return 0;&#125; 测试用例 44 74 -7 -12 -55 73 -8 -6 59 -45 76 -5 -10 60 -25 80 -6 -15 59 0 54 10 0 9 04 10 -2 7 02 10 04 10 -3 5 04 10 -1 8 0 33 10 2 12 10 -53 10 3 1 【201909-4】 推荐系统 思路C++常用数据结构–STL ，照搬大佬的 使用map&lt;int,set&lt;pair&lt;int,int&gt; &gt; &gt; F保存所有数据，格式为map&lt;Score,set&lt;pair&lt;Type,Commodity&gt; &gt; &gt;这样在容器内部首先会按Score排序，同一Score的先按Type排序，再按Commodity排序。使用unordered_map&lt;int,int&gt;[50]保存编号到成绩的映射，格式为unordered_map&lt;Commodity,Score&gt; G[Type]这样指定Type和Commodity可以在F中迅速定位，从F中增删商品的时间度为O(log(Score的种数) * log(该分数的物品数))。 基础知识map&lt;class T1,class T2&gt;特性：存储T1-&gt;T2映射的键值对,map先按照T1升序排序，再按T2升序排序，其中T1,T2可以是任意类（如：int、string、char或自定义类）,T1值唯一，其插入删除的时间复杂度为O(log2) unordered_map&lt;class T1,class T2&gt;特性：仅存储T1-&gt;T2映射的键值对，T1值唯一，其插入和删除的时间复杂度为O(1) 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129#include &lt;iostream&gt;#include &lt;string.h&gt;#include &lt;set&gt;#include &lt;map&gt;#include &lt;vector&gt;#include &lt;tr1/unordered_map&gt;using namespace std::tr1;using namespace std;typedef long long ll;int main()&#123; //总商品种类 n ll n; //商品类别 m int m; //操作数 ll op; //查询次数 int opAsk; //存储编号到分数的映射 ，map&lt;commodity,score&gt; g[Type] unordered_map&lt;ll,ll&gt; g[51]; unordered_map&lt;ll,ll&gt;::iterator itG; //存放商品信息 ，map&lt;score,set&lt;pair&lt;Type,Commodity&gt;&gt;&gt; map&lt;ll,set&lt;pair&lt;int,ll&gt; &gt; &gt; pro; map&lt; ll,set&lt; pair&lt;int,ll&gt; &gt; &gt;::iterator itP; //分数，编号 ll score,commodity; //种类 int type; cin&gt;&gt;m&gt;&gt;n; for(int i = 0; i &lt; n; i++)&#123; cin&gt;&gt;commodity&gt;&gt;score; for(int j = 0; j &lt; m; j++)&#123; pro[score].insert(pair&lt;int,ll&gt;(j,commodity)); g[j][commodity] = score; &#125; &#125; cin&gt;&gt;op; opAsk = 0; while(op--)&#123; int opType; cin&gt;&gt;opType; switch(opType)&#123; //添加 case 1:&#123; cin&gt;&gt;type&gt;&gt;commodity&gt;&gt;score; g[type][commodity] = score; pro[score].insert(pair&lt;int,ll&gt;(type,commodity)); break; &#125; //删除 case 2:&#123; cin&gt;&gt;type&gt;&gt;commodity; //若商品存在 则删除 if((itG = g[type].find(commodity)) != g[type].end())&#123; //找到该分数的容器 itP = pro.find(itG-&gt;second); //删除该容器内指定商品 itP-&gt;second.erase(pair&lt;int,ll&gt;(type,commodity)); //若该分数下无商品，则删除该分数的容器 if(itP-&gt;second.empty()) pro.erase(itP); //删除对应映射 g[type].erase(itG); &#125; break; &#125; //查询 case 3:&#123; opAsk++; //总数 k int k; cin&gt;&gt;k; //每类最大选出个数 ll Cout[m]; for(int i = 0; i &lt; m; i++)&#123; cin&gt;&gt;Cout[i]; &#125; //查询K类 ，不能使用set 因为set将自动排序，该题有bug //set&lt;ll&gt; queryP[51]; //每类选择的编号 vector&lt;ll&gt; queryP[51]; // 按分数由大到小选择前k个物品 for(auto it = pro.rbegin(); it != pro.rend() &amp;&amp; k&gt;0; ++it)&#123; set&lt;pair&lt;int,ll&gt; &gt;&amp;s = it -&gt; second; for(auto itS = s.begin(); itS != s.end()&amp;&amp;k&gt;0; ++itS)&#123; const pair&lt;int,ll&gt;&amp;p = *itS; if(Cout[p.first] &gt; 0)&#123; //queryP[p.first].insert(p.second),--queryCout[p.first],--k; queryP[p.first].push_back(p.second),--Cout[p.first],--k; &#125; &#125; &#125; //输出选择的所有物品 for(int j=0;j&lt;m;++j)&#123;//对所有类输出选择的物品 if(queryP[j].empty())//该类没有选中任何物品 cout&lt;&lt;-1&lt;&lt;endl; else&#123; k=0;//仅仅用于判断是否输出空格 for(auto it=queryP[j].begin();it!=queryP[j].end();++it,++k) cout&lt;&lt;(k==0?"":" ")&lt;&lt;*it; cout&lt;&lt;endl; &#125; &#125; break; &#125; &#125;// end-switch &#125;// end-while return 0;&#125; 测试用例123456789101112132 31 32 23 183 100 1 11 0 4 31 0 5 13 10 2 23 10 1 12 0 13 2 1 13 1 1 1 【 201903-1 】 小中大 注意点：涉及到四舍五入，以及小数点位数 源代码12345678910111213141516171819202122232425262728293031323334353637383940414243#include&lt;iostream&gt;#include&lt;iomanip&gt;using namespace std;typedef long long ll;int main()&#123; ll max,min; ll mid; int n; cin&gt;&gt;n; ll *arr = new ll[n]; for(int i = 0; i &lt; n; i++)&#123; cin&gt;&gt;arr[i]; &#125; max = arr[0]; min = arr[n-1]; if(min &gt; max)&#123; ll t; t = max; max= min; min = t; &#125; if(n%2 == 0)&#123; mid = arr[n/2-1] + arr[n/2]; if(mid%2 == 0)&#123; cout&lt;&lt;max&lt;&lt;" " &lt;&lt;mid/2&lt;&lt;" "&lt;&lt;min; &#125;else&#123; cout&lt;&lt;max&lt;&lt;" " &lt;&lt;fixed&lt;&lt; setprecision(1)&lt;&lt;mid*0.5&lt;&lt;" "&lt;&lt;min; &#125; &#125;else&#123; mid = arr[n/2]; cout&lt;&lt;max&lt;&lt;" " &lt;&lt;mid&lt;&lt;" "&lt;&lt;min; &#125; return 0;&#125; 测试用例123456784-2 -1 3 44-1 4 5 63-1 2 4 【 201903-2 】 二十四点 思路方法一： 中缀表达式先构建表达树，后序遍历得到后缀表达式，然后计算结果 方法二：利用一个栈和一个字符串 得到后缀表达式，然后计算结果 参考 https://blog.csdn.net/fireflylane/article/details/83017889 将中缀表达式转换为后缀表达式step1：初始化一个栈和一个后缀表达式字符串step2：从左到右依次对中缀表达式中的每个字符进行以下处理，直到表达式结束 如果字符是‘)’，将其入栈 如果字符是数字，添加到s2中 如果字符是运算符，先将栈顶优先级不低于该运算符的运算符出栈，添加到s2中，再将该运算符入栈。当‘）’在栈中是，优先级最低如果字符是‘（’，将栈顶元素出栈，添加到s2中，直到出栈的是‘）’ step3：如果表达式结束，但栈中还有元素，将所有元素出栈，添加s2中 step4：将栈s2中元素依次出栈，即得到前缀表达式 后缀表达式的计算后缀表达式没有括号，运算符的顺序即为实际运算顺序，在求值过程中，当遇到运算符时，只要取得前两个操作数就可以立即进行计算。当操作数出现时，不能立即求值，需要先保存等待运算符。对于等待中的操作数而言，后出现的先运算，所以需要一个栈辅助操作。后缀表达式的运算过程如下：step1：设置一个栈step2：从左到右对后缀表达式中的字符进行以下处理： 如果字符是数字，现将其转化为数字，然后入栈 如果字符是运算符，出栈两个值进行计算。计算结果入栈 重复以上步骤，直到后缀表达式扫描结束，栈中最后一个元素就是表达式的结果。 方法三（比较巧妙，只适合本题没有括号的情况）：提前考虑优先级 ，来源 https://blog.csdn.net/Dqmail/article/details/89318208 首先遍历表达式数组，当遇到x / 时 计算结果，例如 +AxB 算为 +0+（AxB）即： 原来的符号变成上一个符号,A位置变成0，B位置变成 A x B ，如果操作符在a[1],计算完后也需要改变为‘+’ ,最后再遍历一回数组依次相加减即可。 注意一点：首先是拿字符数组接收表达式，但如果直接拿字符相加减容易出问题，所以额外用整形数组保存数字。 源代码方法一： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;string str;const int maxn = 1000;int lch[maxn], rch[maxn]; char op[maxn];int nc = 0; //结点数int build_tree(char* s, int x, int y)&#123; int i, c1 = -1, c2 = -1, p = 0; int u; if(y-x == 1) //仅一个字符，建立单独结点 &#123; u = ++nc; lch[u] = rch[u] = 0; op[u] = s[x]; return u; &#125; for(i = x; i &lt; y; i++) &#123; switch(s[i]) &#123; case '(': p++; break; case ')': p--; break; case '+': case '-': if(!p) c1 = i; break; case '*': case '/': if(!p) c2 = i; break; &#125; &#125; if(c1 &lt; 0) c1 = c2; //找不到括号外的加减号，就用乘除号 if(c1 &lt; 0) return build_tree(s, x+1, y-1); //整个表达式被一对括号括起来 u = ++nc; lch[u] = build_tree(s, x, c1); rch[u] = build_tree(s, c1+1, y); op[u] = s[c1]; return u;&#125;int main()&#123; cin&gt;&gt;str; build_tree((char*)str.data(),0,str.length()); for(int i = 0; i &lt; nc; i++ ) cout&lt;&lt;lch[i]; return 0;&#125; 方法二： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107#include&lt;iostream&gt;#include &lt;string&gt;#include &lt;stack&gt;using namespace std;//定义运算符的优先级int symPriority(char a)&#123; if(a == 'x' || a == '/') return 2; if(a == '+' || a == '-') return 1; return 0;&#125;//比较运算符的优先级bool comparePriority(char a, char b)&#123; int aValue = symPriority(a), bValue = symPriority(b); if(aValue &gt;= bValue) return true; return false;&#125;int main()&#123; int n ; cin&gt;&gt;n; while(n--)&#123; //需要计算的中缀表达式 string expression; cin&gt;&gt;expression; //运算符栈，用于保存运算符 stack&lt;char&gt; opStack; //后缀表达式 string symbol; int el = expression.length(); for(int i = 0; i &lt; el; i++)&#123; //如果 （ 压入栈 if(expression[i] == '(')&#123; opStack.push(expression[i]); &#125; //数字 放入 后缀表达式 else if(expression[i] &gt;= '0' &amp;&amp; expression[i] &lt;= '9')&#123; symbol.push_back(expression[i]); &#125; // ) 弹出栈顶元素，直至出栈是的 （ else if(expression[i] == ')')&#123; while(!opStack.empty() &amp;&amp;opStack.top() != '(')&#123; symbol.push_back(opStack.top()); opStack.pop(); &#125; if(opStack.top() == '(') opStack.pop(); &#125; // 若是其他运算符 else&#123; //先将栈顶优先级不低于该运算符的运算符出栈， while(!opStack.empty() &amp;&amp; comparePriority(opStack.top(),expression[i]))&#123; symbol.push_back(opStack.top()); opStack.pop(); &#125; //再压入栈 opStack.push(expression[i]); &#125; &#125; // end of for while(!opStack.empty())&#123; symbol.push_back(opStack.top()); opStack.pop(); &#125; //cout&lt;&lt;symbol&lt;&lt;endl; /* 表达式的计算 */ int sl = symbol.length(); stack&lt;int&gt; op; for(int i = 0; i &lt; sl; i++)&#123; if( symbol[i]&gt;= '0' &amp;&amp; symbol[i] &lt;= '9')&#123; op.push( symbol[i]-'0'); &#125;else&#123; int a = op.top(); op.pop(); int b = op.top(); op.pop(); switch(symbol[i])&#123; case '+': b+=a;op.push(b);break; case '-': b-=a;op.push(b);break; case 'x': b*=a;op.push(b);break; case '/': b/=a;op.push(b);break; &#125; &#125; &#125; // cout&lt;&lt;op.top()&lt;&lt;endl; //判断是否等于24点 if(op.top() == 24)&#123; cout&lt;&lt;"Yes"&lt;&lt;endl; &#125;else&#123; cout&lt;&lt;"No"&lt;&lt;endl; &#125; &#125; return 0;&#125; 方法三： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include&lt;iostream&gt;using namespace std;int main()&#123; int n ; cin&gt;&gt;n; while(n--)&#123; //输入表达式 char a[8]; int b[7]; cin&gt;&gt;a; for(int i = 0; i &lt; 8; i+=2) b[i] = a[i]-'0'; for(int i = 1; i &lt; 7; i+=2)&#123; //遍历一遍 x / if(a[i] == 'x')&#123; b[i+1] *= b[i-1]; b[i-1] = 0; if(i == 3 || i == 5 ) a[i] = a[i-2]; if(i == 1) a[i] = '+'; &#125; if(a[i] == '/')&#123; b[i+1] = b[i-1] / b[i+1]; b[i-1] = 0; if(i == 3 || i == 5 ) a[i] = a[i-2]; if(i == 1) a[i] = '+'; &#125; &#125; int sum = b[0]; //此时表达式只有+-，依次计算 for(int i = 1; i &lt; 7; i+=2)&#123; if(a[i] == '+')&#123; sum += b[i+1] ; &#125; if(a[i] == '-')&#123; sum -= b[i+1] ; &#125; &#125; //判断是否等于24点 if(sum == 24)&#123; cout&lt;&lt;"Yes"&lt;&lt;endl; &#125;else&#123; cout&lt;&lt;"No"&lt;&lt;endl; &#125; &#125;// end of n return 0;&#125; 测试用例1234567891011109+3+4x35+4x5x57-9-9+85x6/5x43+5+7+91x1+9-91x9-5/98/5+6x96x7-3x66x4+4/5 【 201812-2 】 小明放学题目背景 汉东省政法大学附属中学所在的光明区最近实施了名为“智慧光明”的智慧城市项目。具体到交通领域，通过“智慧光明”终端，可以看到光明区所有红绿灯此时此刻的状态。小明的学校也安装了“智慧光明”终端，小明想利用这个终端给出的信息，估算自己放学回到家的时间。 问题描述 一次放学的时候，小明已经规划好了自己回家的路线，并且能够预测经过各个路段的时间。同时，小明通过学校里安装的“智慧光明”终端，看到了出发时刻路上经过的所有红绿灯的指示状态。请帮忙计算小明此次回家所需要的时间。 输入格式 输入的第一行包含空格分隔的三个正整数 r、y、g，表示红绿灯的设置。这三个数均不超过 106。 输入的第二行包含一个正整数 n，表示小明总共经过的道路段数和路过的红绿灯数目。 接下来的 n 行，每行包含空格分隔的两个整数 k、t。k=0 表示经过了一段道路，将会耗时 t 秒，此处 t 不超过 106；k=1、2、3 时，分别表示出发时刻，此处的红绿灯状态是红灯、黄灯、绿灯，且倒计时显示牌上显示的数字是 t，此处 t 分别不会超过 r、y、g。 输出格式 输出一个数字，表示此次小明放学回家所用的时间。 样例输入 30 3 30 8 0 10 1 5 0 11 2 2 0 6 0 3 3 10 0 3 样例输出 46 样例说明 小明先经过第一段路，用时 10 秒。第一盏红绿灯出发时是红灯，还剩 5 秒；小明到达路口时，这个红绿灯已经变为绿灯，不用等待直接通过。接下来经过第二段路，用时 11 秒。第二盏红绿灯出发时是黄灯，还剩两秒；小明到达路口时，这个红绿灯已经变为红灯，还剩 11 秒。接下来经过第三、第四段路，用时 9 秒。第三盏红绿灯出发时是绿灯，还剩 10 秒；小明到达路口时，这个红绿灯已经变为红灯，还剩两秒。接下来经过最后一段路，用时 3 秒。共计 10+11+11+9+2+3 = 46 秒。 评测用例规模与约定 有些测试点具有特殊的性质： 前 2 个测试点中不存在任何信号灯。 测试点的输入数据规模： 前 6 个测试点保证 n ≤ 103。 * 所有测试点保证 n ≤ 105。 数据小于10^6次方，可以使用int，但是累加的话会出现数据溢出，所以还是使用long long 比较好 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#include &lt;iostream&gt;using namespace std;typedef long long ll;int main()&#123; ll r,y,g; int n; ll sum = 0; cin&gt;&gt;r&gt;&gt;y&gt;&gt;g; cin&gt;&gt;n; while(n--)&#123; ll k,t,k2,t2; cin&gt;&gt;k&gt;&gt;t; switch(k)&#123; case 0: k2 = k; t2 = t; break; //红灯 case 1: if(sum &lt; t)&#123; k2 = 1; t2 = t - sum; &#125;else if(sum&gt;t &amp;&amp; sum&lt;t+g)&#123; k2 = 3; &#125;else&#123; int x = (sum-t-g) % (r+y+g); if(x&lt;y)&#123; k2 = 2; t2 = y-x; &#125;else if(x&gt;y &amp;&amp; x&lt; (y+r))&#123; k2 = 1; t2 = y+r-x; &#125;else&#123; k2 = 3; &#125; &#125; break; //黄灯 case 2: if(sum &lt; (t+r))&#123; k2 = 1; t2 = (t+r) - sum; &#125;else if(sum &gt; (t+r) &amp;&amp; sum &lt; (t+r+g))&#123; k2 = 3; &#125;else&#123; int x = (sum-t-r-g) % (r+y+g); if(x&lt;y)&#123; k2 = 2; t2 = y-x; &#125;else if(x&gt;y &amp;&amp; x&lt; (y+r))&#123; k2 = 1; t2 = y+r-x; &#125;else&#123; k2 = 3; &#125; &#125; break; //绿灯 case 3: if(sum &lt; t || sum == t)&#123; k2 = 3; &#125;else&#123; int x = (sum-t) % (r+y+g); if(x&lt;y)&#123; k2 = 2; t2 = y-x; &#125;else if(x&gt;y &amp;&amp; x&lt; (y+r))&#123; k2 = 1; t2 = y+r-x; &#125;else&#123; k2 = 3; &#125; &#125; break; &#125; switch(k2)&#123; case 0: sum += t2; break; case 1: sum += t2; break; case 2: sum += (t2+r); break; case 3: break; &#125; &#125; cout&lt;&lt;sum; return 0;&#125; 【201803-2】碰撞的小球问题描述 数轴上有一条长度为L（L为偶数)的线段，左端点在原点，右端点在坐标L处。有n个不计体积的小球在线段上，开始时所有的小球都处在偶数坐标上，速度方向向右，速度大小为1单位长度每秒。 当小球到达线段的端点（左端点或右端点）的时候，会立即向相反的方向移动，速度大小仍然为原来大小。 当两个小球撞到一起的时候，两个小球会分别向与自己原来移动的方向相反的方向，以原来的速度大小继续移动。 现在，告诉你线段的长度L，小球数量n，以及n个小球的初始位置，请你计算t秒之后，各个小球的位置。 提示 因为所有小球的初始位置都为偶数，而且线段的长度为偶数，可以证明，不会有三个小球同时相撞，小球到达线段端点以及小球之间的碰撞时刻均为整数。 同时也可以证明两个小球发生碰撞的位置一定是整数（但不一定是偶数）。 输入格式 输入的第一行包含三个整数n, L, t，用空格分隔，分别表示小球的个数、线段长度和你需要计算t秒之后小球的位置。 第二行包含n个整数a1, a2, …, an，用空格分隔，表示初始时刻n个小球的位置。 输出格式 输出一行包含n个整数，用空格分隔，第i个整数代表初始时刻位于ai的小球，在t秒之后的位置。 样例输入 3 10 5 4 6 8 样例输出 7 9 9 注意点碰撞之后转向，还要动。 两边都是墙壁。 源代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;iostream&gt;using namespace std;typedef struct node&#123; int number; bool ori = 1; bool noCrush = 1;&#125;node;int main()&#123; int n,l,t; cin&gt;&gt;n&gt;&gt;l&gt;&gt;t; node *a = new node[n]; for(int i = 0; i &lt; n; i++)&#123; cin&gt;&gt;a[i].number; &#125; while(t--)&#123; for(int i = 0; i &lt; n; i++)&#123; //撞到墙壁 if(a[i].number == l)&#123; a[i].ori = 0; &#125;else if(a[i].number == 0)&#123; a[i].ori = 1; &#125;else&#123; //撞到其他小球 if(a[i].noCrush)&#123; for(int j = 0; j &lt; n; j++)&#123; if(i != j &amp;&amp; a[i].number == a[j].number)&#123; a[i].noCrush = 0; a[j].noCrush = 0; break; &#125; &#125;// end of j &#125; &#125; if(!a[i].noCrush)&#123; a[i].ori = !a[i].ori; a[i].noCrush = 1; &#125; if(a[i].ori) a[i].number++; else a[i].number--; &#125;// end of i &#125; for(int i = 0; i &lt; n; i++) cout&lt;&lt;a[i].number&lt;&lt;" "; delete []a; return 0;&#125; 【201803-3】 URL映射问题描述 URL 映射是诸如 Django、Ruby on Rails 等网页框架 (web frameworks) 的一个重要组件。对于从浏览器发来的 HTTP 请求，URL 映射模块会解析请求中的 URL 地址，并将其分派给相应的处理代码。现在，请你来实现一个简单的 URL 映射功能。 本题中 URL 映射功能的配置由若干条 URL 映射规则组成。当一个请求到达时，URL 映射功能会将请求中的 URL 地址按照配置的先后顺序逐一与这些规则进行匹配。当遇到第一条完全匹配的规则时，匹配成功，得到匹配的规则以及匹配的参数。若不能匹配任何一条规则，则匹配失败。 本题输入的 URL 地址是以斜杠 / 作为分隔符的路径，保证以斜杠开头。其他合法字符还包括大小写英文字母、阿拉伯数字、减号 -、下划线 _ 和小数点 .。例如，/person/123/ 是一个合法的 URL 地址，而 /person/123? 则不合法（存在不合法的字符问号 ?）。另外，英文字母区分大小写，因此 /case/ 和 /CAse/ 是不同的 URL 地址。 对于 URL 映射规则，同样是以斜杠开始。除了可以是正常的 URL 地址外，还可以包含参数，有以下 3 种： 字符串 ：用于匹配一段字符串，注意字符串里不能包含斜杠。例如，abcde0123。 整数 ：用于匹配一个不带符号的整数，全部由阿拉伯数字组成。例如，01234。 路径 ：用于匹配一段字符串，字符串可以包含斜杠。例如，abcd/0123/。 以上 3 种参数都必须匹配非空的字符串。简便起见，题目规定规则中 和 前面一定是斜杠，后面要么是斜杠，要么是规则的结束（也就是该参数是规则的最后一部分）。而 的前面一定是斜杠，后面一定是规则的结束。无论是 URL 地址还是规则，都不会出现连续的斜杠。 输入格式 输入第一行是两个正整数 n 和 m，分别表示 URL 映射的规则条数和待处理的 URL 地址个数，中间用一个空格字符分隔。 第 2 行至第 n+1 行按匹配的先后顺序描述 URL 映射规则的配置信息。第 i+1 行包含两个字符串 pi 和 ri，其中 pi 表示 URL 匹配的规则，ri 表示这条 URL 匹配的名字。两个字符串都非空，且不包含空格字符，两者中间用一个空格字符分隔。 第 n+2 行至第 n+m+1 行描述待处理的 URL 地址。第 n+1+i 行包含一个字符串 qi，表示待处理的 URL 地址，字符串中不包含空格字符。 输出格式 输入共 m 行，第 i 行表示 qi 的匹配结果。如果匹配成功，设匹配了规则 pj ，则输出对应的 rj。同时，如果规则中有参数，则在同一行内依次输出匹配后的参数。注意整数参数输出时要把前导零去掉。相邻两项之间用一个空格字符分隔。如果匹配失败，则输出 404。 样例输入 5 4 /articles/2003/ special_case_2003 /articles// year_archive /articles/// month_archive /articles//// article_detail /static/ static_serve /articles/2004/ /articles/1985/09/aloha/ /articles/hello/ /static/js/jquery.js 样例输出 year_archive 2004 article_detail 1985 9 aloha 404 static_serve js/jquery.js 样例说明 对于第 1 个地址 /articles/2004/，无法匹配第 1 条规则，可以匹配第 2 条规则，参数为 2004。 对于第 2 个地址 /articles/1985/09/aloha/，只能匹配第 4 条规则，参数依次为 1985、9（已经去掉前导零）和 aloha。 对于第 3 个地址 /articles/hello/，无法匹配任何一条规则。 对于第 4 个地址 /static/js/jquery.js，可以匹配最后一条规则，参数为 js/jquery.js。 数据规模和约定 1 ≤ n ≤ 100，1 ≤ m ≤ 100。 所有输入行的长度不超过 100 个字符（不包含换行符）。 保证输入的规则都是合法的。 思路一组string的vector存放数据，用“/”分割每条语句。 依次拿规则来匹配url,别弄反了不然思路会有点乱，尤其是&lt; path &gt;规则。 注意事项有：规则的字符串分组必须与url的一样，即在&lt; path &gt;规则中 url后所有字符串为一个整体。还有前导零的去除 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;ctype.h&gt;using namespace std;typedef struct rule&#123; vector&lt;string&gt; p; string r; bool endflag;&#125;rule;void split(vector&lt;string&gt; &amp;v, char *s)&#123; char *sp = strtok(s,"/"); while(sp)&#123; v.push_back(sp); //strtok()是非线程安全的 sp = strtok(NULL,"/"); &#125;&#125;//字符串全是数字bool isint(string s)&#123; for(int i = 0; i &lt; s.length(); i++)&#123; if(!isdigit(s[i])) &#123; return false; &#125; &#125; return true;&#125;//合法字符串bool isLegal(string s)&#123; for(int i = 0; i &lt; s.length(); i++)&#123; if(isdigit(s[i]) || isalpha(s[i]) || s[i]=='/'|| s[i]=='-'|| s[i]=='.'|| s[i]=='_')&#123; continue; &#125;else &#123; return false; &#125; &#125; return true;&#125;int main()&#123; int n,m; cin&gt;&gt;n&gt;&gt;m; rule *a = new rule[n]; for(int i = 0; i &lt; n; i++)&#123; string str; //读取换行符，并舍弃 getline(cin,str,' '); str = str.substr(1); a[i].endflag = (str[str.length()-1] =='/')?0:1; //cout&lt;&lt;"ru last: "&lt;&lt;str[str.length()-1]&lt;&lt;endl; split(a[i].p,(char *)str.data()); cin&gt;&gt;a[i].r; &#125; for(int i = 0; i &lt; m; i++)&#123; string str; vector&lt;string&gt; url; vector&lt;string&gt; ans; //结尾中是否有/ bool flag; //是否存在path //bool pathflag = 0; //分离字符串 cin&gt;&gt;str; flag = (str[str.length()-1] =='/')?0:1; //cout&lt;&lt;"url last: "&lt;&lt;str[str.length()-1]&lt;&lt;endl; split(url,(char *)str.data()); //寻找匹配规则 int j; for(j = 0; j &lt; n; j++)&#123; int ui = 0,pi = 0; int ul = url.size(); int pl = a[j].p.size(); bool match = 1; ans.clear(); while(match &amp;&amp; ui &lt; ul &amp;&amp; pi &lt; pl )&#123; if(!isLegal(url[ui]))&#123; match = 0; ans.clear(); break; &#125; if(a[j].p[pi] == "&lt;int&gt;")&#123; if(isint(url[ui]))&#123; int w; //去除前导零 for(w=0;w&lt;url[ui].size()-1&amp;&amp;url[ui][w]=='0';w++); ans.push_back(url[ui].substr(w)); ui++;pi++; &#125;else&#123; match = 0; &#125; &#125;else if(a[j].p[pi] == "&lt;path&gt;")&#123; if(flag&amp;&amp;a[j].endflag)&#123; //将后面的字符串看作一个整体 string ts; while(ui&lt;ul) ts = ts+"/"+url[ui++]; ans.push_back(ts.substr(1)); pi++; /*pathflag = 1; while(pathflag)&#123; ans.push_back(url[ui]); ui++;pi++; if(ui &lt; ul)&#123; ans.push_back("/"); &#125; else break; &#125;*/ break; &#125;else&#123; match = 0; &#125; &#125;else if(a[j].p[pi] == "&lt;str&gt;" )&#123; ans.push_back(url[ui]); ui++;pi++; &#125; else if(a[j].p[pi] == url[ui])&#123; ui++;pi++; &#125; else&#123; match = 0; &#125; &#125;//// end of match //cout&lt;&lt;flag&lt;&lt;" "&lt;&lt;a[i].endflag; if(match &amp;&amp; (ui == ul) &amp;&amp; (pi == pl)&amp;&amp; (flag==a[j].endflag))&#123; break; break; &#125;else&#123; ans.clear(); &#125; &#125;// end of j if(j != n)&#123; cout&lt;&lt;a[j].r; for(int ansi = 0; ansi &lt; ans.size();ansi++)&#123; cout&lt;&lt;" "&lt;&lt;ans[ansi]; /*if(!pathflag)&#123; if(ansi &lt; ans.size()-1)&#123; cout&lt;&lt;" "; &#125; &#125;*/ &#125; &#125;else&#123; cout&lt;&lt;"404"; &#125; if(i != m-1) cout&lt;&lt;endl; &#125;// end of i delete [] a; return 0;&#125; 测试用例12345678910115 10/articles/2003/ special_case_2003/articles/&lt;int&gt;/&lt;int&gt;/&lt;str&gt;/ article_detail/articles/&lt;str&gt;/&lt;int&gt;/&lt;str&gt;/ le_detail/static/&lt;path&gt; static_serve/&lt;str&gt;/&lt;path&gt; serve/articles/2004/articles/2004//static/js/jquery.js/static/js/articles/1985/09/aloha/ 过程太艰难了。 他人满分代码出处 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118#include&lt;iostream&gt;#include&lt;cstring&gt;#include&lt;string&gt;#include&lt;vector&gt; using namespace std; const int N=105; struct Rule&#123; vector&lt;string&gt;p;//URL匹配的规则 string r;//URL 匹配的名字 bool flag;//标记规则最后是否有"/" &#125;a[N]; //字符串分割函数，将字符串s用"/"分割，并存放于向量v中 void split(vector&lt;string&gt; &amp;v,char *s)&#123; char *sp=strtok(s,"/"); while(sp) &#123; v.push_back(sp); sp=strtok(NULL,"/"); &#125;&#125; //判断字符串s是否都是数字 bool isNum(string s)&#123; for(int i=0;i&lt;s.length();i++) if(!isdigit(s[i])) return false; return true;&#125; int n,m;//规则和查询的条数 //处理URL地址，flag标记此URL地址最后是否有"/" void solve(vector&lt;string&gt;URL,bool flag)&#123; int i; vector&lt;string&gt;ans;//存放参数 for(i=0;i&lt;n;i++)//顺序遍历n条规则 &#123; ans.clear();//先清空 int j=0,k=0; vector&lt;string&gt;t(a[i].p); while(j&lt;t.size()&amp;&amp;k&lt;URL.size())//查看URL是否和此规则匹配 &#123; if(t[j]=="&lt;int&gt;")//情况一：&lt;int&gt; &#123; if(isNum(URL[k]))//如果都是数字 &#123; int w; for(w=0;w&lt;URL[k].size()-1&amp;&amp;URL[k][w]=='0';w++);//去前导零 ans.push_back(URL[k].substr(w)); j++,k++;//匹配下一部分 continue; &#125; &#125; else if(t[j]=="&lt;str&gt;")//情况二：&lt;str&gt; &#123; ans.push_back(URL[k]);//直接记录即可 j++,k++;//匹配下一部分 continue; &#125; else if(t[j]=="&lt;path&gt;")//情况三: &lt;path&gt; &#123; string s; while(k&lt;URL.size()) s=s+"/"+URL[k++]; ans.push_back(s.substr(1));//要去除第一个"/"符号 j++; continue; &#125; else if(t[j]==URL[k]) &#123; j++,k++;//匹配下一部分 continue; &#125; break; &#125; if(j==t.size()&amp;&amp;k==URL.size()&amp;&amp;flag==a[i].flag) break;//如果匹配就跳出 &#125; if(i==n) cout&lt;&lt;"404"&lt;&lt;endl;//如果n条规则都匹配失败，则输出"404" else &#123; cout&lt;&lt;a[i].r;//输出匹配的规则的名字 for(int w=0;w&lt;ans.size();w++)//输出各个参数 cout&lt;&lt;" "&lt;&lt;ans[w]; cout&lt;&lt;endl; &#125;&#125; int main()&#123; cin&gt;&gt;n&gt;&gt;m; string rule; for(int i=0;i&lt;n;i++) &#123; char temp[120]; scanf("%s",temp); cin&gt;&gt;a[i].r; a[i].flag=(temp[strlen(temp)-1]=='/')?true:false;//记录规则的最后是否有"/" split(a[i].p,temp);//分割 &#125; for(int i=0;i&lt;m;i++) &#123; vector&lt;string&gt;URL; char temp[120]; scanf("%s",temp); bool flag=(temp[strlen(temp)-1]=='/')?true:false;//记录规则的最后是否有"/" split(URL,temp);//分割 solve(URL,flag);//判断处理 &#125; return 0;&#125; 杭电OJ大数相加源代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;void sum(char *a, char *b)&#123; int c[1000] = &#123;0&#125;, t[1000] = &#123;0&#125;; int aL = strlen(a); int bL = strlen(b); if( aL &gt;= bL )&#123; //游标 int i; //两数位数差 int x = aL - bL; for(i = bL-1; i &gt; -1 ; i--)&#123; //判断是否进位 c[i+x] = a[i+x]-'0' + b[i]-'0' + t[i+x+1]; if(c[i+x] &gt; 9)&#123; //标志前一位 需要加1（进位） t[i+x] = 1; c[i+x] -= 10; &#125; &#125; i = x-1; //a剩余位数直接赋值 for(; i &gt; -1 ; i--)&#123; c[i] = a[i]-'0' + t[i+1]; if(c[i] &gt; 9)&#123; //标志前一位 需要加1（进位） t[i] = 1; c[i] -= 10; &#125; &#125; if(t[0]==1) c[0] += 10; for(i = 0; i &lt; aL; i++) cout&lt;&lt;c[i]; // a&lt;b &#125;else&#123; sum(b,a); &#125;&#125;int main()&#123; int n,Case=0; cin&gt;&gt;n; while(n--)&#123; char a[1000]; char b[1000]; cin&gt;&gt;a&gt;&gt;b; Case++; cout&lt;&lt;"Case "&lt;&lt;Case&lt;&lt;":"&lt;&lt;endl&lt;&lt;a&lt;&lt;" + "&lt;&lt;b&lt;&lt;" = "; sum(a,b); //最后一行不需要换两行。。 if(n == 0) cout&lt;&lt;endl; else cout&lt;&lt;endl&lt;&lt;endl; &#125; return 0;&#125; 测试数据6组测试数据 699 1Case 1:99 + 1 = 100 888 744Case 2:888 + 744 = 1632 987654321987654321 987654321987654321Case 3:987654321987654321 + 987654321987654321 = 1975308643975308642 9999999999999999999 9Case 4:9999999999999999999 + 9 = 10000000000000000008 44 55Case 5:44 + 55 = 99 Case 6: 454546 4545499999999999999999999999999999 454546 + 4545499999999999999999999999999999 = 4545500000000000000000000000454545 递归转迭代（fi）源代码12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;int main()&#123; int a,b,n; while(cin&gt;&gt;a&gt;&gt;b&gt;&gt;n)&#123; if(a == 0 || b == 0 || n == 0) break; if(n == 1) cout&lt;&lt;1&lt;&lt;endl; else if(n == 2) cout&lt;&lt;1&lt;&lt;endl; else&#123; int sum1 = 1 , sum2 = 1; int sum = 0; for(int i = 3; i &lt;= n; i++)&#123; sum = (a*sum2 + b*sum1) % 7; sum1 = sum2; sum2 = sum; &#125; cout&lt;&lt;sum&lt;&lt;endl; &#125; &#125; return 0;&#125; 字符串统计12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;int main()&#123; int n; cin&gt;&gt;n; //至0结束 while(n)&#123; //记录各种颜色出现多少次 //int *Count = new int[n]; int Count[1000] = &#123;0&#125;; int index = 0; //char (*p)[20] = new char[n][20]; char p[1000][20] = &#123;&#125;; bool flag = true; for(int i=0; i&lt;n; i++)&#123; char str[20]; cin&gt;&gt;str; //计数 if(i == 0)&#123; strcpy(p[index],str); Count[index]++; index++; &#125;else&#123; int j; for(j=0; j&lt;index; j++)&#123; if(strcmp(str,p[j]) == 0)&#123; Count[j]++; flag = false; break; &#125; &#125;//end of for //没有就添加进去 if(flag)&#123; strcpy(p[index],str); Count[index]++; index++; flag = true; &#125; &#125;//end of else &#125; //找到最大值 int Cmax = Count[0],t=0; for(int i = 1; i &lt; index; i++ )&#123; if(Cmax &lt; Count[i])&#123; Cmax = Count[i]; t = i; &#125; &#125; cout&lt;&lt;p[t]&lt;&lt;endl; //释放动态空间 // for(int i = 0; i &lt; n; i++)&#123; // delete []p[i]; // &#125; // delete []p; cin&gt;&gt;n; &#125; return 0;&#125;/*// template 模板template&lt;typename T&gt;//计算数组长度int calculateLength(T &amp;arr)&#123; cout&lt;&lt;"size arr:"&lt;&lt;sizeof(arr)&lt;&lt;endl; cout&lt;&lt;"size arr[0]:"&lt;&lt;sizeof(arr[0])&lt;&lt;endl; return sizeof(arr) / sizeof(arr[0]);&#125;*/ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/* 2072 */#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string ju; string p[10001]; getline(cin,ju,'#'); int len = ju.length(); int index = 0; string letter; letter.clear(); for(int i = 0; i &lt; len; i++)&#123; if(ju[i]&gt;='a' &amp;&amp; ju[i]&lt;='z')&#123; letter.push_back(ju[i]); continue; &#125; if(!letter.empty())&#123; if(index == 0)&#123; p[index] = letter; index++; &#125;else&#123; int j; bool flag = true; for(j = 0; j &lt; index; j++)&#123; if(letter == p[j])&#123; flag = false; &#125; &#125;//end of for if(flag)&#123; p[index] = letter; index++; &#125; &#125;//end of inside if letter.clear(); &#125; &#125;// end of for cout&lt;&lt;index; return 0;&#125; 【1003】Max SumProblem Description Given a sequence a[1],a[2],a[3]……a[n], your job is to calculate the max sum of a sub-sequence. For example, given (6,-1,5,4,-7), the max sum in this sequence is 6 + (-1) + 5 + 4 = 14. Input The first line of the input contains an integer T(1&lt;=T&lt;=20) which means the number of test cases. Then T lines follow, each line starts with a number N(1&lt;=N&lt;=100000), then N integers followed(all the integers are between -1000 and 1000). Output For each test case, you should output two lines. The first line is “Case #:”, # means the number of the test case. The second line contains three integers, the Max Sum in the sequence, the start position of the sub-sequence, the end position of the sub-sequence. If there are more than one result, output the first one. Output a blank line between two cases. Sample Input 12325 6 -1 5 4 -77 0 6 -1 1 -6 7 -5 Sample Output 12345Case 1:14 1 4Case 2:7 1 6 题意给定T组序列，找到各个序列中和最大值，以及始点终点 思路采用动态规划，简化版-》当sum加上a[i]比a[i]小，则结束记录；重新开始下一段和的计算。同时更新最大值以及始点终点。 源代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;using namespace std;typedef long long ll;int all[1000000] = &#123;0&#125;;int main()&#123; int t; cin&gt;&gt;t; for(int index = 1; index &lt;= t; index++)&#123; ll n; cin&gt;&gt;n; int* a = new int[n] ; for(int i = 0; i &lt; n; i++) cin&gt;&gt;a[i]; int allMax,sum,startT,endT,f; allMax = sum = -0xfffffff; for(int i = 0; i &lt; n; i++)&#123; if((sum +a[i] &gt; a[i]) ||(sum +a[i] == a[i])) &#123; sum += a[i]; &#125;else&#123; sum = a[i]; f = i; &#125; if(sum &gt; allMax)&#123; allMax = sum; startT = f; endT = i; &#125; &#125; cout&lt;&lt;"Case " &lt;&lt;index&lt;&lt;":"&lt;&lt;endl; cout&lt;&lt;allMax&lt;&lt;" "&lt;&lt;startT+1&lt;&lt;" "&lt;&lt;endT+1&lt;&lt;endl; if(index != t)&#123; cout&lt;&lt;endl; &#125; &#125; return 0;&#125; 【1024】Max Sum Plus PlusProblem Description Now I think you have got an AC in Ignatius.L’s “Max Sum” problem. To be a brave ACMer, we always challenge ourselves to more difficult problems. Now you are faced with a more difficult problem. Given a consecutive number sequence S1, S2, S3, S4 … Sx, … Sn (1 ≤ x ≤ n ≤ 1,000,000, -32768 ≤ Sx ≤ 32767). We define a function sum(i, j) = Si + … + Sj (1 ≤ i ≤ j ≤ n). Now given an integer m (m &gt; 0), your task is to find m pairs of i and j which make sum(i1, j1) + sum(i2, j2) + sum(i3, j3) + … + sum(im, jm) maximal (ix ≤ iy ≤ jx or ix ≤ jy ≤ jx is not allowed). But I`m lazy, I don’t want to write a special-judge module, so you don’t have to output m pairs of i and j, just output the maximal summation of sum(ix, jx)(1 ≤ x ≤ m) instead. ^_^ Input Each test case will begin with two integers m and n, followed by n integers S1, S2, S3 … Sn.Process to the end of file. Output Output the maximal summation described above in one line. Sample Input 121 3 1 2 32 6 -1 4 -2 3 -2 3 Sample Output 1268 题意n个序列分m组，求出最大m个字段的序列元素和 思路源代码12]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++代码精炼]]></title>
    <url>%2Farticle%2F2fdcd6a9%2F</url>
    <content type="text"><![CDATA[前言主要以 C++为主。 输入输出文件尾类型C 版 1234567#include &lt;stdio.h&gt;int main()&#123; int a,b; while (scanf("%d %d",&amp;a, &amp;b) != EOF) printf("%d\n",a+b);&#125; C++ 版 123456#include&lt;iostream&gt;using namespace std;int main()&#123; int a,b; while(cin&gt;&gt;a&gt;&gt;b)&#123;cout&lt;&lt;a+b&lt;&lt;endl;&#125;&#125; 在C++里，cin本身就是一个对象，因此可以直接运用到while( )检测是否有输入，若无输入则结束运行。 例如： 123 while(cin&gt;&gt;a)&#123; ...&#125; 格式化输出 1printf("%d%c",bmax," \n"[i==n]); 当后面的执行条件i!=n的时候，%c就相当于空格当后面的执行条件i==n的时候，%c就相当于\n 【来源】 字符串类型(1)cin&gt;&gt; ​ 可接受字符串，但遇到“空格”、“TAB”、”回车”（下一次缓冲区读取时 会被cin自动丢弃）均结束从缓冲区读取 (2)getline() ​ 默认”回车”（下一次缓冲区读取时 会被自动丢弃）结束 123456string line;getline（cin，line）;//按回车键结束输入#指定分隔符istream&amp; getline(istream&amp; is,string&amp; str,char delimiter='\n') //输入一串字符（不管多少个回车键），只要是在‘#’号之 前的字符都会读取并保存getline（cin,line,'#'); (3)cin.get() ​ 默认”回车”（下一次缓冲区读取时 仍会被读取）结束 ​ 两种用法： ​ a. cin.get(字符变量名)可以用来接收一个字符 12char ch;ch = cin.get(); or cin.get(ch); ​ b.cin.get(字符数组名,接收字符数目)用来接收一行字符串,可以接收空格 12char a[20];cin.get(a,20); ​ 注意： cin.get()会将回车键存储在缓存中，若后面还有cin.get()函数，则该函数会将缓存中的 回车 取出并赋予后面的输入变量中，故，使用了cin.get()函数就一定后面要加getchar()，将回车键读取并丢弃弃！！！​ (4)cin.getline()​ 接受一个字符串可以接受空格并输出 1234char m[20];cin.getline(m,5);//输入：jkjkjkjkkjkjkjkj//输出：jklj 第5个字符默认添加'\0' (5)gets()【c++11已弃用！！！】​ 接受一个字符，可以接受空格并输出，需包含头文件#include&lt;string&gt; 12char ch;gets(ch); ​ (6)getchar() 需包含头文件`#include&lt;stdio.h&gt;` getchar()是stdio.h中的库函数，它的作用是从stdin流中读入一个字符，也就是说，如果stdin有数据的话不用输入它就可以直接读取了，第一次getchar()时，确实需要人工的输入，但是如果你输了多个字符，以后的getchar()再执行时就会直接从缓冲区中读取了。​ 故一般用getchar()来清除缓存中的字符；​​ 4）输入强行退出​ Ctrl + Z 或输入EOF再按回车键 大佬解析:https://www.cnblogs.com/zzw1024/p/10502011.html 动态创建数组1234567891011//一维数组#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;typedef long long ll;ll *aim = new ll[n];ll *maxj = new ll[n];memset(aim,0,sizeof(aim)*n);memset(maxj,0,sizeof(maxj)*n); 为何动态创建二维数组必先预先知道二维数组每一列的长度 大佬解析过 123456789101112131415161718192021222324252627282930/* 动态创建二维数组 *///半自动化char (*color)[20] = new char[n][20]; // √char *color[20] = new char[n][20]; // × /*[] 的优先级高于 * *color[20] 为 指针数组（array of pointers），即20个 char 类型的指针(*color)[20] 为 数组指针（a pointer to an array），即 指向数组（首地址，++按列大小）的指针*/ //释放 delete [] color;//真正意义上的创建二维数组int **array;array=new int *[row];for(int i = 0; i &lt; row; i++)&#123; array[i]=new int [col]; //以0初始化，#include &lt;string.h&gt; memset(array[i],0,col*sizeof(int));&#125;//释放for (int i = 0; i &lt; row; i ++) &#123; delete[] array[i]; array[i] = NULL; //不要忘记，释放空间后p[i]不会自动指向NULL值，还将守在原处，只是释放内存而已，仅此而已。&#125;delete [] array；array=NULL; 计算数组长度1234567template&lt;typename T&gt;//计算数组长度int calculateLength(T &amp;arr)&#123; cout&lt;&lt;"size arr:"&lt;&lt;sizeof(arr)&lt;&lt;endl; cout&lt;&lt;"size arr[0]:"&lt;&lt;sizeof(arr[0])&lt;&lt;endl; return sizeof(arr) / sizeof(arr[0]);&#125; STL标准库首先使得dev 支持 C++11 使devc++拥有c++11的功能(如何让devc++支持c++11) tools-&gt;compiler options-&gt;add the following commands when calling the compiler(勾选) ，然后添加如下语句（最好release\debug都添上） 1-std=c++11 头文件 1234567//set、map属于std, unordered_map属于std::tr1;#include &lt;set&gt;#include &lt;map&gt;#include &lt;tr1/unordered_map&gt;using namespace std::tr1;using namespace std; 调试 dev 首先设置”生成调试信息“ (1)Tools -&gt; setting -&gt;linker-&gt; generate debugging information 那栏改为”Yes“ (2) tool-&gt;environment options-&gt;watch variable under mouse(勾选) 设置断点后 编译 F5 调试（勾勾） F7运行下一行 四舍五入123456789101112131415161718192021222324252627#include&lt;iomanip&gt;#include&lt;iostream&gt;using namespace std;int main()&#123;double f = 123456789;// 输出1.23457*（10,6）（采用科学记数法变成包含整数和小数，共6位，且最后一位四舍五入）cout&lt;&lt;f&lt;&lt;endl; //输出120000000 1.2*pow（10,6）采用科学记数法,包含整数和小数，共两位，且最后一位四舍五入）cout&lt;&lt;setprecision(2)&lt;&lt;f&lt;&lt;endl; cout&lt;&lt;fixed&lt;&lt;f&lt;&lt;endl; //输出12345689.000000（小数6位补0）cout&lt;&lt;setprecision(2)&lt;&lt;fixed&lt;&lt;f&lt;&lt;endl; //输出12345689.00cout&lt;&lt;fixed&lt;&lt;setprecision(2)&lt;&lt;f&lt;&lt;endl; // 效果同上double f = 3.123456789;// 输出3.12346 （包含整数和小数，且四舍五入）cout&lt;&lt;f&lt;&lt;endl; //输出3.1（包含整数和小数，共两位，且最后一位四舍五入），这条会作用到下一条去cout&lt;&lt;setprecision(2)&lt;&lt;f&lt;&lt;endl; //输出3.123457 （仅包含小数，且四舍五入），没有上一条，则输出六位小数3.123457cout&lt;&lt;fixed&lt;&lt;f&lt;&lt;endl; cout&lt;&lt;setprecision(2)&lt;&lt;fixed&lt;&lt;f&lt;&lt;endl; //输出3.12 （小数2位，四舍五入）cout&lt;&lt;fixed&lt;&lt;setprecision(2)&lt;&lt;f&lt;&lt;endl; // 效果同上 system("pause"); return 0;&#125; setprecision(n)是流格式控制符之一，在iomanip头文件中。 c++默认的流输出数值有效位是6，包括整数和小数，若数值超出6位，则第七位四舍五入到6位数 fixed ：浮点值显示为定点十进制。 默认是小数6位数，不包含整数，若小数位超出6位，则四舍五入到6位数 1.setprecision(n) 指定一个浮点数的精度默认设置输出的数字的总位数为n，包含整数和小数部分；其中setprecision（0）效果是跟c++默认的流输出数值一样，有效位是6位，包括整数和小数 2.fixed ：必须与setprecision(n)配合使用，用来控制小数位数，不够补0，只要写一次fixed，后面的setprecision（n）就都是指小数了。 fixed与setprecision谁先谁后没有关系，但通常是fixed在前先固定6位小数（若此时小数已经超出6位，则先四舍五入到6位）再precision(n)取n位小数（n&lt;6） 3.如果与setiosnags(ios::scientific)合用， 可以控制指数表示法的小数位数。setiosflags(ios::scientific)是用指数方式表示实数。 4.resetiosflags(ios::fixed) 取消精度的设置。 1.）超出的位数会被四舍五入进去！！！ 2）与setw()不同 ，setprecision（n）一直作用到下一个setprecisin（n）之前，所以，只需要写一个setprecision（n）就可以。setw()要每次都写 floor(), ceil()函数都包含在头文件“Math.h”中 Floor() 不大于自变量的最大整数 Ceil() 不小于自变量的最大整数 数组开辟空间来源：C/C++数组的大小最大能有多大？ 局部变量：函数内申请的变量，数组，是在栈（stack）中申请的一段连续的空间。栈的默认大小为1M到2M，如果定义a[1024*1024];运行时就会报”段错误“； 全局变量：全局数组，静态数组（static）则是开在全局区（静态区）（static）。大小为2G，所以能够开的很大； 动态分配：malloc、new出的空间，则是开在堆（heap）的一段不连续的空间。理论上则是硬盘大小； 同一个程序共用栈和静态区，因此要申请一个超大数组或许定义为全局变量，而多个超大数组时最好是动态申请。 bugTime Limit Exceeded（1）可能是某种情况没有考虑到或者逻辑bug（很大概率是这个（；´д｀）ゞ） （2）算法不优 think数据范围，最好定义成long long 型123typedef long long ll;//定义长整型 ll n; 慎用递归，易导致超时动态规划大概率适合求最优解问题经典中的经典算法:动态规划(详细解释,从入门到实践,逐步讲解) 这一篇博文讲得比较透彻 逗号运算符逗号运算符是将一系列运算按顺序执行。 整个逗号表达式的值为系列中最后一个表达式的值。 1var = (count=19, incr=10, count+1); 在这里，首先把 count 赋值为 19，把 incr 赋值为 10，然后把 count 加 1，最后，把最右边表达式 count+1 的计算结果 20 赋给 var。上面表达式中的括号是必需的，因为逗号运算符的优先级低于赋值操作符 12a = 1*2,2*2,3*3;//a = 2;因，优先级低于 = 后面表达式只运行，不保留结果 https://www.runoob.com/cplusplus/cpp-comma-operator.html 计算机存储数据大佬解析: https://blog.csdn.net/daiyutage/article/details/8575248 乘法容易溢出 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;double sum(int n)&#123; if(n%2 != 0) return (n+1)/2*n; else return n/2*(n+1);&#125;int addSum(int n)&#123; int i,sum=0; for(i=1; i&lt;=n; i++)&#123; sum+=i; &#125; return sum;&#125;int main()&#123; int n; while(cin&gt;&gt;n)&#123; //cout&lt;&lt;sum(n)&lt;&lt;endl&lt;&lt;endl; cout&lt;&lt;addSum(n)&lt;&lt;endl&lt;&lt;endl; &#125; return 0;&#125; 初始化数据的重要性 在刷题过程中发现了如上bug ,以下面这段代码为例，目的是输出出现次数最多的字符串。 Count[1000] 、p[1000]若没有进行初始化，在多组数据输入后，虽然两者均为循环内部局部变量，但是未初始化将保留原来的数据，导致影响后续结果。 所以以后编程不要依赖于编译器缺省初始化，定义与初始化尽量同步~(ง •_•)ง 大佬解析：循环体内的局部变量内存分配和释放 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;int main()&#123; int n; cin&gt;&gt;n; //至0结束 while(n)&#123; //记录各种颜色出现多少次 //int *Count = new int[n]; int Count[1000] = &#123;0&#125;; int index = 0; //char (*p)[20] = new char[n][20]; char p[1000][20] = &#123;&#125;; bool flag = true; for(int i=0; i&lt;n; i++)&#123; char str[20]; cin&gt;&gt;str; //计数 if(i == 0)&#123; strcpy(p[index],str); Count[index]++; index++; &#125;else&#123; int j; for(j=0; j&lt;index; j++)&#123; if(strcmp(str,p[j]) == 0)&#123; Count[j]++; flag = false; break; &#125; &#125;//end of for //没有就添加进去 if(flag)&#123; strcpy(p[index],str); Count[index]++; index++; flag = true; &#125; &#125;//end of else &#125; //找到最大值 int Cmax = Count[0],t=0; for(int i = 1; i &lt; index; i++ )&#123; if(Cmax &lt;= Count[i])&#123; Cmax = Count[i]; t = i; &#125; &#125; cout&lt;&lt;p[t]&lt;&lt;endl; //释放动态空间 // for(int i = 0; i &lt; n; i++)&#123; // delete []p[i]; // &#125; // delete []p; cin&gt;&gt;n; &#125; return 0;&#125; C++的String对象（字符串类）String详解]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>C++</tag>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博文常用样式语句]]></title>
    <url>%2Farticle%2Fc4704731%2F</url>
    <content type="text"><![CDATA[文章标识123456789#同级标签tags: - [code] - [C++] - [algorithm]#父子分类categories: - [Programming] - [C++] 正文GitHub支持高亮貌似只能使用html形式 1&lt;label style="color:blue"&gt; XXX &lt;/label&gt; 1&lt;!--more--&gt; #表示只在首页展示以上内容]]></content>
      <categories>
        <category>tiny knowledge</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paperMemo - 3D Reconstruction]]></title>
    <url>%2Farticle%2Fc09ea54%2F</url>
    <content type="text"><![CDATA[三维重建定义根据单视图或者多视图的图像重建三维信息的过程 研究意义 港科大教授权龙认为：真正意义上的计算机视觉要超越识别，感知三维环境。 三维重建将作为计算机视觉的核心。将识别与重建融为一体，实现实时、精确的场景模型重构以及环境感知。作为环境感知的关键技术之一，可用于自动驾驶、虚拟现实、运动目标监测、行为分析、安防监控和重点人群监护等。 实现手段根据 采集设备是否主动发射测量信号 ，分为两类：基于主动视觉理论和基于被动视觉的三维重建方法。 主动视觉三维重建方法：主要包括结构光法和激光扫描法。 被动视觉三维重建方法：被动视觉只使用摄像机采集三维场景得到其投影的二维图像，根据图像的纹理分布等信息恢复深度信息，进而实现三维重建。 根据 模型重构类型 ，分为四种：深度图（depth）、点云（point cloud）、体素（voxel）、网格（mesh） 深度图（depth）: 图中每个像素值代表的是物体到相机xy平面的距离，单位为 mm。 点云（point cloud）：某个坐标系下的点的数据集。点包含了丰富的信息，包括三维坐标X，Y，Z、颜色、分类值、强度值、时间等等。在我看来点云可以将现实世界原子化，通过高精度的点云数据可以还原现实世界。万物皆点云，获取方式可通过三维激光扫描等。 体素（voxel）：三维空间中的一个有大小的点，一个小方块，相当于是三维空间种的像素。 网格（mesh）：由三角形组成的多边形网格。多边形和三角网格在图形学和建模中广泛使用，用来模拟复杂物体的表面，如建筑、车辆、人体，当然还有茶壶等。任意多边形网格都能转换成三角网格。 缺点： 从单张图片恢复出三维物体形状这一研究课题在许多应用中扮演着重要的角色，例如增加现实，图像编辑。但是由于物体的拓扑结构复杂多变，这一课题也颇具挑战性。目前，基于体素表达的方法受限于三维卷积网络计算和内存的限制而难以得到高分辨率的输出。基于点云表达的方法又很难生成平滑而又干净的表面。 三角网格表达对物体形状提供了一种更有效，更自然的离散化逼近方式，但是计算复杂。 （ volume受到分辨率和表达能力的限制，会缺乏很多细节；point cloud 的点之间没有连接关系，会缺乏物体的表面信息。相比较而言mesh的表示方法具有轻量、形状细节丰富的特点。 ） 这些方法本质上是在对一个给定拓扑连接关系的初始网格变形，比较有代表性的初始网格有单位平面，球。尽管它们有一定的效果，但是仍然难以恢复具有复杂拓扑结构的物体表面， 未来趋势将三者方式结合起来，从单张RGB图片中识别多个物体，并重建三维模型。 文献2017 A Point Set Generation Network for3D Object Reconstruction from a Single Image作者：Haoqiang Fan（Tsinghua University）, ​ Hao Su, Leonidas Guibas（Stanford University）来源：CVPR 2017 (oral)文章链接：https://arxiv.org/abs/1612.00603源码链接：https://github.com/fanhqme/PointSetGeneration 方法： 网络分为3个版本，输入都为二维图像I和一个用来使系统产生分布式输出的随机向量r，输出为N * 3的矩阵M。 vanilla versionvanilla version分为Encoder（编码器）和Predictor（预测器），Encoder由卷积层和ReLU层组成，随机向量r干扰了图像I的预测，Predictor由全连接网络生成N个点的坐标。 two prediction branch version该网络由vanilla改进而来，在vanilla的基础上在预测器中加入了deconv（反卷积），由于全连接网络对复杂结构表现出良好的性能，但对于简单光滑的结构便显得有些繁重，故引入deconv结构来优化网络，使得参数变少，并且这种结构对光滑表面效果很好。tips：其中添加了多个编码器和预测器之间的链接，以促进编码和预测之间的信息流。 hourglass version沙漏版本在前一个版本的基础上增加了递归循环，能更好的进行编解码操作，具有较强的表示能力，能较好的融合全局和局部信息。 损失函数： Chamfer distance （倒角距离 ） 在另一个集合中找到最近的点，并将其距离的平方求和。（并不是距离公式，因为它不满足三角形不等式）其特点是能更好的保存物体的详细形状 Earth Mover`s distance （EMD距离） 测量两个分布之间的距离，能产生相较于CD算法更紧凑的结果，但有时会过度收缩局部结构 结果： 成功的重建 失败的重建 贡献： （1）开创了单个2D视角用点云重构3D物体的先例（单图像3D重建） （2）系统地探讨了体系结构中的问题点生成网络的损失函数设计 （3）提出了一种基于单图像任务的三维重建的原理及公式和解决方案 （4）将输入改为RGBD图像，能够更加弥补原先模型缺失的部分 缺点： （1） 对于一部分与训练数据存在一定偏差的输入，该网络会用类似的东西来解释输入。 （2） 对于多个对象的组合，因没有实现检测或注意机制，导致输出失真。 2019 （重点看）A Skeleton-bridged Deep Learning Approach for Generating Meshes of Complex Topologies from Single RGB Images作者： Jiapeng Tang, Xiaoguang Han , Junyi Pan, Kui Jia y, Xin Tong School of Electronic and Information Engineering, South China University of Technology Shenzhen Research Institute of Big Data, the Chinese University of Hong Kong (Shenzhen) Microsoft Research Asia 来源：CVPR 2019(oral)文章链接：https://arxiv.org/abs/1903.04704?context=cs.CV源码链接：暂无 方法： 第一阶段是从输入图像中学习生成骨架点云。为此他们设计了平行的双分支网络架构，被命名为 CurSkeNet 和 SurSkeNet，分别用于曲线状和曲面状骨架点云的合成。为了 CurSkeNet 和 SurSkeNet 的训练，他们针对 ShapeNet 的物体模型处理了骨架数据集来当做 ground truth 用于训练。 他们采用编码器-解码器的网络结构从输入图片 I 学习出对应的骨架 K，它本质上是一个更简洁紧凑的点云表达。 在第二个阶段，他们通过将合成的骨架点云体素化，然后用三维卷积网络对粗糙的骨架体素进行修复提取出一个初始网格。此处为了减小高清体素输出时的网络复杂度，采取了用全局结构引导分块体素修复的方式，得到一个更精细化的体素 V。 最后一个阶段先从体素 M 中提取出一个粗糙的初始网格 Mb，然后再用图神经网络对网格的顶点位置进一步优化，得到最后的输出网格 M。 每个阶段都有一个图像编码器-解码器来提取所各自需要的信息结果： 贡献： 提出了阶段性学习的方法，利用了点云，体积和网格各自的优点，而且对有孔洞的物体又能够很好地重建 骨架桥接的方法 腐蚀学习方法来验证算法功效 缺点： 在多次训练后，仍然会在连接处、角落等缺失，或许添加深度图信息会有所改善 模型过于复杂 所展示的模型只是简单场景中的单个物体，而且最终轮廓比较圆润，没有线条感 Mesh R-CNN作者： Georgia Gkioxari、 Jitendra Malik、 Justin Johnson Facebook AI Research (FAIR) 来源：CVPR 2019(oral)文章链接：https://www.researchgate.net/publication/333650113_Mesh_R-CNN源码链接：暂无 方法： 基于Mask R-CNN（论文链接、源码链接， 在进行目标检测的同时进行实例分割 ）改进而来，增加了网格预测分支来输出高分辨的目标三角网格。 通过先预测转化为物体的粗体素分布并转化为三角形网格表示，然后通过一系列的图卷积神经网络改进网格的边角输出具有不同拓扑结构的网格。 结果： 贡献： 开发了从2D感知到3D形状预测的方法（ 图卷积神经网络 ） 由粗到细调整的思想 目标3D三角网格预测，有效地预测带有孔洞的物体 ，同时对于复杂环境中的三维物体也有良好的预测效果。 缺点： 细节缺失较为严重，如上图的凳腿，椅背 重构的模型看起来比较粗糙，没有线条感（作者解释说缺乏大量的真实场景数据-监督） Robust Point Cloud Based Reconstruction of Large-Scale Outdoor Scenes参考文章港科大教授权龙：计算机视觉下一步将走向三维重建 | CCF-GAIR 2018 基于深度学习的视觉三维重建研究总结 三维重建初探 CVPR 2019 | 基于骨架表达的单张图片三维物体重建方法]]></content>
      <categories>
        <category>Scientific Research</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文小知识]]></title>
    <url>%2Farticle%2Feeee6404%2F</url>
    <content type="text"><![CDATA[a.k.a.（又被称为）also known as的缩写，引出另一种对该物的表述。 例句1:The proposed DUQ is based on sequence-to-sequence (seq2seq, a.k.a. Encoder-Decoder). In part because you have the convenience to select specific keywords, write specific ads and direct the click-through to a specific web page (a.k.a. landing page). 最好把a.k.a连同它的解释一块放在括号中. e.g.(用于举例)exampli gratia（”for example; for instance;such as”: 举例如）的缩写，其目的用若干例子来让前面说法更具体，更易感知。 例句1: Buy some vegetables, e.g., carrots. 使用中，不仅e后的“.”常常被漏掉（如写成eg.） 为了方便记忆，你可把”e.g.” 与 “example given” 联想起来。 最好把e.g.连同它的例子放在括号中，如 例句2：I like quiet activities (e.g., reading) etc.（“等等”）et cetera(“and so forth; and the others; and other things; and the rest; and so on”:等等)的缩写。它放在列表的最后，表示前面的例子还没列举完，最后加个词“等等”。 例句3: I need to go to the store and buy some pie, milk, cheese, etc. etc.前面要有逗号。 不要在e.g.的列表最后用etc( 在including后的列表后也不宜使用etc)，这是因为 e.g. 表示泛泛的举几个例子，并没有囊括所有的实例，其中就已经有“等等”的含义了，如果再加一个 etc. 就多余了，例如这是错的： Writing instructors focus on a number of complex skills that require extensive practice (e.g., organization, clear expression, logical thinking, etc.) et al.（“等人”） 这是et alia（”and others; and co-workers”:等它人）的缩写。它几乎都是在列文献作者时使用，即把主要作者列出后，其它作者全放在et al. 里面。 例句4: These results agree with the ones published by Pelon et al. (2002). 人的场合用et al，而无生命的场合用etc.(et cetera)。 et后不要加“.”,因为et不是缩写。另外，与etc.不同，et al.的前面不要逗号。 i.e.（“换句话说”）这是id est（“that is” , “in other words”:也就是）的缩写。目的是用来进一步解释前面所说的观点（不是像e.g.那样引入实例来形象化），意思是“那就是说，换句话说”。你可把”i.e.” 与 “in essence” 联想起来。 例句5：In 2005, American had the lowest personal saving rate since 1933. In fact it was outright negavetive—i.e., consumers spent more money that they made. 例句6：There are three meals in the day (i.e., breakfast, lunch, and dinner) 使用中，i.e.的第一个”.”也常常被错误地漏掉了。它后面紧跟着一个逗号，再跟一个解释。 如同e.g., i.e.也最好放入括号中，如同例句6那样。 比较下面两个例句。 例句7：I like to eat boardwalk food, i.e., funnel cake and french fries. 例句8：I like to eat boardwalk food, e.g., funnel cake and french fries. 例句7表示只有 funnel cake and french fries这两样boardwalk食物，我喜欢。例句8表示我喜欢boardwalk食物，比如 funnel cake and french fries；其实snow cones and corn dogs等其他类型，我也喜欢。 viz.（”即“ 列项） 这是videlicet（ “namely”, “towit”, “precisely”, “that is to say”：即）的缩写，与e.g.不同，viz位于同位列表之前，要把它前面单词所包含的项目全部列出。 例句9：“Each symbol represents one of the four elements, viz. earth, air, fire, and water.”(每个符号代表如下四个元素之一，即： 地球，空气，火焰和水)。 例句10: The noble gases, viz. helium, neon, argon, xenon, krypton and radon, show a non-expected behaviour when exposed to this new element. 注意 viz.后面无逗号。 信息来源http://blog.sciencenet.cn/blog-510768-1112873.html]]></content>
      <categories>
        <category>tiny knowledge</category>
      </categories>
      <tags>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机图形学-实验]]></title>
    <url>%2Farticle%2F9200fd3%2F</url>
    <content type="text"><![CDATA[实验 GLFW GLAD 123456789101112131415//渲染while (!glfwWindowShouldClose(window))&#123; //glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClearColor(0.0f, 0.34f, 0.57f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); //交换颜色缓存，开始绘制 glfwSwapBuffers(window); //检查触发事件 glfwPollEvents();&#125; VAO 顶点数组对象 VBO 顶点缓冲对象 实验一：绘制三角形123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185#include &lt;glad/glad.h&gt;#include &lt;GLFW/glfw3.h&gt;#include &lt;iostream&gt;using namespace std;const unsigned int SCR_WIDTH = 800;const unsigned int SCR_HEIGHT = 600;int main()&#123; //cout &lt;&lt; SCR_HEIGHT &lt;&lt; endl; /* 初始化OpenGL 1)初始化GLFW 2)创建窗口 3)初始化GLAD 4)创建视口 */ // 1）初始化GLFW glfwInit(); //设置主版本号、次版本号为3.3 glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); //使用核心模式，即只能使用openGL功能的一个子集（没有向后兼容特性） glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //Mac OS需要加上这句 glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); //不可改变窗口大小 glfwWindowHint(GLFW_RESIZABLE, GL_FALSE); // 2)设置GLFW窗口对象 GLFWwindow* window = glfwCreateWindow(SCR_WIDTH, SCR_HEIGHT, "LearnOpenGL", NULL, NULL); if (window == NULL) &#123; //若未创建成功，终止程序 std::cout &lt;&lt; "Failed to create GLFW window" &lt;&lt; std::endl; glfwTerminate(); return -1; &#125; //设置GLFW上下文(状态)为当前线程的上下文 glfwMakeContextCurrent(window); //GLAD管理OpenGL函数指针 if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress)) &#123; std::cout &lt;&lt; "Failed to initialize GLAD" &lt;&lt; std::endl; return -1; &#125; //指定当前视口尺寸（左下角坐标，视口宽高） glViewport(0, 0, SCR_WIDTH, SCR_HEIGHT); /* 数据处理 */ //1）三角形三个顶点输入（标准化，0-1之间） const float triangle[] = &#123; -0.5f,-0.5f,0.0f, //左下 0.5f,-0.5f,0.0f, //右下 0.0f,0.5f,0.0f //正上 &#125;; //2）VAO（顶点数组对象） VBO（顶点缓冲对象） GLuint vertex_array_object; glGenVertexArrays(1, &amp;vertex_array_object); glBindVertexArray(vertex_array_object); GLuint vertex_buffer_object; glGenBuffers(1, &amp;vertex_buffer_object); glBindBuffer(GL_ARRAY_BUFFER, vertex_buffer_object); glBufferData(GL_ARRAY_BUFFER, sizeof(triangle), triangle, GL_STATIC_DRAW); //设置顶点属性指针 //顶点着色器的位置，顶点属性为3分量向量，是否标准化，连续顶点属性之间的间隔，数据偏移量 glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); // 3) 生成并编译着色器 const char *vertex_shader_source = "#version 330 core\n" "layout(location = 0 ) in vec3 aPos;\n" "void main()\n" "&#123;\n" " gl_Position = vec4(aPos, 1.0);\n" "&#125;\n\0"; const char *fragment_shader_source = "#version 330 core\n" "out vec4 FragColor;\n" "void main()\n" "&#123;\n" " FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);\n" "&#125;\n\0" ; //状态标识量 int success; char info_log[512]; //顶点着色器 int vertex_shader = glCreateShader(GL_VERTEX_SHADER); glShaderSource(vertex_shader, 1, &amp;vertex_shader_source, NULL); glCompileShader(vertex_shader); //检查编译是否成功 glGetShaderiv(vertex_shader, GL_COMPILE_STATUS, &amp;success); if (!success) &#123; glGetShaderInfoLog(vertex_shader, 512, NULL, info_log); cout&lt;&lt;"error 1:"&lt;&lt; info_log &lt;&lt; endl; &#125; //片段着色器 int fragment_shader = glCreateShader(GL_FRAGMENT_SHADER); glShaderSource(fragment_shader, 1, &amp;fragment_shader_source, NULL); glCompileShader(fragment_shader); //检查编译是否成功 glGetShaderiv(fragment_shader, GL_COMPILE_STATUS, &amp;success); if (!success) &#123; glGetShaderInfoLog(fragment_shader, 512, NULL, info_log); cout &lt;&lt; "error 2:" &lt;&lt; info_log &lt;&lt; endl; &#125; //链接顶点和片段着色器至一个着色器程序 int shader_program = glCreateProgram(); glAttachShader(shader_program, vertex_shader); glAttachShader(shader_program, fragment_shader); glLinkProgram(shader_program); //检查链接是否成功 glGetProgramiv(shader_program, GL_LINK_STATUS, &amp;success); if (!success) &#123; glGetProgramInfoLog(fragment_shader, 512, NULL, info_log); cout &lt;&lt; "error 3:" &lt;&lt; info_log &lt;&lt; endl; &#125; //渲染 while (!glfwWindowShouldClose(window)) &#123; //渲染指令 glClearColor(0.2f, 0.3f, 0.3f, 1.0f); //清空颜色缓冲后，填充蓝色 //glClearColor(0.0f, 0.34f, 0.57f, 1.0f); //清除颜色缓冲 glClear(GL_COLOR_BUFFER_BIT); //使用着色器程序 glUseProgram(shader_program); //绘制三角形 glBindVertexArray(vertex_array_object); glDrawArrays(GL_TRIANGLES, 0, 3); //解除绑定 glBindVertexArray(0); //交换颜色缓存，开始绘制 glfwSwapBuffers(window); //检查触发事件 glfwPollEvents(); &#125; //删除VAO VBO glDeleteVertexArrays(1,&amp;vertex_array_object); glDeleteBuffers(1, &amp;vertex_buffer_object); //释放资源 glfwTerminate(); return 0;&#125;]]></content>
      <categories>
        <category>Computer Graphics</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机图形学-课程笔记]]></title>
    <url>%2Farticle%2F87477f70%2F</url>
    <content type="text"><![CDATA[VS2017 注释： 先CTRL+K，然后CTRL+C 取消注释： 先CTRL+K，然后CTRL+U 图形应用计算机辅助设计(CAD:computer-aided design) 虚拟现实环境(virtual-reality environment) 科学计算可视化（scientific visualization） 未来发展表情与动作的精细化 图形学与深度学习的碰撞 阴极射线管（CRT） 发光二极管显示器（LED：Liquid-emtting diode） GPU 擅长于计算 像素：由图像的小方格组成的,这些小方块都有一个明确的位置和被分配的色彩数值,小方格颜色和位置就决定该图像所呈现出来的样子 显示分辨率：水平像素数*垂直像素数 ，取决于光点与帧缓存（存放一帧的信息）的大小 帧缓存的容量 = 分辨率 * 颜色位面数 可编程渲染管线发展历程固定管线：程序员控制权减少，不灵活 可编程图形库：自由搭建，功能范围广 从固定到可编程：hooks()函数（钩函数）突破固定功能流水线的限制，使用可编程着色器修改 流水线中特定步骤的行为。 GPU渲染管线应用阶段 -》 几何阶段 -》光栅化 软光栅扫描转换也就是光栅化,点阵单元是像素点阵 图源经过算法计算（不借助硬件提供的api）转换成像素点 逼近的本质相当于 连续量向离散量的转换 直线扫描转换算法逐点比较法、正负法、数值微分算法、Bresenham算法 数值微分算法（DDA） DDA是增量算法，优点：简单直观易实现，缺点：有浮点数和浮点运算，效率不高 记得取整（光栅化过程中不可能绘制半个像素点） 源码实现： Bresenham算法（1）中点 算法步骤： 假定0&lt;k&lt;1,x是最大位移方向；为防止浮点数出现，d（误差项）放大2倍 （2）改进 圆的扫描转换算法 常规计算太复杂 Bresenham算法 椭圆的扫描转换算法在椭圆弧的扫描转换算法中，如果考虑的是中心在原点，第一象限的1/4段椭圆弧，则上下部分的分界点是椭圆弧上法向量x、y两个分量相等的点 多边形的扫描转换算法X-扫描线思想 由于像素点较小，因此中心偏移看不出来 算法效率问题 ​ Y向连贯性算法具体算法思想查看此处 边标志算法上闭下开 区域填充 边界填充算法 8连通边界算法不可以填充4连通边界表示区域 泛填充算法通常用于给区域重新着色 8连通泛填充算法可以填充4泛填充的内点表示区域 重复入栈问题 属性颜色，虚实，宽细，纹理贴图 根据斜率改变模板 走样与反走样 为提高图片质量，进行反走样 造型技术研究如何在计算机中建立恰当的模型表示不同图形对象的技术 对象：规则对象（几何模型）、不规则对象（不能用欧式几何加以描述的对象如山树云烟） 实体 样条 样条的描述方法 Bezier实例 特性： （1）曲线总是通过第一个和最后一个控制点 （2）曲线起始点处的切线落在头两个控制点的连线上，曲线终点处的切线落在后两个控制点的连线上 （3）曲线落在控制点的凸壳内 （4）封闭曲线的第一个点和最后一个点重合； 多个控制点位于同一位置需要更多加权 实体模型的三类表示多边形表示（三角形或四边形） 扫描表示（旋转扫描、广义扫描） 构造实体几何法：由两个实体间的并、交或差操作生成的新的实体（CSG树） 光线投射算法 空间位置枚举 （1）八叉树 （2）松散八叉树 （3）BSP树 与八叉树相比较：自适应分割，有效减少树的深度和搜索时间 ​ 有效识别前向面与后向面 轴对齐：① xyz轴的顺序进行分割 或者 ②最长边 多边形对齐 ： 常运用于深度测试、相交测试、碰撞测试 分形几何熵：体系混乱程度的度量 分形： 具有以非整数维形式充填空间的形态特征，fractal 粒子系统模拟火、烟、水流… 模拟多个粒子及其运动（每个粒子都有生命值） 渲染过程中粒子始终面对着摄像机方向（如NPC：Non-Player Character 的名字） 变换与观察图形的几何变换是指对图形的几何信息经过平移、比例、旋转（逆时针为正方向）、对称、错切（剪切、错位变换，用于产生弹性物体的变形处理）等变换后产生新的图形 相关公式： 齐次坐标用n+1维向量表示一个n维向量（但具有不唯一性） 运用齐次坐标可以同时表示多种变化 齐次坐标三维变换 关于坐标原点： 复合变化其中三维复合变化可通过每次变换矩阵相乘来得到 比较难以理解：https://www.icourse163.org/learn/HUST-1003636001?tid=1206895203#/learn/content?type=detail&amp;id=1211820060&amp;cid=1214742100 （1）对任意参考点： eg： （2）对任意轴： 观察变换 世界坐标到观察坐标系的变换 ：实际上是世界坐标系Q（x,y,z）在观察坐标系中的坐标值 ，最后不需要逆变换回去 模型变化与观察变化具有对偶性 投影变换观察变换中隐含一个观察平面，即投影平面 按照投影中心的位置 投影分类 平行投影 正投影分为 三视图（主侧俯）与正轴测图 等轴测：投影面与三个坐标面的夹角都相等 正二测：投影面与二个坐标面的夹角都相等 正三测：投影面与三个坐标面的夹角都不相等 斜投影 透视投影 规范化投影 观察窗口的大小、投影方式的不同都影响着观察空间 为后续操作方便，因此规范化 通过openGL函数调用来完成这一操作 裁剪与屏幕映射CS算法 按左下右上的顺序求出直线段求出直线段与窗口边界的交点 改进后的CS中点法 LB算法将线段看作“先进后出”的带方向的线，建立参数方程，求出与裁剪窗口的交点，6个点：起终点，与窗口边界及其延长线的交点 多边形的裁剪 该算法遇到凹边形时会出现问题：多余边V2、V3 另一种算法 窗口定义为pw，多边形定义为ps 线段按指定方向，在可见侧进入不可见侧时进行相应操作（以BC,CD为例 到V2时同时输出V1、V2，并返回D点） 三维空间的裁剪增加至6个点，与面的交点 增加至8个点，与面的交点]]></content>
      <categories>
        <category>Computer Graphics</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习-pytorch框架]]></title>
    <url>%2Farticle%2F6dc244e8%2F</url>
    <content type="text"><![CDATA[前言理论知识对于 AI 算法工程师极其重要。敲代码只是思路的一个实现过程。这里的「算法」和计算机 CS 的「算法」还不太一样，AI 算法是偏数学推导的，所以数学底子还是需要点的，学的越深，要求越高。面试的时候，很少让手写代码，90% 都是在问模型抠算法细节。 快速入门教程https://morvanzhou.github.io/tutorials/machine-learning/torch/ Tensor张量是对矢量和矩阵向潜在的更高维度的泛化,表示为基本数据类型的 n 维数组。 张量中的每个元素都具有相同的数据类型，且该数据类型一定是已知的。形状，即张量的维数和每个维度的大小，可能只有部分已知。 具体特点 使用方法 Note（1）任何以“_”结尾的操作都会用结果替换原变量 ​ 例如: x.copy_(y), x.t_(), 都会改变 x. （2）Torch Tensor与NumPy数组共享底层内存地址，修改一个会导致另一个的变化。 （3）所有的 Tensor 类型默认都是基于CPU， CharTensor 类型不支持到 NumPy 的转换. （4）Tensor 和 Function互相连接并生成一个非循环图，它表示和存储了完整的计算历史。每个张量都有一个.grad_fn属性，这个属性引用了一个创建了Tensor的Function（除非这个张量是用户手动创建的，即，这个张量的grad_fn是None） 如果需要计算导数，你可以在Tensor上调用.backward()。如果Tensor是一个标量（即它包含一个元素数据）则不需要为backward()指定任何参数，但是如果它有更多的元素，你需要指定一个gradient 参数来匹配张量的形状。 （5）torch.nn 只支持小批量输入。整个 torch.nn包都只支持小批量样本，而不支持单个样本。例如，nn.Conv2d 接受一个4维的张量，每一维分别是sSamples nChannels Height Width（样本数通道数高宽）如果你有单个样本，只需使用 `input.unsqueeze(0) 来添加其它的维数 （6）output为网络的输出，target为实际值 （7）torch.view()与 np.reshape()的区别： 效果一样，reshape（）操作nparray，view（）操作tensor view（）只能操作contiguous的tensor，且view后的tensor和原tensor共享存储，reshape（）对于是否contiuous的tensor都可以操作。 （8） 12import matplotlib.pyplot as plt plt.imshow(np.transpose(npimg, (1, 2, 0))) img的格式为（channels,imagesize,imagesize），plt.imshow在现实的时候输入的是（imagesize,imagesize,channels） 因此由np.transpose函数进行转换 np.transpose函数理解 常用于图片翻转 （9）在张量创建时，通过设置 requires_grad 标识为Ture来告诉Pytorch需要对该张量进行自动求导，PyTorch会记录该张量的每一步操作历史并自动计算 机器学习知识点快速回顾 神经网络快速回顾 卷积神经网络快速回顾 其中GoogLeNet (Inception) 、ResNet（跳连接）仔细看看 （10）MNIST数据集手写数字识别 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimfrom torchvision import datasets, transformstorch.__version__BATCH_SIZE = 512EPOCHS = 20DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")train_loader = torch.utils.data.DataLoader( datasets.MNIST( 'data', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=BATCH_SIZE, shuffle=True)test_loader = torch.utils.data.DataLoader( datasets.MNIST( 'data', train=False, transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=BATCH_SIZE, shuffle=True)class ConvNet(nn.Module): def __init__(self): super().__init__() # 1,28x28 self.conv1=nn.Conv2d(1, 10, 5) # 10, 24x24 self.conv2=nn.Conv2d(10, 20, 3) # 128, 10x10 self.fc1 = nn.Linear(20*10*10, 500) self.fc2 = nn.Linear(500, 10) def forward(self, x): in_size = x.size(0) out = self.conv1(x) #24 out = F.relu(out) out = F.max_pool2d(out, 2, 2) #12 out = self.conv2(out) #10 out = F.relu(out) out = out.view(in_size, -1) out = self.fc1(out) out = F.relu(out) out = self.fc2(out) out = F.log_softmax(out, dim=1) return outmodel = ConvNet().to(DEVICE)optimizer = optim.Adam(model.parameters())def train(model, device, train_loader, optimizer, epoch): model.train() for batch_idx, (data, target) in enumerate(train_loader): data, target = data.to(device), target.to(device) optimizer.zero_grad() output = model(data) loss = F.nll_loss(output, target) loss.backward() optimizer.step() if(batch_idx+1)%30 == 0: print('Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;'.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))def test(model, device, test_loader): model.eval() test_loss = 0 correct = 0 with torch.no_grad(): for data, target in test_loader: data, target = data.to(device), target.to(device) output = model(data) test_loss += F.nll_loss(output, target, reduction='sum').item() # 将一批的损失相加 pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标 correct += pred.eq(target.view_as(pred)).sum().item() test_loss /= len(test_loader.dataset) print('\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n'.format( test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))for epoch in range(1, EPOCHS + 1): train(model, DEVICE, train_loader, optimizer, epoch) test(model, DEVICE, test_loader) 其中 PyTorch中的nn.Conv1d与nn.Conv2d tips: 在PyTorch中，池化操作默认的stride大小与卷积核的大小一致； 如果池化核的大小为一个方阵，则仅需要指明一个数，即kernel_size参数为常数n，表示池化核大小为n x n。 question window下 tensorboard不显示相应的网络结构以及数据 解决方案https://www.cnblogs.com/tengge/p/6376073.html tips:路径中不能存在中文路径]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习-卷积神经网络]]></title>
    <url>%2Farticle%2Fc486835d%2F</url>
    <content type="text"><![CDATA[互相关运算和卷积运算实际上，卷积运算与互相关运算类似。为了得到卷积运算的输出，我们只需将核数组左右翻转并上下翻转，再与输入数组做互相关运算。可见，卷积运算和互相关运算虽然类似，但如果它们使用相同的核数组，对于同一个输入，输出往往并不相同。 那么，你也许会好奇卷积层为何能使用互相关运算替代卷积运算。其实，在深度学习中核数组都是学出来的：卷积层无论使用互相关运算或卷积运算都不影响模型预测时的输出。 二维卷积层的核心计算是二维互相关运算。在最简单的形式下，它对二维输入数据和卷积核做互相关运算然后加上偏差。 特征图和感受野二维卷积层输出的二维数组可以看作是输入在空间维度（宽和高）上某一级的表征，也叫特征图（feature map）。影响元素x的前向计算的所有可能输入区域（可能大于输入的实际尺寸）叫做x的感受野（receptive field）。 以图为例，输入中阴影部分的四个元素是输出中阴影部分元素的感受野。我们将图中形状为2×2的输出记为Y，并考虑一个更深的卷积神经网络：将Y与另一个形状为2×2的核数组做互相关运算，输出单个元素z。那么，z在Y上的感受野包括Y的全部四个元素，在输入上的感受野包括其中全部9个元素。可见，我们可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征。 我们常使用“元素”一词来描述数组或矩阵中的成员。在神经网络的术语中，这些元素也可称为“单元”。 一般来说，假设输入形状是nh×nw，卷积核窗口形状是kh×kw，那么输出形状将会是(nh−kh+1)×(nw−kw+1). 所以卷积层的输出形状由输入形状和卷积核窗口形状决定。本节我们将介绍卷积层的两个超参数，即填充和步幅。它们可以对给定形状的输入和卷积核改变输出形状。 padding为防止卷积将图片变小，损失信息，在此操作前先进行填充。 一般来说，如果在高的两侧一共填充ph行，在宽的两侧一共填充pw 列，那么输出形状将会是(nh−kh+ph+1)×(nw−kw+pw+1), 也就是说，输出的高和宽会分别增加ph和pw 在很多情况下，我们会设置ph=kh−1和pw=kw−1来使输入和输出具有相同的高和宽。这样会方便在构造网络时推测每个层的输出形状。假设这里kh是奇数，我们会在高的两侧分别填充ph/2行。如果kh是偶数，一种可能是在输入的顶端一侧填充⌈ph/2⌉行，而在底端一侧填充⌊ph/2⌋行。在宽的两侧填充同理。 卷积神经网络经常使用奇数高宽的卷积核，如1、3、5和7，所以两端上的填充个数相等。对任意的二维数组X，设它的第i行第j列的元素为X[i,j]。当两端上的填充个数相等，并使输入和输出具有相同的高和宽时，我们就知道输出Y[i,j]是由输入以X[i,j]为中心的窗口同卷积核进行互相关计算得到的 卷积步长一般来说，当高上步幅为sh，宽上步幅为sw时，输出形状为⌊(nh−kh+ph+sh)/sh⌋×⌊(nw−kw+pw+sw)/sw⌋. 如果设置ph=kh−1和pw=kw−1，那么输出形状将简化为⌊(nh+sh−1)/sh⌋×⌊(nw+sw−1)/sw⌋。更进一步，如果输入的高和宽能分别被高和宽上的步幅整除，那么输出形状将是(nh/sh)×(nw/sw)。 过滤器必须处于图像中或者填充之后得图像区域内，采用向下取整的方法。 在机器学习领域一般没有翻转操作，也叫卷积，但是实际上是互相关操作（cross-correlation）。 多通道输入 多通道输出 1*1卷积层1×1卷积层被当作保持高和宽维度形状不变的全连接层使用。于是，我们可以通过调整网络层之间的通道数来控制模型复杂度。 单层卷积网络 特征 “防止过拟合” 一般卷积神经网络的结构： 全连接层输出层中的神经元和输入层中各个输入完全连接（即：输入和输出全连接）。因此，这里的输出层又叫全连接层（fully-connected layer）或稠密层（dense layer）。梯度会指向各点处的函数值降低的方向。更严格的讲，梯度指示的方向是各点处的函数值减少最多的方向。(采用梯度下降法) 全连接层：上一层与该层（full connect）的每个单元相连接 池化层（pooling）它的提出是为了缓解卷积层对位置的过度敏感性。 举例：实际图像里，我们感兴趣的物体不会总出现在固定位置：即使我们连续拍摄同一个物体也极有可能出现像素位置上的偏移。这会导致同一个边缘对应的输出可能出现在卷积输出Y中的不同位置，进而对后面的模式识别造成不便。 池化层每次对输入数据的一个固定形状窗口（又称池化窗口）中的元素计算输出。不同于卷积层里计算输入和核的互相关性，池化层直接计算池化窗口内元素的最大值或者平均值。该运算也分别叫做最大池化或平均池化。 池化层的输出通道数跟输入通道数相同。 因为在处理多通道输入数据时，池化层对每个输入通道分别池化，而不是像卷积层那样将各通道的输入按通道相加。 作用：最大池化层，增强图片亮度；平均池化层，减少冲击失真，模糊，平滑。 最大池化层（常用） 平均池化层 小结 填充可以增加输出的高和宽。这常用来使输出与输入具有相同的高和宽。 步幅可以减小输出的高和宽，例如输出的高和宽仅为输入的高和宽的1/n（n为大于1的整数）。 最大池化和平均池化分别取池化窗口中输入元素的最大值和平均值作为输出。 池化层的一个主要作用是缓解卷积层对位置的过度敏感性。 可以指定池化层的填充和步幅。 池化层的输出通道数跟输入通道数相同。 CNN卷积神经网络就是含卷积层的网络 卷积层尝试解决这两个问题。一方面，卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性均可能被有效识别；另一方面，卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。 计算神经网络有多少层时，通常只统计具有权重和参数的层。有时将卷积层和池化层计为1层 卷积神经网络的优点：参数共享和稀疏连接来减少参数，用于训练更小的训练集以及防止过拟合。 CNN举例LeNet模型分为卷积层块和全连接层块两个部分 卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用5×5的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为2×2，且步幅为2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。 卷积层块的输出形状为(批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。 其他传统网络AlexNet VGG16 残差网络有助于解决梯度消失和梯度爆炸问题，也能保证深层网络良好的性能 跳远连接：a^[l]数据传送到更远的层 通过1*1卷积来压缩或保持输入层中信道数量 Inception网络不需要人为决定使用那个过滤器或是否需要池化，通过合理构建瓶颈层，可以缩小表示层规模，而又不降低网络性能。 但是直接这样做计算成本太高。 利用1*1卷积层做瓶颈层 参考文献二维卷积层 卷积运行和互相关运算]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Qt creator 封装带图片的可执行文件]]></title>
    <url>%2Farticle%2F1c3f6ab%2F</url>
    <content type="text"><![CDATA[前言经过大半天的折腾，终于将所需要的exe弄出来了。 期间查阅了大量资料，发现大多是简单的一个示例。。 只有一位博主简单说明了一下 带图片资源的操作方式 目的在其他未配置过环境的window电脑上直接运行我们所写程序 环境与软件Qt creator 5.11.1 mingw 32 bit openCV库 kienct 库 Dependency Walker (查询程序所用库的软件) 下载传送门 Enigma Virtual Box(打包整个exe的软件) 下载传送门 初步生成.exe（1）以release形式编译代码 （2）在你项目放置同级目录下会生成对应的buildXXXXX文件-》release文件夹-xxx.exe 自动拷贝所需dll（1）将该exe单独放置在一个文件夹 （2）window搜索框搜索并调用出QT的mingw命令行，使用windeployqt命令 （3）执行以下命令 1234# cd 你所放exe的文件路径cd D:\showEXE # 执行windeployqt xxx(名字).exewindeployqt KinectPeopleDection.exe 添加缺失的dll(动态链接库)此时你可以直接运行该exe文件，但是当你移植到其他电脑时可能会出现库缺失的现象。这可能时因为所使用的第三方库如openCV并没有同步添加进来。 （1）下载Dependency Walker （2）运行并打开xxx.exe （3）检查缺失dll 对比depens所罗列的dll文件与上一步自动拷贝的dll，找出所缺库。这里可以看到openCV kinect的dll根本没有 （4）添加缺失dll full path 可以看到exe所用dll的路径 根据所给路径，将所缺dll复制到所含exe文件夹中 小小坑：感觉应该全部找到了，但是在实际运行中Qt5Test.dll Qt5OpenGL.dll也缺失了，该软件也没有提示… 小小理解：有些系统dll文件引用过来全是64位（如：user32.dll），而mingw编译完是32位的，似乎该软件也提示不兼容。但是我觉得既然在我们的系统上可以运行，就说明没什么太大影响。于是这些dll我选择忽略 图片就位图片文件夹与exe放置在同一目录下 程序修改对应路径12345678910//在mainwindow.h中声明变量，最好是全局变量啦，QString applicationdDirPath; //在mainwindow.cpp//MainWindow::MainWindow(QWidget *parent) 函数里//获取当前程序所在位置 applicationdDirPath = QCoreApplication::applicationDirPath();//程序中的图片路径便是 applicationdDirPath +... QString frameBGRPath = applicationdDirPath + "/img/"+QString::number(collectNumber)+"/bgr"+QString::number(imgCount)+".jpg"; 在此插一个小知识点 QString 字符串拼接类型转换 QString转整型、字符串 eg: 12frameBGRPath.toStdString();frameBGRPath.toInt(); 整型转QString eg: 12int collectNumber = 1;QString bgr = QString::number(collectNumber)； 可选操作更换exe的图标QT程序图标和窗口图标 转icon线上工具 整体打包Enigma Virtual Box下载 QTcreator生成可在其他电脑上跑的exe文件封包过程 参考文献VS2015+QT5.8 程序打包发布详解（包含图片打包，附工具和源码）]]></content>
      <categories>
        <category>Qt creator</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习-深层神经网络]]></title>
    <url>%2Farticle%2Fb4ebaec5%2F</url>
    <content type="text"><![CDATA[深度学习的含义深度学习时所指的”深度”是层与层之间更深层次的协调以及随之产生的更加复杂的连接。最终的结果就是你的模型中，有百万级别甚至十亿级别数量的神经元。这就是为什么通过深度神经网络得到的结果。能够极大地优于，早期的手工构建并且手工调试的模型。 作者：大腿君 链接：https://zhuanlan.zhihu.com/p/32225723 来源：知乎 symbol层数大于3 （tips：不计输入层） n^[ l ] : 每层的单元数 a^[ l ] : 每层的激活函数 —- a^[0]为X ， a^[l]为y^ w^[ l ] : 在 a^[ l ]中计算z^[ l ]的权重 深层神经网络的前向和反向传播（ 深度神经网络版梯度下降法正反向传播 ） 前向传播似乎没有比“显示for循环”更好的办法 z^[i] = w^[i] * a^[i-1] + b^[i] 检查bug ：过一遍生成矩阵的维数 z^[i] 的维数 = [ n^[i] ,1 ] = b^[i] 的维数 w^[i] 的维数 = [ n^[i] , n^[i-1] ] 反向传播 中 dw^[i] 的维数等于 w^[i] ​ db^[i] 的维数等于 b^[i] 向量化实现 搭建神经网络块缓存 z 向量化实现 参数与超参数超参数 最终决定了 h(x)中参数的值 目前根据数据或者经验来不断调试超参数的值 方差 与 偏差偏差 bias 👆 训练集错误率 👆 欠拟合 方差 variance 👆 交叉验证集错误率 👆 过拟合 Dropout 正则化设置神经网络中每个节点消除或保留的概率，随机消除节点，从而得到节点更少，规模更小的网络 dropout 会压缩权重并完成一些预防过拟合的外层正则化，可能更适用于不同的输入范围。 keep-prob 代表每一层上保留单元的概率 梯度爆炸与梯度消失举例 ： 如果 激活函数是线性的，与神经网络层数有关的话，呈指数级关系，容易出现梯度爆炸或消失 通过初始化神经网络的权重来部分解决 采用双边误差的方法来检测梯度的数值逼近 梯度检测检查反向传播是否出错 注意事项： mini-batch梯度下降在面对大型的训练集时，将训练集分为几个 大小一致 的集合依次训练 对比随机梯度下降、batch梯度下降、mini-batch梯度下降batch梯度下降：代价函数从某处值开始向最小值收敛，步长大一些。但在训练集巨大时，单次迭代耗时巨大。 随机梯度下降：随机取点，只对一个样本进行梯度下降，大部分向着全局最小值靠近，小部分方向错误，最终在 最小值附近徘徊，但始终不会收敛。但丧失向量化速度优势 修改mini-batch的size，可以在随机梯度下降与batch梯度下降中转换 如何针对实际情况选择size如果训练集较小（m &lt; 2000）, 使用 batch梯度下降 如果训练集较大, 使用 随机梯度下降 一般的mini-batch size :64 ,128, 256 ,512 适应计算机存储方式 指数加权平均以伦敦每日气温为例， 预测曲线的点与前一天、今天的温度有关 偏差修正紫色初始端路线变为绿色曲线 梯度下降消除摆动算法动量梯度下降在某些情况下希望梯度下降在上下方向缓慢一些，在左右方向快速一些 RMSproproot mean square prop算法也用来加速梯度下降，消除梯度下降中的摆动。 Adamadaptive moment esimation 算法是以上两种算法的结合版 一般情况下只需调整alpha的值，其他缺省 学习率衰减加快学习网络效率，随着时间慢慢减少学习率 局部最优问题因为训练了一个大型的神经网络，所以不太可能陷入一个糟糕的局部最优中 平稳区会降低学习速率 超参数调试方法 （1）使用随机值，而非网格，来明确哪些超参数比较重要 （2）由粗到细，放大 效果较好的点集，更密集地随机取点 （3）选择合适的超参数取值范围 （4）β （指数加权平均参数）不适合线性轴均匀取值，再接近某个值时对结果影响巨大。 “熊猫模式” 与 “鱼子酱模式 ” 随着时间，根据数据的变化改变超参数的值； 同时并行多个模型，挑选适应性较好的模型； 正则化网络的激活函数归一化输入（输入层、隐藏层）来加快学习速率 Batch Norm 归一化 发生在 z与a之间，激活函数前 它减弱了前一层参数的作用与后一层参数的作用之间的联系，使得结构更稳定 在测试阶段的 batch norm 需要逐一处理样本 根据训练集估算 μ和σ^2 Softmax 回归将逻辑回归激活函数推广到了多类即：多个输入值而不是0、1了 深度学习框架 TensorFlow 数据集划分在机器学习领域大多是 训练集 交叉验证集 测试集 70% 30% 60% 20% 20% 而在深度学习领域 训练集 交叉验证集 测试集 98% 1% 1% 因为深度学习比较吃数据，而且数据集比机器学习所需要的大多了 误差分析在结果中找寻错误例子，观察错误标记的例子，对每种错误进行分类，看看真阳性或假阴性。统计不同种错误类型的占比，分析改善后其性能上限。 深度学习对随机误差有很强的鲁棒性 训练集和验证集、测试集要来自同一分布 可避免偏差 ：训练集分类错误率 与 人类分类错误率之间的差距 方差 ：训练集分类错误率 与 traning-dev（或测试集）分类错误率之间的差距 数据不匹配：有时可人工制造数据，但要注意过拟合问题 迁移学习试图优化数据相对较少的任务B，寻找一个相关但不同的任务A（数据量较大）训练得到低层次的特征，改善B的学习情况 何时迁移才起作用： 多任务学习单神经网络同时解决多个问题，（比如 对图片标注多个标签） 在数据量较大的情况下，多任务学习性能较好 代替方式：为每一个问题训练单神经网络 何时“多任务学习”才起作用： 端到端学习需要大数据集才能表现其优点]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习-浅层神经网络]]></title>
    <url>%2Farticle%2F45fe3766%2F</url>
    <content type="text"><![CDATA[神经网络表示a:activation —— 代表着网络中不同层传给下一层的值 a^(i)_j 第 i 层的第 j 的节点。 计算层数时不计入“输入层”，从隐藏层开始数 以逻辑回归为例 计算过程解释 激活函数种类σ激活函数：除非用在二元分类的输出层，不然绝对不要用 tanh函数 在任何场合都具有优越性 ReLU函数 最常用的默认的激活函数 或者带泄露的ReLU函数 非线性激活函数为了计算出更复杂的函数，必须引入非线性激活函数 只用线性激活函数的情况 （1）machine learning on regression problem(回归问题) ​ （2）输出层 ​ （3）在隐藏层使用是与压缩有关的一些非常特殊的情况 导数 梯度下降前向与反向传播(用到导数) keepdims = true ,是为了防止python出现秩为1的矩阵（n, ） 还有种方式是 不使用keepdims参数，而是显式调用reshape,将np.sum的结果写成矩阵形式 随机初始化对于逻辑回归，可以将权重初始化为0 对于神经网络，各参数数组全部初始化为0 ，再使用梯度下降 将无效 因为隐藏层会计算完全一样的函数，出现对称性，权重一致无意义。 而我们需要不同的隐藏单元去计算不同的函数 解决方案： 随机初始化所有参数( 很小的值 ) 示例：]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习-概论]]></title>
    <url>%2Farticle%2F940b252a%2F</url>
    <content type="text"><![CDATA[神经网络在监督学习中发挥很大作用 规模一直推动深度学习的发展。 大型神经网络、算法创新 以及海量数据 深度学习的 “ 端到端模型（end-to-end learning）” 一个神经网络训练过程 X.shape = (NX,M) Y.shape = (1,M) M为训练集的个数 ，N 为X的特征量个数 逻辑回归w b称为拦截器 α 步长或者学习率 在深度学习过程中，能不显式使用for循环就不用。尽量向量化，并行处理。 tips: 并行是同时处理，并发是同一时间间隔内处理 向量化逻辑回归 python中的广播机制在python中使用numpy进行按位运算的时候，broadcasting,广播机制：如果你有一个m*n的矩阵，让它加减乘除一个1*n的矩阵，它会被复制m次，成为一个m*n的矩阵，然后再逐元素地进行加减乘除操作。同样地对m*1的矩阵成立 python编程注意事项1.不用秩为1的数组，而是用对应的行向量或列向量 2.使用assert()来检查矩阵维数 3.不要害怕使用reshape()]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-照片OCR应用]]></title>
    <url>%2Farticle%2F5e39b6d7%2F</url>
    <content type="text"><![CDATA[Photo Optical Character Recognition 机器学习流水线： 滑动窗口以特定的大小遍历整幅图片，传给分类器 在整幅图片中找到包含字符的矩形框 再次利用滑动窗口分离单个字符 获取大量数据以及人工生成 选取不同字体和背景进行人工合成 对现有数据进行字符拉伸、模糊等操作 1 用学习曲线做一个合理检验，查看更多的数据是否有用 2 需要花多少时间来获得当前10倍的数据量 天花板分析（上限分析）在某几个环节给予正确的结果，查看改善后系统准确度变化。 决定集中精力来优化某些模块]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见希腊字母及其读音]]></title>
    <url>%2Farticle%2F3fcc9a30%2F</url>
    <content type="text"><![CDATA[Upper Case Letter Lower Case Letter Greek Letter Name English Equivalent Letter Name Pronounce Α α Alpha a al-fa Β β Beta b be-ta Γ γ Gamma g ga-ma Δ δ Delta d del-ta Ε ε Epsilon e ep-si-lon Ζ ζ Zeta z ze-ta Η η Eta h eh-ta Θ θ Theta th te-ta Ι ι Iota i io-ta Κ κ Kappa k ka-pa Λ λ Lambda l lam-da Μ μ Mu m m-yoo Ν ν Nu n noo Ξ ξ Xi x x-ee Ο ο Omicron o o-mee-c-ron Π π Pi p pa-yee Ρ ρ Rho r row Σ σ Sigma s sig-ma Τ τ Tau t ta-oo Υ υ Upsilon u oo-psi-lon Φ φ Phi ph f-ee Χ χ Chi ch kh-ee Ψ ψ Psi ps p-see Ω ω Omega o o-me-ga 来源： https://blog.csdn.net/justisme/article/details/82874034]]></content>
      <categories>
        <category>tiny knowledge</category>
      </categories>
      <tags>
        <tag>tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-大规模机器学习]]></title>
    <url>%2Farticle%2Fa036031c%2F</url>
    <content type="text"><![CDATA[随机梯度下降打乱数据集顺序，为了收敛更快 比起批量梯度下降 ，随机梯度下降不需要对整个样本求和后来得到梯度项，可以对单个训练样本求梯度，并且在此过程中已经开始优化参数了。在某个区域连续朝着全局最小值的方向徘徊，而不是像批量梯度下降一样直接达到全局最小值 保证收敛以及学习效率α的选择 提前计算 J ，取1000 / 5000样本的均值 红线是α小的曲线 当曲线发散时，可以减小α 当曲线震荡时，可以加大 J 样本数量 假设拥有一个连续的数据不再使用一个固定的数据集，随机梯度下降可以运用于在线学习 Mini-Batch梯度下降（微型梯度下降）在向量化过程中，Mini-Batch梯度下降可能比随机梯度下降速度、效果更优 缺点是需要确定 b 的大小。 改变学习效率 减少映射与数据并行只要是表示对训练集的求和，便可以用MapReduce 适应于多台计算机和多核电脑]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-推荐系统]]></title>
    <url>%2Farticle%2Fe1151c0b%2F</url>
    <content type="text"><![CDATA[以推荐电影为例 symbol 基于内容的推荐算法根据电影内容找到用户特征θ 本质上利用线性回归 其中 Σi:r(i,j) = 1是指 将所有电影 i 的用户评分累加起来 协同过滤（collaborative filtering）及算法不再根据电影内容，而是直接根据用户评分得到电影特征 其中 Σj:r(i,j) = 1是指 将用户 j 评分过所有电影的分值累加起来 没有 X_0 ， θ_0 同时学习几乎所有电影的特征和所有用户参数 ，最终预测所有用户对未评价电影的评分 矢量化：低秩矩阵分解 电影相似度 实施细节均值规范化（防止全未评分用户预测全0） 重新对均值进行协同过滤 编程作业cofiCostFunc.m 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051function [J, grad] = cofiCostFunc(params, Y, R, num_users, num_movies, ... num_features, lambda)%COFICOSTFUNC Collaborative filtering cost function% [J, grad] = COFICOSTFUNC(params, Y, R, num_users, num_movies, ...% num_features, lambda) returns the cost and gradient for the% collaborative filtering problem.%% Unfold the U and W matrices from paramsX = reshape(params(1:num_movies*num_features), num_movies, num_features);Theta = reshape(params(num_movies*num_features+1:end), ... num_users, num_features); % You need to return the following values correctlyJ = 0;X_grad = zeros(size(X));Theta_grad = zeros(size(Theta));% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost function and gradient for collaborative% filtering. Concretely, you should first implement the cost% function (without regularization) and make sure it is% matches our costs. After that, you should implement the % gradient and use the checkCostFunction routine to check% that the gradient is correct. Finally, you should implement% regularization.%% Notes: X - num_movies x num_features matrix of movie features% Theta - num_users x num_features matrix of user features% Y - num_movies x num_users matrix of user ratings of movies% R - num_movies x num_users matrix, where R(i, j) = 1 if the % i-th movie was rated by the j-th user%% You should set the following variables correctly:%% X_grad - num_movies x num_features matrix, containing the % partial derivatives w.r.t. to each element of X% Theta_grad - num_users x num_features matrix, containing the % partial derivatives w.r.t. to each element of Theta%J = sum(sum(((X*Theta&apos; - Y).^2) .* R)) / 2 + lambda/2*(sum(sum(Theta.^2)) + sum(sum(X.^2)));X_grad = ((X*Theta&apos; - Y).* R) * Theta + lambda * X;Theta_grad = ((X*Theta&apos; - Y).* R)&apos; * X+ lambda * Theta;% =============================================================grad = [X_grad(:); Theta_grad(:)];end]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-异常检测以及高斯分布]]></title>
    <url>%2Farticle%2F36321a51%2F</url>
    <content type="text"><![CDATA[异常检测给定样本，判断待测数据是否异常。 高斯分布也称 正态分布，面积积分=1 高斯分布的参数极大似然估计 训练集中各特征量可以不是相互独立的 Π：对一系列数的乘积 算法流程P(x)是对特征的建模 评估异常检测系统用60%带标签的数据计算p(x),20%交叉验证集 20%测试集输出结果 然后计算准确率与召回率 ，F1从而评估异常检测系统 有点类似监督学习 异常检测 vs 监督学习1 是异常的 0 是正常的 可能之后的特征跟现在不一致 使用（1）转换非高斯分布特征 （2）误差分析，或添加新特征 多高斯分布 Σ 协方差矩阵 可体现特征间的相关性 μ 均值 集中点（概率较大的位置） 运用单高斯与多高斯之间的联系 多高斯分布能够自然地捕捉特征之间的关系 而单高斯分布计算量小，适应大规模计算 所以在m&gt;n时用多高斯分布 tips: Σ 如果是奇异矩阵即不可逆，可能有两种情况： ​ （1）没有满足m&gt;n的条件 ​ （2）存在冗余特征（高度线性相关的特征、不包含额外信息） 编程作业estimateGaussian.m 12345678910111213141516171819202122232425262728293031function [mu sigma2] = estimateGaussian(X)%ESTIMATEGAUSSIAN This function estimates the parameters of a %Gaussian distribution using the data in X% [mu sigma2] = estimateGaussian(X), % The input X is the dataset with each n-dimensional data point in one row% The output is an n-dimensional vector mu, the mean of the data set% and the variances sigma^2, an n x 1 vector% % Useful variables[m, n] = size(X);% You should return these values correctlymu = zeros(n, 1);sigma2 = zeros(n, 1);% ====================== YOUR CODE HERE ======================% Instructions: Compute the mean of the data and the variances% In particular, mu(i) should contain the mean of% the data for the i-th feature and sigma2(i)% should contain variance of the i-th feature.%mu = sum(X) / m;sigma2 = sum((X-mu).^2) / m;% =============================================================end selectThreshold.m 123456789101112131415161718192021222324252627282930313233343536373839404142function [bestEpsilon bestF1] = selectThreshold(yval, pval)%SELECTTHRESHOLD Find the best threshold (epsilon) to use for selecting%outliers% [bestEpsilon bestF1] = SELECTTHRESHOLD(yval, pval) finds the best% threshold to use for selecting outliers based on the results from a% validation set (pval) and the ground truth (yval).%bestEpsilon = 0;bestF1 = 0;F1 = 0;stepsize = (max(pval) - min(pval)) / 1000;for epsilon = min(pval):stepsize:max(pval) % ====================== YOUR CODE HERE ====================== % Instructions: Compute the F1 score of choosing epsilon as the % threshold and place the value in F1. The code at the % end of the loop will compare the F1 score for this % choice of epsilon and set it to be the best epsilon if % it is better than the current choice of epsilon. % % Note: You can use predictions = (pval &lt; epsilon) to get a binary vector % of 0&apos;s and 1&apos;s of the outlier predictions predictions = (pval &lt; epsilon); tp = sum( (predictions == 1) &amp; (yval == 1) ); fp = sum( (predictions == 1) &amp; (yval == 0) ); fn = sum( (predictions == 0) &amp; (yval == 1) );; prec = tp / (tp+fp); rec = tp / (tp+fn); F1 = 2*prec*rec / (prec+rec); % ============================================================= if F1 &gt; bestF1 bestF1 = F1; bestEpsilon = epsilon; endendend]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-降维]]></title>
    <url>%2Farticle%2F8226faf3%2F</url>
    <content type="text"><![CDATA[降维运用于数据压缩,减少冗余 运用于可视化,抓住关键数据，绘制2D、3D图像 # 高维特征的问题：• 存在大量冗余的特征，降低了机器学习的性能• 数据可视化问题• 数据处理的维度灾难降维的目的：• 发掘高维数据的内在维度，得到更紧凑(低维)的数据表达 内在维度内在维度：表征数据变化的自由变量的个数 线性降维：关于内在维度的线性子空间的降维问题非线性降维：非线性子空间(流形) 线性降维将d维的原始数据线性投影到𝑑′维子空间• 通常 𝑑′ ≪ 𝑑𝑑′维子空间(投影矩阵)的选择取决于任务的要求 有监督的降维降维要求：• 降维后的不同类别数据之间的差别最大化LDA算法(Linear Discriminative Analysis)：• 最大化 类别间散度(scatter)与类别内散度的比值 无监督的降维特点：数据没有类别标签要求： 降维后保留尽可能多的原始数据的信息 PAC（主成分分析 ）principal components analysis 不是线性回归 PAC 是找到低维子空间（正交子空间 ）来对数据进行投影（对所有 x一 视同仁，没有 y）以便最小化投影误差的平方，也就是min(点与投影后的点之间的距离) 老师版教学过程最近重构性数据样本到投影点的距离最近 最大可分性数据样本的投影点之间尽可能分开 PCA的优化方法 算法过程 吴恩达版教学过程数据预处理（1）特征放缩 （2）均值标准化 计算过程Σ（大写的σ，不是求和符号） （奇异值分解）svd( )数值上更稳定 再进行协方差计算时 结果等于 eig( ) z是降维后的U ，整个过程就是最小的平方投影误差 （数学证明复杂） 主成分数量的选择 压缩重现得到压缩前数据的估计值 应用建议（1）给监督算法加速 训练集利用PCA 建立 X 到 z 的映射，分类精度不会受影响 （2）错误用法 ：防止过拟合 ​ 因为PCA丢掉了一些关键信息 （3）错误用法 ：设计机器学习系统时 不比较 使用PCA和不使用PCA的情况 线性降维的不足• 线性降维基于欧式距离• 欧式距离无法应用于非线性子空间(流形) 非线性降维“流形”是在局部与欧氏空间同胚（等价）的空间，形象的说法：“一块可弯曲的橡皮擦”。换言之，它在局部具有欧氏空间的性质，在局部才能用欧氏距离来进行距离计算。 “流形学习”是一类对分布在流形上的数据样本进行非线性降维的方法。 测地距离(Geodesic Distance)• 测地距离衡量了流形(弯曲表面)上两点之间的最短距离• 测地距离可以由两点之间的邻近点构成的最短路径来近似 等度量映射(ISOMAP)目标：降维后的样本保持原样本空间的测地距离方法：基于测地距离的“多维缩放” (MDS) 核心步骤： 计算任意两样本之间的测地距离(最短路径算法，例如： Djikstar算法) 以所有样本间的测地距离矩阵作为输入，调用MDS算法 多维缩放(MDS: Multi-dimensional Scaling)假定有m个样本,在原始空间中的距离矩阵为D ,其第i行j列的元素dist_i_j 为样本 X_i到 _j的距离。 目标： 在低维空间中保持原始数据样本之间的欧式距离 MDS的求解方法]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-Kmeans聚类算法]]></title>
    <url>%2Farticle%2F63be982%2F</url>
    <content type="text"><![CDATA[在无监督学习中，数据都是不带任何标签的 通过算法发现数据中隐藏的结构从而找到分类簇或者其他形式 k-means聚类算法 随机生成K个聚类中心 迭代以下操作，直至聚类中心不在移动，训练集的标签不再改变 簇分配 移动聚类中心 不易分离簇 优化目标J 也叫失真函数 ，畸变函数 随机初始化使得算法避免局部最优解 随机初始化状态不同，导致结果也不同，可能得到不好的局部最优。 使用多次随机初始化找到使得 J 最小的聚类中心 选取聚类数量（1）手动选择 ​ 可视化数据，观察数据分离情况 （2）“肘部法则” ​ 分别K = 1，2，3，4，5… 绘制 J 的曲线，选择拐点。但是有时很模糊~ （3）接下来数据的分类情况做一个评估 编程作业pca.m 1234567891011121314151617181920212223242526function [U, S] = pca(X)%PCA Run principal component analysis on the dataset X% [U, S, X] = pca(X) computes eigenvectors of the covariance matrix of X% Returns the eigenvectors U, the eigenvalues (on diagonal) in S%% Useful values[m, n] = size(X);% You need to return the following variables correctly.U = zeros(n);S = zeros(n);% ====================== YOUR CODE HERE ======================% Instructions: You should first compute the covariance matrix. Then, you% should use the &quot;svd&quot; function to compute the eigenvectors% and eigenvalues of the covariance matrix. %% Note: When computing the covariance matrix, remember to divide by m (the% number of examples).%sigma = X&apos; * X / m;[U,S,v] = svd(sigma);% =========================================================================end projectData.m 123456789101112131415161718192021222324252627function Z = projectData(X, U, K)%PROJECTDATA Computes the reduced data representation when projecting only %on to the top k eigenvectors% Z = projectData(X, U, K) computes the projection of % the normalized inputs X into the reduced dimensional space spanned by% the first K columns of U. It returns the projected examples in Z.%% You need to return the following variables correctly.Z = zeros(size(X, 1), K);% ====================== YOUR CODE HERE ======================% Instructions: Compute the projection of the data using only the top K % eigenvectors in U (first K columns). % For the i-th example X(i,:), the projection on to the k-th % eigenvector is given as follows:% x = X(i, :)&apos;;% projection_k = x&apos; * U(:, k);%U_redeuce = U(:,1:K);Z = X * U_redeuce;% =============================================================end recoverData.m 12345678910111213141516171819202122232425262728function X_rec = recoverData(Z, U, K)%RECOVERDATA Recovers an approximation of the original data when using the %projected data% X_rec = RECOVERDATA(Z, U, K) recovers an approximation the % original data that has been reduced to K dimensions. It returns the% approximate reconstruction in X_rec.%% You need to return the following variables correctly.X_rec = zeros(size(Z, 1), size(U, 1));% ====================== YOUR CODE HERE ======================% Instructions: Compute the approximation of the data by projecting back% onto the original space using the top K eigenvectors in U.%% For the i-th example Z(i,:), the (approximate)% recovered data for dimension j is given as follows:% v = Z(i, :)&apos;;% recovered_j = v&apos; * U(j, 1:K)&apos;;%% Notice that U(j, 1:K) is a row vector.% X_rec = Z * U(:,1:K)&apos;;% =============================================================end findClosestCentroids.m 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748function idx = findClosestCentroids(X, centroids)%FINDCLOSESTCENTROIDS computes the centroid memberships for every example% idx = FINDCLOSESTCENTROIDS (X, centroids) returns the closest centroids% in idx for a dataset X where each row is a single example. idx = m x 1 % vector of centroid assignments (i.e. each entry in range [1..K])%% Set KK = size(centroids, 1);% You need to return the following variables correctly.idx = zeros(size(X,1), 1);% ====================== YOUR CODE HERE ======================% Instructions: Go over every example, find its closest centroid, and store% the index inside idx at the appropriate location.% Concretely, idx(i) should contain the index of the centroid% closest to example i. Hence, it should be a value in the % range 1..K%% Note: You can use a for-loop over the examples to compute this.%for i = 1:size(X,1) min_dis = Inf; for j = 1:K a = X(i,:) - centroids(j,:); dis = sum(a.^2); if min_dis &gt; dis idx(i) = j; min_dis = dis; endif endforendfor%else methods%for i = 1 : size(X, 1)% for j = 1 : K% dis(j) = sum((centroids(j, :) - X(i, :)) .^ 2, 2);% end% [t, idx(i)] = min(dis); %t存储的最小值， idx存储的最小值的索引%end % =============================================================end computeCentroids.m 12345678910111213141516171819202122232425262728293031323334353637383940414243444546function centroids = computeCentroids(X, idx, K)%COMPUTECENTROIDS returns the new centroids by computing the means of the %data points assigned to each centroid.% centroids = COMPUTECENTROIDS(X, idx, K) returns the new centroids by % computing the means of the data points assigned to each centroid. It is% given a dataset X where each row is a single data point, a vector% idx of centroid assignments (i.e. each entry in range [1..K]) for each% example, and K, the number of centroids. You should return a matrix% centroids, where each row of centroids is the mean of the data points% assigned to it.%% Useful variables[m n] = size(X); %300,2% You need to return the following variables correctly.centroids = zeros(K, n); %3,2% ====================== YOUR CODE HERE ======================% Instructions: Go over every centroid and compute mean of all points that% belong to it. Concretely, the row vector centroids(i, :)% should contain the mean of the data points assigned to% centroid i.%% Note: You can use a for-loop over the centroids to compute this.%for i = 1:m for j= 1:n centroids(idx(i),j) = centroids(idx(i),j) + X(i,j); endforendforfor i = 1 : K id = (idx ==i); centroids(i,:) = centroids(i,:)./sum(id);endfor%else methods（vectorized）%for i = 1 : K% centroids(i, :) = (X&apos; * (idx == i)) / sum(idx == i); %(idx ==i)目的是将不是i值的X中对应数据变为0.% end% =============================================================end kMeansInitCentroids.m 1234567891011121314151617181920212223function centroids = kMeansInitCentroids(X, K)%KMEANSINITCENTROIDS This function initializes K centroids that are to be %used in K-Means on the dataset X% centroids = KMEANSINITCENTROIDS(X, K) returns K initial centroids to be% used with the K-Means on the dataset X%% You should return this values correctlycentroids = zeros(K, size(X, 2));% ====================== YOUR CODE HERE ======================% Instructions: You should set centroids to randomly chosen examples from% the dataset X%% Randomly reorder the indices of examplesrandidx = randperm(size(X, 1));% Take the first K examples as centroidscentroids = X(randidx(1:K), :);% =============================================================end]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexoBlog迁移与GitHub源码备份]]></title>
    <url>%2Farticle%2F67d32740%2F</url>
    <content type="text"><![CDATA[新电脑环境配置安装git/node.js1.安装git ​ https://gitforwindows.org/ ​ 一路next,安装完后 git --version查看版本（可在 git bash里面输入） 2.安装node.js 与 npm ​ https://nodejs.org/en/ (说明：LTS为长期支持版，Current为当前最新版) ​ 一路next，不过在Custom Setup这一步记得选 Add to PATH ​ 输入 node -v 和npm -v 可以查看版本（可在 git bash里面输入） ps：若是出现这种情况 “安装完成node.js 在git bash中输入node -v查询版本时报错：bash: node: command notfound，但在cmd窗口中输入node -v 能查询出版本“，重启一下系统就好了。 切换镜像(加快下载速度)：npm config set registry http://registry.npm.taobao.org/原来的地址：npm config set registry https://registry.npmjs.org/ 安装typora很好用的makeDown软件 https://www.typora.io/ 方式一：备份原机上的博客源码只需备份如下文件即可。 _config.yml .package.json .gitignore(如果有的话) themes/ source/ scffolds/ 新建 blog 文件夹存放博客 （1）在该目录下 右键选择 git bash here （2）安装hexo ​ npm install hexo-cli -g （3）存放 ​ 新博客 hexo init ​ 老博客 直接复制过来之前备份的文件 方式二：拷贝GitHub上的博客源码12#拷贝对应博客仓库远程地址，在此操作前先链接好GitHubgit clone git@github.com:Pabebezz/Pabebezz.github.io.git hexo常用插件安装（见上文“hexo环境搭建”） 拷贝成功 链接GitHub指令版 1234567891011121314151617# a.连接GitHubgit config --global user.name "yourUsername"git config --global user.email "yourUser.com"#使用SSH，保证密码的安全性，省事# b.检查本机是否存在 SSHls -al ~/.ssh# c.删除 C:\Users\***\.ssh 下所有文件 # d.生成SSHssh-keygen -t rsa -C "zezuwang@qq.com"# e.添加SSH到github网页版个人设置那块# f.检测SSH是否配置成功ssh -T git@github.com 123本来记录git config --global user.name "Pabebezz"git config --global user.email "zezuwang@qq.com" 图形界面版 创建本地工作库 生成SSH 放置SSH 遇到的问题 1234567$ ssh -T git@github.comgit@github.com's password:Permission denied, please try again.git@github.com's password:Permission denied, please try again.git@github.com's password:git@github.com: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password). 解决： 12345678Pabebe@DESKTOP-SJKD659 MINGW64 /d/hexoBlog (master)$ eval "$(ssh-agent -s)"Agent pid 252Pabebe@DESKTOP-SJKD659 MINGW64 /d/hexoBlog (master)$ ssh-addEnter passphrase for /c/Users/Pabebe/.ssh/id_rsa:(输入当时图形化创建时输入的口令)Identity added: /c/Users/Pabebe/.ssh/id_rsa (Pabebe@DESKTOP-SJKD659) 如果仍然出现要输入密码的情况，重新生成ssh，再添加公钥。若这操作不行，可能是校园网屏蔽了GitHub，只能等待了。。 成功则出现 hexo环境搭建1234567891011121314151617181920212223#安装便于自动部署到Github上的插件npm install hexo-deployer-git --save#安装atom生成插件，便于感兴趣的小伙伴们订阅npm install hexo-generator-feed --save#安装Sitemap文件生成插件$ npm install hexo-generator-sitemap --save#安装百度Sitemap文件生成插件，因为普通的Sitemap格式不符合百度的要求npm install hexo-generator-baidu-sitemap --save!-- 下面选做 --#安装博客首页生成插件npm install hexo-generator-index --save#安装tag生成插件npm install hexo-generator-tag --save#安装category生成插件npm install hexo-generator-category --save#安装归档生成插件npm install hexo-generator-archive --save#置顶文章npm uninstall hexo-generator-index --save hexo 常用命令12345678#清除生成博客界面的文件hexo clean#生成博客界面hexo g#本地查看hexo s#发布至GitHubhexo d 博客源码备份备份 在GitHub博客仓库新建分支hexo（自定义）； 在该仓库中导航栏 setting-&gt;Branches-&gt;Default branch 设置hexo为默认分支； git clone git@github.com:Pabebezz/yourUsername.github.io.git 将博客仓库clone至本地，将之前备份的文件拷贝至yourUsername.github.io 这一文件夹中。 （可选操作：删除 yourUsername.github.io 内部的文件 因我之前发布了博客，所以包含了博客发布界面） 将themes/next/(我用的是NexT主题)中的.git/删除，否则无法将主题文件夹push； 在Username.github.io文件夹git bash执行(查看分支是不是显示为Hexo) npm install hexo hexo init（新博客写上，老博客忽略该条命令） npm install npm install hexo-deployer-git 中间可能会出现警告，更新对应插件就好了（例如我的） npm upgrade core-js@3 npm upgrade ejs@2.5.5 npm upgrade ajv@^5.0.0 为加快上传速度，可将部分文件不上传至github中。 可选操作：生成“.gitignore”文件 touch .gitignore 在”.gitignore” 文件里输入你要忽略的文件夹及其文件就可以了,例如： db.json debug.log node_modules/ public/ .deploy_git/ 可以直接把.git文件放到原来的hexo文件夹中，这样就变成原有文件夹作为本地仓而不是Username.github.io文件夹。 远程仓库master分支保存静态网页，hexo分支保存源文件。 执行以下命令来提交Hexo网站源文件； git add. #添加目录下所有文件 git commit -m “提交文件” #提交至缓存区，并备注更新说明 git push origin hexo #推送更新至github远程仓库 执行hexo g -d 生成静态网页部署到github上。 日常更新同步的话先执行 git pull #拷贝远程仓库 在本地对博客修改（包括修改主题样式、发布新文章等）后,依次执行下列命令： git add. git commit -m “博客更新” git push origin hexo hexo g -d git命令环境文件推送到hexo分支，然后再hexo发布网站并推送静态文件到master分支。 多终端同步另一台电脑同样搭建好相关环境，安装好插件 1.下拉远程仓库文件 git init #创建全新本地仓库或者将已存在项目加入版本管理git remote add origin &lt;server&gt;git fetch --allgit reset --hard origin/master 2.日常更新 批处理自动部署同步 12345678910@echo offset branchName = hexoset blogPath = F:\hexoBlog::跳转至博客根目录F:cd %blogPath%::下拉远程仓库git pull::停留dos窗口pause 更新 12345678910111213141516171819::不显示所有命令@echo off::set branchName = hexo::set blogPath = D:\hexoBlog ::跳转至博客根目录::D:::cd %blogPath%::输出语句::echo "start commit"::源码提交至GitHub_privategit add .git commit -m "upgrade blog"git push origin master -f::发布博客至GitHub_public::界面并停留dos窗口::hexo clean &amp;&amp; hexo g -d &amp;&amp; pausehexo clean &amp;&amp; hexo g -d 发布完关机 123456789101112131415161718::不显示所有命令@echo off::set branchName = hexo::set blogPath = D:\hexoBlog ::跳转至博客根目录::D:::cd %blogPath%::输出语句::echo "start commit"::源码提交至GitHub_privategit add .git commit -m "upgrade blog"git push origin master -f::发布博客至GitHub_public::运行完自动关机hexo clean &amp;&amp; hexo g -d &amp;&amp; shutdown -s -t 00 hexo环境安装 12345678910111213141516171819202122::不显示所有命令::@echo off::set blogPath = D:\hexoBlog ::跳转至博客根目录::D:::cd %blogPath%npm install hexo --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-generator-feed --savenpm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --savenpm install hexo-generator-index --savenpm install hexo-generator-tag --savenpm install hexo-generator-category --savenpm install hexo-generator-archive --savenpm install hexo-abbrlink --savenpm uninstall hexo-generator-index --savenpm install hexo-generator-index-pin-top --savepause 博客源码同步到GitHub and Gitee 更改.git下的config文件的remote为下面的内容，有多少个远程仓库地址就加多少个url即可 1234567#查看远程地址git remote# 更新git push origin hexo# 出现无法push的情况，强制更新git push -f#如果上述解决方式不管用也可以输入：git pull --rebase origin master 之后再进行git push 即可。 注意：默认只能从config中的第一个url内的仓库pull代码。 博客更新到GitHub and Gitee更改博客根文件下的_config.yml文件的deploy下面repo内容，有多少个远程仓库地址就添加即可 tips:码云（gitee）上备份/做博客如何创建一个首页访问地址不带二级目录的 pages，如ipvb.gitee.io？ 答：如果你想你的 pages 首页访问地址不带二级目录，如ipvb.gitee.io，你需要建立一个与自己个性地址同名的仓库，如 https://gitee.com/ipvb 这个用户，想要创建一个自己的站点，但不想以子目录的方式访问，想以ipvb.gitee.io直接访问，那么他就可以创建一个名字为ipvb的仓库 https://gitee.com/ipvb/ipvb 部署完成后，就可以以 https://ipvb.gitee.io 进行访问了。 here —– 码云Pages问题 官方解决 参考文章使用Hexo搭建博客，备份至GitHub过程（基于网上资料的实践操作） hexo博客搭建及github备份全记录 hexo博客同步管理及迁移 码云 + Hexo 搭建个人博客 git 命令详解 使用bat脚本部署hexo到coding和github (这篇是同时拷贝coding 和 github) git技巧-项目同时推送至github和gitee]]></content>
      <categories>
        <category>gitHub</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-支持向量机]]></title>
    <url>%2Farticle%2F36b4f21c%2F</url>
    <content type="text"><![CDATA[机器学习最具有理论计算的部分，有点难the Support Vector Machine (SVM)监督学习算法 也称大间距分类器，因其设置了一个安全区域 在某些情况下比逻辑回归更适合构造非线性复杂分类器 优化目标： 最小化假设函数，一样是找到最优的θ 决策边界以最大的间距与训练集分开 C过大 对异常点敏感 会导致训练集与边界线之间的间距变小。 向量内积的性质 其中 P 是 投影，有符号的实数 || u|| 向量u的欧几里长度 就是 我们所说的“向量长度” 运用于代价函数的计算 θ的方向与决策边界90°正交 θ_0代表决策边界与Y轴的截距 为什么支持向量机会找到最大间距呢？ 如图它会使得P最大，从而min||θ||，P就是训练集在θ上面的投影， 在这样的过程中便找到了最大间距~ 核函数利用核函数K根据特征 X 和标记点 l 定义新的特征量 f 本质上 f是X与l的相似度 高斯核函数 核函数与标记点共同定义复杂非线性决策边界 越大 特征量x从标记点l离开时变化速度越大 同样不需要正则化θ_0 θT M θ 更多的是为了计算效率，稍微改变了正则化的结果 参数的选择C过大 相当于逻辑回归中 λ过小，不正则化 ，易出现过拟合；反之易出现欠拟合。 σ^2 过大 f变化过于平滑，易出现欠拟合；反之f变化剧烈易出现过拟合。 实现步骤n表示特征量的数量，m表示训练集的数量 可以在n X多 ，m少的情况 不要核函数，得到一条线性决策边界 可以在m X多 ，n少的情况 选择高斯核函数，得到一条复杂非线性决策边界 在进行高斯核函数前不用特征归一化 多类别分类类似于 逻辑回归中的“一对多” ，选择概率最大的 z tips: 逻辑回归与不带核函数的支持向量机十分类似，效果略有不同。 神经网络适合大部分问题，但速度可能被限制 编程作业gaussianKernel.m 1234567891011121314151617181920212223function sim = gaussianKernel(x1, x2, sigma)%RBFKERNEL returns a radial basis function kernel between x1 and x2% sim = gaussianKernel(x1, x2) returns a gaussian kernel between x1 and x2% and returns the value in sim% Ensure that x1 and x2 are column vectorsx1 = x1(:); x2 = x2(:);% You need to return the following variables correctly.sim = 0;% ====================== YOUR CODE HERE ======================% Instructions: Fill in this function to return the similarity between x1% and x2 computed using a Gaussian kernel with bandwidth% sigma%%sim = exp(- sum((x1-x2).^2)/2/(sigma^2));% ============================================================= end dataset3Params.m 1234567891011121314151617181920212223242526272829303132333435363738394041424344function [C, sigma] = dataset3Params(X, y, Xval, yval)%DATASET3PARAMS returns your choice of C and sigma for Part 3 of the exercise%where you select the optimal (C, sigma) learning parameters to use for SVM%with RBF kernel% [C, sigma] = DATASET3PARAMS(X, y, Xval, yval) returns your choice of C and % sigma. You should complete this function to return the optimal C and % sigma based on a cross-validation set.%% You need to return the following variables correctly.C = 1;sigma = 0.3;% ====================== YOUR CODE HERE ======================% Instructions: Fill in this function to return the optimal C and sigma% learning parameters found using the cross validation set.% You can use svmPredict to predict the labels on the cross% validation set. For example, % predictions = svmPredict(model, Xval);% will return the predictions on the cross validation set.%% Note: You can compute the prediction error using % mean(double(predictions ~= yval))%C_multi = [0.01,0.03,0.1,0.3,1,3,10,30];sigma_multi = [0.01,0.03,0.1,0.3,1,3,10,30];min_err = Inf;for i = 1:length(C_multi) for j = 1:length(sigma_multi) model= svmTrain(X, y, C_multi(i), @(x1, x2) gaussianKernel(x1, x2, sigma_multi(j))); predictions = svmPredict(model, Xval); err = mean(double(predictions ~= yval)); if min_err &gt; err C = C_multi(i); sigma = sigma_multi(j); min_err = err; endif endforendfor% =========================================================================end processEmail.m 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122function word_indices = processEmail(email_contents)%PROCESSEMAIL preprocesses a the body of an email and%returns a list of word_indices % word_indices = PROCESSEMAIL(email_contents) preprocesses % the body of an email and returns a list of indices of the % words contained in the email. %% Load VocabularyvocabList = getVocabList();% Init return valueword_indices = [];% ========================== Preprocess Email ===========================% Find the Headers ( \n\n and remove )% Uncomment the following lines if you are working with raw emails with the% full headers% hdrstart = strfind(email_contents, ([char(10) char(10)]));% email_contents = email_contents(hdrstart(1):end);% Lower caseemail_contents = lower(email_contents);% Strip all HTML% Looks for any expression that starts with &lt; and ends with &gt; and replace% and does not have any &lt; or &gt; in the tag it with a spaceemail_contents = regexprep(email_contents, &apos;&lt;[^&lt;&gt;]+&gt;&apos;, &apos; &apos;);% Handle Numbers% Look for one or more characters between 0-9email_contents = regexprep(email_contents, &apos;[0-9]+&apos;, &apos;number&apos;);% Handle URLS% Look for strings starting with http:// or https://email_contents = regexprep(email_contents, ... &apos;(http|https)://[^\s]*&apos;, &apos;httpaddr&apos;);% Handle Email Addresses% Look for strings with @ in the middleemail_contents = regexprep(email_contents, &apos;[^\s]+@[^\s]+&apos;, &apos;emailaddr&apos;);% Handle $ signemail_contents = regexprep(email_contents, &apos;[$]+&apos;, &apos;dollar&apos;);% ========================== Tokenize Email ===========================% Output the email to screen as wellfprintf(&apos;\n==== Processed Email ====\n\n&apos;);% Process filel = 0;while ~isempty(email_contents) % Tokenize and also get rid of any punctuation [str, email_contents] = ... strtok(email_contents, ... [&apos; @$/#.-:&amp;*+=[]?!()&#123;&#125;,&apos;&apos;&quot;&gt;_&lt;;%&apos; char(10) char(13)]); % Remove any non alphanumeric characters str = regexprep(str, &apos;[^a-zA-Z0-9]&apos;, &apos;&apos;); % Stem the word % (the porterStemmer sometimes has issues, so we use a try catch block) try str = porterStemmer(strtrim(str)); catch str = &apos;&apos;; continue; end; % Skip the word if it is too short if length(str) &lt; 1 continue; end % Look up the word in the dictionary and add to word_indices if % found % ====================== YOUR CODE HERE ====================== % Instructions: Fill in this function to add the index of str to % word_indices if it is in the vocabulary. At this point % of the code, you have a stemmed word from the email in % the variable str. You should look up str in the % vocabulary list (vocabList). If a match exists, you % should add the index of the word to the word_indices % vector. Concretely, if str = &apos;action&apos;, then you should % look up the vocabulary list to find where in vocabList % &apos;action&apos; appears. For example, if vocabList&#123;18&#125; = % &apos;action&apos;, then, you should add 18 to the word_indices % vector (e.g., word_indices = [word_indices ; 18]; ). % % Note: vocabList&#123;idx&#125; returns a the word with index idx in the % vocabulary list. % % Note: You can use strcmp(str1, str2) to compare two strings (str1 and % str2). It will return 1 only if the two strings are equivalent. % for i = 1:length(vocabList) if strcmp(str,vocabList(i)) == 1 word_indices = [word_indices ; i]; endif endfor % ============================================================= % Print to screen, ensuring that the output lines are not too long if (l + length(str) + 1) &gt; 78 fprintf(&apos;\n&apos;); l = 0; end fprintf(&apos;%s &apos;, str); l = l + length(str) + 1;end% Print footerfprintf(&apos;\n\n=========================\n&apos;);end emailFeatures.m 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859function x = emailFeatures(word_indices)%EMAILFEATURES takes in a word_indices vector and produces a feature vector%from the word indices% x = EMAILFEATURES(word_indices) takes in a word_indices vector and % produces a feature vector from the word indices. % Total number of words in the dictionaryn = 1899;% You need to return the following variables correctly.x = zeros(n, 1);% ====================== YOUR CODE HERE ======================% Instructions: Fill in this function to return a feature vector for the% given email (word_indices). To help make it easier to % process the emails, we have have already pre-processed each% email and converted each word in the email into an index in% a fixed dictionary (of 1899 words). The variable% word_indices contains the list of indices of the words% which occur in one email.% % Concretely, if an email has the text:%% The quick brown fox jumped over the lazy dog.%% Then, the word_indices vector for this text might look % like:% % 60 100 33 44 10 53 60 58 5%% where, we have mapped each word onto a number, for example:%% the -- 60% quick -- 100% ...%% (note: the above numbers are just an example and are not the% actual mappings).%% Your task is take one such word_indices vector and construct% a binary feature vector that indicates whether a particular% word occurs in the email. That is, x(i) = 1 when word i% is present in the email. Concretely, if the word &apos;the&apos; (say,% index 60) appears in the email, then x(60) = 1. The feature% vector should look like:%% x = [ 0 0 0 0 1 0 0 0 ... 0 0 0 0 1 ... 0 0 0 1 0 ..];%%for i=1:length(word_indices) x(word_indices(i)) = 1; endfor% ========================================================================= end]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-评价方法]]></title>
    <url>%2Farticle%2Ff46160db%2F</url>
    <content type="text"><![CDATA[模型选择60% 训练集 20%验证集 20%测试集 训练集计算误差，利用交叉验证集选择维数，泛化能力 偏差与方差偏差（与训练集数据拟合程度），方差（与验证集数据拟合程度） 项数少 ：高偏差，高方差 项数多：低偏差，高方差 正则化：防止过拟合 lambda 小 ：低偏差，高方差 lambda大：高偏差，高方差 学习曲线当模型高偏差时，加大训练集无用。 当模型高方差时，加大训练集可能有用。 大型神经网络比小型神经网络性能要好 设计复杂学习系统 从简单的算法开始 绘制学习曲线 误差分析（验证集） 误差评估偏斜类 skewed class (其中一类占比巨大。不对称性分类) 查准率 = 真的 / 预测真的 召回率 = 真的 / （实际是真的，预测真或假） 平衡查准率与召回率F_1的值 综合： 机器学习数据大量数据 适合 大量参数的模型 编程作业linearRegCostFunction.m 1234567891011121314151617181920212223242526272829303132function [J, grad] = linearRegCostFunction(X, y, theta, lambda)%LINEARREGCOSTFUNCTION Compute cost and gradient for regularized linear %regression with multiple variables% [J, grad] = LINEARREGCOSTFUNCTION(X, y, theta, lambda) computes the % cost of using theta as the parameter for linear regression to fit the % data points in X and y. Returns the cost in J and the gradient in grad% Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost and gradient of regularized linear % regression for a particular choice of theta.%% You should set J to the cost and grad to the gradient.%h = X * theta;J = sum((h-y).^2)/2/m+ lambda/2/m*sum(theta(2:end).^2);grad = X&apos; * (h-y)/m + lambda/m*theta;grad(1) = grad(1) - lambda/m*theta(1);% =========================================================================grad = grad(:);end learningCurve.m 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566function [error_train, error_val] = ... learningCurve(X, y, Xval, yval, lambda)%LEARNINGCURVE Generates the train and cross validation set errors needed %to plot a learning curve% [error_train, error_val] = ...% LEARNINGCURVE(X, y, Xval, yval, lambda) returns the train and% cross validation set errors for a learning curve. In particular, % it returns two vectors of the same length - error_train and % error_val. Then, error_train(i) contains the training error for% i examples (and similarly for error_val(i)).%% In this function, you will compute the train and test errors for% dataset sizes from 1 up to m. In practice, when working with larger% datasets, you might want to do this in larger intervals.%% Number of training examplesm = size(X, 1);% You need to return these values correctlyerror_train = zeros(m, 1);error_val = zeros(m, 1);% ====================== YOUR CODE HERE ======================% Instructions: Fill in this function to return training errors in % error_train and the cross validation errors in error_val. % i.e., error_train(i) and % error_val(i) should give you the errors% obtained after training on i examples.%% Note: You should evaluate the training error on the first i training% examples (i.e., X(1:i, :) and y(1:i)).%% For the cross-validation error, you should instead evaluate on% the _entire_ cross validation set (Xval and yval).%% Note: If you are using your cost function (linearRegCostFunction)% to compute the training and cross validation error, you should % call the function with the lambda argument set to 0. % Do note that you will still need to use lambda when running% the training to obtain the theta parameters.%% Hint: You can loop over the examples with the following:%% for i = 1:m% % Compute train/cross validation errors using training examples % % X(1:i, :) and y(1:i), storing the result in % % error_train(i) and error_val(i)% ....% % end%% ---------------------- Sample Solution ----------------------for i = 1:m theta = trainLinearReg(X(1:i, :), y(1:i),lambda); error_train(i) = linearRegCostFunction(X(1:i, :), y(1:i),theta,0); error_val(i) = linearRegCostFunction(Xval, yval,theta,0); end% -------------------------------------------------------------% =========================================================================end polyFeatures.m 12345678910111213141516171819202122232425function [X_poly] = polyFeatures(X, p)%POLYFEATURES Maps X (1D vector) into the p-th power% [X_poly] = POLYFEATURES(X, p) takes a data matrix X (size m x 1) and% maps each example into its polynomial features where% X_poly(i, :) = [X(i) X(i).^2 X(i).^3 ... X(i).^p];%% You need to return the following variables correctly.X_poly = zeros(numel(X), p);% ====================== YOUR CODE HERE ======================% Instructions: Given a vector X, return a matrix X_poly where the p-th % column of X contains the values of X to the p-th power.%% for i = 1:numel(X) for j = 1:p X_poly(i,j) = X(i).^j;endfor% =========================================================================end validationCurve.m 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152function [lambda_vec, error_train, error_val] = ... validationCurve(X, y, Xval, yval)%VALIDATIONCURVE Generate the train and validation errors needed to%plot a validation curve that we can use to select lambda% [lambda_vec, error_train, error_val] = ...% VALIDATIONCURVE(X, y, Xval, yval) returns the train% and validation errors (in error_train, error_val)% for different values of lambda. You are given the training set (X,% y) and validation set (Xval, yval).%% Selected values of lambda (you should not change this)lambda_vec = [0 0.001 0.003 0.01 0.03 0.1 0.3 1 3 10]&apos;;% You need to return these variables correctly.error_train = zeros(length(lambda_vec), 1);error_val = zeros(length(lambda_vec), 1);% ====================== YOUR CODE HERE ======================% Instructions: Fill in this function to return training errors in % error_train and the validation errors in error_val. The % vector lambda_vec contains the different lambda parameters % to use for each calculation of the errors, i.e, % error_train(i), and error_val(i) should give % you the errors obtained after training with % lambda = lambda_vec(i)%% Note: You can loop over lambda_vec with the following:%% for i = 1:length(lambda_vec)% lambda = lambda_vec(i);% % Compute train / val errors when training linear % % regression with regularization parameter lambda% % You should store the result in error_train(i)% % and error_val(i)% ....% % end%%for i = 1:length(lambda_vec) lambda = lambda_vec(i); theta = trainLinearReg(X, y,lambda); error_train(i) = linearRegCostFunction(X, y,theta,0); error_val(i) = linearRegCostFunction(Xval, yval,theta,0); endfor% =========================================================================end]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-神经网络（后向传播）]]></title>
    <url>%2Farticle%2F336e6e71%2F</url>
    <content type="text"><![CDATA[symbolsL ： 神经网络的层数 S_l ： 第 l 层神经网络的神经元数 K ：分类个数 代价函数从逻辑回归算法中衍生到神经网络 每个 logistic regression algorithm 的代价函数 然后 K次输出 最后求和。 不对偏置单元(bias)进行正则化操作，即含X_0的项 步骤定义：误差项 delta(l)_j 表示第 l 层的第 j 的激活值与y之间的误差。 不严谨地说 ：在忽略lambda(正则项)或lambda=0，误差项 = 相应的代价项的偏导 由此可以计算出所需参数。 综上： ▲是大写的delta 更好地理解 delta(l)_j 其实是代价函数关于Z(l)__j的偏导，其值只计算隐藏单元而不计算偏置单元。 参数矩阵与向量 公式中参数的形式均为向量，所以需要将矩阵转化为向量形式。 矩阵-&gt;向量： a = [ b1(:); b2(:); b3(:) ] 向量-&gt;矩阵： b1 = reshape(a(1:110),10,11); %向量前110个数组成10行11列的矩阵。 梯度检测（1）梯度估计 （2）J(θ)偏导数 （3）检查J(θ)偏导数 是否等于 反向传播的导数，近似相等则反向传播正确实现 综合检测步骤： 注意在正确之后，关闭梯度检测再进行训练分类器。 θ随机初始化防止 θ值相同，限制学习模型的特征输入 总结训练神经网络 （1）选择网络架构： 输入特征项数，输出分类项 ，隐藏层（1个或者 多个但每层隐藏单元相同） （2）随机初始化θ （3）完成前向传播算法得到h_θ(x) （4）完成代价函数 J(θ) 的计算 ​ (5) 完成反向传播算法得到 J关于θ的偏导数 （6）遍历训练集，运行前向传播算法和反向传播算法，得到每层激活项a(l)与delta(l) （7）梯度检查 （8）高级优化算法与反向传播算法结合计算min J. 编程作业nnCostFunction.m 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121function [J grad] = nnCostFunction(nn_params, ... input_layer_size, ... hidden_layer_size, ... num_labels, ... X, y, lambda)%NNCOSTFUNCTION Implements the neural network cost function for a two layer%neural network which performs classification% [J grad] = NNCOSTFUNCTON(nn_params, hidden_layer_size, num_labels, ...% X, y, lambda) computes the cost and gradient of the neural network. The% parameters for the neural network are &quot;unrolled&quot; into the vector% nn_params and need to be converted back into the weight matrices. % % The returned parameter grad should be a &quot;unrolled&quot; vector of the% partial derivatives of the neural network.%% Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices% for our 2 layer neural networkTheta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)), ... hidden_layer_size, (input_layer_size + 1));Theta2 = reshape(nn_params((1 + (hidden_layer_size * (input_layer_size + 1))):end), ... num_labels, (hidden_layer_size + 1));% Setup some useful variablesm = size(X, 1); % You need to return the following variables correctly J = 0;Theta1_grad = zeros(size(Theta1));Theta2_grad = zeros(size(Theta2));% ====================== YOUR CODE HERE ======================% Instructions: You should complete the code by working through the% following parts.%% Part 1: Feedforward the neural network and return the cost in the% variable J. After implementing Part 1, you can verify that your% cost function computation is correct by verifying the cost% computed in ex4.m%将y扩展为5000*10的0/1表示形式expend = eye(num_labels);%disp(expend);disp(&quot;\n&quot;);%disp(y(500:505,:));disp(&quot;\n&quot;);y = expend(y,:);%disp(y(500:505,:));one = ones(m,1);a1 = [one,X];z2 = Theta1 * a1&apos; ;a2 = sigmoid(z2);a2 = [one,a2&apos;];z3 = a2 * Theta2&apos;;h = sigmoid(z3);J = sum(sum((y-1).*log(1-h) - y.*log(h))) / m ;reg = lambda/2/m * (sum(sum(Theta1(:,2:end).^2)) + sum(sum(Theta2(:,2:end).^2)));%reg = lambda/2/m *(sum(sum(Theta1.^2)) + sum(sum(Theta2.^2))% - sum(sum(Theta1(:,1).^2)) + sum(sum(Theta2(:,1).^2)));J = J + reg;%% Part 2: Implement the backpropagation algorithm to compute the gradients% Theta1_grad and Theta2_grad. You should return the partial derivatives of% the cost function with respect to Theta1 and Theta2 in Theta1_grad and% Theta2_grad, respectively. After implementing Part 2, you can check% that your implementation is correct by running checkNNGradients%% Note: The vector y passed into the function is a vector of labels% containing values from 1..K. You need to map this vector into a % binary vector of 1&apos;s and 0&apos;s to be used with the neural network% cost function.%% Hint: We recommend implementing backpropagation using a for-loop% over the training examples if you are implementing it for the % first time.delta3 = h - y;delta2 = delta3 * Theta2 ;delta2 = delta2(:,2:end);delta2 = delta2 .* sigmoidGradient(z2)&apos;;D1 = zeros(size(Theta1));D2 = zeros(size(Theta2));D1 = D1 + delta2&apos; * a1;D2 = D2 + delta3&apos; * a2;%% Part 3: Implement regularization with the cost function and gradients.%% Hint: You can implement this around the code for% backpropagation. That is, you can compute the gradients for% the regularization separately and then add them to Theta1_grad% and Theta2_grad from Part 2.%Theta1_grad = ( D1 + lambda * Theta1 ) / m;Theta2_grad = ( D2 + lambda * Theta2 ) / m;Theta1_grad(:,1) = Theta1_grad(:,1) - lambda / m * Theta1(:,1);Theta2_grad(:,1) = Theta2_grad(:,1) - lambda / m * Theta2(:,1);%找到每个X最大的估计数字，h归一化% maxValue = max(h,[],2);% h = (h &gt;= maxValue);% -------------------------------------------------------------% =========================================================================% Unroll gradientsgrad = [Theta1_grad(:) ; Theta2_grad(:)];end sigmoidGradient.m 1234567891011121314151617181920function g = sigmoidGradient(z)%SIGMOIDGRADIENT returns the gradient of the sigmoid function%evaluated at z% g = SIGMOIDGRADIENT(z) computes the gradient of the sigmoid function% evaluated at z. This should work regardless if z is a matrix or a% vector. In particular, if z is a vector or matrix, you should return% the gradient for each element.g = zeros(size(z));% ====================== YOUR CODE HERE ======================% Instructions: Compute the gradient of the sigmoid function evaluated at% each value of z (z can be a matrix, vector or scalar).g = sigmoid(z) .* (1-sigmoid(z));% =============================================================end randInitializeWeights.m 1234567891011121314151617181920212223242526272829function W = randInitializeWeights(L_in, L_out)%RANDINITIALIZEWEIGHTS Randomly initialize the weights of a layer with L_in%incoming connections and L_out outgoing connections% W = RANDINITIALIZEWEIGHTS(L_in, L_out) randomly initializes the weights % of a layer with L_in incoming connections and L_out outgoing % connections. %% Note that W should be set to a matrix of size(L_out, 1 + L_in) as% the first column of W handles the &quot;bias&quot; terms%% You need to return the following variables correctly W = zeros(L_out, 1 + L_in);% ====================== YOUR CODE HERE ======================% Instructions: Initialize W randomly so that we break the symmetry while% training the neural network.%% Note: The first column of W corresponds to the parameters for the bias unit%epsilon_init = 0.12;W = rand(L_out, 1 + L_in)*2*epsilon_init - epsilon_init;% =========================================================================end]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-神经网络（前向传播）]]></title>
    <url>%2Farticle%2F4640c193%2F</url>
    <content type="text"><![CDATA[原因适应于非线性假设 sigmoid（logistic）activation function : 激活函数 指代 g(z) X_0 偏置单元，值永远是1 θ 代表 参数或权重 架构输入层-》隐藏层（不止一个）-》输出层 符号： a(i)_j表示 第i层，第j个神经元或单元的激活项(由具体的神经元计算并输出的值) θ(i) 表示 从第i层到第i+1层之间映射的权重矩阵 偏置单元省略没有写。 如果第 j 层中有 S_j 个单元，第 j+1 层中有 S_j+1 个单元，则θ(j)的维数： S_j+1*（ S_j + 1） 前向传播（向量化）依次计算激活项，从输入项到输出项的过程。 下面是它的向量化实现 最后一层隐藏层到输出层 类似于 逻辑回归 多类别分类（一对多分类的扩展） 编程作业displayData.m 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859function [h, display_array] = displayData(X, example_width)%DISPLAYDATA Display 2D data in a nice grid% [h, display_array] = DISPLAYDATA(X, example_width) displays 2D data% stored in X in a nice grid. It returns the figure handle h and the % displayed array if requested.% Set example_width automatically if not passed inif ~exist(&apos;example_width&apos;, &apos;var&apos;) || isempty(example_width) example_width = round(sqrt(size(X, 2)));end% Gray Imagecolormap(gray);% Compute rows, cols[m n] = size(X);example_height = (n / example_width);% Compute number of items to displaydisplay_rows = floor(sqrt(m));display_cols = ceil(m / display_rows);% Between images paddingpad = 1;% Setup blank displaydisplay_array = - ones(pad + display_rows * (example_height + pad), ... pad + display_cols * (example_width + pad));% Copy each example into a patch on the display arraycurr_ex = 1;for j = 1:display_rows for i = 1:display_cols if curr_ex &gt; m, break; end % Copy the patch % Get the max value of the patch max_val = max(abs(X(curr_ex, :))); display_array(pad + (j - 1) * (example_height + pad) + (1:example_height), ... pad + (i - 1) * (example_width + pad) + (1:example_width)) = ... reshape(X(curr_ex, :), example_height, example_width) / max_val; curr_ex = curr_ex + 1; end if curr_ex &gt; m, break; endend% Display Imageh = imagesc(display_array, [-1 1]);% Do not show axisaxis image offdrawnow;end lrCostFunction.m 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152function [J, grad] = lrCostFunction(theta, X, y, lambda)%LRCOSTFUNCTION Compute cost and gradient for logistic regression with %regularization% J = LRCOSTFUNCTION(theta, X, y, lambda) computes the cost of using% theta as the parameter for regularized logistic regression and the% gradient of the cost w.r.t. to the parameters. % Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost of a particular choice of theta.% You should set J to the cost.% Compute the partial derivatives and set grad to the partial% derivatives of the cost w.r.t. each parameter in theta%% Hint: The computation of the cost function and gradients can be% efficiently vectorized. For example, consider the computation%% sigmoid(X * theta)%% Each row of the resulting matrix will contain the value of the% prediction for that example. You can make use of this to vectorize% the cost function and gradient computations. %% Hint: When computing the gradient of the regularized cost function, % there&apos;re many possible vectorized solutions, but one solution% looks like:% grad = (unregularized gradient for logistic regression)% temp = theta; % temp(1) = 0; % because we don&apos;t add anything for j = 0 % grad = grad + YOUR_CODE_HERE (using the temp variable)%h = sigmoid(X * theta);J = sum((y-1)&apos; *log(1-h) - y&apos; *log(h))/m + lambda/2/m * (sum(theta.^2) - theta(1)^2);grad = (X&apos;*(h-y) + theta*lambda) / m;grad(1) = grad(1) - lambda/m*theta(1);% =============================================================grad = grad(:);end oneVsAll.m 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364function [all_theta] = oneVsAll(X, y, num_labels, lambda)%ONEVSALL trains multiple logistic regression classifiers and returns all%the classifiers in a matrix all_theta, where the i-th row of all_theta %corresponds to the classifier for label i% [all_theta] = ONEVSALL(X, y, num_labels, lambda) trains num_labels% logistic regression classifiers and returns each of these classifiers% in a matrix all_theta, where the i-th row of all_theta corresponds % to the classifier for label i% Some useful variablesm = size(X, 1);n = size(X, 2);% You need to return the following variables correctly all_theta = zeros(num_labels, n + 1);% Add ones to the X data matrixX = [ones(m, 1) X];% ====================== YOUR CODE HERE ======================% Instructions: You should complete the following code to train num_labels% logistic regression classifiers with regularization% parameter lambda. %% Hint: theta(:) will return a column vector.%% Hint: You can use y == c to obtain a vector of 1&apos;s and 0&apos;s that tell you% whether the ground truth is true/false for this class.%% Note: For this assignment, we recommend using fmincg to optimize the cost% function. It is okay to use a for-loop (for c = 1:num_labels) to% loop over the different classes.%% fmincg works similarly to fminunc, but is more efficient when we% are dealing with large number of parameters.%% Example Code for fmincg:%% % Set Initial theta% initial_theta = zeros(n + 1, 1);% % % Set options for fminunc% options = optimset(&apos;GradObj&apos;, &apos;on&apos;, &apos;MaxIter&apos;, 50);% % % Run fmincg to obtain the optimal theta% % This function will return theta and the cost % [theta] = ...% fmincg (@(t)(lrCostFunction(t, X, (y == c), lambda)), ...% initial_theta, options);%for c = 1:num_labels initial_theta = zeros(n+1 , 1); options = optimset(&apos;GradObj&apos;, &apos;on&apos;, &apos;MaxIter&apos;, 50); initial_theta = fmincg(@(t)(lrCostFunction(t, X, (y==c), lambda)),initial_theta,options); all_theta(c,:) = initial_theta&apos;;end% =========================================================================end predict.m 1234567891011121314151617181920212223242526272829303132333435363738394041function p = predict(Theta1, Theta2, X)%PREDICT Predict the label of an input given a trained neural network% p = PREDICT(Theta1, Theta2, X) outputs the predicted label of X given the% trained weights of a neural network (Theta1, Theta2)% Useful valuesm = size(X, 1);num_labels = size(Theta2, 1);% You need to return the following variables correctly p = zeros(size(X, 1), 1);% ====================== YOUR CODE HERE ======================% Instructions: Complete the following code to make predictions using% your learned neural network. You should set p to a % vector containing labels between 1 to num_labels.%% Hint: The max function might come in useful. In particular, the max% function can also return the index of the max element, for more% information see &apos;help max&apos;. If your examples are in rows, then, you% can use max(A, [], 2) to obtain the max for each row.%one = ones(size(X,1),1);addX = [one,X];z = addX * Theta1&apos;;a = sigmoid(z);addA = [one,a];h = addA * Theta2&apos;;maxRow = zeros(size(X,1) ,1);for i =1:m [maxRow(i), p(i)] = max(h(i,:));endfor% =========================================================================end predictOneVsAll.m 123456789101112131415161718192021222324252627282930313233343536373839404142434445function p = predictOneVsAll(all_theta, X)%PREDICT Predict the label for a trained one-vs-all classifier. The labels %are in the range 1..K, where K = size(all_theta, 1). % p = PREDICTONEVSALL(all_theta, X) will return a vector of predictions% for each example in the matrix X. Note that X contains the examples in% rows. all_theta is a matrix where the i-th row is a trained logistic% regression theta vector for the i-th class. You should set p to a vector% of values from 1..K (e.g., p = [1; 3; 1; 2] predicts classes 1, 3, 1, 2% for 4 examples) m = size(X, 1);num_labels = size(all_theta, 1);% You need to return the following variables correctly p = zeros(size(X, 1), 1);% Add ones to the X data matrixX = [ones(m, 1) X];% ====================== YOUR CODE HERE ======================% Instructions: Complete the following code to make predictions using% your learned logistic regression parameters (one-vs-all).% You should set p to a vector of predictions (from 1 to% num_labels).%% Hint: This code can be done all vectorized using the max function.% In particular, the max function can also return the index of the % max element, for more information see &apos;help max&apos;. If your examples % are in rows, then, you can use max(A, [], 2) to obtain the max % for each row.% % size(h) = 50000*10 h保存的是预测5000个数据所属label的概率情况 h = sigmoid(X * all_theta&apos;);rowMax = zeros(size(X,1),1);%这是取每行(最后一个参数：2)最大值 ps:取每列(最后一个参数：1)最大值%rowMax = max(h,[],2);%取每行最大值的索引值for i = 1:m [rowMax(i), p(i)] = max(h(i,:));end% ========================================================================= sigmoid.m 123456function g = sigmoid(z)%SIGMOID Compute sigmoid functoon% J = SIGMOID(z) computes the sigmoid of z.g = 1.0 ./ (1.0 + exp(-z));end]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-逻辑回归]]></title>
    <url>%2Farticle%2Fa0a1582a%2F</url>
    <content type="text"><![CDATA[sigmoid function also logistic function “分类问题”–逻辑回归算法 决策边界 不是训练集的属性，而是假设本身和其参数的属性 计算的是 属于1 的概率 cost function 适用于梯度下降的变形式： 综上： 来源于统计学的极大似然估计法—-凸函数 高级优化 使用库~直接调用，适用于大型的机器学习 多元分类：”一对多“分类采用多个分类器，针对其中一种情况进行训练 拟合泛化 ：一个假设模型应用到新样本的能力~ 欠拟合/过拟合 高方差 减少特征变量但是同时舍弃了一些有用信息 正则化简化假设模型，更少的倾向过拟合 线性回归正则化后一项是正则化项 1不惩罚 θ_0 （1）梯度下降： （2）正则化方程： 虽然octave在一般的正则化方程中 pinv() 可能会给 奇异矩阵 可逆结果，但是这不能泛化。但经过正则化 正则方程后，一定是可逆的。 逻辑回归正则化1不惩罚 θ_0 注意：虽然看起来和 线性回归一样，但是 h(x)不同 （3）高级算法： fminunc() :函数在无约束条件下的最小值 不需要写任何循环，也无需设置循环；只需要提供一个计算“代价”和“梯度”的函数，就返回正确的优化参数、代价值、θ tips: octave下标从1开始。。 编程作业costFunction.m 123456789101112131415161718192021222324252627282930function [J, grad] = costFunction(theta, X, y)%COSTFUNCTION Compute cost and gradient for logistic regression% J = COSTFUNCTION(theta, X, y) computes the cost of using theta as the% parameter for logistic regression and the gradient of the cost% w.r.t. to the parameters.% Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost of a particular choice of theta.% You should set J to the cost.% Compute the partial derivatives and set grad to the partial% derivatives of the cost w.r.t. each parameter in theta%% Note: grad should have the same dimensions as theta%h = sigmoid(X * theta);J = sum( log(1-h)&apos;*(y-1) - log(h)&apos;*y )/m;grad = X&apos; * (h - y)/m;% =============================================================end costFunctionReg.m 123456789101112131415161718192021222324252627282930313233343536function [J, grad] = costFunctionReg(theta, X, y, lambda)%COSTFUNCTIONREG Compute cost and gradient for logistic regression with regularization% J = COSTFUNCTIONREG(theta, X, y, lambda) computes the cost of using% theta as the parameter for regularized logistic regression and the% gradient of the cost w.r.t. to the parameters. % Initialize some useful valuesm = length(y); % number of training examples% You need to return the following variables correctly J = 0;grad = zeros(size(theta));% ====================== YOUR CODE HERE ======================% Instructions: Compute the cost of a particular choice of theta.% You should set J to the cost.% Compute the partial derivatives and set grad to the partial% derivatives of the cost w.r.t. each parameter in thetah = sigmoid(X * theta);J = sum( log(1-h)&apos;*(y-1) - log(h)&apos;*y )/m + lambda/2/m * (sum(theta.^2)- theta(1)^2);for j = 1:length(theta) if j == 1 grad(j)= ((h - y)&apos; * X(:,j)) /m; else grad(j) = ( (h - y)&apos; * X(:,j) + theta(j)*lambda) / m; end%另一种方法：%grad = X&apos; * (h - y)/m + theta*lambda / m; %grad(1) = grad(1) -theta(1)*lambda / m;% =============================================================end plotData.m 123456789101112131415161718192021222324function plotData(X, y)%PLOTDATA Plots the data points X and y into a new figure % PLOTDATA(x,y) plots the data points with + for the positive examples% and o for the negative examples. X is assumed to be a Mx2 matrix.% Create New Figurefigure; hold on;% ====================== YOUR CODE HERE ======================% Instructions: Plot the positive and negative examples on a% 2D plot, using the option &apos;k+&apos; for the positive% examples and &apos;ko&apos; for the negative examples.%%pos = find(y == 1);neg = find(y == 0);%plot(X(pos,1), X(pos,2), &apos;k+&apos;, &apos;LineWidth&apos;, 2, &apos;MarkerSize&apos;, 7);plot(X(neg,1),X(neg,2), &apos;ko&apos;, &apos;markerFaceColor&apos;, &apos;y&apos;, &apos;MarkerSize&apos;, 7);% =========================================================================hold off;end predict.m 123456789101112131415161718192021222324252627282930313233343536function p = predict(theta, X)%PREDICT Predict whether the label is 0 or 1 using learned logistic %regression parameters theta% p = PREDICT(theta, X) computes the predictions for X using a % threshold at 0.5 (i.e., if sigmoid(theta&apos;*x) &gt;= 0.5, predict 1)m = size(X, 1); % Number of training examples% You need to return the following variables correctlyp = zeros(m, 1);% ====================== YOUR CODE HERE ======================% Instructions: Complete the following code to make predictions using% your learned logistic regression parameters. % You should set p to a vector of 0&apos;s and 1&apos;s%p = sigmoid(X * theta);rows = size(p,1);cols = size(p,2);for i = 1:rows for j = 1:cols if p(i,j) &lt; 0.5 p(i,j) = 0; else p(i,j) = 1; endend%p = sigmoid(X*theta)&gt;0.5;% =========================================================================end sigmoid.m 1234567891011121314151617181920function g = sigmoid(z)%SIGMOID Compute sigmoid function% g = SIGMOID(z) computes the sigmoid of z.% You need to return the following variables correctly g = zeros(size(z));% ====================== YOUR CODE HERE ======================% Instructions: Compute the sigmoid of each value of z (z can be a matrix,% vector or scalar).%rows = size(z)(1);%cols = size(z)(2);%if rows == 1 &amp;&amp; cols == 1 one = ones(size(z)); g = one ./ (1 + exp(-z));% =============================================================end]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-知识点]]></title>
    <url>%2Farticle%2Fafd3b944%2F</url>
    <content type="text"><![CDATA[分类监督学习 supervised learning“right answer” for each of our examples in the data regression(回归) ：predict a real-valued output classification(分类)：predict discrete-valued output (类似于0、1问题) 无监督学习 unsupervise learning数据未标记，类别未知。 计算机自己根据样本间的相似性对样本集进行分类 如何看懂一篇机器学习论文 symbolsm = number of training examples x’s = “input” variable / features y’s = “output”variable / “target” variable (x,y) - one training example (x^(i) , y^(i)) - the i training example ( i 表示索引，不是幂) hypothesis（假设，机器学习术语— 输出函数） univariate 单因素 编程环境Octave 最好是.exe 正常安装，不然其他还需要编译。 官网：http://www.gnu.org/software/octave/#install 镜像：https://mirrors.kernel.org/gnu/octave/ Octave语法疑点对 Octave中 A*B A.*B 这两种矩阵相乘做一个理解： 举例： a = [1 2 3;4 5 6] b = [1 1 1;1 1 1] c = [1 ; 1; 1] 分别做 a*b a.*b a*c a.*c ,结果如图 然后更换a、b的值，结果如下 可以得出： A.*B 是 矩阵A中的元素 × B中对应位置的元素 ​ A*B 是 线性代数中矩阵相乘的实现，即要满足 A的列数 = B的行数 ​ 补充：A‘ * B 只是A的转置矩阵再与B相乘。]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-线性回归]]></title>
    <url>%2Farticle%2F19883263%2F</url>
    <content type="text"><![CDATA[单变量线性回归symbols m = number of training examples x’s = “input” variable / features y’s = “output”variable / “target” variable (x,y) - one training example (x^(i) , y^(i)) - the i training example ( i 表示索引，不是幂) hypothesis（假设，机器学习术语— 输出函数） univariate 单因素 代价函数 调整参数 最小化代价函数—– h(x)-y ，拟合数据 contour figure /plot (等高线图) 梯度下降（gradient descent）似乎只找到局部最优解 a:=b 赋值 a = b 真假判断 converge(收敛) diverge(发散) 线性回归的代价函数总是convex function(凸函数) bow - shape “Batch”:Each step of gradient descent uses all the training examples 多变量线性回归 其中X_0 为 1，这是为了适应计算机索引（从0开始）并不破坏原有顺序而添加的。 代价函数J对θ求偏导，其中x,y均为常量，h(x)是与θ有关的线性函数 多元梯度下降特征缩放是为了加快梯度下降速度，减少收敛所需次数。 不需要特别精确，只需使得特征在一相似范围内，一般约束到[-1,1]左右(接近)，区间范围不宜过大或过小 ​ Xi := Xi/range 均值归一化使得特征值具有为0的平均值，计算公式如下： 调试debug : making sure gradient descent is working correctly. （a）画出J(θ)与迭代次数的关系曲线图，直观得出结果 （b）自动判断if J(θ) &lt; ε 则收敛 若 J(θ)随迭代次数而上升，则降低学习率α，但α太小，则梯度下降缓慢。 每3（10）倍取一个α值，选择合适的learning rate —- α 特征与多项式回归特征的选择是自由的~ 取决于从什么角度来看问题，最终更拟合数据，建立更好的模型。 直线可能不太合适时，考虑多项式（注意特征缩放）。 正规方程直接求解θ，与梯度下降不同。不需要特征缩放 （a）令偏导数为0，求解θ1、2、3…的值，计算可能复杂 （b）看成向量，公式求解 对于特征量小于10000的线性回归模型，正规方程比梯度下降优 正规方程在矩阵不可逆的情况下的solution矩阵不可逆？？？ Octave中 ocpinv() inv() 两种方式优缺点对比]]></content>
      <categories>
        <category>machine learning</category>
      </categories>
      <tags>
        <tag>study notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量拷贝文件名]]></title>
    <url>%2Farticle%2F22ee1c26%2F</url>
    <content type="text"><![CDATA[操作新建 txt 文件 写入如下命令： 12345dir （目标文件夹）/b &gt; （生成的.txt/.docx/.excel输出路径）如：dir E:\program\opencv\msvc410\install\x64\vc15\lib\*.lib /b &gt; E:\program\opencv\msvc410\install\x64\vc15\lib\libname.txt将 E:\program\opencv\msvc410\install\x64\vc15\lib 文件夹下 所有.lib的文件名 打印到 同一目录下的libname.txt中 保存，将该txt文件后缀改为.bat ，运行，完成~]]></content>
      <categories>
        <category>window</category>
      </categories>
      <tags>
        <tag>skill</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重编译openCV源码（4.1.0）with CUDA]]></title>
    <url>%2Farticle%2F3833e1c9%2F</url>
    <content type="text"><![CDATA[起因在利用openCV的GPU模块中 发现CUDA系列头文件找不到了openCV2 cudaXXXX.hpp file not found.md回想之前编译openCV源代码的时候，好像忘勾选CUDA了 解决方案重编译openCV。。。 相关环境openCV and contribute 4.1.0 -》后面尝试过 4.0.1-》还是确定为 4.1.0 cuda 10.1 cmake 3.14.3(默认安装并已添加环境变量) vs 2017(默认安装） TBB 4.4（可选） 题外话CUDA SDK不支持mingw编译，因此选用的是VS编译器 先备注起来，以后可能会用到 这是mingw编译器的操作 打开命令行 cd 到你编译后的文件夹中 其中-j8是指用8个线程进行编译，你可以根据自己的计算机选择线程数量cd E:\program\opencv\CUDA_Buildmingw32-make -j8 我大概编译了15分钟mingw32-make install 编译前准备工作1.安装CUDA toolkit安装之前电脑需装配VS2017社区版，并且关闭其应用。更重要的一点：关闭360等软件。。不然会导致安装失败。https://developer.nvidia.com/cuda-toolkit-archive选择对应版本 （本文 10.1）一路默认就OK了（可以自定义下安装目录） CUDA_BIN_PATH %CUDA_PATH%\bin CUDA_LIB_PATH %CUDA_PATH%\lib\x64 CUDA_SDK_BIN_PATH %CUDA_SDK_PATH%\bin\win64 CUDA_SDK_LIB_PATH %CUDA_SDK_PATH%\common\lib\x64 然后，在系统变量 PATH 添加： %CUDA_LIB_PATH%;%CUDA_BIN_PATH%;%CUDA_SDK_LIB_PATH%;%CUDA_SDK_BIN_PATH% 重启生效 检测是否安装成功 （以自带示例来测试） 命令行 cd C:\Program Files\NVIDIA GPU ComputingToolkit\CUDA\v10.1\extras\demo_suite 分别运行deviceQuery、bandwidthTest 如果两次都出现result pass，则成功啦~~~ 2.安装TBB（VS2015可安装，2017需要VC14才行）（Thread BuildingBlocks,线程构建模块，是Intel公司开发的并行编程开发的工具）https://github.com/01org/tbb/releases 选择对应系统 （本文 Win TBB 4.4）然后设置环境变量：在系统-&gt; 高级系统设置-&gt;环境变量-&gt;path 后边加入下边地址：..(tbb安装目录)\tbb44_20160413oss\bin\intel64\vc14 3.检查V2017的vc版本因为我安装的是最新版V2107，在最后用VS生成库文件的时候，出现了许多bug，具体可看最后的“遇到的问题” 查看vc工具集版本 打开 C:\Program Files (x86)\Microsoft Visual Studio\2017 \Community\VC\Tools\MSVC (默认安装目录） 我安装目录是：E:\program\VisualStudio\VC\Tools\MSVC 如果vc版本大于14.11，请更换VC版本 具体操作查看文章 “遇到的问题”-》“VS生成过程中的问题”-》“2” 4.下载openCV4.1.0以及contribute源码解压,最好放到同一目录下，注意路径中不含中文 https://github.com/opencv/opencv/releaseshttps://github.com/opencv/opencv_contrib/releases/ 其中build 是自己建立的 cmake重编译 点击右侧“Browse Source”按钮输入OpenCV源码所在路径 点击右侧“Browse Build”输入生成的OpenCV工程存放目录 点击左下角Configure按钮，配置编译器 cmake 新版本（3.14.3） cmake 老版本（3.9.0） 再一次点击Configure 注意输出栏会出现“CUDA detected 10.1” 修改红底色配置项 勾选 WITH_CUDA WITH_QT WITH_OPENGL OPENCV_ENABLE_NONFREE WITH_OPENCL_SVM WITH_TBB (VS2015可选) BUILD_EXAMPLES(可选，创建openCV实例) BUILD_opencv_world(可选，所有库变成一个) 不要勾选 Build_CUDA_STUBS ENABLE_PRECOMPILED_HEADERS 同时需要修改…(你源码解压路径)\opencv-4.1.0\modules\videoio\src下文件“cap_Dshow.cpp”，修改是在“#include “cap_dshow.hpp”（在第45行）前加宏定义“#define NO_DSHOW_STRSAFE”，如下图所示： 配置opencv_contrib的文件路径…(你源码解压路径)\opencv_contrib-4.0.1\modules 再一次点击Configure 配置Qt/TBB的路径QT配置如下： 如QT5Test_DIR E:/program/Qt5.11.2/5.10.0/msvc2017_64/lib/cmake/Qt5Concurrent TBB配置如下： 如：TBB_ENV_INCLUDE E:/program/tbb/tbb2019_20190320oss/include 再一次点击Configure。 配置CUDA架构版本网上查询显卡对应架构版本，==CUDA_GENERATION== 选择对应架构版本 再一次点击Configure，直至没有红底色栏出现。 再检查一下之前的勾选项，点generate生成MakeFile文件 点Open project打开项目文件 VS后续操作1.权限 以==管理员的身份==打开项目（你自定义的文件里），因为编译过程可能会出现需要系统授权才能访问的文件 2.测试 Cmake完成之后，==不要全部编译==。先选择==opencv_cudaarithm,opencv_cudabgsegm==这两个项目编译，因为这两个项目编译起来非常慢而且最容易出问题。在项目上 右键-&gt;生成，当这些文件都没有问题时，正式生成所有库文件。 3.正式开始生成 打开项目后， 点击“生成”-》“批生成”-》勾选install的“debug”和”release”，同时生成两个版本~ 时间较长。 如果全部编译完毕之后，如果有一两个项目没有编译成功，没必要再全部重新编译。只需要在VS侧边栏的“解决方案资源管理器”找到对应的项目重新生成就行了（各种库生成失败，可以看看文章后面“==vs生成过程中的问题==”）。 openCV环境配置以及测试生成成功后，将 E:\program\opencv\msvc410\install\x64\vc15\bin 添加入 path VS的网上有 ：https://blog.csdn.net/qq_41175905/article/details/80560429 QT mvsc版如下： 环境变量 path 添加：E:\program\opencv\msvc410\install\x64\vc15\bin （里面是dll动态链接库） 新建QT项目，套件为 mvsc 2017 64bit （因为openCV4.1.0只能用64位的） .pro文件内添加open’CV环境 1234#openCVLIBS += E:/program/opencv/msvc410/install/x64/vc15/lib/*.libINCLUDEPATH += E:/program/opencv/msvc410/install/include/ \ E:/program/opencv/msvc410/install/include/opencv2/ main.cpp 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include "mainwindow.h"#include &lt;QApplication&gt;#include &lt;opencv2/opencv.hpp&gt;#include &lt;opencv2/core/version.hpp&gt;#include "opencv2/core/cuda.hpp"#include "opencv2/imgproc.hpp"#include "opencv2/highgui.hpp"#include "opencv2/calib3d.hpp"#include "opencv2/video.hpp"#include "opencv2/cudalegacy.hpp"#include "opencv2/cudaimgproc.hpp"#include "opencv2/cudaarithm.hpp"#include "opencv2/cudawarping.hpp"#include "opencv2/cudafeatures2d.hpp"#include "opencv2/cudafilters.hpp"#include "opencv2/cudaoptflow.hpp"#include "opencv2/cudabgsegm.hpp"using namespace cv;using namespace std;int main(int argc, char *argv[])&#123; QApplication a(argc, argv); MainWindow w; //w.show();// Mat dst = imread("更换你的图片路径");// imshow("show",dst); namespace GPU = cv::cuda; // 首先要检查是否CUDA模块是否可用 if(GPU::getCudaEnabledDeviceCount()==0)&#123; cerr&lt;&lt;"此OpenCV编译的时候没有启用CUDA模块"&lt;&lt;endl; return -1; &#125;else&#123; cout&lt;&lt;"GPU enable :"&lt;&lt;GPU::getCudaEnabledDeviceCount()&lt;&lt;endl; &#125; const int rows = 16*50; const int cols = 16*60; const int type = CV_8UC3; // 初始化一个黑色的GpuMat GPU::GpuMat gpuMat(rows,cols,type,Scalar(0,0,0)); // 定义一个空Mat Mat dst; // 把gpuMat中数据下载到dst(从显存下载到内存) gpuMat.download(dst); // 显示 imshow("show1",dst); waitKey(1000); // 读取一张图片 Mat arr = imread("更换你的图片路径"); imshow("show2",arr); waitKey(1000); // 上传到gpuMat(若gpuMat不为空，会先释放原来的数据，再把新的数据上传上去) gpuMat.upload(arr); // 定义另外一个空的GpuMat GPU::GpuMat gray; // 把gpuMat转换为灰度图gray GPU::cvtColor(gpuMat,gray,0); // 下载到dst，如果dst不为空，旧数据会被覆盖 gray.download(dst); // 显示 imshow("show3",dst); waitKey(0); return a.exec();&#125; 遇到的问题1.CUDA版本与显卡驱动不适配运行示例时出现的错误提示 123cudaGetDeviceProperties returned 35-&gt; CUDA driver version is insufficient for CUDA runtime versionCUDA error at C:/dvs/p4/build/sw/rel/gpgpu/toolkit/r10.1/demo_suite/bandwidthTest/![img](file:///C:\Users\Pabebe\AppData\Local\Temp\%W@GJ$ACOF(TYDYECOKVDYB.png)bandwidthTest.cu:255 code=35(cudaErrorInsufficientDriver) "cudaSetDevice(currentDevice)" https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html从该网站可以得到对应版本要求，进行更换或升级显卡驱动 2.编译openCV-cuda模块出现如下问题CMake Error: The following variables are used in this project, but they are set to NOTFOUND.Please set them or make sure they are set and tested correctly in the CMake files:CUDA_cublas_LIBRARY (ADVANCED) CUDA_npps_LIBRARY (ADVANCED) 1我看了github上的解决方案， 就是编译器选择 vs 15 2017 win64 (cmake的版本为3.9.0，最新版没有该选项),就不会出现CUDA_cublas_LIBRARY (ADVANCED)CUDA_npps_LIBRARY (ADVANCED)了。 但是会出现CUDA_nppi_LIBRARY (ADVANCED)，这个网上有修改的方案。大佬说是CUDA9.0版本不支持2.0架构，我觉得CUDA10.1估计也是。 首先找到 FindCUDA.cmake 参考文章： https://blog.csdn.net/u014613745/article/details/78310916 （1）跟着上面大佬的步骤改就是了。 （2）最后一步添加头文件的文件路径变了 E:\program\openCV4.1.0\opencv-4.1.0\modules\core\include\opencv2\core\cuda ..(解压的地址)\opencv_contrib-4.1.0\modules\cudev \include\opencv2\cudev\common.hpp （3）文件OpenCVDetectCUDA.cmake中 set(_generations “Fermi” “kepler” “Maxwell” “Pascal”)中”Fermi”去掉 3.VS2017与VS2015的区别 重点是使用CMAKE编译时CUDA_HOST_COMPILER项的选择，正常更改的路径如下： C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC\Tools\MSVC\14.16.27023\bin\Hostx64\x64\cl.exe 当时安装VS2017时，没有把所有的东西都安装在C盘，所以我的路径是 E:/program/VisualStudio/VC/Tools/MSVC/14.16.27023/bin/Hostx64/x64/cl.exe 参考文章： https://blog.csdn.net/baidu_33310451/article/details/89456480 若还是出现该问题，更换openCV版本 -》 4.0.1（我就是..） 4.VS生成过程中的问题1.生成cuda_imgcodec.lib时 （1）error : dynamic initialization is not supported for a constant variable 解决方案：https://answers.opencv.org/question/205673/building-opencv-with-cuda-win10-vs-2017/ 对E:\program\openCV4.0.1\opencv-4.0.1（openCV源码路径）\modules\core\include\opencv2\core\cuda\detail\color_detail.hpp 文件中96-127行“const” 修改为“constexpr” （2）E0282 全局范围没有 “max”/“min” opencv_core E:\program\openCV4.0.1\opencv-4.0.1\modules\core\include\opencv2\core\cuda\detail\color_detail.hpp 1614 解决方案：双击该错误，跳转至错误行，在::前添加std ​ int ix = std::min(std::max(int(x), 0), n-1); 2.生成cuda_arithm.lib时 (1)template instantiation resulted in unexpected function type of “std::true_type (std::integral_constant&lt;__nv_bool, false&gt; )” (the meaning of a name may have changed since the template declaration – the type of the template is “std::true_type (std::is_same&lt;std::decay&lt;decltype(())&gt;::type, void&gt;::type )”) opencv_cudaarithm e:\program\opencv4.0.1\opencv-4.0.1\modules\core\include\opencv2\core\cvstd_wrapper.hpp 49 (2)name followed by “::” must be a class or namespace name opencv_cudaarithm e:\program\opencv4.0.1\opencv-4.0.1\modules\core\include\opencv2\core\cvstd_wrapper.hpp 52 (3)incomplete type is not allowed opencv_cudaarithm e:\program\opencv4.0.1\opencv-4.0.1\modules\core\include\opencv2\core\cvstd_wrapper.hpp 45 总算找到了解决方案：VS2017的VC编译器版本过高 （1）首先下载V14.11的工具集 启动VS intall ，点击对应2017版本“更多”下的“修改” ，选择“单个工具‘，安装V14.11的工具集。 （2）根据官网https://cmake.org/cmake/help/latest/variable/CMAKE_GENERATOR_TOOLSET.html#variable:CMAKE_GENERATOR_TOOLSET cmake-gui的生成器参数设置方法，设置VS的VCv14.11的工具集 参考文章： https://blog.csdn.net/hybtalented/article/details/80434075?tdsourcetag=s_pctim_aiomsg https://blog.csdn.net/ewqapple/article/details/81974210 12按他们所说的修改方式，我在cmake-gui中配置的时候出错了。下面还是按照我的做吧。 ——下面是按参考文章的做法—- 更改默认Visual Studio 2017 VC 工具链 打开 C:\Program Files (x86)\Microsoft Visual Studio\2017 \Community\VC\Auxiliary\Build（默认安装目录） 而我的在 E:\program\VisualStudio\VC\Auxiliary\Build 修改Microsoft.VCToolsVersion.default.props 、Microsoft.VCRedistVersion.default.txt、Microsoft.VCToolsVersion.default.txt的读写权限 右键 属性-&gt;安全 其中Microsoft.VCToolsVersion.default.props修改了也没用，那我们直接以管理员的身份运行该文件 桌面菜单栏右键”任务管理器”-》文件-》运行新任务 将以上三个文件内VS默认编译工具链修改为 14.11.25503 （一般后缀名为.props 的文件是VC工具集的配置文件） 备注一下： VS原始默认工具集版本 VCToolsVersion 14.16.27023 VCToolsRedistVersion 14.16.27012 现在默认 VCToolsVersion 14.11.25503 VCToolsRedistVersion 14.11.25325 E:\program\VisualStudio\VC\Auxiliary\Build\ 生成opencv_cvv.lib 在stringutils.cpp 出现“常量中有换行符” 等错误 解决方案：用==记事本==打开“stringutils.cpp” ，另存为 “UTF-8”格式覆盖原来的文件，再重新生成“opencv_cvv” 参考文献：http://www.cnblogs.com/cocos2d-x/archive/2012/02/26/2368873.html#commentform 5.QT使用cuda版open’CV出现的错误:error: C1083: 无法打开包括文件: “cuda_runtime.h”: No such file or directory E:\program\opencv\msvc410\install\include\opencv2\core\cuda\common.hpp:46 双击错误信息，引入cuda_runtime.h所在的绝对路径]]></content>
      <categories>
        <category>openCV</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub更新项目步骤及常见问题]]></title>
    <url>%2Farticle%2Fd0a29510%2F</url>
    <content type="text"><![CDATA[gitHub上更新项目该文以本人博客网站文章上传为例，同时记录问题 配置SSH key为获取GitHub权限，但直接提交账号密码不安全，因此 利用公私钥来解决这一问题。博客目录下右键 Git GUI Here 创建新的本地仓库为你的项目所在地，本文为博客根目录点 Help-&gt;show SSH Key-&gt;Generate Key（有的话就不需要了）拷贝SSH key的内容，添加到GitHub中。GitHub网站上头像-&gt;setting-&gt;SSH and GPG keys-&gt;new SSH key -&gt;title里面可以写点提示性话语，把之前的Key粘贴过来-&gt;Add SSH Key验证：博客目录下右键 Git Bash Here ssh -T git@github.com出现“Hi Pabebezz! You’ve successfully authenticated, but GitHub does not provide shell access.” 则成功 修改站点配置文件(_根目录下的config.yml)deploy: type: git repo: git@github.com:username.github.io.git #自己gitHub项目地址 branch: master 将Hexo与GitHub pages联系起来（1）设置本地Git的user name 和 email 博客目录下右键 Git Bash Here git config –global user.name “Pabebezz” git config –global user.email “zezuwang@qq.com“ 新建GitHub远程仓库仓库是否存在初始化文件（1）不存在 此时,仓库为空 博客目录下右键 Git Bash Here 1hexo g 1hexo d //远程发布到gitHub上 1hexo s //本地查看 localhost:4000 （2）存在 看“问题栏” gitHub使用过程中遇到的问题简单测试$ hexo dERROR Deployer not found: git解决：$ npm install hexo-deployer-git –save 修改next主题相关颜色E:\program\Blog\themes\next\source\css_variables\base.styl YAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at linhexo clean g d后出现错误 解决办法：检测文章开头的一系列格式，“源代码模式” 有空格，三条下划线不能少]]></content>
      <categories>
        <category>gitHub</category>
      </categories>
      <tags>
        <tag>tutorial</tag>
      </tags>
  </entry>
</search>
